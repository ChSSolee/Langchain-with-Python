{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f96cf92d",
   "metadata": {},
   "source": [
    "# 15. 평가\n",
    "- LLM(Large Language Model) 평가는 인공지능 언어 모델의 성능, 정확성, 일관성 및 기타 중요한 측면을 측정하고 분석하는 과정\n",
    "- 이는 모델의 개선, 비교, 선택 및 응용 프로그램에 적합한 모델 결정에 필수적인 단계\n",
    "\n",
    "<br>\n",
    "\n",
    "#### 평가 방법\n",
    "1. 자동화된 메트릭: BLEU, ROUGE, METEOR, SemScore 등의 지표를 사용\n",
    "2. **인간 평가**: 전문가나 크라우드소싱을 통한 직접적인 평가를 수행\n",
    "3. **작업 기반 평가**: 특정 작업에서의 성능을 측정\n",
    "4. **LLM-as-judge**: 다른 LLM을 평가자로 사용하는 방법\n",
    "\n",
    "<br>\n",
    "\n",
    "#### LangChain에서의 Evaluation\n",
    "1. **모듈화된 평가 컴포넌트**: 다양한 평가 방법을 쉽게 구현하고 조합\n",
    "2. **Chain 평가**: 전체 LLM 애플리케이션 파이프라인을 평가\n",
    "3. **데이터셋 기반 평가**: 사용자 정의 데이터셋을 사용하여 모델을 평가\n",
    "4. **평가 지표**: 정확성, 일관성, 관련성 등 다양한 지표를 제공\n",
    "\n",
    "<br>\n",
    "\n",
    "### LLM-as-judge\n",
    "- LLM-as-judge는 다른 LLM의 출력을 평가하기 위해 LLM을 사용\n",
    "\n",
    "<br>\n",
    "\n",
    "1. **자동화**: 인간의 개입 없이 대규모 평가를 수행\n",
    "2. **일관성**: 평가 기준을 일관되게 적용\n",
    "3. **유연성**: 다양한 평가 기준과 상황에 적응\n",
    "4. **비용 효율성**: 인간 평가자에 비해 비용이 적게 들 수 있음\n",
    "\n",
    "<br>\n",
    "\n",
    "#### LLM-as-judge의 작동 방식\n",
    "1. **입력 제공**: 평가할 LLM의 출력과 평가 기준을 제공\n",
    "2. **분석**: 평가자 LLM이 제공된 출력을 분석\n",
    "3. **평가**: 정의된 기준에 따라 점수나 피드백을 생성\n",
    "4. **결과 집계**: 여러 평가 결과를 종합하여 최종 평가를 도출\n",
    "\n",
    "<br>\n",
    "\n",
    "#### 평가의 중요성\n",
    "1. **모델 개선**: 약점을 식별하고 개선 방향을 제시\n",
    "2. **신뢰성 확보**: 모델의 성능과 한계를 이해하는 데 도움\n",
    "3. **적합한 모델 선택**: 특정 작업이나 도메인에 가장 적합한 모델을 선택\n",
    "4. **윤리적 고려사항**: 편향, 공정성 등의 윤리적 측면을 평가\n",
    "\n",
    "<br>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c4884e",
   "metadata": {},
   "source": [
    "## 15-01. 합성 테스트 데이터셋 생성 (RAGAS)\n",
    "- RAG(검색 증강 생성) 증강 파이프라인의 성능을 평가하는 것은 매우 중요\n",
    "- **그러나 문서에서 수백 개의 QA(질문-문맥-응답) 샘플을 수동으로 생성하는 것은 시간과 노동력이 많이 소요되며,**\n",
    "  \n",
    "  **또한 사람이 만든 질문은 철저한 평가에 필요한 복잡성 수준에 도달하기 어려워 궁극적으로 평가의 품질에 영향을 미칠 수 있음**\n",
    "\n",
    "  $\\rightarrow$ **합성 데이터 생성을 사용하면 데이터 집계 프로세스에서 개발자의 시간을 감소**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cdf2f24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY 정보로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4140253",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 문서 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "659d343f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PDFPlumberLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d51e465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52b3dea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = PDFPlumberLoader(\"data/SPRI_AI_Brief_2023년12월호_F.pdf\")\n",
    "\n",
    "docs = loader.load()\n",
    "docs = docs[3:-1]\n",
    "\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1816c194",
   "metadata": {},
   "source": [
    "- 각 문서 객체에는 `metadata` 를 통해 액세스할 수 있는 문서에 대한 추가 정보를 저장하는 데 사용할 수 있는 메타데이터 사전이 포함되어 있으며,\n",
    "  \n",
    "  **메타데이터의 `filename` 속성이 필요**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "550252dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 3, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4'}\n",
      "{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 4, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4'}\n",
      "{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 5, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4'}\n",
      "{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 6, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4'}\n",
      "{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 7, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4'}\n"
     ]
    }
   ],
   "source": [
    "for doc in docs[:5]:\n",
    "    print(doc.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a15077c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in docs:\n",
    "    doc.metadata[\"filename\"] = doc.metadata[\"source\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c80278",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 데이터셋 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8131600c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -qU ragas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bbd9586",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\langai_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\user\\anaconda3\\envs\\langai_env\\Lib\\site-packages\\instructor\\providers\\gemini\\client.py:5: FutureWarning: \n",
      "\n",
      "All support for the `google.generativeai` package has ended. It will no longer be receiving \n",
      "updates or bug fixes. Please switch to the `google.genai` package as soon as possible.\n",
      "See README for more details:\n",
      "\n",
      "https://github.com/google-gemini/deprecated-generative-ai-python/blob/main/README.md\n",
      "\n",
      "  import google.generativeai as genai  # type: ignore[import-not-found]\n"
     ]
    }
   ],
   "source": [
    "from ragas.testset import TestsetGenerator\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from ragas.testset.graph import KnowledgeGraph\n",
    "from ragas.testset.persona import Persona\n",
    "\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_classic.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033b3e17",
   "metadata": {},
   "source": [
    "#### Ragas 최신 버전의 내부 작동 프로세스\n",
    "1. **문서 임베딩 및 관계 추출 (Graph Construction)**\n",
    "- 입력된 모든 docs를 분석하여 핵심 개체(Entity)와 개념을 추출\n",
    "- 문서 A와 문서 B가 연결되는 지점(예: 동일한 인물, 연속된 사건)을 찾아 선으로 연결 $\\rightarrow$ Knowledge Graph\n",
    "\n",
    "<br>\n",
    "\n",
    "2. **페르소나 생성 (Persona Generation)**\n",
    "- 이 데이터를 실제로 사용할 '가상의 사용자'들을 생성 (예: \"이 문서를 처음 보는 초보자\", \"기술적인 질문을 던지는 전문가\" 등)\n",
    "- 이 페르소나들이 각자의 관점에서 질문을 던지게 하여 문제의 다양성을 확보\n",
    "\n",
    "<br>\n",
    "\n",
    "3. **진화적 질문 생성 (Evolution)**\n",
    "- Simple: 그래프의 한 노드(정보)에서 바로 질문을 생성\n",
    "- Reasoning: 노드 여러 개를 거쳐야 답이 나오는 논리적인 질문을 생성\n",
    "- Multi-context: 서로 다른 문서 조각들에 흩어진 정보를 조합해야 풀 수 있는 고난도 문제를 생성\n",
    "\n",
    "<br>\n",
    "\n",
    "4. **검증 및 필터링 (Critic)**\n",
    "- 만들어진 질문이 너무 쉽지는 않은지, 정답(`ground_truth`)이 문서 내에 확실히 존재하는지 비평기(Critic) LLM이 검수\n",
    "\n",
    "<br>\n",
    "\n",
    "1. 질문을 만들어낼 **'지능(LLM)'** 과 문서를 읽어낼 **'눈(Embedding)'** 을 결정\n",
    "- `LangchainLLMWrapper` / `Wrapper`: Ragas는 전용 도구\n",
    " - Ragas가 이해할 수 있게 Langchain 객체에 **'어댑터(Wrapper)'**를 끼워주는 작업\n",
    "- `TestsetGenerator`: `gpt-4o-mini`라는 지능과 `text-embedding-3-small`이라는 시력을 가진 **문제 출제 위원회(Generator)**를 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4aff0167",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_60740\\2902844630.py:1: DeprecationWarning: LangchainLLMWrapper is deprecated and will be removed in a future version. Use llm_factory instead: from openai import OpenAI; from ragas.llms import llm_factory; llm = llm_factory('gpt-4o-mini', client=OpenAI(api_key='...'))\n",
      "  generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o-mini\"))\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_60740\\2902844630.py:2: DeprecationWarning: LangchainEmbeddingsWrapper is deprecated and will be removed in a future version. Use the modern embedding providers instead: embedding_factory('openai', model='text-embedding-3-small', client=openai_client) or from ragas.embeddings import OpenAIEmbeddings, GoogleEmbeddings, HuggingFaceEmbeddings\n",
      "  generator_embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings(model=\"text-embedding-3-small\"))\n"
     ]
    }
   ],
   "source": [
    "generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o-mini\"))\n",
    "generator_embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings(model=\"text-embedding-3-small\"))\n",
    "\n",
    "generator = TestsetGenerator(\n",
    "    llm=generator_llm,\n",
    "    embedding_model=generator_embeddings,\n",
    "    # language=\"korean\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6edce7",
   "metadata": {},
   "source": [
    "2. 테스트 셋 생성\n",
    "- **눈(Embedding)** 으로 문서들 사이의 관계를 파악해 **지식 지도(Knowledge Graph)** 를 도출\n",
    "- **지능(LLM)** 으로 \"이 내용으로 어떻게 하면 어려운 문제를 낼까?\" 고민하며 질문($Q$), 답변($A$), 그리고 근거 문장($Context$)을 쌍으로 생성\n",
    "\n",
    "<br>\n",
    "\n",
    "- 네트워크나 그래프 이론에서 Hop은 한 지점에서 다른 지점으로 이동할 때 거치는 '다리(Edge)'의 개수\n",
    "- 1-Hop (Single-Hop): 질문에 대한 답이 하나의 노드(정보 덩어리) 안에 바로 있는 경우\n",
    "  - 예) \"A사의 24년 매출은?\" $\\rightarrow$ [A사 매출 노드]에서 즉시 확인 가능.\n",
    "- 2-Hop 이상 (Multi-Hop): 여러 노드를 건너가며 정보를 조합해야 답이 나오는 경우\n",
    "  - 예) \"A사 매출에 가장 큰 기여를 한 제품의 개발팀장은 누구인가?\"[A사 매출] 노드에서 [제품 명칭] 확인 (1-Hop)[제품 명칭] 노드에서 [담당 팀장] 확인 (2-Hop)\n",
    "\n",
    "<br>\n",
    "\n",
    "| 구분 | Hop 수 | 정보의 형태 | 난이도 | 주요 평가 지표 | \n",
    "| - | - | - | - | - |\n",
    "| SingleHopSpecific| 1개 | 구체적 (Specific) | 하 | 정밀도 (Precision)|\n",
    "| MultiHopSpecific | 2개 이상 | 구체적 (Specific)| 중 | 컨텍스트 재구성 (Context Relevancy)|\n",
    "| MultiHopAbstract | 2개 이상 | 추상적 (Abstract) | 상 | 답변 충실도 (Answer Faithfulness)|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b579d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset import TestsetGenerator\n",
    "from ragas.testset.synthesizers import (\n",
    "    SingleHopSpecificQuerySynthesizer,\n",
    "    MultiHopSpecificQuerySynthesizer,\n",
    "    MultiHopAbstractQuerySynthesizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b45fe491",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_distribution = [\n",
    "    (SingleHopSpecificQuerySynthesizer(llm=generator_llm), 0.5),\n",
    "    (MultiHopSpecificQuerySynthesizer(llm=generator_llm), 0.25),\n",
    "    (MultiHopAbstractQuerySynthesizer(llm=generator_llm), 0.25),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031ac6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying HeadlinesExtractor: 100%|██████████| 19/19 [00:15<00:00,  1.19it/s]\n",
      "Applying HeadlineSplitter: 100%|██████████| 19/19 [00:00<00:00, 1049.76it/s]\n",
      "Applying SummaryExtractor: 100%|██████████| 19/19 [00:15<00:00,  1.21it/s]\n",
      "Applying CustomNodeFilter: 100%|██████████| 49/49 [00:34<00:00,  1.41it/s]\n",
      "Applying EmbeddingExtractor: 100%|██████████| 19/19 [00:07<00:00,  2.71it/s]\n",
      "Applying ThemesExtractor: 100%|██████████| 44/44 [00:35<00:00,  1.24it/s]\n",
      "Applying NERExtractor: 100%|██████████| 44/44 [00:32<00:00,  1.34it/s]\n",
      "Applying CosineSimilarityBuilder: 100%|██████████| 1/1 [00:00<00:00, 500.04it/s]\n",
      "Applying OverlapScoreBuilder: 100%|██████████| 1/1 [00:00<00:00, 39.18it/s]\n",
      "Generating personas: 100%|██████████| 3/3 [00:03<00:00,  1.01s/it]\n",
      "Generating Scenarios: 100%|██████████| 3/3 [00:12<00:00,  4.24s/it]\n",
      "Generating Samples: 100%|██████████| 11/11 [00:09<00:00,  1.20it/s]\n"
     ]
    }
   ],
   "source": [
    "testset = generator.generate_with_langchain_docs(\n",
    "    documents=docs,\n",
    "    testset_size=10,\n",
    "    query_distribution=query_distribution,\n",
    "    language=\"korean\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb6ea409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference</th>\n",
       "      <th>persona_name</th>\n",
       "      <th>query_style</th>\n",
       "      <th>query_length</th>\n",
       "      <th>synthesizer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What actions has President Biden taken regardi...</td>\n",
       "      <td>[1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n 미국, 안전하...</td>\n",
       "      <td>President Biden has signed an executive order ...</td>\n",
       "      <td>AI Safety Advocate</td>\n",
       "      <td>WEB_SEARCH_LIKE</td>\n",
       "      <td>LONG</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How does the recent AI executive order address...</td>\n",
       "      <td>[형평성과 시민권 향상 △소비자\\n보호 △노동자 지원 △혁신과 경쟁 촉진 △국제협력...</td>\n",
       "      <td>The recent AI executive order includes measure...</td>\n",
       "      <td>Policy Analyst in Technology Ethics</td>\n",
       "      <td>WEB_SEARCH_LIKE</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What measures are included in the AI executive...</td>\n",
       "      <td>[혁신과 경쟁 촉진 △국제협력을 골자로 함 £바이든 대통령, AI 행정명령 통해 안...</td>\n",
       "      <td>The AI executive order announced by President ...</td>\n",
       "      <td>Policy Analyst in Technology Ethics</td>\n",
       "      <td>PERFECT_GRAMMAR</td>\n",
       "      <td>SHORT</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the focus of E.O. 14110 regarding AI t...</td>\n",
       "      <td>[분야의 전문 지식을 갖춘 외국인들이 미국에서 공부하고 취업할 수 있도록 지원 ☞ ...</td>\n",
       "      <td>E.O. 14110 is focused on the safe, secure, and...</td>\n",
       "      <td>Policy Analyst in Technology Ethics</td>\n",
       "      <td>WEB_SEARCH_LIKE</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What role did Japan play in the G7's establish...</td>\n",
       "      <td>[G7, 첨단 AI 시스템의 위험 관리를 위한 국제 행동강령 마련 n 주요 7개국(...</td>\n",
       "      <td>Japan was one of the major seven countries (G7...</td>\n",
       "      <td>Policy Analyst in Technology Ethics</td>\n",
       "      <td>WEB_SEARCH_LIKE</td>\n",
       "      <td>LONG</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What are the implications of Samsung's on-devi...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nKEY Contents n 삼성전자가 온디바이스에서 작동 가능...</td>\n",
       "      <td>The introduction of Samsung's on-device AI mod...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What significant developments in AI technology...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nKEY Contents n 삼성전자가 온디바이스에서 작동 가능...</td>\n",
       "      <td>On November 8, 2023, during the 'Samsung AI Fo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What are the implications of the launch of the...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n데이터 출처 탐색기, 광범위한 데이터셋 정보 제공을 통해 데이...</td>\n",
       "      <td>The launch of the Data Provenance Explorer pla...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>영국 과학혁신기술부가 설립한 AI 안전 연구소의 목표는 무엇이며, AI 안전성 정상...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교...</td>\n",
       "      <td>영국 과학혁신기술부가 설립한 AI 안전 연구소의 목표는 첨단 AI의 위험을 이해하고...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What initiatives are being taken by the UK gov...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교...</td>\n",
       "      <td>The UK government is establishing the AI Safet...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>영국 AI 안전 연구소는 어떻게 국제 협력을 통해 AI 안전성을 보장하려고 하나?</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교...</td>\n",
       "      <td>영국 AI 안전 연구소는 AI 안전성 정상회의에 참가한 28개국과 협력하여 AI 시...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           user_input  \\\n",
       "0   What actions has President Biden taken regardi...   \n",
       "1   How does the recent AI executive order address...   \n",
       "2   What measures are included in the AI executive...   \n",
       "3   What is the focus of E.O. 14110 regarding AI t...   \n",
       "4   What role did Japan play in the G7's establish...   \n",
       "5   What are the implications of Samsung's on-devi...   \n",
       "6   What significant developments in AI technology...   \n",
       "7   What are the implications of the launch of the...   \n",
       "8   영국 과학혁신기술부가 설립한 AI 안전 연구소의 목표는 무엇이며, AI 안전성 정상...   \n",
       "9   What initiatives are being taken by the UK gov...   \n",
       "10      영국 AI 안전 연구소는 어떻게 국제 협력을 통해 AI 안전성을 보장하려고 하나?   \n",
       "\n",
       "                                   reference_contexts  \\\n",
       "0   [1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n 미국, 안전하...   \n",
       "1   [형평성과 시민권 향상 △소비자\\n보호 △노동자 지원 △혁신과 경쟁 촉진 △국제협력...   \n",
       "2   [혁신과 경쟁 촉진 △국제협력을 골자로 함 £바이든 대통령, AI 행정명령 통해 안...   \n",
       "3   [분야의 전문 지식을 갖춘 외국인들이 미국에서 공부하고 취업할 수 있도록 지원 ☞ ...   \n",
       "4   [G7, 첨단 AI 시스템의 위험 관리를 위한 국제 행동강령 마련 n 주요 7개국(...   \n",
       "5   [<1-hop>\\n\\nKEY Contents n 삼성전자가 온디바이스에서 작동 가능...   \n",
       "6   [<1-hop>\\n\\nKEY Contents n 삼성전자가 온디바이스에서 작동 가능...   \n",
       "7   [<1-hop>\\n\\n데이터 출처 탐색기, 광범위한 데이터셋 정보 제공을 통해 데이...   \n",
       "8   [<1-hop>\\n\\n1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교...   \n",
       "9   [<1-hop>\\n\\n1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교...   \n",
       "10  [<1-hop>\\n\\n1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교...   \n",
       "\n",
       "                                            reference  \\\n",
       "0   President Biden has signed an executive order ...   \n",
       "1   The recent AI executive order includes measure...   \n",
       "2   The AI executive order announced by President ...   \n",
       "3   E.O. 14110 is focused on the safe, secure, and...   \n",
       "4   Japan was one of the major seven countries (G7...   \n",
       "5   The introduction of Samsung's on-device AI mod...   \n",
       "6   On November 8, 2023, during the 'Samsung AI Fo...   \n",
       "7   The launch of the Data Provenance Explorer pla...   \n",
       "8   영국 과학혁신기술부가 설립한 AI 안전 연구소의 목표는 첨단 AI의 위험을 이해하고...   \n",
       "9   The UK government is establishing the AI Safet...   \n",
       "10  영국 AI 안전 연구소는 AI 안전성 정상회의에 참가한 28개국과 협력하여 AI 시...   \n",
       "\n",
       "                           persona_name      query_style query_length  \\\n",
       "0                    AI Safety Advocate  WEB_SEARCH_LIKE         LONG   \n",
       "1   Policy Analyst in Technology Ethics  WEB_SEARCH_LIKE       MEDIUM   \n",
       "2   Policy Analyst in Technology Ethics  PERFECT_GRAMMAR        SHORT   \n",
       "3   Policy Analyst in Technology Ethics  WEB_SEARCH_LIKE       MEDIUM   \n",
       "4   Policy Analyst in Technology Ethics  WEB_SEARCH_LIKE         LONG   \n",
       "5                                   NaN              NaN          NaN   \n",
       "6                                   NaN              NaN          NaN   \n",
       "7                                   NaN              NaN          NaN   \n",
       "8                                   NaN              NaN          NaN   \n",
       "9                                   NaN              NaN          NaN   \n",
       "10                                  NaN              NaN          NaN   \n",
       "\n",
       "                         synthesizer_name  \n",
       "0   single_hop_specific_query_synthesizer  \n",
       "1   single_hop_specific_query_synthesizer  \n",
       "2   single_hop_specific_query_synthesizer  \n",
       "3   single_hop_specific_query_synthesizer  \n",
       "4   single_hop_specific_query_synthesizer  \n",
       "5    multi_hop_specific_query_synthesizer  \n",
       "6    multi_hop_specific_query_synthesizer  \n",
       "7    multi_hop_specific_query_synthesizer  \n",
       "8    multi_hop_abstract_query_synthesizer  \n",
       "9    multi_hop_abstract_query_synthesizer  \n",
       "10   multi_hop_abstract_query_synthesizer  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = testset.to_pandas()\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf775fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()\n",
    "\n",
    "# DataFrame을 CSV 파일로 저장\n",
    "test_df.to_csv(\"data/ragas_synthetic_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdc5e98",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<br>\n",
    "\n",
    "## 02. RAGAS를 이용한 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4ff880b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7653976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference</th>\n",
       "      <th>persona_name</th>\n",
       "      <th>query_style</th>\n",
       "      <th>query_length</th>\n",
       "      <th>synthesizer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What actions has President Biden taken regardi...</td>\n",
       "      <td>['1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n 미국, 안전...</td>\n",
       "      <td>President Biden has signed an executive order ...</td>\n",
       "      <td>AI Safety Advocate</td>\n",
       "      <td>WEB_SEARCH_LIKE</td>\n",
       "      <td>LONG</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How does the recent AI executive order address...</td>\n",
       "      <td>['형평성과 시민권 향상 △소비자\\n보호 △노동자 지원 △혁신과 경쟁 촉진 △국제협...</td>\n",
       "      <td>The recent AI executive order includes measure...</td>\n",
       "      <td>Policy Analyst in Technology Ethics</td>\n",
       "      <td>WEB_SEARCH_LIKE</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What measures are included in the AI executive...</td>\n",
       "      <td>['혁신과 경쟁 촉진 △국제협력을 골자로 함 £바이든 대통령, AI 행정명령 통해 ...</td>\n",
       "      <td>The AI executive order announced by President ...</td>\n",
       "      <td>Policy Analyst in Technology Ethics</td>\n",
       "      <td>PERFECT_GRAMMAR</td>\n",
       "      <td>SHORT</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the focus of E.O. 14110 regarding AI t...</td>\n",
       "      <td>['분야의 전문 지식을 갖춘 외국인들이 미국에서 공부하고 취업할 수 있도록 지원 ☞...</td>\n",
       "      <td>E.O. 14110 is focused on the safe, secure, and...</td>\n",
       "      <td>Policy Analyst in Technology Ethics</td>\n",
       "      <td>WEB_SEARCH_LIKE</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What role did Japan play in the G7's establish...</td>\n",
       "      <td>['G7, 첨단 AI 시스템의 위험 관리를 위한 국제 행동강령 마련 n 주요 7개국...</td>\n",
       "      <td>Japan was one of the major seven countries (G7...</td>\n",
       "      <td>Policy Analyst in Technology Ethics</td>\n",
       "      <td>WEB_SEARCH_LIKE</td>\n",
       "      <td>LONG</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_input  \\\n",
       "0  What actions has President Biden taken regardi...   \n",
       "1  How does the recent AI executive order address...   \n",
       "2  What measures are included in the AI executive...   \n",
       "3  What is the focus of E.O. 14110 regarding AI t...   \n",
       "4  What role did Japan play in the G7's establish...   \n",
       "\n",
       "                                  reference_contexts  \\\n",
       "0  ['1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n 미국, 안전...   \n",
       "1  ['형평성과 시민권 향상 △소비자\\n보호 △노동자 지원 △혁신과 경쟁 촉진 △국제협...   \n",
       "2  ['혁신과 경쟁 촉진 △국제협력을 골자로 함 £바이든 대통령, AI 행정명령 통해 ...   \n",
       "3  ['분야의 전문 지식을 갖춘 외국인들이 미국에서 공부하고 취업할 수 있도록 지원 ☞...   \n",
       "4  ['G7, 첨단 AI 시스템의 위험 관리를 위한 국제 행동강령 마련 n 주요 7개국...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  President Biden has signed an executive order ...   \n",
       "1  The recent AI executive order includes measure...   \n",
       "2  The AI executive order announced by President ...   \n",
       "3  E.O. 14110 is focused on the safe, secure, and...   \n",
       "4  Japan was one of the major seven countries (G7...   \n",
       "\n",
       "                          persona_name      query_style query_length  \\\n",
       "0                   AI Safety Advocate  WEB_SEARCH_LIKE         LONG   \n",
       "1  Policy Analyst in Technology Ethics  WEB_SEARCH_LIKE       MEDIUM   \n",
       "2  Policy Analyst in Technology Ethics  PERFECT_GRAMMAR        SHORT   \n",
       "3  Policy Analyst in Technology Ethics  WEB_SEARCH_LIKE       MEDIUM   \n",
       "4  Policy Analyst in Technology Ethics  WEB_SEARCH_LIKE         LONG   \n",
       "\n",
       "                        synthesizer_name  \n",
       "0  single_hop_specific_query_synthesizer  \n",
       "1  single_hop_specific_query_synthesizer  \n",
       "2  single_hop_specific_query_synthesizer  \n",
       "3  single_hop_specific_query_synthesizer  \n",
       "4  single_hop_specific_query_synthesizer  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/ragas_synthetic_dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d759507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['user_input', 'reference_contexts', 'reference', 'persona_name', 'query_style', 'query_length', 'synthesizer_name'],\n",
       "    num_rows: 11\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = Dataset.from_pandas(df)\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "395dd8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_list(example):\n",
    "    contexts = ast.literal_eval(example[\"reference_contexts\"])\n",
    "    return {\"reference_contexts\": contexts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bcc76484",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 11/11 [00:00<00:00, 2153.74 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['user_input', 'reference_contexts', 'reference', 'persona_name', 'query_style', 'query_length', 'synthesizer_name'],\n",
      "    num_rows: 11\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_dataset = test_dataset.map(convert_to_list)\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044af868",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3a94ea9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a844c97",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "1. **문서 로드**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d24972e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyMuPDFLoader(\"data/SPRI_AI_Brief_2023년12월호_F.pdf\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ec0de2",
   "metadata": {},
   "source": [
    "2. **문서 분할**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "18bb4d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "split_documents = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa47082",
   "metadata": {},
   "source": [
    "3. **임베딩 생성**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "94b10afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e686a1d",
   "metadata": {},
   "source": [
    "4. **DB 생성 및 저장**\n",
    "- 벡터스토어를 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f8ef1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS.from_documents(documents=split_documents, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21994cec",
   "metadata": {},
   "source": [
    "5. **검색기 생성**\n",
    "- 문서에 포함되어 있는 정보를 검색하고 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f1d78640",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b7db25",
   "metadata": {},
   "source": [
    "6. **프롬프트 생성**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f9c0b6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "\n",
    "#Context: \n",
    "{context}\n",
    "\n",
    "#Question:\n",
    "{question}\n",
    "\n",
    "#Answer:\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9103ce3",
   "metadata": {},
   "source": [
    "7. **언어모델(LLM) 생성**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3e1672c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e7fa3e",
   "metadata": {},
   "source": [
    "8. **체인 생성**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8482d7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ff8629",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 배치 데이터셋 생성\n",
    "- 다량의 질문을 한 번에 처리할 때 용이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e2a5d7b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What actions has President Biden taken regarding the development and use of AI to ensure safety and reliability?',\n",
       " 'How does the recent AI executive order address issues related to 주택?',\n",
       " 'What measures are included in the AI executive order announced by President Biden?']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_dataset = [question for question in test_dataset[\"user_input\"]]\n",
    "batch_dataset[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f64c93",
   "metadata": {},
   "source": [
    "- `batch()` 를 호출하여 배치 데이터셋에 대한 답변"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d0f580c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['President Biden has signed an executive order on October 30, 2023, to ensure the safe and reliable development and use of AI. The executive order outlines several actions, including:\\n\\n1. Establishing safety and security standards for AI systems.\\n2. Enhancing privacy protection.\\n3. Promoting fairness and civil rights.\\n4. Protecting consumers.\\n5. Supporting workers.\\n6. Encouraging innovation and competition.\\n7. Fostering international cooperation.\\n\\nAdditionally, the order requires companies developing powerful AI systems to share safety test results and key system information with the U.S. government. It also aims to establish standards and best practices for verifying the safety and reliability of AI systems and for marking AI-generated content.',\n",
       " 'The recent AI executive order addresses issues related to housing by expanding measures to prevent discrimination and bias caused by the irresponsible use of AI in the housing sector. It aims to develop best practices for the use of AI in the criminal justice system and to establish clear guidelines to prevent discrimination by AI algorithms in housing rentals.',\n",
       " 'The AI executive order announced by President Biden includes the following measures:\\n\\n1. Establishing safety and security standards for AI.\\n2. Protecting personal information.\\n3. Enhancing fairness and civil rights.\\n4. Protecting consumers.\\n5. Supporting workers.\\n6. Promoting innovation and competition.\\n7. Encouraging international cooperation.\\n\\nAdditionally, the order requires companies developing powerful AI systems to share safety test results and key information about their systems with the U.S. government. It also aims to establish standards and best practices for verifying the safety and reliability of AI systems and for labeling AI-generated content.']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = chain.batch(batch_dataset)\n",
    "answer[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51041585",
   "metadata": {},
   "source": [
    "- LLM 이 생성한 답변을 `'answer'` 컬럼에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7dbf17a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"answer\" in test_dataset.column_names:\n",
    "    test_dataset = test_dataset.remove_columns([\"answer\"]).add_column(\"answer\", answer)\n",
    "else:\n",
    "    test_dataset = test_dataset.add_column(\"answer\", answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c10e33f",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 답변 평가\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Context Recall\n",
    "- **Context recall은 검색된 context가 LLM 이 생성한 답변과 얼마나 일치하는지를 측정**\n",
    "  \n",
    "  $\\rightarrow$ **모범 답안(Ground Truth)의 내용 중 몇 %나 검색 결과(Context)에 들어있는가?**\n",
    "- **이는 `user_input`, `reference_name` 및 검색된 `reference_contexts` 를 사용하여 계산되며, 값은 0에서 1 사이로, 높을수록 더 나은 성능을 의미**\n",
    "\n",
    "$$\n",
    "\\text{context recall} = \\frac{|\\text{GT claims that can be attributed to context}|}{|\\text{Number of claims in GT}|}\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\frac{|\\text{그 팩트들 중 '검색된 문서'를 근거로 설명 가능한 것의 개수}|}{|\\text{모범 답안에 들어있는 전체 팩트(주장)의 개수}|}\n",
    "$$\n",
    "\n",
    "- $\\rightarrow$ **검색 시스템(Retriever)** 의 성능을 평가\n",
    "- 예) 상황: 사용자가 \"독도는 어느 나라 땅이야?\"\n",
    "  - 모범 답안 (GT): \"독도는 대한민국의 영토이며, 행정구역상 경상북도 울릉군에 속합니다.\" (주장 2개)\n",
    "  - 검색된 문서 (Context): \"독도는 동해에 있는 섬으로 대한민국이 실효 지배 중입니다.\" (행정구역 정보 없음)\n",
    "  \n",
    "  $\\rightarrow$ 이 경우, 모범 답안의 주장 2개 중 1개(대한민국 영토)만 검색 문서에 들어있으므로 **Context Recall은 0.5 (50%)**\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Context Precision\n",
    "- **Context Precision은 contexts 내의 ground-truth 관련 항목들이 상위 순위에 있는지를 평가하는 지표**\n",
    "  \n",
    "  $\\rightarrow$ **정답에 결정적인 힌트가 들어있는 문서가 얼마나 앞페이지(상위 순위)에 배치되어 있는가?**\n",
    "\n",
    "  (RAG 시스템에서 LLM은 앞쪽에 배치된 정보(Context)를 더 중요하게 생각하는 경향 (Lost in the Middle 현상))\n",
    "\n",
    "- **`user_input`, `reference_name`, 그리고 `reference_contexts`를 사용하여 계산되며, 0에서 1 사이의 값**\n",
    "- **높은 점수일수록 더 나은 정밀도를 의미**\n",
    "\n",
    "<br>\n",
    "\n",
    "- **관련 있는 문서($v_k=1$)가 나타날 때마다 그때의 정밀도($\\text{Precision@k}$)를 기록해서 평균**\n",
    "  - **$v_k \\in {0, 1}$: 순위 $k$에 있는 문서가 정답과 관련이 있으면 1, 없으면 0**\n",
    "\n",
    "$$\n",
    "\\text{Context Precision@K} = \\frac{\\sum_{k=1}^{K} (\\text{Precision@k} \\times v_k)}{\\text{Total number of relevant items in the top K results}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{Precision@k} = \\frac{\\text{true positives@k}}{(\\text{true positives@k + false positives@k})} = \\text{1등부터 k등까지 중에서 진짜 정답 관련 문서가 몇 \\%인가}\n",
    "$$\n",
    "\n",
    "$\\rightarrow$ **이 지표는 정보 검색 시스템에서 검색된 컨텍스트의 품질을 평가하는 데 사용**\n",
    "\n",
    "$\\rightarrow$ **관련 정보가 얼마나 정확하게 상위 순위에 배치되었는지를 측정함으로써 시스템의 성능을 판단**\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Answer Relevancy\n",
    "- **생성된 답변이 주어진  Prompt에 얼마나 적절한지 평가**\n",
    "  \n",
    "  $\\rightarrow$ **답변 시스템의 성능을 평가하는 데 유용하며, 생성된 답변이 원래 질문의 의도를 얼마나 잘 반영하는지 측정**\n",
    "\n",
    "- 목적 : 생성된 답변의 관련성\n",
    "- 점수 해석 : 낮은 점수는 불완전하거나 중복 정보를 포함한 답변을, 높은 점수는 더 나은 관련성을 나타냄\n",
    "- 계산에 사용되는 요소 : `user_input`, `refernce_contexts`, `answer`\n",
    "\n",
    "<br>\n",
    "\n",
    "- 원래 `user_input`과 `answer`를 기반으로 생성된 인공적인 질문들 간의 평균 코사인 유사도\n",
    "  - $E_{g_i}$는 생성된 질문 $i$의 임베딩\n",
    "  - $E_o$는 원래 질문의 임베딩\n",
    "  - $N$은 생성된 질문의 수\n",
    "- 실제로는 점수가 대부분 0과 1 사이에 있지만, 최대 -1에서 1 사이의 값을 가질 수 있음\n",
    "\n",
    "$$\n",
    "\\text{answer relevancy} = \\frac{1}{N} \\sum_{i=1}^N \\cos(E_{g_i}, E_o)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{answer relevancy} = \\frac{1}{N} \\sum_{i=1}^N \\frac{E_{g_i} \\cdot E_o}{|E_{g_i}| |E_o|}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Faithfulness\n",
    "- **생성된 답변의 사실적 일관성을, 주어진 컨텍스트와 비교하며 측정**\n",
    "- 목적 : 답변의 사실적 일관성을 컨텍스트와 비교하며 평가\n",
    "- 계산 요소 : 답변과 검색된 컨텍스트를 사용\n",
    "- 점수 범위 : 0에서 1사이로 조정되며, 높을수록 더 좋음\n",
    "\n",
    "<br>\n",
    "\n",
    "- 계산\n",
    "1. 생성된 답변에서 주장들을 식별\n",
    "2. 각 주장들을 주어진 컨텍스트와 대조 검증하여 컨텍스트에 추론 가능한지 확인\n",
    "3. 점수 계산\n",
    "\n",
    "$$\n",
    "\\text{Faithfulness score} = \\frac{|\\text{Number of claims in the generated answer that can be inferred from given context}|}{|\\text{Total number of claims in the generated answer}|}\n",
    "$$\n",
    "\n",
    "- 예시\n",
    "1. 질문: \"아인슈타인은 어디서, 언제 태어났나요?\"\n",
    "2. 컨텍스트: \"알버트 아인슈타인(1879년 3월 14일 출생)은 독일 출신의 이론 물리학자로, 역사상 가장 위대하고 영향력 있는 과학자 중 한 명으로 여겨집니다.\"\n",
    "3. 높은 충실도 답변: \"아인슈타인은 1879년 3월 14일 독일에서 태어났습니다.\"\n",
    "4. 낮은 충실도 답변: \"아인슈타인은 1879년 3월 20일 독일에서 태어났습니다.\"\n",
    "\n",
    "<br>\n",
    "\n",
    "$\\rightarrow$ **생성된 답변이 주어진 컨텍스트에 얼마나 충실한지를 평가하는 데 유용, 특히 질문-답변 시스템의 정확성과 신뢰성을 측정하는 데 중요**\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ba549b",
   "metadata": {},
   "source": [
    "```python\n",
    "from ragas import evaluate\n",
    "# from ragas.metrics.collections import answer_relevancy, faithfulness, context_recall, context_precision\n",
    "from ragas.metrics import (\n",
    "    ContextPrecision,\n",
    "    Faithfulness,\n",
    "    AnswerRelevancy,\n",
    "    ContextRecall,\n",
    ")\n",
    "\n",
    "result = evaluate(\n",
    "    dataset=test_dataset,\n",
    "    metrics=[\n",
    "        ContextPrecision(),\n",
    "        Faithfulness(),\n",
    "        AnswerRelevancy(),\n",
    "        ContextRecall(),\n",
    "    ],\n",
    "    column_map={\n",
    "        \"retrieved_contexts\": \"reference_contexts\", \n",
    "        \"user_input\": \"user_input\", \n",
    "        \"reference\": \"reference\",\n",
    "    }\n",
    ")\n",
    "\n",
    "result_df = result.to_pandas()\n",
    "result_df.head()\n",
    "\n",
    "result_df.loc[:, \"context_precision\":\"context_recall\"]\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

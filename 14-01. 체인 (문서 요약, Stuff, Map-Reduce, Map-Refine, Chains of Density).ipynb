{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e5ed77e",
   "metadata": {},
   "source": [
    "# 14. 체인 (Chains)\n",
    "- **체인의 생성 단계는 모든 과정을 하나로 묶어 RAG 파이프라인으로 조립하여 완성하는 단계**\n",
    "- 문서 기반 RAG의 구조도\n",
    "\n",
    "<img src='https://static.wikidocs.net/images/page/233774/RAG_%E1%84%80%E1%85%AE%E1%84%8C%E1%85%A9%E1%84%83%E1%85%A9_RunnablePassthrough.png' width=800>\n",
    "\n",
    "<br>\n",
    "\n",
    "### 코드\n",
    "- LCEL문법을 사용하여 7단계의 전 과정을 하나의 체인으로 묶음\n",
    "\n",
    "```python\n",
    "# 체인(Chain) 생성\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "- 완성된 체인에 질의하는 코드\n",
    "\n",
    "```python\n",
    "# 체인 실행(Run Chain)\n",
    "# 문서에 대한 질의를 입력하고, 답변을 출력\n",
    "question = \"삼성전자가 자체 개발한 AI 의 이름은?\"\n",
    "response = chain.invoke(question)\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<br>\n",
    "\n",
    "## 01. 문서 요약\n",
    "\n",
    "<br>\n",
    "\n",
    "#### 주요 개요\n",
    "1. **Stuff**: 전체 문서 한 번에 요약\n",
    "2. **Map-Reduce**: 분할 요약 후 일괄 병합\n",
    "3. **Map-Refine**: 분할 요약 후 점진적인 병합\n",
    "4. **Chain of Density**: N번 반복 실행하며, 누락된 entity를 보완하며 요약 개선\n",
    "5. **Clustering-Map-Refine**: 문서의 Chunk 를 N 개의 클러스터로 나누고, 각 클러스터에서 중심점에 가까운 문서에 대한 요약을 Refine 요약\n",
    "\n",
    "<br>\n",
    "\n",
    "### 대표적인 요약 방식\n",
    "- 요약기를 구축할 떄 중심적인 질문은 **문서를 LLM 컨텍스트 창에 어떻게 전달할 것인가**\n",
    "\n",
    "1. **`Stuff`** : 단순히 모든 문서를 단일 프롬프트로 '넣는' 방식 (가장 단순)\n",
    "2. **`Map-Reduce`**: 각 문서를 `map` 단계에서 개별적으로 요약한 다음, `reduce` 단계에서 요약본들을 최종 요약본으로 합침\n",
    "3. **`Refine`** : 입력 문서를 순회하며 반복적으로 답변을 업데이트하며 응답을 구성. 각 문서에 대해 모든 비문서 입력, 현재 문서, 그리고 최신 중간 답변을 `chian`에 전달하여 새로운 답변을 얻음\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66569ba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY 정보로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605c463f",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### `Stuff`\n",
    "- `stuff documents chain`(\"stuff\"는 \"채우다\" 또는 \"채우기 위해\"의 의미)는 문서 체인 중 가장 간단한 방식\n",
    "- **문서 목록을 가져와서 모두 프롬프트에 삽입한 다음, 그 프롬프트를 LLM에 전달**\n",
    "- **이 체인은 문서가 작고 대부분의 호출에 몇 개만 전달되는 애플리케이션에 적합**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea6a348d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bcf88ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 글자수: 1708\n",
      "\n",
      "========= 앞부분 미리보기 =========\n",
      "\n",
      "제목: \n",
      "AI2, 상업 활용까지 자유로운 '진짜' 오픈 소스 LLM '올모' 출시\n",
      "\n",
      "내용:\n",
      "앨런AI연구소(AI2)가 완전한 오픈 소스 대형언어모델(LLM) '올모(OLMo)’를 출시했다. 데이터 수집, 학습, 배포의 전 과정을 투명하게 공개한 데다 상업적 사용까지 허용한 진정한 의미의 오픈 소스 LLM이라는 평가다.\n",
      "벤처비트는 1일(현지시간) 비영리 민간 AI 연구기관인 AI2가 ‘최초의 진정한 오픈 소스 LLM 및 프레임워크’라고 소개한 ‘올모’를 출시했다고 보도했다. \n",
      "이에 따르면 올모는 모델 코드와 모델 가중치뿐만 아니라 훈련 코드, 훈련 데이터, 관련 툴킷 및 평가 툴킷도 제공한다. 이를 통해 모델이 어떻게 구축되었는지 심층적으로 분석, LLM의 작동 방식과 응답을 생성하는 원리를 더 잘 이해할 수 있다. \n",
      "올모 프레임워크는 70억 매개변수의 ‘올모 7B’ 등 4가지 변형 모델과 10억 매개변수의 ‘올모 1B’ 모델을 제공한다. 모델들은 훈련 데이터를 생성하는 코드를 포함해 \n"
     ]
    }
   ],
   "source": [
    "loader = TextLoader(\"data/news.txt\")\n",
    "docs = loader.load()\n",
    "print(f\"총 글자수: {len(docs[0].page_content)}\")\n",
    "print(\"\\n========= 앞부분 미리보기 =========\\n\")\n",
    "print(docs[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f7c3a4",
   "metadata": {},
   "source": [
    "- 한국어로 요약을 작성하라는 Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7b74336",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic import hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f85ef4f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please summarize the sentence according to the following REQUEST.\n",
      "REQUEST:\n",
      "1. Summarize the main points in bullet points in KOREAN.\n",
      "2. Each summarized sentence must start with an emoji that fits the meaning of the each sentence.\n",
      "3. Use various emojis to make the summary more interesting.\n",
      "4. Translate the summary into KOREAN if it is written in ENGLISH.\n",
      "5. DO NOT translate any technical terms.\n",
      "6. DO NOT include any unnecessary information.\n",
      "\n",
      "CONTEXT:\n",
      "\u001b[33;1m\u001b[1;3m{context}\u001b[0m\n",
      "\n",
      "SUMMARY:\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = hub.pull(\"teddynote/summary-stuff-documents-korean\")\n",
    "prompt.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06189a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 🚀 앨런AI연구소(AI2)가 완전한 오픈 소스 LLM '올모(OLMo)'를 출시했다.  \n",
      "- 📊 데이터 수집, 학습, 배포 과정을 투명하게 공개하고 상업적 사용을 허용한다.  \n",
      "- 🛠️ 모델 코드, 가중치, 훈련 코드, 데이터 및 평가 툴킷을 제공한다.  \n",
      "- 📈 '올모 7B'와 '올모 1B' 등 4가지 변형 모델을 포함한다.  \n",
      "- 🔍 AI2의 '돌마(Dolma)' 데이터 세트를 기반으로 3조개의 토큰으로 훈련되었다.  \n",
      "- 📜 아파치 2.0 라이선스에 따라 상업적 활용에 제한이 없다.  \n",
      "- 🧪 연구자들이 모델의 작동 방식을 과학적으로 이해할 수 있도록 돕는다.  \n",
      "- 🌟 올모는 상업용 제품과 동등한 성능을 보여준다.  \n",
      "- ⚠️ 비영어권 언어에 대한 낮은 품질과 약한 코드 생성 기능이 있다.  \n",
      "- 🔄 AI2는 올모를 계속해서 향상할 계획이다.  \n",
      "- 🌐 올모의 모든 리소스는 깃허브 및 허깅페이스에서 무료로 제공된다.  "
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_classic.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_classic.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "# from langchain_teddynote.callbacks import StreamingCallback\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model_name=\"gpt-4o-mini\",\n",
    "    streaming=True,\n",
    "    temperature=0,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()],\n",
    ")\n",
    "\n",
    "stuff_chain = create_stuff_documents_chain(llm, prompt)\n",
    "answer = stuff_chain.invoke({\"context\": docs})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28624c0",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Map-Reduce\n",
    "- **Map-Reduce 방식의 요약은 긴 문서를 효율적으로 요약하는 기법**\n",
    "- **이 방법은 문서를 작은 `chunk`로 나누는 `map` 단계와, 각 `chunk`의 요약을 결합하는 `reduce` 단계로 결합**\n",
    "\n",
    "1. `Map` 단계에서는 각 `chunk`를 병렬로 요약\n",
    "2. `Reduce` 단계에서는 이 요약들을 하나의 최종 요약으로 통합\n",
    "\n",
    "- **이 접근법은 대규모 문서를 처리할 때 특히 유용하며, 언어 모델의 토큰 제한을 우회**\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src='https://static.wikidocs.net/images/page/234020/summarization_use_case_2.png' width=800>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d3798b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af77c259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 페이지수: 5\n"
     ]
    }
   ],
   "source": [
    "loader = PyPDFLoader(\"data/SPRI_AI_Brief_2023년12월호_F.pdf\")\n",
    "docs = loader.load()\n",
    "docs = docs[3:8]  # 여기서 문서의 일부만 요약\n",
    "print(f\"총 페이지수: {len(docs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13288e76",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Map\n",
    "- **`Map` 단계에서는 각 Chunk 에 대한 요약을 생성 (혹은 핵심 내용 추출. 마지막 `reduce` 단계에서 요약을 하나로 합치는 과정이기 때문)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab167380",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic import hub\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c8c1a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "You are a professional main thesis extractor.\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Your task is to extract main thesis from given documents. Answer should be in same language as given document. \n",
      "\n",
      "#Format: \n",
      "- thesis 1\n",
      "- thesis 2\n",
      "- thesis 3\n",
      "- ...\n",
      "\n",
      "Here is a given document: \n",
      "\u001b[33;1m\u001b[1;3m{doc}\u001b[0m\n",
      "\n",
      "Write 1~5 sentences.\n",
      "#Answer:\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    model_name=\"gpt-4o-mini\",\n",
    ")\n",
    "\n",
    "# map prompt 다운로드\n",
    "map_prompt = hub.pull(\"teddynote/map-prompt\")\n",
    "\n",
    "# 프롬프트 출력\n",
    "map_prompt.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f4d8c4",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- **`map_chain` 생성**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ce2bef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_chain = map_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc544a3a",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- **`batch()` 를 호출하여 각 문서에 대한 요약본을 생성**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4dcb0f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_summaries = map_chain.batch(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5ccbe8",
   "metadata": {},
   "source": [
    "- 요약된 문서의 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21ef9fc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc_summaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1776de",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- 일부 문서의 요약 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "88f2aed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 미국 바이든 대통령이 안전하고 신뢰할 수 있는 AI 개발과 사용을 보장하기 위한 행정명령을 발표하였다.\n",
      "- 이 행정명령은 AI의 안전과 보안 기준 마련, 개인정보보호, 형평성과 시민권 향상, 소비자 보호, 노동자 지원, 혁신과 경쟁 촉진, 국제협력을 포함한다.\n",
      "- AI 시스템의 안전성과 신뢰성을 확인하기 위한 표준 및 모범사례를 확립하고, AI의 무책임한 사용으로 인한 차별과 편견을 방지하기 위한 조치를 확대할 예정이다.\n",
      "- 또한, 국가 차원에서 AI 연구 인프라를 확충하고 중소기업과 개발자에게 기술과 인프라를 지원하여 AI 연구를 촉진할 계획이다.\n"
     ]
    }
   ],
   "source": [
    "print(doc_summaries[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058f9c31",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Reduce\n",
    "- `Reduce` 단계에서는 `map` 단계에서 진행한 핵심 내용들을 하나의 최종 요약으로 통합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6423370a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_prompt = hub.pull(\"teddynote/reduce-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f7642da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "You are a professional summarizer. You are given a list of summaries of documents and you are asked to create a single summary of the documents.\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "#Instructions: \n",
      "1. Extract main points from a list of summaries of documents\n",
      "2. Make final summaries in bullet points format.\n",
      "3. Answer should be written in \u001b[33;1m\u001b[1;3m{language}\u001b[0m.\n",
      "\n",
      "#Format: \n",
      "- summary 1\n",
      "- summary 2\n",
      "- summary 3\n",
      "- ...\n",
      "\n",
      "Here is a list of summaries of documents: \n",
      "\u001b[33;1m\u001b[1;3m{doc_summaries}\u001b[0m\n",
      "\n",
      "#SUMMARY:\n"
     ]
    }
   ],
   "source": [
    "reduce_prompt.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b135da7",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- **`Reduce Chain` 생성**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "59d9551e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_chain = reduce_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "57b6baaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 미국 바이든 대통령이 AI 개발과 사용의 안전성을 보장하기 위한 행정명령을 발표하였으며, 이는 AI의 안전 기준, 개인정보 보호, 형평성 향상 등을 포함한다.\n",
      "- G7은 '히로시마 AI 프로세스'를 통해 AI 국제 행동강령에 합의하고, AI 시스템의 투명성과 책임성을 강화할 것을 제안하였다.\n",
      "- 영국 AI 안전성 정상회의에서 블레츨리 선언이 발표되었으며, AI 시스템의 안전성을 보장하기 위한 협력의 중요성이 강조되었다.\n",
      "- 미국 캘리포니아 북부지방법원은 생성 AI 기업에 대한 저작권 소송을 기각하였고, 원고에게 고소장 수정을 요청하였다.\n",
      "- 미국 연방거래위원회(FTC)는 생성 AI의 소비자 및 창작자에 대한 피해 가능성을 우려하며, 시장 지배력 강화에 대한 경고를 발령하였다."
     ]
    }
   ],
   "source": [
    "for chunk in reduce_chain.stream({\"doc_summaries\": doc_summaries, \"language\": \"Korean\"}):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4d361e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba26c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "@chain\n",
    "def map_reduce_chain(docs):\n",
    "    map_llm = ChatOpenAI(\n",
    "        temperature=0,\n",
    "        model_name=\"gpt-4o-mini\",\n",
    "    )\n",
    "\n",
    "    # map prompt 다운로드\n",
    "    map_prompt = hub.pull(\"teddynote/map-prompt\")\n",
    "\n",
    "    # map chain 생성\n",
    "    map_chain = map_prompt | map_llm | StrOutputParser()\n",
    "\n",
    "    # 첫 번째 프롬프트, ChatOpenAI, 문자열 출력 파서를 연결하여 체인을 생성\n",
    "    doc_summaries = map_chain.batch(docs)\n",
    "\n",
    "    # reduce prompt 다운로드\n",
    "    reduce_prompt = hub.pull(\"teddynote/reduce-prompt\")\n",
    "    reduce_llm = ChatOpenAI(\n",
    "        model_name=\"gpt-4o\",\n",
    "        temperature=0,\n",
    "        callbacks=[StreamingStdOutCallbackHandler()],\n",
    "        streaming=True,\n",
    "    )\n",
    "\n",
    "    reduce_chain = reduce_prompt | reduce_llm | StrOutputParser()\n",
    "\n",
    "    return reduce_chain.invoke({\"doc_summaries\": doc_summaries, \"language\": \"Korean\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6d95f78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 미국 바이든 대통령은 AI의 안전하고 신뢰할 수 있는 개발과 사용을 보장하기 위한 행정명령을 발표하였으며, AI의 안전성, 개인정보보호, 형평성, 소비자 보호, 노동자 지원, 혁신 촉진 등을 포함한다.\n",
      "- G7은 '히로시마 AI 프로세스'를 통해 AI 국제 행동강령에 합의하였으며, AI의 위험 평가, 투명성, 책임성, 정보공유, 이해관계자 협력을 요구하고, AI 생성 콘텐츠의 신뢰성을 보장하기 위한 메커니즘 개발을 강조하였다.\n",
      "- 영국 AI 안전성 정상회의에서 블레츨리 선언이 발표되었으며, AI 안전성을 보장하기 위해 이해관계자의 협력과 첨단 AI 개발 기업의 책임을 강조하였다. 영국은 AI 안전 연구소 출범과 안전 테스트 계획을 발표하였다.\n",
      "- 미국 캘리포니아 북부지방법원은 예술가들이 제기한 생성 AI 기업에 대한 저작권 소송을 기각하였으나, 특정 작품에 대한 저작권 침해 소송은 계속 진행 중이다.\n",
      "- 미국 연방거래위원회(FTC)는 생성 AI로 인한 소비자와 창작자의 피해 가능성 및 빅테크의 시장 지배력 강화 우려를 표명하며, 소비자 보호와 공정한 경쟁 시장 유지를 위해 모든 법적 권한을 활용할 것을 강조하였다."
     ]
    }
   ],
   "source": [
    "answer = map_reduce_chain.invoke(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a32f4ce",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Map-Refine\n",
    "\n",
    "1. **`Map` 단계** : 문서를 여러 개의 작은 `chunk`로 나누고, 각 `chunk`에 대해 개별적으로 요약을 생성\n",
    "2. **`Refine` 단계** : 생성된 요약들을 순차적으로 처리하며 최종 요약을 점진적으로 개선. 각 단계에서 이전 요약과 새로운 `chunk`의 정보를 결합하여 요약을 갱신\n",
    "3. **반복 과정** : 모든 `chunk`가 처리될 때까지 `Refine`단계를 반복\n",
    "4. **최종 요약** : 마지막 `chunk`까지 처리한 후 얻은 요약이 최종 결과\n",
    "\n",
    "<br>\n",
    "\n",
    "- **Map-Refine 방식의 장점은 문서의 순서를 유지하면서 점진적으로 요약을 개선할 수 있다는 것 $\\rightarrow$ 이는 특히 문서의 맥락이 중요한 경우에 유용**\n",
    "- **그러나 이 방식은 Map-Reduce 에 비해 순차적으로 처리되기 때문에 병렬화가 어려워 대규모 문서 처리 시 시간이 더 오래 걸릴 수 있음**\n",
    "\n",
    "<img src='https://static.wikidocs.net/images/page/234020/summarization_use_case_3.png' width=800>\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Map\n",
    "- `Map` 단계에서 각 chunk에 대한 요약을 생성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a829e35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic import hub\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "306eed8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "You are an expert summarizer. Your task is to summarize the following document in \u001b[33;1m\u001b[1;3m{language}\u001b[0m.\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Extract most important main thesis from the documents, then summarize in bullet points.\n",
      "\n",
      "#Format:\n",
      "- summary 1\n",
      "- summary 2\n",
      "- summary 3\n",
      "-...\n",
      "\n",
      "Here is a given document: \n",
      "\u001b[33;1m\u001b[1;3m{documents}\u001b[0m\n",
      "\n",
      "Write 1~5 sentences. Think step by step.\n",
      "#Summary:\n"
     ]
    }
   ],
   "source": [
    "# map llm 생성\n",
    "map_llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    model_name=\"gpt-4o-mini\",\n",
    ")\n",
    "\n",
    "# map chain 생성\n",
    "map_summary = hub.pull(\"teddynote/map-summary-prompt\")\n",
    "\n",
    "# 프롬프트 출력\n",
    "map_summary.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffc5e60",
   "metadata": {},
   "source": [
    "- `map_chain`을 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "69ff95fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_chain = map_summary | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a342cfc",
   "metadata": {},
   "source": [
    "- 첫 문서의 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fc5915e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 미국 바이든 대통령이 안전하고 신뢰할 수 있는 AI 개발과 사용을 위한 행정명령을 발표하였다.\n",
      "- 이 행정명령은 AI의 안전과 보안 기준, 개인정보 보호, 형평성과 시민권 향상, 소비자 보호, 노동자 지원, 혁신과 경쟁 촉진, 국제 협력을 포함한다.\n",
      "- AI 시스템 개발 기업은 안전 테스트 결과와 시스템 정보를 미국 정부와 공유해야 하며, AI의 책임 있는 사용을 위한 법적 지침이 마련된다.\n",
      "- 소비자 보호와 근로자 지원을 위해 의료 분야에서의 AI 사용 촉진 및 교육 도구 개발이 강조된다.\n",
      "- 국가 차원에서 AI 연구 인프라를 확충하고 외국인 전문가의 유입을 지원하는 방안도 포함되어 있다.\n"
     ]
    }
   ],
   "source": [
    "print(map_chain.invoke({\"documents\": docs[0], \"language\": \"Korean\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12398808",
   "metadata": {},
   "source": [
    "- 모든 문서를 입력으로 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d126143b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_doc = [{\"documents\": doc, \"language\": \"Korean\"} for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a66ee3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['- 미국 바이든 대통령이 안전하고 신뢰할 수 있는 AI 개발과 사용을 위한 행정명령을 발표하였다.\\n- 이 행정명령은 AI의 안전과 보안 기준, 개인정보 보호, 형평성과 시민권 향상, 소비자 보호, 노동자 지원, 혁신과 경쟁 촉진, 국제 협력을 포함한다.\\n- AI 시스템 개발 기업은 안전 테스트 결과와 시스템 정보를 정부와 공유해야 하며, AI의 책임 있는 사용을 위한 법적 지침이 마련된다.\\n- 소비자 보호와 근로자 지원을 위해 의료 분야에서의 AI 사용 촉진 및 교육 도구 개발이 강조된다.\\n- 국가 차원에서 AI 연구 인프라를 확충하고 외국인 전문가의 유입을 지원하는 방안도 포함되어 있다.', \"- G7은 2023년 10월 30일 '히로시마 AI 프로세스'를 통해 첨단 AI 시스템을 개발하는 기업을 위한 국제 행동강령에 합의하였다.\\n- 이 행동강령은 AI 수명주기 전반에 걸친 위험 평가 및 완화, 투명성과 책임성 보장, 정보 공유 및 협력, 보안 통제, 콘텐츠 인증 및 출처 확인 등의 조치를 요구한다.\\n- G7은 AI 시스템의 성능과 한계를 공개하고, 적절한 사용 영역을 알리며, 강력한 보안 통제를 구현할 것을 권장하고 있다.\\n- 또한, AI 생성 콘텐츠의 신뢰성을 높이기 위해 기술적 인증 메커니즘을 개발하고, 사회적 위험을 완화하기 위한 연구에 우선 투자할 것을 강조하고 있다.\\n- 이 행동강령은 빠르게 발전하는 기술에 대응하기 위해 이해관계자 협의를 통해 필요에 따라 개정될 예정이다.\", '- 28개국이 참여한 영국 AI 안전성 정상회의에서 AI 안전 보장을 위한 블레츨리 선언이 발표되었다.\\n- 선언은 AI 시스템의 안전성을 보장하기 위해 모든 이해관계자의 협력이 중요하다고 강조하며, 첨단 AI 개발 기업의 책임을 지적했다.\\n- 영국 총리는 AI 안전 연구소의 출범을 발표하고, 정부 주도의 안전 테스트 계획을 수립할 것이라고 밝혔다.\\n- 참가국들은 AI의 위험과 가능성에 대한 과학적 평가를 위한 보고서 작성을 합의하고, 한국과 프랑스와의 후속 정상회의 계획도 논의되었다.', '- 미국 캘리포니아 북부지방법원은 예술가들이 미드저니, 스태빌리티AI, 디비언트아트를 상대로 제기한 저작권 침해 소송을 기각했다.\\n- 기각 사유로는 고소장에 제시된 작품들이 저작권청에 등록되지 않았고, AI로 생성된 이미지와 특정 작품 간의 유사성을 입증하기 어렵다는 점이 지적되었다.\\n- 판사는 원고 측에 고소장을 수정하고 저작권이 침해된 특정 이미지를 중심으로 소송 범위를 줄여 다시 제기할 것을 요청했다.\\n- 그러나 사라 앤더슨이 저작권을 보유한 16개 작품에 대한 스태빌리티AI의 저작권 침해 소송은 계속 진행된다.', '- 미국 연방거래위원회(FTC)는 저작권청에 AI와 관련된 소비자 보호 및 경쟁 문제에 대한 의견서를 제출했다.\\n- FTC는 생성 AI가 소비자와 창작자에게 피해를 줄 수 있으며, 일부 빅테크가 시장 지배력을 강화할 우려가 있다고 경고했다.\\n- 생성 AI의 사용으로 인해 소비자의 개인정보 침해, 차별, 사기 범죄 등의 위험이 존재한다고 지적했다.\\n- FTC는 저작권법에 저촉되는 행위가 불공정 경쟁이나 기만행위로 이어질 수 있음을 강조하며, 창작자의 경쟁력이 저하될 수 있다고 밝혔다.\\n- FTC는 AI 관련 불법 행위에 대해 법적 권한을 활용하여 소비자를 보호하고 공정한 경쟁 시장을 유지하겠다고 다짐했다.']\n"
     ]
    }
   ],
   "source": [
    "print(map_chain.batch(input_doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f2260d",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Refine\n",
    "- 이전의 `Map` 단계에서 생성한 chunk들을 순차적으로 처리하며 최종 요약을 점진적으로 개선\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d628a98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "You are an expert summarizer.\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Your job is to produce a final summary\n",
      "\n",
      "We have provided an existing summary up to a certain point:\n",
      "\u001b[33;1m\u001b[1;3m{previous_summary}\u001b[0m\n",
      "\n",
      "We have the opportunity to refine the existing summary(only if needed) with some more context below.\n",
      "------------\n",
      "\u001b[33;1m\u001b[1;3m{current_summary}\u001b[0m\n",
      "------------\n",
      "Given the new context, refine the original summary in \u001b[33;1m\u001b[1;3m{language}\u001b[0m.\n",
      "If the context isn't useful, return the original summary.\n"
     ]
    }
   ],
   "source": [
    "refine_prompt = hub.pull(\"teddynote/refine-prompt\")\n",
    "refine_prompt.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3211c54c",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- `refine_llm` 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "075b6383",
   "metadata": {},
   "outputs": [],
   "source": [
    "refine_llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    model_name=\"gpt-4o-mini\",\n",
    ")\n",
    "\n",
    "# refine chain 생성\n",
    "refine_chain = refine_prompt | refine_llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26246f59",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- `map_reduce_chain` 생성 예시\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "27fc2a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "94b16c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "@chain\n",
    "def map_refine_chain(docs):\n",
    "\n",
    "    # map chain 생성\n",
    "    map_summary = hub.pull(\"teddynote/map-summary-prompt\")\n",
    "\n",
    "    map_chain = (\n",
    "        map_summary\n",
    "        | ChatOpenAI(\n",
    "            model_name=\"gpt-4o-mini\",\n",
    "            temperature=0,\n",
    "        )\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    input_doc = [{\"documents\": doc.page_content, \"language\": \"Korean\"} for doc in docs]\n",
    "\n",
    "    # 첫 번째 프롬프트, ChatOpenAI, 문자열 출력 파서를 연결하여 체인을 생성\n",
    "    doc_summaries = map_chain.batch(input_doc)\n",
    "\n",
    "    refine_prompt = hub.pull(\"teddynote/refine-prompt\")\n",
    "\n",
    "    refine_llm = ChatOpenAI(\n",
    "        model_name=\"gpt-4o-mini\",\n",
    "        temperature=0,\n",
    "        callbacks=[StreamingStdOutCallbackHandler()],\n",
    "        streaming=True,\n",
    "    )\n",
    "\n",
    "    refine_chain = refine_prompt | refine_llm | StrOutputParser()\n",
    "\n",
    "    previous_summary = doc_summaries[0]\n",
    "\n",
    "    for current_summary in doc_summaries[1:]:\n",
    "\n",
    "        previous_summary = refine_chain.invoke(\n",
    "            {\n",
    "                \"previous_summary\": previous_summary,\n",
    "                \"current_summary\": current_summary,\n",
    "                \"language\": \"Korean\",\n",
    "            }\n",
    "        )\n",
    "        print(\"\\n\\n-----------------\\n\\n\")\n",
    "\n",
    "    return previous_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3a12fd20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 미국 바이든 대통령이 안전하고 신뢰할 수 있는 AI 개발과 사용을 위한 행정명령을 발표하였다.\n",
      "- 이 행정명령은 AI의 안전과 보안 기준, 개인정보 보호, 형평성과 시민권 향상, 소비자 보호, 노동자 지원, 혁신과 경쟁 촉진, 국제 협력을 포함한다.\n",
      "- AI 시스템 개발 기업은 안전 테스트 결과와 시스템 정보를 정부와 공유해야 하며, AI의 책임 있는 사용을 위한 법적 지침이 마련된다.\n",
      "- 의료 분야에서의 AI 사용 촉진과 학교 내 AI 교육 도구 개발을 통해 소비자와 근로자를 보호하는 원칙이 설정된다.\n",
      "- 국가 차원에서 AI 연구 인프라를 확충하고 외국인 전문가의 유입을 지원하여 AI 분야의 혁신을 촉진할 계획이다.\n",
      "- 또한, G7은 '히로시마 AI 프로세스'를 통해 AI 기업을 위한 국제 행동강령에 합의하였으며, 이는 AI 시스템의 위험 식별과 완화를 위한 자발적 채택을 권장하고, 위험 평가와 투명성, 책임성을 강조한다.\n",
      "- G7은 AI 기술의 빠른 발전에 대응하기 위해 행동강령을 개정할 계획이며, 사회적 위험 완화와 세계적 문제 해결을 위한 AI 시스템 개발을 우선시하고 국제 기술 표준의 개발을 가속화할 예정이다.\n",
      "\n",
      "-----------------\n",
      "\n",
      "\n",
      "- 미국 바이든 대통령이 안전하고 신뢰할 수 있는 AI 개발과 사용을 위한 행정명령을 발표하였다.\n",
      "- 이 행정명령은 AI의 안전과 보안 기준, 개인정보 보호, 형평성과 시민권 향상, 소비자 보호, 노동자 지원, 혁신과 경쟁 촉진, 국제 협력을 포함한다.\n",
      "- AI 시스템 개발 기업은 안전 테스트 결과와 시스템 정보를 정부와 공유해야 하며, AI의 책임 있는 사용을 위한 법적 지침이 마련된다.\n",
      "- 의료 분야에서의 AI 사용 촉진과 학교 내 AI 교육 도구 개발을 통해 소비자와 근로자를 보호하는 원칙이 설정된다.\n",
      "- 국가 차원에서 AI 연구 인프라를 확충하고 외국인 전문가의 유입을 지원하여 AI 분야의 혁신을 촉진할 계획이다.\n",
      "- G7은 '히로시마 AI 프로세스'를 통해 AI 기업을 위한 국제 행동강령에 합의하였으며, 이는 AI 시스템의 위험 식별과 완화를 위한 자발적 채택을 권장하고, 위험 평가와 투명성, 책임성을 강조한다.\n",
      "- G7은 AI 기술의 빠른 발전에 대응하기 위해 행동강령을 개정할 계획이며, 사회적 위험 완화와 세계적 문제 해결을 위한 AI 시스템 개발을 우선시하고 국제 기술 표준의 개발을 가속화할 예정이다.\n",
      "- 또한, 28개국이 참여한 영국 AI 안전성 정상회의에서 AI 안전 보장을 위한 블레츨리 선언이 발표되었다. 이 선언은 AI 시스템의 안전성을 보장하기 위해 모든 이해관계자의 협력이 중요하다고 강조하며, 첨단 AI 개발 기업의 책임을 지적했다.\n",
      "- 영국 총리는 AI 안전 연구소의 출범을 발표하고, 정부 주도의 안전 테스트 계획을 수립할 것이라고 밝혔다. 참가국들은 AI 위험과 가능성에 대한 과학적 평가를 위한 보고서 작성을 합의하고, 한국과 프랑스와의 후속 정상회의 계획도 논의되었다.\n",
      "\n",
      "-----------------\n",
      "\n",
      "\n",
      "- 미국 바이든 대통령이 안전하고 신뢰할 수 있는 AI 개발과 사용을 위한 행정명령을 발표하였다.\n",
      "- 이 행정명령은 AI의 안전과 보안 기준, 개인정보 보호, 형평성과 시민권 향상, 소비자 보호, 노동자 지원, 혁신과 경쟁 촉진, 국제 협력을 포함한다.\n",
      "- AI 시스템 개발 기업은 안전 테스트 결과와 시스템 정보를 정부와 공유해야 하며, AI의 책임 있는 사용을 위한 법적 지침이 마련된다.\n",
      "- 의료 분야에서의 AI 사용 촉진과 학교 내 AI 교육 도구 개발을 통해 소비자와 근로자를 보호하는 원칙이 설정된다.\n",
      "- 국가 차원에서 AI 연구 인프라를 확충하고 외국인 전문가의 유입을 지원하여 AI 분야의 혁신을 촉진할 계획이다.\n",
      "- G7은 '히로시마 AI 프로세스'를 통해 AI 기업을 위한 국제 행동강령에 합의하였으며, 이는 AI 시스템의 위험 식별과 완화를 위한 자발적 채택을 권장하고, 위험 평가와 투명성, 책임성을 강조한다.\n",
      "- G7은 AI 기술의 빠른 발전에 대응하기 위해 행동강령을 개정할 계획이며, 사회적 위험 완화와 세계적 문제 해결을 위한 AI 시스템 개발을 우선시하고 국제 기술 표준의 개발을 가속화할 예정이다.\n",
      "- 또한, 28개국이 참여한 영국 AI 안전성 정상회의에서 AI 안전 보장을 위한 블레츨리 선언이 발표되었다. 이 선언은 AI 시스템의 안전성을 보장하기 위해 모든 이해관계자의 협력이 중요하다고 강조하며, 첨단 AI 개발 기업의 책임을 지적했다.\n",
      "- 영국 총리는 AI 안전 연구소의 출범을 발표하고, 정부 주도의 안전 테스트 계획을 수립할 것이라고 밝혔다. 참가국들은 AI 위험과 가능성에 대한 과학적 평가를 위한 보고서 작성을 합의하고, 한국과 프랑스와의 후속 정상회의 계획도 논의되었다.\n",
      "- 한편, 미국 캘리포니아 북부지방법원은 예술가들이 미드저니, 스태빌리티AI, 디비언트아트를 상대로 제기한 저작권 침해 소송을 기각하였다. 기각 사유는 고소장에 제시된 작품들이 저작권청에 등록되지 않았고, AI로 생성된 이미지와 특정 작품 간의 유사성을 입증하기 어렵다는 점이었다. 판사는 원고 측에 고소장을 수정하고 저작권이 침해된 특정 이미지를 중심으로 소송 범위를 줄여 다시 제기할 것을 요청하였다. 그러나 사라 앤더슨이 저작권을 보유한 16개 작품에 대한 스태빌리티AI의 저작권 침해 소송은 계속 진행된다.\n",
      "\n",
      "-----------------\n",
      "\n",
      "\n",
      "- 미국 바이든 대통령이 안전하고 신뢰할 수 있는 AI 개발과 사용을 위한 행정명령을 발표하였다.\n",
      "- 이 행정명령은 AI의 안전과 보안 기준, 개인정보 보호, 형평성과 시민권 향상, 소비자 보호, 노동자 지원, 혁신과 경쟁 촉진, 국제 협력을 포함한다.\n",
      "- AI 시스템 개발 기업은 안전 테스트 결과와 시스템 정보를 정부와 공유해야 하며, AI의 책임 있는 사용을 위한 법적 지침이 마련된다.\n",
      "- 의료 분야에서의 AI 사용 촉진과 학교 내 AI 교육 도구 개발을 통해 소비자와 근로자를 보호하는 원칙이 설정된다.\n",
      "- 국가 차원에서 AI 연구 인프라를 확충하고 외국인 전문가의 유입을 지원하여 AI 분야의 혁신을 촉진할 계획이다.\n",
      "- G7은 '히로시마 AI 프로세스'를 통해 AI 기업을 위한 국제 행동강령에 합의하였으며, 이는 AI 시스템의 위험 식별과 완화를 위한 자발적 채택을 권장하고, 위험 평가와 투명성, 책임성을 강조한다.\n",
      "- G7은 AI 기술의 빠른 발전에 대응하기 위해 행동강령을 개정할 계획이며, 사회적 위험 완화와 세계적 문제 해결을 위한 AI 시스템 개발을 우선시하고 국제 기술 표준의 개발을 가속화할 예정이다.\n",
      "- 또한, 28개국이 참여한 영국 AI 안전성 정상회의에서 AI 안전 보장을 위한 블레츨리 선언이 발표되었다. 이 선언은 AI 시스템의 안전성을 보장하기 위해 모든 이해관계자의 협력이 중요하다고 강조하며, 첨단 AI 개발 기업의 책임을 지적했다.\n",
      "- 영국 총리는 AI 안전 연구소의 출범을 발표하고, 정부 주도의 안전 테스트 계획을 수립할 것이라고 밝혔다. 참가국들은 AI 위험과 가능성에 대한 과학적 평가를 위한 보고서 작성을 합의하고, 한국과 프랑스와의 후속 정상회의 계획도 논의되었다.\n",
      "- 한편, 미국 캘리포니아 북부지방법원은 예술가들이 미드저니, 스태빌리티AI, 디비언트아트를 상대로 제기한 저작권 침해 소송을 기각하였다. 기각 사유는 고소장에 제시된 작품들이 저작권청에 등록되지 않았고, AI로 생성된 이미지와 특정 작품 간의 유사성을 입증하기 어렵다는 점이었다. 판사는 원고 측에 고소장을 수정하고 저작권이 침해된 특정 이미지를 중심으로 소송 범위를 줄여 다시 제기할 것을 요청하였다. 그러나 사라 앤더슨이 저작권을 보유한 16개 작품에 대한 스태빌리티AI의 저작권 침해 소송은 계속 진행된다.\n",
      "- 미국 연방거래위원회(FTC)는 저작권청에 AI와 관련된 소비자 보호 및 경쟁 문제에 대한 의견서를 제출했다. FTC는 생성 AI가 소비자와 창작자에게 피해를 줄 수 있으며, 일부 빅테크가 시장 지배력을 강화할 우려가 있다고 경고했다. 생성 AI의 사용으로 인해 소비자의 개인정보 침해, 차별, 사기 범죄 등의 위험이 존재한다고 지적했다. FTC는 저작권법에 저촉되는 행위가 불공정 경쟁이나 기만행위로 이어질 수 있음을 강조하며, 창작자의 권리 보호를 위한 조치를 취할 것이라고 밝혔다. FTC는 AI 관련 불법 행위에 대해 법적 권한을 활용하여 소비자를 보호하고 공정한 경쟁 시장을 유지하겠다고 다짐했다.\n",
      "\n",
      "-----------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "refined_summary = map_refine_chain.invoke(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ec847a",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Chain of Density\n",
    "- https://arxiv.org/pdf/2309.04269\n",
    "- **Chain of Density\" (CoD) 프롬프트는 GPT-4를 사용한 요약 생성을 개선하기 위해 개발된 기법**\n",
    "  - 이 방법은 초기에 개체가 적은 요약을 생성한 후, 길이를 늘리지 않으면서 누락된 중요 개체들을 반복적으로 통합하는 과정을 거침. \n",
    "  - 연구 결과, CoD로 생성된 요약은 일반 프롬프트보다 더 추상적이고 정보 융합이 뛰어나며, 인간이 작성한 요약과 비슷한 밀도를 가진 것으로 나타남\n",
    "\n",
    "<br>\n",
    "\n",
    "- **점진적 개선**: CoD는 초기에 개체가 적은 간단한 요약을 생성한 후, 단계적으로 중요한 개체들을 추가하며 요약을 개선\n",
    "  - 이 과정에서 요약의 길이는 유지되면서 정보 밀도가 증가하여 읽기 쉬우면서도 정보량이 풍부한 요약이 생성\n",
    "\n",
    "- **정보 밀도와 가독성의 균형**: CoD 방식은 요약의 정보 밀도를 조절하여 정보성과 가독성 사이의 최적 균형점을 탐색\n",
    "  - 연구 결과에 따르면, 사람들은 일반적인 GPT-4 요약보다 더 밀도 있지만 사람이 작성한 요약만큼 밀도가 높지 않은 CoD 요약을 선호하는 것으로 나타남\n",
    "\n",
    "- **추상화와 정보 융합 개선**: CoD로 생성된 요약은 더 추상적이고 정보 융합이 뛰어나며, 원문의 앞부분에 치우치는 경향(lead bias)이 덜함. \n",
    "  - 이는 요약의 전반적인 품질과 가독성을 향상시키는 데 기여\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Chain of Density Prompt 입력 파라미터\n",
    "- **`content_category`**: 콘텐츠 종류(예: 기사, 동영상 녹취록, 블로그 게시물, 연구 논문). 기본값: Article\n",
    "- **`content`**: 요약할 콘텐츠\n",
    "- **`entity_range`**: 콘텐츠에서 선택하여 요약에 추가할 엔티티의 수의 범위. 기본값은 1-3\n",
    "- **`max_words`**: 1번 요약시, 요약에 포함할 최대 단어. 기본값은 80\n",
    "- **`iterations`**: 엔티티 고밀도화 라운드 수. 총 요약은 반복 횟수+1 \n",
    "  - 80단어의 경우 3회 반복이 이상적\n",
    "  - 요약이 더 길면 4~5회, 그리고 `entity_range`를 1~4로 변경하는 것도 유용\n",
    "  - 기본값: 3\n",
    "  - 이 코드는 Chain of Density 프롬프트를 사용하여 텍스트 요약을 생성하는 체인을 구성\n",
    "\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "405a4e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "from langchain_classic import hub\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import SimpleJsonOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7069c1e",
   "metadata": {},
   "source": [
    "- `{content}`를 제외한 모든 입력에 대한 기본값 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cbb301f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cod_chain_inputs = {\n",
    "    \"content\": lambda d: d.get(\"content\"),\n",
    "    \"content_category\": lambda d: d.get(\"content_category\", \"Article\"),\n",
    "    \"entity_range\": lambda d: d.get(\"entity_range\", \"1-3\"),\n",
    "    \"max_words\": lambda d: int(d.get(\"max_words\", 80)),\n",
    "    \"iterations\": lambda d: int(d.get(\"iterations\", 5)),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54801a2c",
   "metadata": {},
   "source": [
    "- Chain of Density 프롬프트 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "aed83011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "As an expert copy-writer, you will write increasingly concise, entity-dense summaries of the user provided \u001b[33;1m\u001b[1;3m{content_category}\u001b[0m. The initial summary should be under \u001b[33;1m\u001b[1;3m{max_words}\u001b[0m words and contain \u001b[33;1m\u001b[1;3m{entity_range}\u001b[0m informative Descriptive Entities from the \u001b[33;1m\u001b[1;3m{content_category}\u001b[0m.\n",
      "\n",
      "A Descriptive Entity is:\n",
      "- Relevant: to the main story.\n",
      "- Specific: descriptive yet concise (5 words or fewer).\n",
      "- Faithful: present in the \u001b[33;1m\u001b[1;3m{content_category}\u001b[0m.\n",
      "- Anywhere: located anywhere in the \u001b[33;1m\u001b[1;3m{content_category}\u001b[0m.\n",
      "\n",
      "# Your Summarization Process\n",
      "- Read through the \u001b[33;1m\u001b[1;3m{content_category}\u001b[0m and the all the below sections to get an understanding of the task.\n",
      "- Pick \u001b[33;1m\u001b[1;3m{entity_range}\u001b[0m informative Descriptive Entities from the \u001b[33;1m\u001b[1;3m{content_category}\u001b[0m (\";\" delimited, do not add spaces).\n",
      "- In your output JSON list of dictionaries, write an initial summary of max \u001b[33;1m\u001b[1;3m{max_words}\u001b[0m words containing the Entities.\n",
      "- You now have `[{\"missing_entities\": \"...\", \"denser_summary\": \"...\"}]`\n",
      "\n",
      "Then, repeat the below 2 steps \u001b[33;1m\u001b[1;3m{iterations}\u001b[0m times:\n",
      "\n",
      "- Step 1. In a new dict in the same list, identify \u001b[33;1m\u001b[1;3m{entity_range}\u001b[0m new informative Descriptive Entities from the \u001b[33;1m\u001b[1;3m{content_category}\u001b[0m which are missing from the previously generated summary.\n",
      "- Step 2. Write a new, denser summary of identical length which covers every Entity and detail from the previous summary plus the new Missing Entities.\n",
      "\n",
      "A Missing Entity is:\n",
      "- An informative Descriptive Entity from the \u001b[33;1m\u001b[1;3m{content_category}\u001b[0m as defined above.\n",
      "- Novel: not in the previous summary.\n",
      "\n",
      "# Guidelines\n",
      "- The first summary should be long (max \u001b[33;1m\u001b[1;3m{max_words}\u001b[0m words) yet highly non-specific, containing little information beyond the Entities marked as missing. Use overly verbose language and fillers (e.g., \"this \u001b[33;1m\u001b[1;3m{content_category}\u001b[0m discusses\") to reach ~\u001b[33;1m\u001b[1;3m{max_words}\u001b[0m words.\n",
      "- Make every word count: re-write the previous summary to improve flow and make space for additional entities.\n",
      "- Make space with fusion, compression, and removal of uninformative phrases like \"the \u001b[33;1m\u001b[1;3m{content_category}\u001b[0m discusses\".\n",
      "- The summaries should become highly dense and concise yet self-contained, e.g., easily understood without the \u001b[33;1m\u001b[1;3m{content_category}\u001b[0m.\n",
      "- Missing entities can appear anywhere in the new summary.\n",
      "- Never drop entities from the previous summary. If space cannot be made, add fewer new entities.\n",
      "- You're finished when your JSON list has 1+\u001b[33;1m\u001b[1;3m{iterations}\u001b[0m dictionaries of increasing density.\n",
      "\n",
      "# IMPORTANT\n",
      "- Remember, to keep each summary to max \u001b[33;1m\u001b[1;3m{max_words}\u001b[0m words.\n",
      "- Never remove Entities or details. Only add more from the \u001b[33;1m\u001b[1;3m{content_category}\u001b[0m.\n",
      "- Do not discuss the \u001b[33;1m\u001b[1;3m{content_category}\u001b[0m itself, focus on the content: informative Descriptive Entities, and details.\n",
      "- Remember, if you're overusing filler phrases in later summaries, or discussing the \u001b[33;1m\u001b[1;3m{content_category}\u001b[0m itself, not its contents, choose more informative Descriptive Entities and include more details from the \u001b[33;1m\u001b[1;3m{content_category}\u001b[0m.\n",
      "- Answer with a minified JSON list of dictionaries with keys \"missing_entities\" and \"denser_summary\".\n",
      "- \"denser_summary\" should be written in the same language as the \"content\".\n",
      "\n",
      "## Example output\n",
      "[{\"missing_entities\": \"ent1;ent2\", \"denser_summary\": \"<vague initial summary with entities 'ent1','ent2'>\"}, {\"missing_entities\": \"ent3\", \"denser_summary\": \"denser summary with 'ent1','ent2','ent3'\"}, ...]\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "\u001b[33;1m\u001b[1;3m{content_category}\u001b[0m:\n",
      "\u001b[33;1m\u001b[1;3m{content}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "cod_prompt = hub.pull(\"teddynote/chain-of-density-prompt\")\n",
    "cod_prompt.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d0e9a7",
   "metadata": {},
   "source": [
    "- Chain of Density 체인 생성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "db98f900",
   "metadata": {},
   "outputs": [],
   "source": [
    "cod_chain = (\n",
    "    cod_chain_inputs\n",
    "    | cod_prompt\n",
    "    | ChatOpenAI(temperature=0, model=\"gpt-4o-mini\")\n",
    "    | SimpleJsonOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7c905e",
   "metadata": {},
   "source": [
    "- 두 번째 체인 생성, 최종 요약만 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5cf66b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "cod_final_summary_chain = cod_chain | (\n",
    "    lambda output: output[-1].get(\n",
    "        \"denser_summary\", '오류: 마지막 딕셔너리에 \"denser_summary\" 키가 없습니다'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "630dc6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = docs[1].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e02ff7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과를 저장할 빈 리스트 초기화\n",
    "results: list[dict[str, str]] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "14291c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'missing_entities': 'G7;AI 국제 행동강령;히로시마 AI 프로세스', 'denser_summary': 'G7은 2023년 10월 30일 히로시마 AI 프로세스를 통해 AI 기업을 위한 AI 국제 행동강령을 합의했다. 이 행동강령은 AI 위험 식별과 완화를 위한 자발적 채택을 권장하며, AI 수명주기 전반의 위험 평가, 투명성, 책임성, 정보 공유 및 보안 통제를 요구한다.'}, {'missing_entities': 'AI 위험 식별;투명성;정보 공유', 'denser_summary': 'G7은 2023년 10월 30일 히로시마 AI 프로세스를 통해 AI 기업을 위한 AI 국제 행동강령을 합의했다. 이 행동강령은 AI 위험 식별과 완화를 위한 자발적 채택을 권장하며, AI 수명주기 전반의 위험 평가, 투명성 및 책임성, 정보 공유와 보안 통제를 요구한다.'}, {'missing_entities': 'AI 수명주기;보안 통제;AI 거버넌스', 'denser_summary': 'G7은 2023년 10월 30일 히로시마 AI 프로세스를 통해 AI 기업을 위한 AI 국제 행동강령을 합의했다. 이 행동강령은 AI 위험 식별과 완화를 위한 자발적 채택을 권장하며, AI 수명주기 전반의 위험 평가, 투명성, 정보 공유, 보안 통제 및 AI 거버넌스를 요구한다.'}, {'missing_entities': '물리보안;사이버보안;신뢰할 수 있는 콘텐츠', 'denser_summary': 'G7은 2023년 10월 30일 히로시마 AI 프로세스를 통해 AI 기업을 위한 AI 국제 행동강령을 합의했다. 이 행동강령은 AI 위험 식별과 완화를 위한 자발적 채택을 권장하며, AI 수명주기 전반의 위험 평가, 투명성, 정보 공유, 물리보안, 사이버보안 및 신뢰할 수 있는 콘텐츠 인증을 요구한다.'}, {'missing_entities': '기후 위기;세계 보건;교육', 'denser_summary': 'G7은 2023년 10월 30일 히로시마 AI 프로세스를 통해 AI 기업을 위한 AI 국제 행동강령을 합의했다. 이 행동강령은 AI 위험 식별과 완화를 위한 자발적 채택을 권장하며, AI 수명주기 전반의 위험 평가, 투명성, 정보 공유, 물리보안, 사이버보안, 신뢰할 수 있는 콘텐츠 인증 및 기후 위기, 세계 보건, 교육 문제 해결을 요구한다.'}]\r"
     ]
    }
   ],
   "source": [
    "# cod_chain을 스트리밍 모드로 실행하고 부분적인 JSON 결과를 처리\n",
    "for partial_json in cod_chain.stream(\n",
    "    {\"content\": content, \"content_category\": \"Article\"}\n",
    "):\n",
    "    # 각 반복마다 results를 업데이트\n",
    "    results = partial_json\n",
    "\n",
    "    # 현재 결과를 같은 줄에 출력 (캐리지 리턴을 사용하여 이전 출력을 덮어씀)\n",
    "    print(results, end=\"\\r\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "35a2c21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "### CoD Summary 1/5, 추가된 엔티티(entity): G7, AI 국제 행동강령, 히로시마 AI 프로세스\n",
      "\n",
      "G7은 2023년 10월 30일 히로시마 AI 프로세스를 통해 AI 기업을 위한 AI 국제 행동강령을 합의했다. 이 행동강령은 AI 위험 식별과\n",
      "완화를 위한 자발적 채택을 권장하며, AI 수명주기 전반의 위험 평가, 투명성, 책임성, 정보 공유 및 보안 통제를 요구한다.\n",
      "\n",
      "### CoD Summary 2/5, 추가된 엔티티(entity): AI 위험 식별, 투명성, 정보 공유\n",
      "\n",
      "G7은 2023년 10월 30일 히로시마 AI 프로세스를 통해 AI 기업을 위한 AI 국제 행동강령을 합의했다. 이 행동강령은 AI 위험 식별과\n",
      "완화를 위한 자발적 채택을 권장하며, AI 수명주기 전반의 위험 평가, 투명성 및 책임성, 정보 공유와 보안 통제를 요구한다.\n",
      "\n",
      "### CoD Summary 3/5, 추가된 엔티티(entity): AI 수명주기, 보안 통제, AI 거버넌스\n",
      "\n",
      "G7은 2023년 10월 30일 히로시마 AI 프로세스를 통해 AI 기업을 위한 AI 국제 행동강령을 합의했다. 이 행동강령은 AI 위험 식별과\n",
      "완화를 위한 자발적 채택을 권장하며, AI 수명주기 전반의 위험 평가, 투명성, 정보 공유, 보안 통제 및 AI 거버넌스를 요구한다.\n",
      "\n",
      "### CoD Summary 4/5, 추가된 엔티티(entity): 물리보안, 사이버보안, 신뢰할 수 있는 콘텐츠\n",
      "\n",
      "G7은 2023년 10월 30일 히로시마 AI 프로세스를 통해 AI 기업을 위한 AI 국제 행동강령을 합의했다. 이 행동강령은 AI 위험 식별과\n",
      "완화를 위한 자발적 채택을 권장하며, AI 수명주기 전반의 위험 평가, 투명성, 정보 공유, 물리보안, 사이버보안 및 신뢰할 수 있는 콘텐츠\n",
      "인증을 요구한다.\n",
      "\n",
      "### CoD Summary 5/5, 추가된 엔티티(entity): 기후 위기, 세계 보건, 교육\n",
      "\n",
      "G7은 2023년 10월 30일 히로시마 AI 프로세스를 통해 AI 기업을 위한 AI 국제 행동강령을 합의했다. 이 행동강령은 AI 위험 식별과\n",
      "완화를 위한 자발적 채택을 권장하며, AI 수명주기 전반의 위험 평가, 투명성, 정보 공유, 물리보안, 사이버보안, 신뢰할 수 있는 콘텐츠 인증\n",
      "및 기후 위기, 세계 보건, 교육 문제 해결을 요구한다.\n",
      "\n",
      "\n",
      "============== [최종 요약] =================\n",
      "\n",
      "G7은 2023년 10월 30일 히로시마 AI 프로세스를 통해 AI 기업을 위한 AI 국제 행동강령을 합의했다. 이 행동강령은 AI 위험 식별과 완화를 위한 자발적 채택을 권장하며, AI 수명주기 전반의 위험 평가, 투명성, 정보 공유, 물리보안, 사이버보안, 신뢰할 수 있는 콘텐츠 인증 및 기후 위기, 세계 보건, 교육 문제 해결을 요구한다.\n"
     ]
    }
   ],
   "source": [
    "# 총 요약 수 계산\n",
    "total_summaries = len(results)\n",
    "print(\"\\n\")\n",
    "\n",
    "# 각 요약을 순회하며 처리\n",
    "i = 1\n",
    "for cod in results:\n",
    "    # 누락된 엔티티들을 추출하고 포맷팅\n",
    "    added_entities = \", \".join(\n",
    "        [\n",
    "            ent.strip()\n",
    "            for ent in cod.get(\n",
    "                \"missing_entities\", 'ERR: \"missing_entiies\" key not found'\n",
    "            ).split(\";\")\n",
    "        ]\n",
    "    )\n",
    "    # 더 밀도 있는 요약 추출\n",
    "    summary = cod.get(\"denser_summary\", 'ERR: missing key \"denser_summary\"')\n",
    "\n",
    "    # 요약 정보 출력 (번호, 총 개수, 추가된 엔티티)\n",
    "    print(\n",
    "        f\"### CoD Summary {i}/{total_summaries}, 추가된 엔티티(entity): {added_entities}\"\n",
    "        + \"\\n\"\n",
    "    )\n",
    "    # 요약 내용을 80자 너비로 줄바꿈하여 출력\n",
    "    print(textwrap.fill(summary, width=80) + \"\\n\")\n",
    "    i += 1\n",
    "\n",
    "print(\"\\n============== [최종 요약] =================\\n\")\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d6cd2f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G7은 2023년 10월 30일 히로시마 AI 프로세스를 통해 AI 기업을 위한 AI 국제 행동강령을 합의했다. 이 행동강령은 AI 위험 식별과 완화를 위한 자발적 채택을 권장하며, AI 수명주기 전반의 위험 평가, 투명성, 정보 공유, 물리보안, 사이버보안, 신뢰할 수 있는 콘텐츠 인증 및 기후 위기, 세계 보건, 교육 문제 해결을 요구한다.\n"
     ]
    }
   ],
   "source": [
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48410332",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Clustering-Map-Refine\n",
    "- **Map-Reduce나 Map-Refine 방식은 모두 시간이 오래 걸리고, 비용이 많이듬**\n",
    "    \n",
    "    $\\rightarrow$ **문서를 몇 개 (N 개)의 클러스터로 나눈 뒤, 가장 중심축에서 가까운 문서를 클러스터의 대표 문서로 인지하고, 이를 Map-Reduce(혹은 Map-Refine)방식으로 요약**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ce4a5b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3f80e731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = PyMuPDFLoader(\"data/SPRI_AI_Brief_2023년12월호_F.pdf\")\n",
    "docs = loader.load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3672e7ca",
   "metadata": {},
   "source": [
    "- 하나의 문서로 텍스트를 합침 $\\rightarrow$ page별로 구분하지 않기 위함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c8a98527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27977"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b010e59",
   "metadata": {},
   "source": [
    "- `RecursiveCharacterTextSplitter` 를 사용하여 하나의 Text 를 여러 문서로 나눔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0d8b538e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "af431e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "split_docs = text_splitter.split_text(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "25c2784a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 나누어진 문서의 수를 확인\n",
    "len(split_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566b7588",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- `Upstage Embeddings` 모델을 사용하여 문서를 임베딩\n",
    "\n",
    "```python\n",
    "from langchain.upstage import UpstageEmbeddings\n",
    "\n",
    "embeddings = UpstageEmbeddings(model=\"solar-embedding-1-large-passage\")\n",
    "vectors = embeddings.embed_documents(split_docs)\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "- 총 79개의 문서를 10개 클러스터로 나누고, 이때 KMeans 를 사용하여 클러스터링을 수행\n",
    "\n",
    "```python\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "num_clusters = 10\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=123).fit(vectors)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbfb7f0",
   "metadata": {},
   "source": [
    "```python\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "reduced_data_tsne = tsne.fit_transform(np.array(vectors))\n",
    "\n",
    "# seaborn 스타일 설정\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "# 축소된 데이터 플롯\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.scatterplot(\n",
    "    x=reduced_data_tsne[:, 0],\n",
    "    y=reduced_data_tsne[:, 1],\n",
    "    hue=kmeans.labels_,\n",
    "    palette=\"deep\",\n",
    "    s=100,\n",
    ")\n",
    "plt.xlabel(\"Dimension 1\", fontsize=12)\n",
    "plt.ylabel(\"Dimension 2\", fontsize=12)\n",
    "plt.title(\"Clustered Embeddings\", fontsize=16)\n",
    "plt.legend(title=\"Cluster\", title_fontsize=12)\n",
    "\n",
    "# 배경색 설정\n",
    "plt.gcf().patch.set_facecolor(\"white\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "<img src='images/clustered_embeddings.png' width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd47bdcd",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- 각 cluster 의 중심점에 가장 가까운 임베딩을 찾아서 저장\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# 가장 가까운 점들을 저장할 빈 리스트 생성\n",
    "closest_indices = []\n",
    "\n",
    "# 클러스터 수만큼 반복\n",
    "for i in range(num_clusters):\n",
    "\n",
    "    # 해당 클러스터 중심으로부터의 거리 목록 구하기\n",
    "    distances = np.linalg.norm(vectors - kmeans.cluster_centers_[i], axis=1)\n",
    "\n",
    "    # 가장 가까운 점의 인덱스 찾기 (argmin을 사용하여 최소 거리 찾기)\n",
    "    closest_index = np.argmin(distances)\n",
    "\n",
    "    # 해당 인덱스를 가장 가까운 인덱스 리스트에 추가\n",
    "    closest_indices.append(closest_index)\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "- 문서의 요약을 순서대로 진행하기 위하여 오름차순 정렬\n",
    "\n",
    "```python\n",
    "selected_indices = sorted(closest_indices)\n",
    "selected_indices\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "- 선택된 10개의 문서를 출력\n",
    "\n",
    "```python\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "selected_docs = [Document(page_content=split_docs[doc]) for doc in selected_indices]\n",
    "selected_docs\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "- 이전에 생성한 `map_refine_chain`을 사용하여 요약 생성\n",
    "\n",
    "```python\n",
    "refined_summary = map_refine_chain.invoke(selected_docs)\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "- 최종 결과 출력\n",
    "\n",
    "```python\n",
    "print(refined_summary)\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

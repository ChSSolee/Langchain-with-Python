{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "845a5e8b",
   "metadata": {},
   "source": [
    "## 웹 문서(WebBaseLoader)\n",
    "\n",
    "<br>\n",
    "\n",
    "### `WebBaseLoader`\n",
    "- `WebBaseLoader`는 웹 기반 문서를 로드하는 로더\n",
    "- `bs4` 라이브러리를 사용하여 웹 페이지를 파싱\n",
    "  - `bs4.SoupStrainer`를 사용하여 파싱할 요소를 지정\n",
    "  - `bs_kwargs` 매개변수를 사용하여 `bs4.SoupStrainer`의 추가적인 인수를 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0404f918",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3547b340",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bf41f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서의 수: 1\n"
     ]
    }
   ],
   "source": [
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://n.news.naver.com/article/437/0000378416\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            \"div\",\n",
    "            attrs={\"class\": [\"newsct_article _article_body\", \"media_end_head_title\"]},\n",
    "        )\n",
    "    ),\n",
    "    header_template={\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.0.0 Safari/537.36\",\n",
    "    },\n",
    ")\n",
    "\n",
    "docs = loader.load()\n",
    "print(f\"문서의 수: {len(docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d93e66d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n출산 직원에게 '1억원' 쏜다…회사의 파격적 저출생 정책\\n\\n\\n[앵커]올해 아이 낳을 계획이 있는 가족이라면 솔깃할 소식입니다. 정부가 저출생 대책으로 매달 주는 부모 급여, 0세\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b5df38",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "* SSL 인증 오류를 우회하려면, `verify` 옵션을 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1ea787",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader.requests_kwargs = {\"verify\": False}\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb296ae3",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 여러 웹 페이지 로드\n",
    "- `web_paths`에 리스트 전달\n",
    "\n",
    "```python\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=[\n",
    "        \"https://n.news.naver.com/article/437/0000378416\",\n",
    "        \"https://n.news.naver.com/mnews/hotissue/article/092/0002340014?type=series&cid=2000063\",\n",
    "    ],\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            \"div\",\n",
    "            attrs={\"class\": [\"newsct_article _article_body\", \"media_end_head_title\"]},\n",
    "        )\n",
    "    ),\n",
    "    header_template={\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.0.0 Safari/537.36\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# 데이터 로드\n",
    "docs = loader.load()\n",
    "\n",
    "# 문서 수 확인\n",
    "print(len(docs))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896a9095",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- **`requests_per_second` : 초당 요청수 설정**\n",
    "\n",
    "<br>\n",
    "\n",
    "```python\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "loader.requests_per_second = 1\n",
    "docs = loader.aload()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb55cc85",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<br>\n",
    "\n",
    "## 텍스트(`TextLoader`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cc457a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bb3969c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서의 수: 1\n",
      "\n",
      "[메타데이터]\n",
      "\n",
      "{'source': 'data/appendix-keywords.txt'}\n",
      "\n",
      "========= [앞부분] 미리보기 =========\n",
      "\n",
      "Semantic Search\n",
      "\n",
      "정의: 의미론적 검색은 사용자의 질의를 단순한 키워드 매칭을 넘어서 그 의미를 파악하여 관련된 결과를 반환하는 검색 방식입니다.\n",
      "예시: 사용자가 \"태양계 행성\"이라고 검색하면, \"목성\", \"화성\" 등과 같이 관련된 행성에 대한 정보를 반환합니다.\n",
      "연관키워드: 자연어 처리, 검색 알고리즘, 데이터 마이닝\n",
      "\n",
      "Embedding\n",
      "\n",
      "정의: 임베딩은 단어나 문장 같은 텍스트 데이터를 저차원의 연속적인 벡터로 변환하는 과정입니다. 이를 통해 컴퓨터가 텍스트를 이해하고 처리할 수 있게 합니다.\n",
      "예시: \"사과\"라는 단어를 [0.65, -0.23, 0.17]과 같은 벡터로 표현합니다.\n",
      "연관키워드: 자연어 처리, 벡터화, 딥러닝\n",
      "\n",
      "Token\n",
      "\n",
      "정의: 토큰은 텍스트를 더 작은 단위로 분할하는 것을 의미합니다. 이는 일반적으로 단어, 문장, 또는 구절일 수 있습니다.\n",
      "예시: 문장 \"나는 학교에 간다\"를 \"나는\", \"학교에\", \"간다\"로 분할합니다.\n",
      "연관키워드: 토큰화, 자연어\n"
     ]
    }
   ],
   "source": [
    "loader = TextLoader(\"data/appendix-keywords.txt\")\n",
    "\n",
    "docs = loader.load()\n",
    "print(f\"문서의 수: {len(docs)}\\n\")\n",
    "print(\"[메타데이터]\\n\")\n",
    "print(docs[0].metadata)\n",
    "print(\"\\n========= [앞부분] 미리보기 =========\\n\")\n",
    "print(docs[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461b83e3",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 파일 인코딩 자동 감지\n",
    "- **`silent_errors`**: 디렉토리로더에 `silent_errors` 매개변수를 전달하여 로드할 수 없는 파일을 건너뛰고 로드 프로세스를 계속할 수 있음\n",
    "- **`autodetect_encoding`**: 로더 클래스에 자동 감지 인코딩을 전달하여 실패하기 전에 파일 인코딩을 자동으로 감지하도록 요청"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87f60c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5e1bcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/\"\n",
    "\n",
    "text_loader_kwargs = {\"autodetect_encoding\": True}\n",
    "\n",
    "loader = DirectoryLoader(\n",
    "    path,\n",
    "    glob=\"**/*.txt\",\n",
    "    loader_cls=TextLoader,\n",
    "    silent_errors=True,\n",
    "    loader_kwargs=text_loader_kwargs,\n",
    ")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3500aae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data\\\\appendix-keywords-CP949.txt',\n",
       " 'data\\\\appendix-keywords-EUCKR.txt',\n",
       " 'data\\\\appendix-keywords-utf8.txt',\n",
       " 'data\\\\appendix-keywords.txt',\n",
       " 'data\\\\chain-of-density.txt',\n",
       " 'data\\\\reference.txt']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_sources = [doc.metadata[\"source\"] for doc in docs]\n",
    "doc_sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ba1b5b",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<br>\n",
    "\n",
    "## JSON\n",
    "\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c089974",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bdb9ad73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'address': {'city': '서울', 'street': '312번지', 'zipCode': '83795'},\n",
      "  'age': 31,\n",
      "  'carOwnership': True,\n",
      "  'hobbies': ['요리', '음악 감상', '사진 촬영'],\n",
      "  'isMarried': True,\n",
      "  'name': '박시우',\n",
      "  'phoneNumbers': ['483-4639-1933', '947-4179-7976']},\n",
      " {'address': {'city': '서울', 'street': '877번지', 'zipCode': '36780'},\n",
      "  'age': 31,\n",
      "  'carOwnership': True,\n",
      "  'hobbies': ['여행', '음악 감상', '등산'],\n",
      "  'isMarried': False,\n",
      "  'name': '정수아',\n",
      "  'phoneNumbers': ['337-5721-3227', '387-3768-9586']},\n",
      " {'address': {'city': '서울', 'street': '175번지', 'zipCode': '89067'},\n",
      "  'age': 43,\n",
      "  'carOwnership': True,\n",
      "  'hobbies': ['등산', '독서', '게임'],\n",
      "  'isMarried': False,\n",
      "  'name': '최도윤',\n",
      "  'phoneNumbers': ['354-5563-4638', '471-9212-1826']}]\n"
     ]
    }
   ],
   "source": [
    "file_path = \"data/people.json\"\n",
    "data = json.loads(Path(file_path).read_text())\n",
    "\n",
    "pprint(data[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd765cd8",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### `JSONLoader`\n",
    "\n",
    "```bash\n",
    "$ pip install jq\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c780f15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import JSONLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7c10417d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\Sol\\\\Python\\\\LangChain\\\\data\\\\people.json', 'seq_num': 1}, page_content='[\"483-4639-1933\", \"947-4179-7976\"]'),\n",
      " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\Sol\\\\Python\\\\LangChain\\\\data\\\\people.json', 'seq_num': 2}, page_content='[\"337-5721-3227\", \"387-3768-9586\"]'),\n",
      " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\Sol\\\\Python\\\\LangChain\\\\data\\\\people.json', 'seq_num': 3}, page_content='[\"354-5563-4638\", \"471-9212-1826\"]'),\n",
      " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\Sol\\\\Python\\\\LangChain\\\\data\\\\people.json', 'seq_num': 4}, page_content='[\"468-2796-2152\", \"922-5760-7030\"]'),\n",
      " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\Sol\\\\Python\\\\LangChain\\\\data\\\\people.json', 'seq_num': 5}, page_content='[\"751-2823-8259\", \"722-7267-9516\"]'),\n",
      " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\Sol\\\\Python\\\\LangChain\\\\data\\\\people.json', 'seq_num': 6}, page_content='[\"462-4433-5968\", \"483-1709-4850\"]'),\n",
      " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\Sol\\\\Python\\\\LangChain\\\\data\\\\people.json', 'seq_num': 7}, page_content='[\"382-2779-3692\", \"835-4343-5346\"]'),\n",
      " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\Sol\\\\Python\\\\LangChain\\\\data\\\\people.json', 'seq_num': 8}, page_content='[\"136-2831-1021\", \"818-9721-7208\"]'),\n",
      " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\Sol\\\\Python\\\\LangChain\\\\data\\\\people.json', 'seq_num': 9}, page_content='[\"423-5001-2734\", \"256-4271-3750\"]'),\n",
      " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\Sol\\\\Python\\\\LangChain\\\\data\\\\people.json', 'seq_num': 10}, page_content='[\"668-1157-6180\", \"815-9997-6459\"]'),\n",
      " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\Sol\\\\Python\\\\LangChain\\\\data\\\\people.json', 'seq_num': 11}, page_content='[\"745-5529-4411\", \"437-3892-3668\"]'),\n",
      " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\Sol\\\\Python\\\\LangChain\\\\data\\\\people.json', 'seq_num': 12}, page_content='[\"914-2071-3446\", \"539-6835-4629\"]'),\n",
      " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\Sol\\\\Python\\\\LangChain\\\\data\\\\people.json', 'seq_num': 13}, page_content='[\"709-3578-3445\", \"907-3295-1822\"]'),\n",
      " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\Sol\\\\Python\\\\LangChain\\\\data\\\\people.json', 'seq_num': 14}, page_content='[\"508-9125-7029\", \"939-1920-5084\"]'),\n",
      " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\Sol\\\\Python\\\\LangChain\\\\data\\\\people.json', 'seq_num': 15}, page_content='[\"891-2980-9497\", \"811-3249-9899\"]'),\n",
      " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\Sol\\\\Python\\\\LangChain\\\\data\\\\people.json', 'seq_num': 16}, page_content='[\"499-4872-5904\", \"140-3733-7715\"]'),\n",
      " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\Sol\\\\Python\\\\LangChain\\\\data\\\\people.json', 'seq_num': 17}, page_content='[\"672-6315-8675\", \"975-1259-1656\"]'),\n",
      " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\Sol\\\\Python\\\\LangChain\\\\data\\\\people.json', 'seq_num': 18}, page_content='[\"853-1953-3723\", \"408-3476-1336\"]'),\n",
      " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\Sol\\\\Python\\\\LangChain\\\\data\\\\people.json', 'seq_num': 19}, page_content='[\"290-8270-9786\", \"483-1765-4028\"]'),\n",
      " Document(metadata={'source': 'C:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\Sol\\\\Python\\\\LangChain\\\\data\\\\people.json', 'seq_num': 20}, page_content='[\"460-4533-7245\", \"344-2344-7362\"]')]\n"
     ]
    }
   ],
   "source": [
    "loader = JSONLoader(\n",
    "    file_path=\"data/people.json\",\n",
    "    jq_schema=\".[].phoneNumbers\",\n",
    "    text_content=False,\n",
    ")\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "pprint(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf4acab",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<br>\n",
    "\n",
    "## [Arxiv](https://arxiv.org/)\n",
    "- arXiv은 물리학, 수학, 컴퓨터 과학, 정량 생물학, 정량 금융, 통계, 전기공학 및 시스템 과학, 경제학 분야의 200만 편의 학술 논문을 위한 오픈 액세스 아카이브"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1456794b",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "```bash\n",
    "$ pip install -qU langchain-community arxiv pymupdf\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae218c90",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 1. 객체 생성\n",
    "- `model` 객체를 인스턴스화하고 문서를 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "531b6611",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import ArxivLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c701e2d",
   "metadata": {},
   "source": [
    "- `Query` 에 검색하고자 하는 논문의 주제를 입력\n",
    "- `load_max_docs` : 최대 문서 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724bb8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = ArxivLoader(\n",
    "    query=\"Chain of thought\",\n",
    "    load_max_docs=2,\n",
    "    load_all_available_meta=True,  # 메타데이터 전체 로드 여부\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ac354f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = loader.load()\n",
    "# docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85f6bc70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Published': '2024-10-04',\n",
       " 'Title': 'Understanding Reasoning in Chain-of-Thought from the Hopfieldian View',\n",
       " 'Authors': 'Lijie Hu, Liang Liu, Shu Yang, Xin Chen, Zhen Tan, Muhammad Asif Ali, Mengdi Li, Di Wang',\n",
       " 'Summary': \"Large Language Models have demonstrated remarkable abilities across various tasks, with Chain-of-Thought (CoT) prompting emerging as a key technique to enhance reasoning capabilities. However, existing research primarily focuses on improving performance, lacking a comprehensive framework to explain and understand the fundamental factors behind CoT's success. To bridge this gap, we introduce a novel perspective grounded in the Hopfieldian view of cognition in cognitive neuroscience. We establish a connection between CoT reasoning and key cognitive elements such as stimuli, actions, neural populations, and representation spaces. From our view, we can understand the reasoning process as the movement between these representation spaces. Building on this insight, we develop a method for localizing reasoning errors in the response of CoTs. Moreover, we propose the Representation-of-Thought (RoT) framework, which leverages the robustness of low-dimensional representation spaces to enhance the robustness of the reasoning process in CoTs. Experimental results demonstrate that RoT improves the robustness and interpretability of CoT reasoning while offering fine-grained control over the reasoning process.\",\n",
       " 'entry_id': 'http://arxiv.org/abs/2410.03595v1',\n",
       " 'published_first_time': '2024-10-04',\n",
       " 'comment': '28 pages, a new version of \"A Hopfieldian View-based Interpretation for Chain-of-Thought Reasoning\"',\n",
       " 'journal_ref': None,\n",
       " 'doi': None,\n",
       " 'primary_category': 'cs.AI',\n",
       " 'categories': ['cs.AI', 'cs.CL', 'cs.LG'],\n",
       " 'links': ['https://arxiv.org/abs/2410.03595v1',\n",
       "  'https://arxiv.org/pdf/2410.03595v1']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390f2d2e",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 논문 요약\n",
    "- **`get_summaries_as_docs()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06f38afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large Language Models have demonstrated remarkable abilities across various tasks, with Chain-of-Thought (CoT) prompting emerging as a key technique to enhance reasoning capabilities. However, existing research primarily focuses on improving performance, lacking a comprehensive framework to explain and understand the fundamental factors behind CoT's success. To bridge this gap, we introduce a novel perspective grounded in the Hopfieldian view of cognition in cognitive neuroscience. We establish a connection between CoT reasoning and key cognitive elements such as stimuli, actions, neural populations, and representation spaces. From our view, we can understand the reasoning process as the movement between these representation spaces. Building on this insight, we develop a method for localizing reasoning errors in the response of CoTs. Moreover, we propose the Representation-of-Thought (RoT) framework, which leverages the robustness of low-dimensional representation spaces to enhance the robustness of the reasoning process in CoTs. Experimental results demonstrate that RoT improves the robustness and interpretability of CoT reasoning while offering fine-grained control over the reasoning process.\n"
     ]
    }
   ],
   "source": [
    "docs = loader.get_summaries_as_docs()\n",
    "\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc55c63",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<br>\n",
    "\n",
    "## `LlamaParser`\n",
    "- `LlamaParse` : LlamaIndex에서 개발한 문서 파싱 서비스로, 대규모 언어 모델(LLM)을 위해 특별히 설계\n",
    "  - PDF, Word, PowerPoint, Excel 등 다양한 문서 형식 지원\n",
    "  - 자연어 지시를 통한 맞춤형 출력 형식 제공\n",
    "  - 복잡한 표와 이미지 추출 기능\n",
    "  - JSON 모드 지원\n",
    "  - 외국어 지원\n",
    "- 사용자는 무료로 하루 1,000페이지를 처리할 수 있으며, 유료 플랜을 통해 추가 용량을 확보\n",
    "  \n",
    "<br>\n",
    "\n",
    "```bash\n",
    "$ pip install llama-index-core llama-parse llama-index-readers-file\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c2e42e",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- API 키 설정 : API 키를 발급 후 `.env` 파일에 `LLAMA_CLOUD_API_KEY` 에 설정\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe085e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from llama_parse import LlamaParse\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9f358c",
   "metadata": {},
   "source": [
    "- 파서 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "426050bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = LlamaParse(\n",
    "    result_type=\"markdown\",  # \"markdown\"과 \"text\" 사용 가능\n",
    "    num_workers=8,  # worker 수 (기본값: 4)\n",
    "    verbose=True,\n",
    "    language=\"ko\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491bd671",
   "metadata": {},
   "source": [
    "- `SimpleDirectoryReader`를 사용하여 파일 파싱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ca31577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id cbfc58a0-c066-46c1-b919-8d929fb2a72f\n"
     ]
    }
   ],
   "source": [
    "file_extractor = {\".pdf\": parser}\n",
    "\n",
    "documents = SimpleDirectoryReader(\n",
    "    input_files=[\"data/SPRI_AI_Brief_2023년12월호_F.pdf\"],\n",
    "    file_extractor=file_extractor,\n",
    ").load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "446e3ec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54809295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# SPRiAl Brief\\n\\n# 인공지능 산업의 최신동향\\n\\n# 2023년 12월호\\n\\n# SPRi소프트웨어정책연구소\\n\\n# Software Policy &#x26; Research Institute\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa9b0d4",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### `LlamaIndex` $\\rightarrow$  LangChain Document 로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c20c02a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [doc.to_langchain_format() for doc in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95d33906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# SPRiAl Brief\\n\\n# 인공지능 산업의 최신동향\\n\\n# 2023년 12월호\\n\\n# SPRi소프트웨어정책연구소\\n\\n# Software Policy &#x26; Research Institute\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9331fb5f",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### MultiModal Model로 파싱\n",
    "- `use_vendor_multimodal_model`: 멀티모달 모델 사용 여부를 지정\n",
    "  - `True`로 설정하면 외부 벤더의 멀티모달 모델을 사용\n",
    "- `vendor_multimodal_model_name`: 사용할 멀티모달 모델의 이름을 지정. (여기서는 \"openai-gpt4o\")\n",
    "- `vendor_multimodal_api_key`: 멀티모달 모델 API 키 (환경 변수에서 OpenAI API 키)\n",
    "- `result_type`: 파싱 결과의 형식을 지정 \n",
    "- `language`: 파싱할 문서의 언어를 지정\n",
    "- `skip_diagonal_text`: 대각선 텍스트를 건너뛸지 여부를 결정\n",
    "- `page_separator`: 페이지 구분자를 지정\n",
    "- **`user_prompt` : 사용자 정의 파싱 지침**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9856bf",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- 사용자 정의 파싱 지침"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b5f86d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt  = (\n",
    "    \"You are parsing a brief of AI Report. Please extract tables in markdown format.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdda7d10",
   "metadata": {},
   "source": [
    "- 파서 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7de480c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = LlamaParse(\n",
    "    use_vendor_multimodal_model=True,\n",
    "    vendor_multimodal_model_name=\"openai-gpt4o\",\n",
    "    vendor_multimodal_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    result_type=\"markdown\",\n",
    "    language=\"ko\",\n",
    "    user_prompt=user_prompt \n",
    "    # skip_diagonal_text=True,\n",
    "    # page_separator=\"\\n=================\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe10023a",
   "metadata": {},
   "source": [
    "- parsing 된 결과\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "db118122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 9c936777-d586-41bd-b511-b8c7f35ab9fe\n"
     ]
    }
   ],
   "source": [
    "parsed_docs = documents.load_data(file_path=\"data/SPRI_AI_Brief_2023년12월호_F.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7eb526",
   "metadata": {},
   "source": [
    "- langchain 도큐먼트로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f1cfc2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [doc.to_langchain_format() for doc in parsed_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a4fe12ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n2023년 12월호\\n\\n# CONTENTS\\n\\n## I. 인공지능 산업 동향 브리프\\n\\n1. 정책/법제\\n   - 미국, 안전하고 신뢰할 수 있는 AI 개발과 사용에 관한 행정명령 발표 ........................................ 1\\n   - G7, 히로시마 AI 프로세스를 통해 AI 기업 대상 국제 행동강령에 합의 ........................................ 2\\n   - 영국 AI 안전성 정상회의에 참가한 28개국, AI 위협에 공동 대응 선언 ........................................ 3\\n   - 미국 법원, 예술가들이 생성 AI 기업에 제기한 저작권 소송 기각 ................................................. 4\\n   - 미국 연방거래위원회, 저작권침해 소비자 보호와 경쟁 촉진의 AI 의견서 제출 .......................... 5\\n   - EU AI 법 3자 협상, 기반모델 규제 관련 견해차로 난항 .............................................................. 6\\n\\n2. 기업/산업\\n   - 미국 프런티어 모델 그룹, 1,000만 달러 규모의 AI 안전 기금 조성 ............................................. 7\\n   - 코히어, 데이터 투명성 확보를 위한 데이터 출처 탐색기 공개 ..................................................... 8\\n   - 앤트로픽 클라우드, 최신 LLM ‘동의치원인 2.0’ 공개 ................................................................. 9\\n   - 삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개 ........................................................................ 10\\n   - 구글, 앤스로픽에 20억 달러 투자로 생성 AI 협력 강화 .............................................................. 11\\n   - IDC, 2027년 AI 소프트웨어 매출 2,500억 달러 돌파 전망 ......................................................... 12\\n   - 빌 게이츠, AI 에이전트로 인한 컴퓨터 사용의 패러다임 변화 전망 ........................................... 13\\n   - 유튜브, 2024년부터 AI 생성 콘텐츠 표시 의무화 ....................................................................... 14\\n\\n3. 기술/연구\\n   - 영국 과학혁신기술부, AI 안전 연구소 설립 발표 ......................................................................... 15\\n   - 구글 딥마인드, 범용 AI 모델의 기능과 동작에 대한 분류 체계 발표 ......................................... 16\\n   - 칼럼비아의 LLM 확장 지수 평가에서 GPT-4가 가장 우수 ......................................................... 17\\n\\n4. 인력/교육\\n   - 영국 옥스퍼드 인터넷 연구소, AI 기술자의 임금이 평균 21% 높아 ........................................... 18\\n\\n## II. 주요 행사\\n\\n- CES 2024 ........................................................................................................................................... 19\\n- AIMLA 2024 ....................................................................................................................................... 19\\n- AAAI Conference on Artificial Intelligence ....................................................................................... 19\\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[1].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cda009",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang_env",
   "language": "python",
   "name": "lang_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05183b67",
   "metadata": {},
   "source": [
    "# 01. LangChain\n",
    "\n",
    "- `LangChain`은 언어 모델을 활용해 다양한 애플리케이션을 개발할 수 있는 프레임워크\n",
    "  - 문맥을 인식하는 기능: `LangChain`은 언어 모델을 다양한 문맥 소스와 연결\n",
    "    - 여기에는 프롬프트 지시사항, 소수의 예시, 응답에 근거한 내용 등이 포함\n",
    "    - 이를 통해 언어 모델은 제공된 정보를 기반으로 더 정확하고 관련성 높은 답변을 생성\n",
    "  - 추론하는 기능: 언어 모델은 주어진 문맥을 바탕으로 어떠한 답변을 제공하거나, 어떤 조치를 취해야 할지를 스스로 추론\n",
    "    - 언어 모델이 단순히 정보를 재생산하는 것을 넘어서, 주어진 상황을 분석하고 적절한 해결책을 제시할 수 있음을 의미\n",
    "\n",
    "<br>\n",
    "\n",
    "### 설치\n",
    "\n",
    "```bash\n",
    "$ pip install -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "### 구성\n",
    "- [**LangChain 라이브러리**](https://python.langchain.com/v0.2/docs/introduction/) : Python 및 JavaScript 라이브러리. 다양한 컴포넌트의 인터페이스와 통합, 이러한 컴포넌트를 체인과 에이전트로 결합하는 기본 런타임, 그리고 즉시 사용 가능한 체인과 에이전트의 구현을 포함\n",
    "- [**LangChain 템플릿**](https://templates.langchain.com/) : 다양한 작업을 위한 쉽게 배포할 수 있는 참조 아키텍처 모음\n",
    "- [**LangServe**](https://github.com/langchain-ai/langserve) : LangChain 체인을 REST API로 배포하기 위한 라이브러리\n",
    "- [**LangSmith**](https://smith.langchain.com/) : 어떤 LLM 프레임워크에도 구축된 체인을 디버그, 테스트, 평가, 모니터링할 수 있게 해주며 LangChain과 원활하게 통합되는 개발자 플랫폼\n",
    "- [**LangGraph**](https://langchain-ai.github.io/langgraph/) : LLM을 사용한 상태유지가 가능한 다중 액터 애플리케이션을 구축하기 위한 라이브러리로, LangChain 위에 구축되었으며 LangChain과 함께 사용하도록 설계\n",
    "  - 여러 계산 단계에서 다중 체인(또는 액터)을 순환 방식으로 조정할 수 있는 능력을 LangChain 표현 언어에 추가\n",
    "\n",
    "<br>\n",
    "\n",
    "### 개발 용이성\n",
    "\n",
    "<br>\n",
    "\n",
    "#### **컴포넌트의 조립 및 통합**\n",
    "- LangChain은 언어 모델과의 작업을 위한 조립 가능한 도구 및 통합을 제공\n",
    "- 컴포넌트는 모듈식으로 설계되어, 사용하기 쉬우며, 이는 개발자가 LangChain 프레임워크를 자유롭게 활용\n",
    "  \n",
    "#### **즉시 사용 가능한 체인**\n",
    "- 고수준 작업을 수행하기 위한 컴포넌트의 내장 조합을 제공\n",
    "- 이러한 체인은 개발 과정을 간소화하고 속도를 높임\n",
    "\n",
    "<br>\n",
    "\n",
    "### 주요 모듈\n",
    "\n",
    "<br>\n",
    "\n",
    "- **모델 I/O** : 프롬프트 관리, 최적화 및 LLM과의 일반적인 인터페이스와 작업을 위한 유틸리티를 포함\n",
    "* **검색** : '데이터 강화 생성'에 초점을 맞춘 이 모듈은 생성 단계에서 필요한 데이터를 외부 데이터 소스에서 가져오는 작업을 담당\n",
    "- **에이전트** : 언어 모델이 어떤 조치를 취할지 결정하고, 해당 조치를 실행하며, 관찰하고, 필요한 경우 반복하는 과정을 포함\n",
    "\n",
    "<br>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270dd1cc",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 01-01. OpenAI AI \n",
    "\n",
    "<br>\n",
    "\n",
    "### 1. OpenAI API 웹 사이트 : https://platform.openai.com/docs/overview\n",
    "- Your profile\n",
    "\n",
    "<img src='https://wikidocs.net/images/page/233342/capture-20240611-212254.png' width='500'>\n",
    "\n",
    "- API Key 관리 메뉴 (https://platform.openai.com/api-keys) $\\rightarrow$ Create new secret key\n",
    "\n",
    "<img src='https://wikidocs.net/images/page/233342/capture-20240611-212634.png' width='500'>\n",
    "\n",
    "- Name과 프로젝트 입력\n",
    "\n",
    "<img src='https://wikidocs.net/images/page/233342/capture-20240611-212716.png' width='500'>\n",
    "\n",
    "- Key Copy\n",
    "  - 키가 유출되면 다른 사람이 내 API KEY 를 사용하여 GPT 를 사용할 수 있으며, 결제는 제 지갑에서 결제\n",
    "\n",
    "<img src='https://wikidocs.net/images/page/233342/capture-20240611-212824.png' width='500'>\n",
    "\n",
    "- 환경 (`.env`) 설정\n",
    "  - 프로젝트 루트 디렉토리에 `.env` 파일을 생성\n",
    "  - `.env` 파일에 방금복사한 키를 입력 한 뒤 저장\n",
    "  \n",
    "<img src='https://wikidocs.net/images/page/233342/capture-20240611-213141.png' width='500'>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f19ec8f",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- LangChain 업데이트\n",
    "\n",
    "```bash\n",
    "$ pip install -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b329a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48f1ffa",
   "metadata": {},
   "source": [
    "- API KEY 정보로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37627de8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26ef341",
   "metadata": {},
   "source": [
    "- API Key 가 잘 설정되었는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "355624c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75b672a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"[API KEY]\\n{os.environ['OPENAI_API_KEY']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a18aaeb",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<br>\n",
    "\n",
    "## 01-03. LangSmith 추적 설정\n",
    "\n",
    "<br>\n",
    "\n",
    "### LangSmith 추적 설정\n",
    "- LangSmith는 LLM 애플리케이션 개발, 모니터링 및 테스트 를 위한 플랫폼\n",
    "- 프로젝트나 LangChain 학습을 시작하시는 분들이라면 LangSmith는 꼭 설정 후 진행하는 것을 추천\n",
    "\n",
    "#### LangSmith 추적 기능\n",
    "- 추적은 LLM 애플리케이션의 동작을 이해하기 위한 강력한 도구\n",
    "- LangSmith는 LangChain 사용 여부와 관계없이 동급 최고의 추적 기능을 제공\n",
    "- 추적은 다음과 같은 문제를 추적하는 데 도움\n",
    "  - 예상치 못한 최종 결과\n",
    "  - 에이전트가 루핑되는 이유\n",
    "  - 체인이 예상보다 느린 이유\n",
    "  - 에이전트가 각 단계에서 사용한 토큰 수\n",
    "\n",
    "<br>\n",
    "\n",
    "#### 프로젝트 단위 추적\n",
    "- 프로젝트 단위로 실행 카운트, Error 발생률, 토큰 사용량, 과금 정보등을 확인 가능\n",
    "\n",
    "<img src='https://wikidocs.net/images/page/250954/capture-20240617-192525.png' width='500'>\n",
    "\n",
    "<img src='https://wikidocs.net/images/page/250954/capture-20240617-193239.png' width='500'>\n",
    "\n",
    "<br>\n",
    "\n",
    "- 1개의 실행에 대한 세부 단계별 추적\n",
    "  - 1개의 실행을 한 뒤 retrieve 된 문서의 검색 결과 뿐만 아니라, GPT 의 입출력 내용에 대해서 자세하게 기록\n",
    "     \n",
    "    $\\rightarrow$ 문서의 검색된 내용을 확인 후 검색 알고리즘을 변경해야할지 혹은 프롬프트를 변경해야할지 판단하는데 도움\n",
    "\n",
    "  - 상단에는 1개의 실행(Run) 이 걸린 시간(약 30초)와 사용된 토큰(5,104) 등이 표기가 되고, 토큰에 마우스 호버를 하게 되면 청구 금액까지 표기\n",
    "  \n",
    "<img src='https://wikidocs.net/images/page/250954/capture-20240617-192921.png' width='500'>\n",
    "\n",
    "<br>\n",
    "\n",
    "### LangSmith 추적 사용\n",
    "\n",
    "<br>\n",
    "\n",
    "#### LangSmith API Key 발급\n",
    "\n",
    "1. https://smith.langchain.com 으로 접속\n",
    "2. 가입후 이메일 인증\n",
    "3. 왼쪽 톱니바퀴(Setting) - 가운데 \"Personal\" - \"Create API Key\" 를 눌러 API 키를 발급\n",
    "\n",
    "<img src='https://wikidocs.net/images/page/250954/capture-20240617-194107.png' width='500'>\n",
    "\n",
    "<img src='https://wikidocs.net/images/page/250954/capture-20240617-194249.png' width='500'>\n",
    "\n",
    "<img src='https://wikidocs.net/images/page/250954/capture-20240617-194345.png' width='500'>\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `.env` 에 LangSmith 키 설정\n",
    "1. `.env` 파일에 LangSmith 에서 발급받은 키와 프로젝트 정보를 입력\n",
    "  - `LANGCHAIN_TRACING_V2`: \"true\" 로 설정하면 추적을 시작\n",
    "  - `LANGCHAIN_ENDPOINT`: https://api.smith.langchain.com \n",
    "  - `LANGCHAIN_API_KEY`: 이전 단계에서 발급받은 키 를 입력\n",
    "  - `LANGCHAIN_PROJECT`: 프로젝트 명 을 기입하면 해당 프로젝트 그룹으로 모든 실행(Run) 이 추적\n",
    "\n",
    "<img src='https://wikidocs.net/images/page/250954/capture-20240617-193540.png' width='500'>\n",
    "\n",
    "<br>\n",
    "\n",
    "### Jupyter Notebook 혹은 코드에서 추적을 활성화\n",
    "- .env 에 설정한 내용을 불러옴\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a5d65a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0646f1da",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- 혹은 직접 설정\n",
    "\n",
    "```python\n",
    "import os\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"LangChain 프로젝트명\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"LangChain API KEY 입력\"\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2eba0ec",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 01-04. OpenAI API\n",
    "\n",
    "<br>\n",
    "\n",
    "- `temperature` : 사용할 샘플링 온도는 0과 2 사이에서 선택 \n",
    "  - 0.8과 같은 높은 값은 출력을 더 무작위하게 만들고, 0.2와 같은 낮은 값은 출력을 더 집중되고 결정론적으로\n",
    "  \n",
    "- `max_tokens` : 채팅 완성에서 생성할 토큰의 최대 개수\n",
    "- `model_name` : [적용 가능한 모델](https://platform.openai.com/docs/pricing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "277064aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langsmith import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9bfafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    temperature=0.1,  # 창의성 (0.0 ~ 2.0)\n",
    "    model_name=\"gpt-4o\"\n",
    ")\n",
    "\n",
    "question = \"대한민국의 수도는 어디인가요?\"\n",
    "llm.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3558ac53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run ID: eff473cc-48f0-4196-89b6-cd062ae2e5df\n",
      "입력: {'messages': [[{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': '대한민국의 수도는 어디인가요?', 'type': 'human'}}]]}\n",
      "출력: {'generations': [[{'text': '대한민국의 수도는 서울입니다.', 'generation_info': {'finish_reason': 'stop', 'logprobs': None}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': '대한민국의 수도는 서울입니다.', 'additional_kwargs': {'refusal': None}, 'response_metadata': {'token_usage': {'completion_tokens': 8, 'prompt_tokens': 16, 'total_tokens': 24, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_f33640a400', 'id': 'chatcmpl-CLgvyzD8FdU6wKtDEU9TWr99BWNt6', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, 'type': 'ai', 'id': 'run--eff473cc-48f0-4196-89b6-cd062ae2e5df-0', 'usage_metadata': {'input_tokens': 16, 'output_tokens': 8, 'total_tokens': 24, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}, 'tool_calls': [], 'invalid_tool_calls': []}}}]], 'llm_output': {'token_usage': {'completion_tokens': 8, 'prompt_tokens': 16, 'total_tokens': 24, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_f33640a400', 'id': 'chatcmpl-CLgvyzD8FdU6wKtDEU9TWr99BWNt6', 'service_tier': 'default'}, 'run': None, 'type': 'LLMResult'}\n",
      "실행 시간: 0:00:01.131053\n",
      "토큰 사용량: None\n"
     ]
    }
   ],
   "source": [
    "# LangSmith 클라이언트 생성\n",
    "client = Client()\n",
    "\n",
    "# 가장 최근 실행(run) 불러오기\n",
    "runs = client.list_runs(project_name=\"langsmith-openai\", limit=1)\n",
    "run = next(runs)\n",
    "\n",
    "# 실행 메타데이터 확인\n",
    "print(\"Run ID:\", run.id)\n",
    "print(\"입력:\", run.inputs)\n",
    "print(\"출력:\", run.outputs)\n",
    "print(\"실행 시간:\", run.end_time - run.start_time)\n",
    "print(\"토큰 사용량:\", run.extra.get(\"usage\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11eff1d6",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 답변의 형식(AI Message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1dca1272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='대한민국의 수도는 서울입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 16, 'total_tokens': 24, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_f33640a400', 'id': 'chatcmpl-CLgy6onUVYLXv4q58xLIueHioefW3', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--318fea6a-f906-4794-9345-c93b511ebf00-0', usage_metadata={'input_tokens': 16, 'output_tokens': 8, 'total_tokens': 24, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 질의내용\n",
    "question = \"대한민국의 수도는 어디인가요?\"\n",
    "\n",
    "# 질의\n",
    "response = llm.invoke(question)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d3f8908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'대한민국의 수도는 서울입니다.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45907f61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'completion_tokens': 8,\n",
       "  'prompt_tokens': 16,\n",
       "  'total_tokens': 24,\n",
       "  'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "   'audio_tokens': 0,\n",
       "   'reasoning_tokens': 0,\n",
       "   'rejected_prediction_tokens': 0},\n",
       "  'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       " 'model_name': 'gpt-4o-2024-08-06',\n",
       " 'system_fingerprint': 'fp_f33640a400',\n",
       " 'id': 'chatcmpl-CLgy6onUVYLXv4q58xLIueHioefW3',\n",
       " 'service_tier': 'default',\n",
       " 'finish_reason': 'stop',\n",
       " 'logprobs': None}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.response_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a82bdd",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### LogProb 활성화\n",
    "- 주어진 텍스트에 대한 모델의 **토큰 확률의 로그 값** 을 의미\n",
    "- 토큰이란 문장을 구성하는 개별 단어나 문자 등의 요소를 의미하고, **확률은 모델이 그 토큰을 예측할 확률**을 나타냄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4ab934e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_logprob = ChatOpenAI(\n",
    "    temperature=0.1,  # 창의성 (0.0 ~ 2.0)\n",
    "    max_tokens=2048,  # 최대 토큰수\n",
    "    model_name=\"gpt-4o-mini\",  # 모델명\n",
    ").bind(logprobs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "384e28d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"대한민국의 수도는 어디인가요?\"\n",
    "response = llm_with_logprob.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f638ab96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'completion_tokens': 8,\n",
       "  'prompt_tokens': 16,\n",
       "  'total_tokens': 24,\n",
       "  'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "   'audio_tokens': 0,\n",
       "   'reasoning_tokens': 0,\n",
       "   'rejected_prediction_tokens': 0},\n",
       "  'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       " 'model_name': 'gpt-4o-mini-2024-07-18',\n",
       " 'system_fingerprint': 'fp_560af6e559',\n",
       " 'id': 'chatcmpl-CLgzER7uGylaAKaOQ7PdrGKKaia2G',\n",
       " 'service_tier': 'default',\n",
       " 'finish_reason': 'stop',\n",
       " 'logprobs': {'content': [{'token': '대한',\n",
       "    'bytes': [235, 140, 128, 237, 149, 156],\n",
       "    'logprob': -3.845798710244708e-05,\n",
       "    'top_logprobs': []},\n",
       "   {'token': '민국',\n",
       "    'bytes': [235, 175, 188, 234, 181, 173],\n",
       "    'logprob': -6.704273118884885e-07,\n",
       "    'top_logprobs': []},\n",
       "   {'token': '의',\n",
       "    'bytes': [236, 157, 152],\n",
       "    'logprob': -2.7968066206085496e-05,\n",
       "    'top_logprobs': []},\n",
       "   {'token': ' 수도',\n",
       "    'bytes': [32, 236, 136, 152, 235, 143, 132],\n",
       "    'logprob': -4.0126840758603066e-05,\n",
       "    'top_logprobs': []},\n",
       "   {'token': '는',\n",
       "    'bytes': [235, 138, 148],\n",
       "    'logprob': -5.538490950129926e-05,\n",
       "    'top_logprobs': []},\n",
       "   {'token': ' 서울',\n",
       "    'bytes': [32, 236, 132, 156, 236, 154, 184],\n",
       "    'logprob': -0.00019769940990954638,\n",
       "    'top_logprobs': []},\n",
       "   {'token': '입니다',\n",
       "    'bytes': [236, 158, 133, 235, 139, 136, 235, 139, 164],\n",
       "    'logprob': -0.0017078984528779984,\n",
       "    'top_logprobs': []},\n",
       "   {'token': '.',\n",
       "    'bytes': [46],\n",
       "    'logprob': -1.9361264946837764e-07,\n",
       "    'top_logprobs': []}],\n",
       "  'refusal': None}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.response_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd9050b",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 스트리밍 출력\n",
    "- 스트리밍 옵션은 질의에 대한 답변을 실시간으로 받을 때 유용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2d808b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = llm.stream(\"대한민국의 아름다운 관광지 10곳과 주소를 알려주세요!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3ad802ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "대한민국에는 아름다운 관광지가 많이 있습니다. 아래는 그 중 10곳과 해당 주소입니다.\n",
      "\n",
      "1. **경복궁**\n",
      "   - 주소: 서울특별시 종로구 사직로 161\n",
      "\n",
      "2. **부산 해운대 해수욕장**\n",
      "   - 주소: 부산광역시 해운대구 우동\n",
      "\n",
      "3. **제주 성산일출봉**\n",
      "   - 주소: 제주특별자치도 서귀포시 성산읍 일출로 284-12\n",
      "\n",
      "4. **경주 불국사**\n",
      "   - 주소: 경상북도 경주시 불국로 385\n",
      "\n",
      "5. **설악산 국립공원**\n",
      "   - 주소: 강원도 속초시 설악산로 833\n",
      "\n",
      "6. **전주 한옥마을**\n",
      "   - 주소: 전라북도 전주시 완산구 기린대로 99\n",
      "\n",
      "7. **남이섬**\n",
      "   - 주소: 강원도 춘천시 남산면 남이섬길 1\n",
      "\n",
      "8. **안동 하회마을**\n",
      "   - 주소: 경상북도 안동시 풍천면 전서로 186\n",
      "\n",
      "9. **서울 남산타워 (N서울타워)**\n",
      "   - 주소: 서울특별시 용산구 남산공원길 105\n",
      "\n",
      "10. **순천만 습지**\n",
      "    - 주소: 전라남도 순천시 순천만길 513-25\n",
      "\n",
      "이곳들은 각기 다른 매력을 가지고 있어 다양한 경험을 제공할 것입니다. 여행 계획에 참고하시기 바랍니다!"
     ]
    }
   ],
   "source": [
    "for token in answer:\n",
    "    print(token.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4193bfa",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 멀티모달 모델(이미지 인식)\n",
    "- 멀티모달은 여러 가지 형태의 정보(모달)를 통합하여 처리하는 기술이나 접근 방식을 의미\n",
    "  - 텍스트: 문서, 책, 웹 페이지 등의 글자로 된 정보\n",
    "  - 이미지: 사진, 그래픽, 그림 등 시각적 정보\n",
    "  - 오디오: 음성, 음악, 소리 효과 등의 청각적 정보\n",
    "  - 비디오: 동영상 클립, 실시간 스트리밍 등 시각적 및 청각적 정보의 결합\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aec3f6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    temperature=0.1,  # 창의성 (0.0 ~ 2.0)\n",
    "    max_tokens=2048,  # 최대 토큰수\n",
    "    model_name=\"gpt-4o\",  # 모델명\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "522d7b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_URL = \"https://t3.ftcdn.net/jpg/03/77/33/96/360_F_377339633_Rtv9I77sSmSNcev8bEcnVxTHrXB4nRJ5.jpg\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac0a773",
   "metadata": {},
   "source": [
    "<img src='https://t3.ftcdn.net/jpg/03/77/33/96/360_F_377339633_Rtv9I77sSmSNcev8bEcnVxTHrXB4nRJ5.jpg' width='500'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1b68dcff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이 이미지는 표 형식의 데이터 테이블입니다. \n",
      "\n",
      "- 표의 제목은 \"TABLE 001: LOREM IPSUM DOLOR AMIS ENIMA ACCUMER TUNA\"입니다.\n",
      "- 표는 다섯 개의 열로 구성되어 있으며, 각 열의 제목은 \"Loremis\", \"Amis terim\", \"Gato lepis\", \"Tortores\"입니다.\n",
      "- 각 행에는 다양한 데이터가 포함되어 있으며, 숫자, 백분율, \"YES\"/\"NO\", \"N/A\"와 같은 값들이 있습니다.\n",
      "- 표 아래에는 작은 글씨로 된 설명문이 있습니다. \n",
      "\n",
      "이 표는 예시 데이터로 보이며, 실제 의미 있는 정보를 제공하지 않습니다."
     ]
    }
   ],
   "source": [
    "for chunk in llm.stream([\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"이 이미지를 보고 무엇이 보이는지 설명해줘.\"},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": IMAGE_URL}}\n",
    "            ]\n",
    "        }\n",
    "    ]):\n",
    "    \n",
    "    if chunk.content:\n",
    "        print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cc726c",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### System, User 프롬프트 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6cc09722",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"당신은 표(재무제표) 를 해석하는 금융 AI 어시스턴트 입니다. \n",
    "당신의 임무는 주어진 테이블 형식의 재무제표를 바탕으로 흥미로운 사실을 정리하여 친절하게 답변하는 것입니다.\"\"\"\n",
    "\n",
    "user_prompt = \"\"\"당신에게 주어진 표는 회사의 재무제표 입니다. 흥미로운 사실을 정리하여 답변하세요.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "620dc2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH_FROM_FILE = \"https://storage.googleapis.com/static.fastcampus.co.kr/prod/uploads/202212/080345-661/kwon-01.png\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4629fc1b",
   "metadata": {},
   "source": [
    "<img src='https://storage.googleapis.com/static.fastcampus.co.kr/prod/uploads/202212/080345-661/kwon-01.png' width='500'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0f3c90a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "주어진 재무상태표를 분석해보면 다음과 같은 흥미로운 사실을 발견할 수 있습니다:\n",
      "\n",
      "1. **유동자산 감소**: \n",
      "   - 제 19기(2019년) 유동자산은 8,349,633백만원으로, 제 18기(2018년) 8,602,837백만원에 비해 감소했습니다. 이는 현금 및 현금성 자산의 감소가 주요 원인으로 보입니다.\n",
      "\n",
      "2. **현금 및 현금성 자산 감소**:\n",
      "   - 제 19기에는 1,002,263백만원으로, 제 18기 1,690,862백만원에 비해 크게 감소했습니다. 이는 회사의 유동성에 영향을 미칠 수 있습니다.\n",
      "\n",
      "3. **매출채권 감소**:\n",
      "   - 매출채권은 제 19기에 3,981,935백만원으로, 제 18기 4,004,920백만원에 비해 소폭 감소했습니다.\n",
      "\n",
      "4. **기타유동자산 증가**:\n",
      "   - 제 19기 기타유동자산은 207,596백만원으로, 제 18기 156,538백만원에 비해 증가했습니다. 이는 회사의 단기 자산 관리 전략 변화로 볼 수 있습니다.\n",
      "\n",
      "5. **비유동자산 증가**:\n",
      "   - 비유동자산은 제 19기에 18,677,453백만원으로, 제 18기 15,127,741백만원에 비해 크게 증가했습니다. 이는 장기적인 투자나 자산 취득이 있었음을 시사합니다.\n",
      "\n",
      "6. **재고자산 증가**:\n",
      "   - 재고자산은 제 19기에 2,670,294백만원으로, 제 18기 2,426,364백만원에 비해 증가했습니다. 이는 생산 증가나 판매 감소의 가능성을 나타낼 수 있습니다.\n",
      "\n",
      "이러한 변화들은 회사의 재무 전략이나 시장 상황에 따른 결과일 수 있으며, 추가적인 분석이 필요할 수 있습니다."
     ]
    }
   ],
   "source": [
    "for chunk in llm.stream(\n",
    "    [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": user_prompt},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": IMAGE_PATH_FROM_FILE}}\n",
    "            ]\n",
    "        }\n",
    "    ]):\n",
    "    \n",
    "    if chunk.content:\n",
    "        print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b1ab9a",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<br>\n",
    "\n",
    "## 01-05. LangChain Explression Language (LCEL)\n",
    "\n",
    "<br>\n",
    "\n",
    "### 프롬프트 + 모델 + 출력 파서\n",
    "- 가장 기본적이고 일반적인 사용 사례는 prompt 템플릿과 모델을 함께 연결하는 것\n",
    "\n",
    "<br>\n",
    "\n",
    "### 프롬프트 템플릿의 활용\n",
    "- 사용자의 입력 변수를 사용하여 완전한 프롬프트 문자열을 만드는 데 사용되는 템플릿\n",
    "  - `template`: 템플릿 문자열. 이 문자열 내에서 중괄호 {}는 변수\n",
    "  - `input_variables`: 중괄호 안에 들어갈 변수의 이름을 리스트로 정의\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9abed5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb0ee38",
   "metadata": {},
   "source": [
    "- `from_template()` 메소드를 사용하여 `PromptTemplate` 객체 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "50570698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['country'], input_types={}, partial_variables={}, template='{country}의 수도는 어디인가요?')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# template 정의\n",
    "template = \"{country}의 수도는 어디인가요?\"\n",
    "\n",
    "# from_template 메소드를 이용하여 PromptTemplate 객체 생성\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789258ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'대한민국의 수도는 어디인가요?'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prompt 생성\n",
    "prompt = prompt_template.format(country=\"대한민국\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6aa919e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    temperature=0.1,  # 창의성 (0.0 ~ 2.0)\n",
    "    max_tokens=2048,  # 최대 토큰수\n",
    "    model_name=\"gpt-4o\",  # 모델명\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85586de8",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Chain 생성\n",
    "\n",
    "<br>\n",
    "\n",
    "#### LCEL(LangChain Expression Language)\n",
    "\n",
    "<img src='https://wikidocs.net/images/page/233344/lcel.png' width='700'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b8596e",
   "metadata": {},
   "source": [
    "- LCEL을 사용하여 다양한 구성 요소를 단일 체인으로 결합\n",
    "    - `|` 기호는 unix 파이프 연산자와 유사하며, 서로 다른 구성 요소를 연결하고 한 구성 요소의 출력을 다음 구성 요소의 입력으로 전달\n",
    "  \n",
    "```python\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be84406",
   "metadata": {},
   "source": [
    "- 체인에서 사용자 입력은 프롬프트 템플릿으로 전달 $\\rightarrow$ 프롬프트 템플릿 출력은 모델로 전달"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1aa7568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt 를 PromptTemplate 객체로 생성\n",
    "prompt = PromptTemplate.from_template(\"{topic} 에 대해 쉽게 설명해주세요.\")\n",
    "\n",
    "model = ChatOpenAI()\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bca5e4",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### `invoke()`호출\n",
    "- python 딕셔너리 형태로 입력값을 전달\n",
    "- `invoke()` 함수 호출 시, 입력값을 전달"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4cac94",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- input 딕셔너리에 주제를 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da30687",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = {\"topic\": \"인공지능 모델의 학습 원리\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad68118e",
   "metadata": {},
   "source": [
    "- `prompt` 객체와 `model` 객체를 파이프(|) 연산자로 연결하고 `invoke` 메서드를 사용하여 `input`을 전달\n",
    "  \n",
    "  이를 통해 모델이 생성한 메시지를 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ee1af930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리는 데이터를 입력하여 모델이 일정한 패턴이나 규칙을 학습하는 과정입니다.\n",
      "\n",
      "일반적으로 학습 과정은 다음과 같은 단계로 이루어집니다.\n",
      "\n",
      "1. 데이터 수집: 학습에 필요한 데이터를 수집하고 준비합니다.\n",
      "\n",
      "2. 데이터 전처리: 수집한 데이터를 모델에 입력할 수 있는 형태로 변환합니다.\n",
      "\n",
      "3. 모델 구성: 학습하고자 하는 목표에 맞는 모델을 선택하고 구성합니다.\n",
      "\n",
      "4. 모델 학습: 입력 데이터를 모델에 주고, 모델이 예측한 결과와 실제 결과를 비교하여 오차를 줄여나가는 과정을 반복합니다.\n",
      "\n",
      "5. 모델 평가: 모델의 성능을 평가하고 필요에 따라 수정합니다.\n",
      "\n",
      "6. 예측: 학습된 모델을 사용하여 새로운 데이터에 대한 예측을 수행합니다.\n",
      "\n",
      "이러한 과정을 통해 인공지능 모델은 입력 데이터와 출력 데이터 사이의 패턴이나 규칙을 학습하여 원하는 작업을 수행할 수 있게 됩니다."
     ]
    }
   ],
   "source": [
    "for chunk in chain.stream(input):\n",
    "    if chunk.content:\n",
    "        print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e462c51",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 출력파서(Output Parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0ae69180",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "93f0dfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113a419c",
   "metadata": {},
   "source": [
    "- Chain 에 출력파서를 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "885c7471",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1650303",
   "metadata": {},
   "source": [
    "- chain 객체의 invoke 메서드를 사용하여 input을 전달"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144e1ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리는 데이터를 입력으로 받아서 패턴을 학습하는 과정입니다. 이 과정은 크게 입력층, 은닉층, 출력층으로 이루어진 신경망 구조를 사용합니다.\n",
      "\n",
      "먼저, 입력층에서 모델에 데이터를 입력하면, 이 데이터는 은닉층을 거쳐 출력층으로 전달됩니다. 은닉층은 입력층의 데이터를 가중치와 활성화 함수를 통해 변환하고, 출력층은 최종 예측 값을 출력합니다.\n",
      "\n",
      "이때, 모델은 예측 값과 실제 값 사이의 차이(오차)를 계산하고, 이 오차를 최소화하기 위해 가중치를 조정하는 과정을 반복합니다. 이때 가중치를 조정하는 방법은 역전파 알고리즘을 사용합니다. 역전파 알고리즘은 오차를 출력층부터 입력층으로 거꾸로 전파하면서 가중치를 업데이트하는 방법입니다.\n",
      "\n",
      "이렇게 반복해서 모델이 데이터의 패턴을 학습하고, 최적의 가중치를 찾아내는 과정이 인공지능 모델의 학습 원리입니다."
     ]
    }
   ],
   "source": [
    "input = {\"topic\": \"인공지능 모델의 학습 원리\"}\n",
    "\n",
    "for chunk in chain.stream(input):\n",
    "    if chunk:\n",
    "        print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca31aea",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 템플릿을 변경하여 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ac50d1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "당신은 영어를 가르치는 10년차 영어 선생님입니다. 상황에 [FORMAT]에 영어 회화를 작성해 주세요.\n",
    "\n",
    "상황:\n",
    "{question}\n",
    "\n",
    "FORMAT:\n",
    "- 영어 회화:\n",
    "- 한글 해석:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322c304d",
   "metadata": {},
   "source": [
    "- 프롬프트 템플릿을 이용하여 프롬프트를 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0933e1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# ChatOpenAI 챗모델을 초기화\n",
    "model = ChatOpenAI(model_name=\"gpt-4-turbo\")\n",
    "\n",
    "# 문자열 출력 파서를 초기화\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d084119d",
   "metadata": {},
   "source": [
    "- Chain 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0c552b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6e1a9ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 회화:\n",
      "- Hello, I'd like a table for one, please.\n",
      "- Could I see the menu, please?\n",
      "- I think I'm ready to order. I'll have the grilled chicken with vegetables.\n",
      "- Could I get a glass of water as well, please?\n",
      "- Thank you!\n",
      "\n",
      "한글 해석:\n",
      "- 안녕하세요, 혼자 사용할 테이블을 부탁합니다.\n",
      "- 메뉴판 좀 볼 수 있을까요?\n",
      "- 주문할게요. 그릴에 구운 닭고기와 야채를 주세요.\n",
      "- 물 한 잔도 주실 수 있나요?\n",
      "- 감사합니다!\n"
     ]
    }
   ],
   "source": [
    "answer = chain.stream({\"question\": \"저는 식당에 가서 음식을 주문하고 싶어요\"})\n",
    "\n",
    "for chunk in answer:\n",
    "    if chunk:\n",
    "        print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daac4772",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<br>\n",
    "\n",
    "## 01-06. LCEL 인터페이스\n",
    "- 사용자 정의 체인을 가능한 쉽게 만들 수 있도록, `Runnable` 프로토콜을 구현\n",
    "- `Runnable` 프로토콜은 대부분의 컴포넌트에 구현되어 있음\n",
    "\n",
    "<br>\n",
    "\n",
    "- 사용자 정의 체인을 정의하고 표준 방식으로 호출하는 것을 쉽게 만들 수 있음\n",
    "\n",
    "- **표준 인터페이스**\n",
    "  - `stream` : 응답의 청크를 스트리밍\n",
    "  - `invoke` : 입력에 대해 체인을 호출\n",
    "  - `batch` : 입력 목록에 대해 체인을 호출\n",
    "\n",
    "<br>\n",
    "\n",
    "- **비동기 메소드**\n",
    "  - `astream` : 비동기적으로 응답의 청크를 스트리밍\n",
    "  - `ainvoke` : 비동기적으로 입력에 대해 체인을 호출\n",
    "  - `abatch` : 비동기적으로 입력 목록에 대해 체인을 호출\n",
    "  - `astream_log` : 최종 응답뿐만 아니라 발생하는 중간 단계를 스트리밍\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cc6b85",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- LCEL문법을 사용하여 chain 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4eb22d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "prompt = PromptTemplate.from_template(\"{topic} 에 대하여 3문장으로 설명해줘.\")\n",
    "chain = prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7742b21c",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### `stream`: 실시간 출력\n",
    "- 이 함수는 `chain.stream` 메서드를 사용하여 주어진 토픽에 대한 데이터 스트림을 생성하고, 이 스트림을 반복하여 각 데이터의 내용(`content`)을 즉시 출력\n",
    "- `end=\"\"` 인자는 출력 후 줄바꿈을 하지 않도록 설정하며, `flush=True` 인자는 출력 버퍼를 즉시 비움"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7f1c38fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "멀티모달은 여러 가지 유형의 데이터를 통합하여 처리하고 분석하는 접근 방식을 의미합니다. 예를 들어, 텍스트, 이미지, 오디오 등 다양한 형식을 동시에 고려하여 보다 풍부한 정보를 제공할 수 있습니다. 이러한 기술은 인공지능, 머신러닝, 자연어 처리 등에서 더욱 효과적이고 실용적인 결과를 얻기 위해 활용되고 있습니다."
     ]
    }
   ],
   "source": [
    "# chain.stream 메서드를 사용하여 '멀티모달' 토픽에 대한 스트림을 생성하고 반복\n",
    "for token in chain.stream({\"topic\": \"멀티모달\"}):\n",
    "    # 스트림에서 받은 데이터의 내용을 출력 \n",
    "    # 줄바꿈 없이 이어서 출력하고, 버퍼를 즉시 비움\n",
    "    print(token, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d68e5b0",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### `invoke`: 호출\n",
    "- `chain` 객체의 `invoke` 메서드는 주제를 인자로 받아 해당 주제에 대한 처리를 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9e5eba5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGPT는 OpenAI에서 개발한 대화형 인공지능 모델로, 자연어 처리 기술을 기반으로 합니다. 사용자의 질문이나 요청에 대해 인간처럼 자연스러운 언어로 응답할 수 있도록 설계되었습니다. 학습된 데이터에 기반하여 다양한 주제에 대한 정보 제공 및 대화 지원이 가능합니다.\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke({\"topic\": \"ChatGPT\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fecca3",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### `batch`: 배치(단위 실행)\n",
    "- 함수 `chain.batch`는 여러 개의 딕셔너리를 포함하는 리스트를 인자로 받아, 각 딕셔너리에 있는 `topic` 키의 값을 사용하여 일괄 처리를 수행\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1c22f2d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ChatGPT는 OpenAI에서 개발한 대화형 인공지능 모델로, 자연어 처리 기술을 기반으로 사용자와의 대화를 생성합니다. 다양한 주제에 대한 질문에 응답하고, 정보 제공 및 대화 지원을 통해 사용자와 소통할 수 있습니다. 이 모델은 대규모 텍스트 데이터로 학습되어 높은 수준의 언어 이해와 생성 능력을 갖추고 있습니다.',\n",
       " '인스타그램은 사용자가 사진과 비디오를 공유할 수 있는 소셜 미디어 플랫폼입니다. 사용자는 다양한 필터와 편집 도구를 활용해 콘텐츠를 꾸미고, 다른 사용자와 상호작용하며 팔로우할 수 있습니다. 또한, 스토리 기능과 IGTV를 통해 일상적인 순간이나 긴 형식의 콘텐츠를 더욱 쉽게 공유할 수 있습니다.']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.batch(\n",
    "    [\n",
    "        {\"topic\": \"ChatGPT\"}, \n",
    "        {\"topic\": \"Instagram\"}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6097205f",
   "metadata": {},
   "source": [
    "- **`max_concurrency` 매개변수를 사용하여 동시 요청 수를 설정**\n",
    "  - `config` 딕셔너리는 `max_concurrency` 키를 통해 동시에 처리할 수 있는 최대 작업 수를 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "77c8aad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ChatGPT는 OpenAI가 개발한 인공지능 언어 모델로, 자연어 처리 기술을 기반으로 사용자의 질문이나 요청에 대해 적절한 응답을 생성합니다. 이 모델은 방대한 양의 텍스트 데이터를 학습하여 다양한 주제에 대해 유용한 정보를 제공할 수 있습니다. 사용자와의 상호작용을 통해 질문에 답하거나 대화를 이어가는 능력을 가지고 있습니다.',\n",
       " '인스타그램은 사용자들이 사진과 동영상을 공유할 수 있는 소셜 미디어 플랫폼입니다. 사용자들은 다양한 필터와 편집 도구를 사용하여 콘텐츠를 꾸밀 수 있으며, 해시태그를 통해 관심 있는 주제를 탐색할 수 있습니다. 또한, 인스타그램은 친구와 소통할 수 있는 기능뿐만 아니라 브랜드와 기업들에게 마케팅 기회를 제공하는 중요한 플랫폼으로 성장했습니다.',\n",
       " '멀티모달은 다양한 형태의 데이터를 동시에 처리하고 분석하는 개념으로, 텍스트, 이미지, 음성 등 여러 유형의 정보가 결합되어 나타납니다. 이러한 방식은 데이터 간의 상호작용을 통해 보다 깊이 있는 이해를 가능하게 하며, 인공지능 모델들의 성능을 향상시킵니다. 예를 들어, 멀티모달 기술은 이미지 설명 생성, 감정 분석 및 추천 시스템 등 다양한 응용 분야에서 활용됩니다.',\n",
       " '프로그래밍은 컴퓨터가 수행할 수 있는 명령어를 작성하는 과정입니다. 이를 통해 다양한 소프트웨어와 애플리케이션을 개발할 수 있으며, 문제 해결 및 자동화를 가능하게 합니다. 프로그래밍 언어를 사용하여 코드로 표현하며, 논리적 사고와 창의력이 중요한 역할을 합니다.',\n",
       " '머신러닝은 데이터를 기반으로 패턴을 학습하고 예측을 수행하는 인공지능의 한 분야입니다. 알고리즘을 사용하여 경험을 통해 성능을 향상시키며, 지도학습, 비지도학습, 강화학습 등의 다양한 접근 방식을 포함합니다. 이를 통해 이미지 인식, 자연어 처리, 추천 시스템 등 다양한 응용 분야에서 활용되고 있습니다.']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.batch(\n",
    "    [\n",
    "        {\"topic\": \"ChatGPT\"},\n",
    "        {\"topic\": \"Instagram\"},\n",
    "        {\"topic\": \"멀티모달\"},\n",
    "        {\"topic\": \"프로그래밍\"},\n",
    "        {\"topic\": \"머신러닝\"},\n",
    "    ],\n",
    "    config={\"max_concurrency\": 3},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fad217",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### `async stream`: 비동기 스트림\n",
    "- 함수 `chain.astream`은 비동기 스트림을 생성하며, 주어진 토픽에 대한 메시지를 비동기적으로 처리\n",
    "- 비동기 `for` 루프(`async for`)를 사용하여 스트림에서 메시지를 순차적으로 받아오고, print 함수를 통해 메시지의 내용(`s.content`)을 즉시 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "15953842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YouTube는 사용자들이 비디오를 업로드, 공유 및 시청할 수 있는 온라인 플랫폼입니다. 2005년에 설립된 이 플랫폼은 콘텐츠 제작자와 소비자 간의 소통과 창작의 장이 되어 다양한 주제의 영상이 포함되어 있습니다. 현재 YouTube는 세계에서 가장 큰 비디오 공유 사이트 중 하나로, 광고, 구독 및 슈퍼챗 등을 통해 수익을 창출하는 시스템을 운영하고 있습니다."
     ]
    }
   ],
   "source": [
    "async for token in chain.astream({\"topic\": \"YouTube\"}):\n",
    "    print(token, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05ea16a",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### `async invoke`: 비동기 호출\n",
    "- `chain` 객체의 `ainvoke` 메서드는 비동기적으로 주어진 인자를 사용하여 작업을 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0028c453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA Corporation (NVDA)는 그래픽 처리 장치(GPU) 및 인공지능(AI) 기술의 선도적인 제조업체입니다. 게임, 데이터 센터, 자율주행차 등 다양한 분야에서 활용되는 고성능 칩셋을 개발하여, 컴퓨터 비전과 머신 러닝 분야에서 중요성을 잘 인정받고 있습니다. 최근에는 AI 기술의 발전으로 인해 NVIDIA의 제품 수요가 급증하며 주목받고 있습니다.'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_process = chain.ainvoke({\"topic\": \"NVDA\"})\n",
    "await my_process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58df1f0b",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### `async batch`: 비동기 배치\n",
    "- 함수 `abatch`는 비동기적으로 일련의 작업을 일괄 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2b7a2f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['YouTube는 사용자들이 동영상을 업로드, 공유 및 시청할 수 있는 세계 최대의 비디오 플랫폼입니다. 이 플랫폼은 다양한 콘텐츠, 즉 음악, 게임, 교육, 리뷰 등 여러 분야의 동영상을 제공하며, 크리에이터들이 광고 수익을 통해 수익을 창출할 수 있는 기회를 제공합니다. 또한, 사용자간의 소통을 장려하고, 좋아요, 댓글, 구독 등의 기능을 통해 커뮤니티 형성이 가능합니다.',\n",
       " 'Instagram은 사용자가 사진과 동영상을 공유할 수 있는 소셜 미디어 플랫폼입니다. 다양한 필터와 편집 도구를 제공하여 사용자가 자신의 콘텐츠를 창의적으로 표현할 수 있도록 도와줍니다. 또한, 친구와의 소통뿐만 아니라, 관심사를 기반으로 한 다양한 콘텐츠를 탐색할 수 있는 기능도 제공합니다.',\n",
       " 'Facebook은 2004년 마크 저커버그가 설립한 소셜 미디어 플랫폼으로, 사용자들이 친구 및 가족과 소통하고, 정보를 공유하며, 다양한 콘텐츠를 탐색할 수 있는 공간입니다. 사용자들은 개인 프로필을 만들고, 사진과 게시물을 공유하며, 그룹이나 페이지에 참여하여 관심 있는 주제에 대해 논의할 수 있습니다. 또한 Facebook은 광고 및 마케팅 도구를 제공하여 기업과 개인이 더 넓은 청중에게 다가갈 수 있도록 지원합니다.']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_abatch_process = chain.abatch(\n",
    "    [{\"topic\": \"YouTube\"}, {\"topic\": \"Instagram\"}, {\"topic\": \"Facebook\"}]\n",
    ")\n",
    "\n",
    "await my_abatch_process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9916923d",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Parallel: 병렬성\n",
    "- `RunnableParallel` 클래스를 사용하여 이 두 체인을 키로 결합하여 동시에 실행할 수 있는 `combined` 객체를 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a7d114ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a745628e",
   "metadata": {},
   "source": [
    "- {country} 의 수도를 물어보는 체인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fb3b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain1 = (\n",
    "    PromptTemplate.from_template(\"{country} 의 수도는 어디야?\")\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cece69c",
   "metadata": {},
   "source": [
    "- {country} 의 면적을 물어보는 체인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8efedb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain2 = (\n",
    "    PromptTemplate.from_template(\"{country} 의 면적은 얼마야?\")\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57caea1a",
   "metadata": {},
   "source": [
    "- 2개 체인을 동시에 생성하는 병렬 실행 체인을 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1cfe2b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = RunnableParallel(capital=chain1, area=chain2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2fddc710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'대한민국의 수도는 서울입니다.'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain1.invoke({\"country\": \"대한민국\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6e2d2a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'미국의 총 면적은 약 9,826,675 평방 킬로미터(3,796,742 평방 마일)입니다. 이 면적에는 주와 영토가 모두 포함됩니다. 미국은 세계에서 세 번째로 큰 나라입니다.'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain2.invoke({\"country\": \"미국\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd13f02f",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- `combined` 객체의 `invoke` 메서드는 주어진 country에 대한 처리를 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "96b1f8db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'capital': '대한민국의 수도는 서울입니다.',\n",
       " 'area': '대한민국의 면적은 약 100,210 평방킬로미터입니다. 이는 한반도의 남쪽에 위치한 지역의 규모를 나타내며, 다양한 지형과 자연환경을 포함하고 있습니다.'}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.invoke({\"country\": \"대한민국\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb95896",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 배치에서의 병렬 처리\n",
    "- `combined.batch` 함수는 주어진 데이터를 배치로 처리하는 데 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "dc895e49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'capital': '대한민국의 수도는 서울입니다.',\n",
       "  'area': '대한민국의 면적은 약 100,210 평방킬로미터(약 38,691 평방 마일)입니다.'},\n",
       " {'capital': '미국의 수도는 워싱턴 D.C.입니다.',\n",
       "  'area': '미국의 면적은 약 9,831,510 평방킬로미터(약 3,796,742 평방마일)입니다. 이는 세계에서 세 번째로 큰 나라로, 러시아와 캐나다에 이어서 면적이 가장 큰 국가입니다.'}]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.batch([{\"country\": \"대한민국\"}, {\"country\": \"미국\"}])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27b9945",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<br>\n",
    "\n",
    "## 01-07. `Runnable`\n",
    "\n",
    "<br>\n",
    "\n",
    "### 데이터를 효과적으로 전달하는 방법\n",
    "- `RunnablePassthrough` 는 입력을 변경하지 않거나 추가 키를 더하여 전달할 수 있음\n",
    "- `RunnablePassthrough()` 가 단독으로 호출되면, 단순히 입력을 받아 그대로 전달\n",
    "- `RunnablePassthrough.assign(...)` 방식으로 호출되면, 입력을 받아 assign 함수에 전달된 추가 인수를 추가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62df5e1",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### `RunnablePassthrough`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "30a77b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "19053be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(\"{num} 의 10배는?\")\n",
    "llm = ChatOpenAI(temperature=0, model='gpt-4o-mini')\n",
    "\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d9e311",
   "metadata": {},
   "source": [
    "- 1개의 변수만 템플릿에 포함하고 있다면, 값만 전달하는 것도 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dfac71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='5의 10배는 50입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 14, 'total_tokens': 24, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CLjkxG1ASlQaTQsMkbMohaXazZGS6', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--10738ce4-79a1-48a2-89ec-cd2ccd0f6ad9-0', usage_metadata={'input_tokens': 14, 'output_tokens': 10, 'total_tokens': 24, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"num\": 5})\n",
    "# chain.invoke(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3034396",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- `RunnablePassthrough` 는 `runnable` 객체이며, `runnable` 객체는 `invoke()` 메소드를 사용하여 별도 실행이 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3ec4ce86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "babed284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num': 10}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# runnable\n",
    "RunnablePassthrough().invoke({\"num\": 10})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1a622d",
   "metadata": {},
   "source": [
    "* `RunnablePassthrough` 로 체인을 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3fe88cd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='100', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 16, 'total_tokens': 17, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CLjnhlTWN02pyhzeGGQgZRE36avaI', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--45f61073-72ea-41f0-9fb3-d59a7a5b4b5b-0', usage_metadata={'input_tokens': 16, 'output_tokens': 1, 'total_tokens': 17, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable_chain = {\"num\": RunnablePassthrough()} | prompt | ChatOpenAI()\n",
    "\n",
    "runnable_chain.invoke(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fadbbd",
   "metadata": {},
   "source": [
    "- `RunnablePassthrough.assign()` 을 사용하는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "062c1529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num': 1}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RunnablePassthrough().invoke({\"num\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5a93e189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num': 1, 'new_num': 3}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(RunnablePassthrough.assign(new_num=lambda x: x[\"num\"] * 3)).invoke({\"num\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db2a910",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### `RunnableParallel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7b93f21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddcc344",
   "metadata": {},
   "source": [
    "- `RunnableParallel` 인스턴스를 생성\n",
    "  - 이 인스턴스는 여러 `Runnable` 인스턴스를 병렬로 실행할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "95dd2dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "runnable = RunnableParallel(\n",
    "    # RunnablePassthrough 인스턴스를 'passed' 키워드 인자로 전달\n",
    "    # 이는 입력된 데이터를 그대로 통과시키는 역할\n",
    "    passed=RunnablePassthrough(),\n",
    "    \n",
    "    # 'extra' 키워드 인자로 RunnablePassthrough.assign을 사용하여, 'mult' 람다 함수를 할당\n",
    "    # 이 함수는 입력된 딕셔너리의 'num' 키에 해당하는 값을 3배로 증가\n",
    "    extra=RunnablePassthrough.assign(mult=lambda x: x[\"num\"] * 3),\n",
    "    \n",
    "    # 'modified' 키워드 인자로 람다 함수를 전달\n",
    "    # 이 함수는 입력된 딕셔너리의 'num' 키에 해당하는 값에 1을 더함\n",
    "    modified=lambda x: x[\"num\"] + 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2677a1f",
   "metadata": {},
   "source": [
    "- `runnable` 인스턴스에 `{'num': 1}` 딕셔너리를 입력으로 전달하여 `invoke` 메소드를 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "58961afa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'passed': {'num': 1}, 'extra': {'num': 1, 'mult': 3}, 'modified': 2}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable.invoke({\"num\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1203a26",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### `RunnableLambda`\n",
    "- `RunnableLambda` 를 사용하여 사용자 정의 함수를 맵핑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "92ba0222",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e3d8e0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_today(a):\n",
    "    return datetime.today().strftime(\"%b-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "50349b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2d59d441",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(\n",
    "    \"{today} 가 생일인 유명인 {n} 명을 나열하세요. 생년월일을 표기해 주세요.\"\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16cd202",
   "metadata": {},
   "source": [
    "- chain 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4b1d8d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    {\"today\": RunnableLambda(get_today), \"n\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "df7a19a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10월 1일이 생일인 유명인 세 명은 다음과 같습니다.\n",
      "\n",
      "1. 줄리 앤드류스 (Julie Andrews) - 1935년 10월 1일\n",
      "2. 지미 카터 (Jimmy Carter) - 1924년 10월 1일\n",
      "3. 자카리 레비 (Zachary Levi) - 1980년 10월 1일\n",
      "\n",
      "이들은 각각 영화, 정치, 엔터테인먼트 분야에서 잘 알려진 인물들입니다.\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c415746",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- `itemgetter` 를 사용하여 특정 키를 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1542ce41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f9b4300b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장의 길이를 반환하는 함수\n",
    "def length_function(text):\n",
    "    return len(text)\n",
    "\n",
    "\n",
    "# 두 문장의 길이를 곱한 값을 반환하는 함수\n",
    "def _multiple_length_function(text1, text2):\n",
    "    return len(text1) * len(text2)\n",
    "\n",
    "\n",
    "# _multiple_length_function 함수를 사용하여 두 문장의 길이를 곱한 값을 반환하는 함수\n",
    "def multiple_length_function(_dict):\n",
    "    return _multiple_length_function(_dict[\"text1\"], _dict[\"text2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "fc07577a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"{a} + {b} 는 무엇인가요?\")\n",
    "model = ChatOpenAI()\n",
    "\n",
    "chain1 = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7b108055",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    {\n",
    "        \"a\": itemgetter(\"word1\") | RunnableLambda(length_function),\n",
    "        \"b\": {\"text1\": itemgetter(\"word1\"), \"text2\": itemgetter(\"word2\")}\n",
    "        | RunnableLambda(multiple_length_function),\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2d396d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='5 + 25 = 30 입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 22, 'total_tokens': 32, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CLk4ybKrAnGXwSrgGU9ndeL729qZ9', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--cfd06bd9-0216-4550-a34a-6a935d7ca32f-0', usage_metadata={'input_tokens': 22, 'output_tokens': 10, 'total_tokens': 32, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"word1\": \"hello\", \"word2\": \"world\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang_env",
   "language": "python",
   "name": "lang_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

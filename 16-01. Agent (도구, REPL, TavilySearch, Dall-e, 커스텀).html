<!DOCTYPE html>

<html lang="en">
<head><meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>16-01. Agent (도구, REPL, TavilySearch, Dall-e, 커스텀)</title><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<style type="text/css">
    pre { line-height: 125%; }
td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
.highlight .hll { background-color: var(--jp-cell-editor-active-background) }
.highlight { background: var(--jp-cell-editor-background); color: var(--jp-mirror-editor-variable-color) }
.highlight .c { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment */
.highlight .err { color: var(--jp-mirror-editor-error-color) } /* Error */
.highlight .k { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword */
.highlight .o { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator */
.highlight .p { color: var(--jp-mirror-editor-punctuation-color) } /* Punctuation */
.highlight .ch { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Multiline */
.highlight .cp { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Preproc */
.highlight .cpf { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Single */
.highlight .cs { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Special */
.highlight .kc { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Pseudo */
.highlight .kr { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Type */
.highlight .m { color: var(--jp-mirror-editor-number-color) } /* Literal.Number */
.highlight .s { color: var(--jp-mirror-editor-string-color) } /* Literal.String */
.highlight .ow { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator.Word */
.highlight .pm { color: var(--jp-mirror-editor-punctuation-color) } /* Punctuation.Marker */
.highlight .w { color: var(--jp-mirror-editor-variable-color) } /* Text.Whitespace */
.highlight .mb { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Bin */
.highlight .mf { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Float */
.highlight .mh { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Hex */
.highlight .mi { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer */
.highlight .mo { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Oct */
.highlight .sa { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Affix */
.highlight .sb { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Backtick */
.highlight .sc { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Char */
.highlight .dl { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Delimiter */
.highlight .sd { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Doc */
.highlight .s2 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Double */
.highlight .se { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Escape */
.highlight .sh { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Heredoc */
.highlight .si { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Interpol */
.highlight .sx { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Other */
.highlight .sr { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Regex */
.highlight .s1 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Single */
.highlight .ss { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Symbol */
.highlight .il { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer.Long */
  </style>
<style type="text/css">
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*
 * Mozilla scrollbar styling
 */

/* use standard opaque scrollbars for most nodes */
[data-jp-theme-scrollbars='true'] {
  scrollbar-color: rgb(var(--jp-scrollbar-thumb-color))
    var(--jp-scrollbar-background-color);
}

/* for code nodes, use a transparent style of scrollbar. These selectors
 * will match lower in the tree, and so will override the above */
[data-jp-theme-scrollbars='true'] .CodeMirror-hscrollbar,
[data-jp-theme-scrollbars='true'] .CodeMirror-vscrollbar {
  scrollbar-color: rgba(var(--jp-scrollbar-thumb-color), 0.5) transparent;
}

/* tiny scrollbar */

.jp-scrollbar-tiny {
  scrollbar-color: rgba(var(--jp-scrollbar-thumb-color), 0.5) transparent;
  scrollbar-width: thin;
}

/* tiny scrollbar */

.jp-scrollbar-tiny::-webkit-scrollbar,
.jp-scrollbar-tiny::-webkit-scrollbar-corner {
  background-color: transparent;
  height: 4px;
  width: 4px;
}

.jp-scrollbar-tiny::-webkit-scrollbar-thumb {
  background: rgba(var(--jp-scrollbar-thumb-color), 0.5);
}

.jp-scrollbar-tiny::-webkit-scrollbar-track:horizontal {
  border-left: 0 solid transparent;
  border-right: 0 solid transparent;
}

.jp-scrollbar-tiny::-webkit-scrollbar-track:vertical {
  border-top: 0 solid transparent;
  border-bottom: 0 solid transparent;
}

/*
 * Lumino
 */

.lm-ScrollBar[data-orientation='horizontal'] {
  min-height: 16px;
  max-height: 16px;
  min-width: 45px;
  border-top: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='vertical'] {
  min-width: 16px;
  max-width: 16px;
  min-height: 45px;
  border-left: 1px solid #a0a0a0;
}

.lm-ScrollBar-button {
  background-color: #f0f0f0;
  background-position: center center;
  min-height: 15px;
  max-height: 15px;
  min-width: 15px;
  max-width: 15px;
}

.lm-ScrollBar-button:hover {
  background-color: #dadada;
}

.lm-ScrollBar-button.lm-mod-active {
  background-color: #cdcdcd;
}

.lm-ScrollBar-track {
  background: #f0f0f0;
}

.lm-ScrollBar-thumb {
  background: #cdcdcd;
}

.lm-ScrollBar-thumb:hover {
  background: #bababa;
}

.lm-ScrollBar-thumb.lm-mod-active {
  background: #a0a0a0;
}

.lm-ScrollBar[data-orientation='horizontal'] .lm-ScrollBar-thumb {
  height: 100%;
  min-width: 15px;
  border-left: 1px solid #a0a0a0;
  border-right: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='vertical'] .lm-ScrollBar-thumb {
  width: 100%;
  min-height: 15px;
  border-top: 1px solid #a0a0a0;
  border-bottom: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='horizontal']
  .lm-ScrollBar-button[data-action='decrement'] {
  background-image: var(--jp-icon-caret-left);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='horizontal']
  .lm-ScrollBar-button[data-action='increment'] {
  background-image: var(--jp-icon-caret-right);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='vertical']
  .lm-ScrollBar-button[data-action='decrement'] {
  background-image: var(--jp-icon-caret-up);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='vertical']
  .lm-ScrollBar-button[data-action='increment'] {
  background-image: var(--jp-icon-caret-down);
  background-size: 17px;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-Widget {
  box-sizing: border-box;
  position: relative;
  overflow: hidden;
}

.lm-Widget.lm-mod-hidden {
  display: none !important;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.lm-AccordionPanel[data-orientation='horizontal'] > .lm-AccordionPanel-title {
  /* Title is rotated for horizontal accordion panel using CSS */
  display: block;
  transform-origin: top left;
  transform: rotate(-90deg) translate(-100%);
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-CommandPalette {
  display: flex;
  flex-direction: column;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-CommandPalette-search {
  flex: 0 0 auto;
}

.lm-CommandPalette-content {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  min-height: 0;
  overflow: auto;
  list-style-type: none;
}

.lm-CommandPalette-header {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.lm-CommandPalette-item {
  display: flex;
  flex-direction: row;
}

.lm-CommandPalette-itemIcon {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemContent {
  flex: 1 1 auto;
  overflow: hidden;
}

.lm-CommandPalette-itemShortcut {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemLabel {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.lm-close-icon {
  border: 1px solid transparent;
  background-color: transparent;
  position: absolute;
  z-index: 1;
  right: 3%;
  top: 0;
  bottom: 0;
  margin: auto;
  padding: 7px 0;
  display: none;
  vertical-align: middle;
  outline: 0;
  cursor: pointer;
}
.lm-close-icon:after {
  content: 'X';
  display: block;
  width: 15px;
  height: 15px;
  text-align: center;
  color: #000;
  font-weight: normal;
  font-size: 12px;
  cursor: pointer;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-DockPanel {
  z-index: 0;
}

.lm-DockPanel-widget {
  z-index: 0;
}

.lm-DockPanel-tabBar {
  z-index: 1;
}

.lm-DockPanel-handle {
  z-index: 2;
}

.lm-DockPanel-handle.lm-mod-hidden {
  display: none !important;
}

.lm-DockPanel-handle:after {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  content: '';
}

.lm-DockPanel-handle[data-orientation='horizontal'] {
  cursor: ew-resize;
}

.lm-DockPanel-handle[data-orientation='vertical'] {
  cursor: ns-resize;
}

.lm-DockPanel-handle[data-orientation='horizontal']:after {
  left: 50%;
  min-width: 8px;
  transform: translateX(-50%);
}

.lm-DockPanel-handle[data-orientation='vertical']:after {
  top: 50%;
  min-height: 8px;
  transform: translateY(-50%);
}

.lm-DockPanel-overlay {
  z-index: 3;
  box-sizing: border-box;
  pointer-events: none;
}

.lm-DockPanel-overlay.lm-mod-hidden {
  display: none !important;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-Menu {
  z-index: 10000;
  position: absolute;
  white-space: nowrap;
  overflow-x: hidden;
  overflow-y: auto;
  outline: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-Menu-content {
  margin: 0;
  padding: 0;
  display: table;
  list-style-type: none;
}

.lm-Menu-item {
  display: table-row;
}

.lm-Menu-item.lm-mod-hidden,
.lm-Menu-item.lm-mod-collapsed {
  display: none !important;
}

.lm-Menu-itemIcon,
.lm-Menu-itemSubmenuIcon {
  display: table-cell;
  text-align: center;
}

.lm-Menu-itemLabel {
  display: table-cell;
  text-align: left;
}

.lm-Menu-itemShortcut {
  display: table-cell;
  text-align: right;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-MenuBar {
  outline: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-MenuBar-content {
  margin: 0;
  padding: 0;
  display: flex;
  flex-direction: row;
  list-style-type: none;
}

.lm-MenuBar-item {
  box-sizing: border-box;
}

.lm-MenuBar-itemIcon,
.lm-MenuBar-itemLabel {
  display: inline-block;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-ScrollBar {
  display: flex;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-ScrollBar[data-orientation='horizontal'] {
  flex-direction: row;
}

.lm-ScrollBar[data-orientation='vertical'] {
  flex-direction: column;
}

.lm-ScrollBar-button {
  box-sizing: border-box;
  flex: 0 0 auto;
}

.lm-ScrollBar-track {
  box-sizing: border-box;
  position: relative;
  overflow: hidden;
  flex: 1 1 auto;
}

.lm-ScrollBar-thumb {
  box-sizing: border-box;
  position: absolute;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-SplitPanel-child {
  z-index: 0;
}

.lm-SplitPanel-handle {
  z-index: 1;
}

.lm-SplitPanel-handle.lm-mod-hidden {
  display: none !important;
}

.lm-SplitPanel-handle:after {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  content: '';
}

.lm-SplitPanel[data-orientation='horizontal'] > .lm-SplitPanel-handle {
  cursor: ew-resize;
}

.lm-SplitPanel[data-orientation='vertical'] > .lm-SplitPanel-handle {
  cursor: ns-resize;
}

.lm-SplitPanel[data-orientation='horizontal'] > .lm-SplitPanel-handle:after {
  left: 50%;
  min-width: 8px;
  transform: translateX(-50%);
}

.lm-SplitPanel[data-orientation='vertical'] > .lm-SplitPanel-handle:after {
  top: 50%;
  min-height: 8px;
  transform: translateY(-50%);
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-TabBar {
  display: flex;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-TabBar[data-orientation='horizontal'] {
  flex-direction: row;
  align-items: flex-end;
}

.lm-TabBar[data-orientation='vertical'] {
  flex-direction: column;
  align-items: flex-end;
}

.lm-TabBar-content {
  margin: 0;
  padding: 0;
  display: flex;
  flex: 1 1 auto;
  list-style-type: none;
}

.lm-TabBar[data-orientation='horizontal'] > .lm-TabBar-content {
  flex-direction: row;
}

.lm-TabBar[data-orientation='vertical'] > .lm-TabBar-content {
  flex-direction: column;
}

.lm-TabBar-tab {
  display: flex;
  flex-direction: row;
  box-sizing: border-box;
  overflow: hidden;
  touch-action: none; /* Disable native Drag/Drop */
}

.lm-TabBar-tabIcon,
.lm-TabBar-tabCloseIcon {
  flex: 0 0 auto;
}

.lm-TabBar-tabLabel {
  flex: 1 1 auto;
  overflow: hidden;
  white-space: nowrap;
}

.lm-TabBar-tabInput {
  user-select: all;
  width: 100%;
  box-sizing: border-box;
}

.lm-TabBar-tab.lm-mod-hidden {
  display: none !important;
}

.lm-TabBar-addButton.lm-mod-hidden {
  display: none !important;
}

.lm-TabBar.lm-mod-dragging .lm-TabBar-tab {
  position: relative;
}

.lm-TabBar.lm-mod-dragging[data-orientation='horizontal'] .lm-TabBar-tab {
  left: 0;
  transition: left 150ms ease;
}

.lm-TabBar.lm-mod-dragging[data-orientation='vertical'] .lm-TabBar-tab {
  top: 0;
  transition: top 150ms ease;
}

.lm-TabBar.lm-mod-dragging .lm-TabBar-tab.lm-mod-dragging {
  transition: none;
}

.lm-TabBar-tabLabel .lm-TabBar-tabInput {
  user-select: all;
  width: 100%;
  box-sizing: border-box;
  background: inherit;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-TabPanel-tabBar {
  z-index: 1;
}

.lm-TabPanel-stackedPanel {
  z-index: 0;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Collapse {
  display: flex;
  flex-direction: column;
  align-items: stretch;
}

.jp-Collapse-header {
  padding: 1px 12px;
  background-color: var(--jp-layout-color1);
  border-bottom: solid var(--jp-border-width) var(--jp-border-color2);
  color: var(--jp-ui-font-color1);
  cursor: pointer;
  display: flex;
  align-items: center;
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  text-transform: uppercase;
  user-select: none;
}

.jp-Collapser-icon {
  height: 16px;
}

.jp-Collapse-header-collapsed .jp-Collapser-icon {
  transform: rotate(-90deg);
  margin: auto 0;
}

.jp-Collapser-title {
  line-height: 25px;
}

.jp-Collapse-contents {
  padding: 0 12px;
  background-color: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  overflow: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensureUiComponents() in @jupyterlab/buildutils */

/**
 * (DEPRECATED) Support for consuming icons as CSS background images
 */

/* Icons urls */

:root {
  --jp-icon-add-above: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGcgY2xpcC1wYXRoPSJ1cmwoI2NsaXAwXzEzN18xOTQ5MikiPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGQ9Ik00Ljc1IDQuOTMwNjZINi42MjVWNi44MDU2NkM2LjYyNSA3LjAxMTkxIDYuNzkzNzUgNy4xODA2NiA3IDcuMTgwNjZDNy4yMDYyNSA3LjE4MDY2IDcuMzc1IDcuMDExOTEgNy4zNzUgNi44MDU2NlY0LjkzMDY2SDkuMjVDOS40NTYyNSA0LjkzMDY2IDkuNjI1IDQuNzYxOTEgOS42MjUgNC41NTU2NkM5LjYyNSA0LjM0OTQxIDkuNDU2MjUgNC4xODA2NiA5LjI1IDQuMTgwNjZINy4zNzVWMi4zMDU2NkM3LjM3NSAyLjA5OTQxIDcuMjA2MjUgMS45MzA2NiA3IDEuOTMwNjZDNi43OTM3NSAxLjkzMDY2IDYuNjI1IDIuMDk5NDEgNi42MjUgMi4zMDU2NlY0LjE4MDY2SDQuNzVDNC41NDM3NSA0LjE4MDY2IDQuMzc1IDQuMzQ5NDEgNC4zNzUgNC41NTU2NkM0LjM3NSA0Ljc2MTkxIDQuNTQzNzUgNC45MzA2NiA0Ljc1IDQuOTMwNjZaIiBmaWxsPSIjNjE2MTYxIiBzdHJva2U9IiM2MTYxNjEiIHN0cm9rZS13aWR0aD0iMC43Ii8+CjwvZz4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiIGNsaXAtcnVsZT0iZXZlbm9kZCIgZD0iTTExLjUgOS41VjExLjVMMi41IDExLjVWOS41TDExLjUgOS41Wk0xMiA4QzEyLjU1MjMgOCAxMyA4LjQ0NzcyIDEzIDlWMTJDMTMgMTIuNTUyMyAxMi41NTIzIDEzIDEyIDEzTDIgMTNDMS40NDc3MiAxMyAxIDEyLjU1MjMgMSAxMlY5QzEgOC40NDc3MiAxLjQ0NzcxIDggMiA4TDEyIDhaIiBmaWxsPSIjNjE2MTYxIi8+CjxkZWZzPgo8Y2xpcFBhdGggaWQ9ImNsaXAwXzEzN18xOTQ5MiI+CjxyZWN0IGNsYXNzPSJqcC1pY29uMyIgd2lkdGg9IjYiIGhlaWdodD0iNiIgZmlsbD0id2hpdGUiIHRyYW5zZm9ybT0ibWF0cml4KC0xIDAgMCAxIDEwIDEuNTU1NjYpIi8+CjwvY2xpcFBhdGg+CjwvZGVmcz4KPC9zdmc+Cg==);
  --jp-icon-add-below: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGcgY2xpcC1wYXRoPSJ1cmwoI2NsaXAwXzEzN18xOTQ5OCkiPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGQ9Ik05LjI1IDEwLjA2OTNMNy4zNzUgMTAuMDY5M0w3LjM3NSA4LjE5NDM0QzcuMzc1IDcuOTg4MDkgNy4yMDYyNSA3LjgxOTM0IDcgNy44MTkzNEM2Ljc5Mzc1IDcuODE5MzQgNi42MjUgNy45ODgwOSA2LjYyNSA4LjE5NDM0TDYuNjI1IDEwLjA2OTNMNC43NSAxMC4wNjkzQzQuNTQzNzUgMTAuMDY5MyA0LjM3NSAxMC4yMzgxIDQuMzc1IDEwLjQ0NDNDNC4zNzUgMTAuNjUwNiA0LjU0Mzc1IDEwLjgxOTMgNC43NSAxMC44MTkzTDYuNjI1IDEwLjgxOTNMNi42MjUgMTIuNjk0M0M2LjYyNSAxMi45MDA2IDYuNzkzNzUgMTMuMDY5MyA3IDEzLjA2OTNDNy4yMDYyNSAxMy4wNjkzIDcuMzc1IDEyLjkwMDYgNy4zNzUgMTIuNjk0M0w3LjM3NSAxMC44MTkzTDkuMjUgMTAuODE5M0M5LjQ1NjI1IDEwLjgxOTMgOS42MjUgMTAuNjUwNiA5LjYyNSAxMC40NDQzQzkuNjI1IDEwLjIzODEgOS40NTYyNSAxMC4wNjkzIDkuMjUgMTAuMDY5M1oiIGZpbGw9IiM2MTYxNjEiIHN0cm9rZT0iIzYxNjE2MSIgc3Ryb2tlLXdpZHRoPSIwLjciLz4KPC9nPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGZpbGwtcnVsZT0iZXZlbm9kZCIgY2xpcC1ydWxlPSJldmVub2RkIiBkPSJNMi41IDUuNUwyLjUgMy41TDExLjUgMy41TDExLjUgNS41TDIuNSA1LjVaTTIgN0MxLjQ0NzcyIDcgMSA2LjU1MjI4IDEgNkwxIDNDMSAyLjQ0NzcyIDEuNDQ3NzIgMiAyIDJMMTIgMkMxMi41NTIzIDIgMTMgMi40NDc3MiAxMyAzTDEzIDZDMTMgNi41NTIyOSAxMi41NTIzIDcgMTIgN0wyIDdaIiBmaWxsPSIjNjE2MTYxIi8+CjxkZWZzPgo8Y2xpcFBhdGggaWQ9ImNsaXAwXzEzN18xOTQ5OCI+CjxyZWN0IGNsYXNzPSJqcC1pY29uMyIgd2lkdGg9IjYiIGhlaWdodD0iNiIgZmlsbD0id2hpdGUiIHRyYW5zZm9ybT0ibWF0cml4KDEgMS43NDg0NmUtMDcgMS43NDg0NmUtMDcgLTEgNCAxMy40NDQzKSIvPgo8L2NsaXBQYXRoPgo8L2RlZnM+Cjwvc3ZnPgo=);
  --jp-icon-add: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDEzaC02djZoLTJ2LTZINXYtMmg2VjVoMnY2aDZ2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-bell: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE2IDE2IiB2ZXJzaW9uPSIxLjEiPgogICA8cGF0aCBjbGFzcz0ianAtaWNvbjIganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMzMzMzMzIgogICAgICBkPSJtOCAwLjI5Yy0xLjQgMC0yLjcgMC43My0zLjYgMS44LTEuMiAxLjUtMS40IDMuNC0xLjUgNS4yLTAuMTggMi4yLTAuNDQgNC0yLjMgNS4zbDAuMjggMS4zaDVjMC4wMjYgMC42NiAwLjMyIDEuMSAwLjcxIDEuNSAwLjg0IDAuNjEgMiAwLjYxIDIuOCAwIDAuNTItMC40IDAuNi0xIDAuNzEtMS41aDVsMC4yOC0xLjNjLTEuOS0wLjk3LTIuMi0zLjMtMi4zLTUuMy0wLjEzLTEuOC0wLjI2LTMuNy0xLjUtNS4yLTAuODUtMS0yLjItMS44LTMuNi0xLjh6bTAgMS40YzAuODggMCAxLjkgMC41NSAyLjUgMS4zIDAuODggMS4xIDEuMSAyLjcgMS4yIDQuNCAwLjEzIDEuNyAwLjIzIDMuNiAxLjMgNS4yaC0xMGMxLjEtMS42IDEuMi0zLjQgMS4zLTUuMiAwLjEzLTEuNyAwLjMtMy4zIDEuMi00LjQgMC41OS0wLjcyIDEuNi0xLjMgMi41LTEuM3ptLTAuNzQgMTJoMS41Yy0wLjAwMTUgMC4yOCAwLjAxNSAwLjc5LTAuNzQgMC43OS0wLjczIDAuMDAxNi0wLjcyLTAuNTMtMC43NC0wLjc5eiIgLz4KPC9zdmc+Cg==);
  --jp-icon-bug-dot: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQiIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiPgogICAgICAgIDxwYXRoIGZpbGwtcnVsZT0iZXZlbm9kZCIgY2xpcC1ydWxlPSJldmVub2RkIiBkPSJNMTcuMTkgOEgyMFYxMEgxNy45MUMxNy45NiAxMC4zMyAxOCAxMC42NiAxOCAxMVYxMkgyMFYxNEgxOC41SDE4VjE0LjAyNzVDMTUuNzUgMTQuMjc2MiAxNCAxNi4xODM3IDE0IDE4LjVDMTQgMTkuMjA4IDE0LjE2MzUgMTkuODc3OSAxNC40NTQ5IDIwLjQ3MzlDMTMuNzA2MyAyMC44MTE3IDEyLjg3NTcgMjEgMTIgMjFDOS43OCAyMSA3Ljg1IDE5Ljc5IDYuODEgMThINFYxNkg2LjA5QzYuMDQgMTUuNjcgNiAxNS4zNCA2IDE1VjE0SDRWMTJINlYxMUM2IDEwLjY2IDYuMDQgMTAuMzMgNi4wOSAxMEg0VjhINi44MUM3LjI2IDcuMjIgNy44OCA2LjU1IDguNjIgNi4wNEw3IDQuNDFMOC40MSAzTDEwLjU5IDUuMTdDMTEuMDQgNS4wNiAxMS41MSA1IDEyIDVDMTIuNDkgNSAxMi45NiA1LjA2IDEzLjQyIDUuMTdMMTUuNTkgM0wxNyA0LjQxTDE1LjM3IDYuMDRDMTYuMTIgNi41NSAxNi43NCA3LjIyIDE3LjE5IDhaTTEwIDE2SDE0VjE0SDEwVjE2Wk0xMCAxMkgxNFYxMEgxMFYxMloiIGZpbGw9IiM2MTYxNjEiLz4KICAgICAgICA8cGF0aCBkPSJNMjIgMTguNUMyMiAyMC40MzMgMjAuNDMzIDIyIDE4LjUgMjJDMTYuNTY3IDIyIDE1IDIwLjQzMyAxNSAxOC41QzE1IDE2LjU2NyAxNi41NjcgMTUgMTguNSAxNUMyMC40MzMgMTUgMjIgMTYuNTY3IDIyIDE4LjVaIiBmaWxsPSIjNjE2MTYxIi8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-bug: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0yMCA4aC0yLjgxYy0uNDUtLjc4LTEuMDctMS40NS0xLjgyLTEuOTZMMTcgNC40MSAxNS41OSAzbC0yLjE3IDIuMTdDMTIuOTYgNS4wNiAxMi40OSA1IDEyIDVjLS40OSAwLS45Ni4wNi0xLjQxLjE3TDguNDEgMyA3IDQuNDFsMS42MiAxLjYzQzcuODggNi41NSA3LjI2IDcuMjIgNi44MSA4SDR2MmgyLjA5Yy0uMDUuMzMtLjA5LjY2LS4wOSAxdjFINHYyaDJ2MWMwIC4zNC4wNC42Ny4wOSAxSDR2MmgyLjgxYzEuMDQgMS43OSAyLjk3IDMgNS4xOSAzczQuMTUtMS4yMSA1LjE5LTNIMjB2LTJoLTIuMDljLjA1LS4zMy4wOS0uNjYuMDktMXYtMWgydi0yaC0ydi0xYzAtLjM0LS4wNC0uNjctLjA5LTFIMjBWOHptLTYgOGgtNHYtMmg0djJ6bTAtNGgtNHYtMmg0djJ6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-build: url(data:image/svg+xml;base64,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);
  --jp-icon-caret-down-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iOS45LDEzLjYgMy42LDcuNCA0LjQsNi42IDkuOSwxMi4yIDE1LjQsNi43IDE2LjEsNy40ICIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-caret-down-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNS45TDksOS43bDMuOC0zLjhsMS4yLDEuMmwtNC45LDVsLTQuOS01TDUuMiw1Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-caret-down: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNy41TDksMTEuMmwzLjgtMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-caret-left: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik0xMC44LDEyLjhMNy4xLDlsMy44LTMuOGwwLDcuNkgxMC44eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-caret-right: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik03LjIsNS4yTDEwLjksOWwtMy44LDMuOFY1LjJINy4yeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-caret-up-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iMTUuNCwxMy4zIDkuOSw3LjcgNC40LDEzLjIgMy42LDEyLjUgOS45LDYuMyAxNi4xLDEyLjYgIi8+Cgk8L2c+Cjwvc3ZnPgo=);
  --jp-icon-caret-up: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik01LjIsMTAuNUw5LDYuOGwzLjgsMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-case-sensitive: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgogIDxnIGNsYXNzPSJqcC1pY29uLWFjY2VudDIiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTcuNiw4aDAuOWwzLjUsOGgtMS4xTDEwLDE0SDZsLTAuOSwySDRMNy42LDh6IE04LDkuMUw2LjQsMTNoMy4yTDgsOS4xeiIvPgogICAgPHBhdGggZD0iTTE2LjYsOS44Yy0wLjIsMC4xLTAuNCwwLjEtMC43LDAuMWMtMC4yLDAtMC40LTAuMS0wLjYtMC4yYy0wLjEtMC4xLTAuMi0wLjQtMC4yLTAuNyBjLTAuMywwLjMtMC42LDAuNS0wLjksMC43Yy0wLjMsMC4xLTAuNywwLjItMS4xLDAuMmMtMC4zLDAtMC41LDAtMC43LTAuMWMtMC4yLTAuMS0wLjQtMC4yLTAuNi0wLjNjLTAuMi0wLjEtMC4zLTAuMy0wLjQtMC41IGMtMC4xLTAuMi0wLjEtMC40LTAuMS0wLjdjMC0wLjMsMC4xLTAuNiwwLjItMC44YzAuMS0wLjIsMC4zLTAuNCwwLjQtMC41QzEyLDcsMTIuMiw2LjksMTIuNSw2LjhjMC4yLTAuMSwwLjUtMC4xLDAuNy0wLjIgYzAuMy0wLjEsMC41LTAuMSwwLjctMC4xYzAuMiwwLDAuNC0wLjEsMC42LTAuMWMwLjIsMCwwLjMtMC4xLDAuNC0wLjJjMC4xLTAuMSwwLjItMC4yLDAuMi0wLjRjMC0xLTEuMS0xLTEuMy0xIGMtMC40LDAtMS40LDAtMS40LDEuMmgtMC45YzAtMC40LDAuMS0wLjcsMC4yLTFjMC4xLTAuMiwwLjMtMC40LDAuNS0wLjZjMC4yLTAuMiwwLjUtMC4zLDAuOC0wLjNDMTMuMyw0LDEzLjYsNCwxMy45LDQgYzAuMywwLDAuNSwwLDAuOCwwLjFjMC4zLDAsMC41LDAuMSwwLjcsMC4yYzAuMiwwLjEsMC40LDAuMywwLjUsMC41QzE2LDUsMTYsNS4yLDE2LDUuNnYyLjljMCwwLjIsMCwwLjQsMCwwLjUgYzAsMC4xLDAuMSwwLjIsMC4zLDAuMmMwLjEsMCwwLjIsMCwwLjMsMFY5Ljh6IE0xNS4yLDYuOWMtMS4yLDAuNi0zLjEsMC4yLTMuMSwxLjRjMCwxLjQsMy4xLDEsMy4xLTAuNVY2Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-check: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik05IDE2LjE3TDQuODMgMTJsLTEuNDIgMS40MUw5IDE5IDIxIDdsLTEuNDEtMS40MXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-circle-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyIDJDNi40NyAyIDIgNi40NyAyIDEyczQuNDcgMTAgMTAgMTAgMTAtNC40NyAxMC0xMFMxNy41MyAyIDEyIDJ6bTAgMThjLTQuNDEgMC04LTMuNTktOC04czMuNTktOCA4LTggOCAzLjU5IDggOC0zLjU5IDgtOCA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-circle: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iOSIgY3k9IjkiIHI9IjgiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-clear: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8bWFzayBpZD0iZG9udXRIb2xlIj4KICAgIDxyZWN0IHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgZmlsbD0id2hpdGUiIC8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSI4IiBmaWxsPSJibGFjayIvPgogIDwvbWFzaz4KCiAgPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxyZWN0IGhlaWdodD0iMTgiIHdpZHRoPSIyIiB4PSIxMSIgeT0iMyIgdHJhbnNmb3JtPSJyb3RhdGUoMzE1LCAxMiwgMTIpIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIxMCIgbWFzaz0idXJsKCNkb251dEhvbGUpIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-close: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1ub25lIGpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIGpwLWljb24zLWhvdmVyIiBmaWxsPSJub25lIj4KICAgIDxjaXJjbGUgY3g9IjEyIiBjeT0iMTIiIHI9IjExIi8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIGpwLWljb24tYWNjZW50Mi1ob3ZlciIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMTkgNi40MUwxNy41OSA1IDEyIDEwLjU5IDYuNDEgNSA1IDYuNDEgMTAuNTkgMTIgNSAxNy41OSA2LjQxIDE5IDEyIDEzLjQxIDE3LjU5IDE5IDE5IDE3LjU5IDEzLjQxIDEyeiIvPgogIDwvZz4KCiAgPGcgY2xhc3M9ImpwLWljb24tbm9uZSBqcC1pY29uLWJ1c3kiIGZpbGw9Im5vbmUiPgogICAgPGNpcmNsZSBjeD0iMTIiIGN5PSIxMiIgcj0iNyIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-code-check: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBzaGFwZS1yZW5kZXJpbmc9Imdlb21ldHJpY1ByZWNpc2lvbiI+CiAgICA8cGF0aCBkPSJNNi41OSwzLjQxTDIsOEw2LjU5LDEyLjZMOCwxMS4xOEw0LjgyLDhMOCw0LjgyTDYuNTksMy40MU0xMi40MSwzLjQxTDExLDQuODJMMTQuMTgsOEwxMSwxMS4xOEwxMi40MSwxMi42TDE3LDhMMTIuNDEsMy40MU0yMS41OSwxMS41OUwxMy41LDE5LjY4TDkuODMsMTZMOC40MiwxNy40MUwxMy41LDIyLjVMMjMsMTNMMjEuNTksMTEuNTlaIiAvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-code: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIiIGhlaWdodD0iMjIiIHZpZXdCb3g9IjAgMCAyOCAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTExLjQgMTguNkw2LjggMTRMMTEuNCA5LjRMMTAgOEw0IDE0TDEwIDIwTDExLjQgMTguNlpNMTYuNiAxOC42TDIxLjIgMTRMMTYuNiA5LjRMMTggOEwyNCAxNEwxOCAyMEwxNi42IDE4LjZWMTguNloiLz4KCTwvZz4KPC9zdmc+Cg==);
  --jp-icon-collapse-all: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTggMmMxIDAgMTEgMCAxMiAwczIgMSAyIDJjMCAxIDAgMTEgMCAxMnMwIDItMiAyQzIwIDE0IDIwIDQgMjAgNFMxMCA0IDYgNGMwLTIgMS0yIDItMnoiIC8+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTE4IDhjMC0xLTEtMi0yLTJTNSA2IDQgNnMtMiAxLTIgMmMwIDEgMCAxMSAwIDEyczEgMiAyIDJjMSAwIDExIDAgMTIgMHMyLTEgMi0yYzAtMSAwLTExIDAtMTJ6bS0yIDB2MTJINFY4eiIgLz4KICAgICAgICA8cGF0aCBkPSJNNiAxM3YyaDh2LTJ6IiAvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-console: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwMCAyMDAiPgogIDxnIGNsYXNzPSJqcC1jb25zb2xlLWljb24tYmFja2dyb3VuZC1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMjg4RDEiPgogICAgPHBhdGggZD0iTTIwIDE5LjhoMTYwdjE1OS45SDIweiIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtY29uc29sZS1pY29uLWNvbG9yIGpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIiBmaWxsPSIjZmZmIj4KICAgIDxwYXRoIGQ9Ik0xMDUgMTI3LjNoNDB2MTIuOGgtNDB6TTUxLjEgNzdMNzQgOTkuOWwtMjMuMyAyMy4zIDEwLjUgMTAuNSAyMy4zLTIzLjNMOTUgOTkuOSA4NC41IDg5LjQgNjEuNiA2Ni41eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-copy: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTExLjksMUgzLjJDMi40LDEsMS43LDEuNywxLjcsMi41djEwLjJoMS41VjIuNWg4LjdWMXogTTE0LjEsMy45aC04Yy0wLjgsMC0xLjUsMC43LTEuNSwxLjV2MTAuMmMwLDAuOCwwLjcsMS41LDEuNSwxLjVoOCBjMC44LDAsMS41LTAuNywxLjUtMS41VjUuNEMxNS41LDQuNiwxNC45LDMuOSwxNC4xLDMuOXogTTE0LjEsMTUuNWgtOFY1LjRoOFYxNS41eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-copyright: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGVuYWJsZS1iYWNrZ3JvdW5kPSJuZXcgMCAwIDI0IDI0IiBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCI+CiAgPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0xMS44OCw5LjE0YzEuMjgsMC4wNiwxLjYxLDEuMTUsMS42MywxLjY2aDEuNzljLTAuMDgtMS45OC0xLjQ5LTMuMTktMy40NS0zLjE5QzkuNjQsNy42MSw4LDksOCwxMi4xNCBjMCwxLjk0LDAuOTMsNC4yNCwzLjg0LDQuMjRjMi4yMiwwLDMuNDEtMS42NSwzLjQ0LTIuOTVoLTEuNzljLTAuMDMsMC41OS0wLjQ1LDEuMzgtMS42MywxLjQ0QzEwLjU1LDE0LjgzLDEwLDEzLjgxLDEwLDEyLjE0IEMxMCw5LjI1LDExLjI4LDkuMTYsMTEuODgsOS4xNHogTTEyLDJDNi40OCwyLDIsNi40OCwyLDEyczQuNDgsMTAsMTAsMTBzMTAtNC40OCwxMC0xMFMxNy41MiwyLDEyLDJ6IE0xMiwyMGMtNC40MSwwLTgtMy41OS04LTggczMuNTktOCw4LThzOCwzLjU5LDgsOFMxNi40MSwyMCwxMiwyMHoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-cut: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkuNjQgNy42NGMuMjMtLjUuMzYtMS4wNS4zNi0xLjY0IDAtMi4yMS0xLjc5LTQtNC00UzIgMy43OSAyIDZzMS43OSA0IDQgNGMuNTkgMCAxLjE0LS4xMyAxLjY0LS4zNkwxMCAxMmwtMi4zNiAyLjM2QzcuMTQgMTQuMTMgNi41OSAxNCA2IDE0Yy0yLjIxIDAtNCAxLjc5LTQgNHMxLjc5IDQgNCA0IDQtMS43OSA0LTRjMC0uNTktLjEzLTEuMTQtLjM2LTEuNjRMMTIgMTRsNyA3aDN2LTFMOS42NCA3LjY0ek02IDhjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTAgMTJjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTYtNy41Yy0uMjggMC0uNS0uMjItLjUtLjVzLjIyLS41LjUtLjUuNS4yMi41LjUtLjIyLjUtLjUuNXpNMTkgM2wtNiA2IDIgMiA3LTdWM3oiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-delete: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2cHgiIGhlaWdodD0iMTZweCI+CiAgICA8cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIiAvPgogICAgPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjI2MjYyIiBkPSJNNiAxOWMwIDEuMS45IDIgMiAyaDhjMS4xIDAgMi0uOSAyLTJWN0g2djEyek0xOSA0aC0zLjVsLTEtMWgtNWwtMSAxSDV2MmgxNFY0eiIgLz4KPC9zdmc+Cg==);
  --jp-icon-download: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDloLTRWM0g5djZINWw3IDcgNy03ek01IDE4djJoMTR2LTJINXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-duplicate: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiIGNsaXAtcnVsZT0iZXZlbm9kZCIgZD0iTTIuNzk5OTggMC44NzVIOC44OTU4MkM5LjIwMDYxIDAuODc1IDkuNDQ5OTggMS4xMzkxNCA5LjQ0OTk4IDEuNDYxOThDOS40NDk5OCAxLjc4NDgyIDkuMjAwNjEgMi4wNDg5NiA4Ljg5NTgyIDIuMDQ4OTZIMy4zNTQxNUMzLjA0OTM2IDIuMDQ4OTYgMi43OTk5OCAyLjMxMzEgMi43OTk5OCAyLjYzNTk0VjkuNjc5NjlDMi43OTk5OCAxMC4wMDI1IDIuNTUwNjEgMTAuMjY2NyAyLjI0NTgyIDEwLjI2NjdDMS45NDEwMyAxMC4yNjY3IDEuNjkxNjUgMTAuMDAyNSAxLjY5MTY1IDkuNjc5NjlWMi4wNDg5NkMxLjY5MTY1IDEuNDAzMjggMi4xOTA0IDAuODc1IDIuNzk5OTggMC44NzVaTTUuMzY2NjUgMTEuOVY0LjU1SDExLjA4MzNWMTEuOUg1LjM2NjY1Wk00LjE0MTY1IDQuMTQxNjdDNC4xNDE2NSAzLjY5MDYzIDQuNTA3MjggMy4zMjUgNC45NTgzMiAzLjMyNUgxMS40OTE3QzExLjk0MjcgMy4zMjUgMTIuMzA4MyAzLjY5MDYzIDEyLjMwODMgNC4xNDE2N1YxMi4zMDgzQzEyLjMwODMgMTIuNzU5NCAxMS45NDI3IDEzLjEyNSAxMS40OTE3IDEzLjEyNUg0Ljk1ODMyQzQuNTA3MjggMTMuMTI1IDQuMTQxNjUgMTIuNzU5NCA0LjE0MTY1IDEyLjMwODNWNC4xNDE2N1oiIGZpbGw9IiM2MTYxNjEiLz4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNOS40MzU3NCA4LjI2NTA3SDguMzY0MzFWOS4zMzY1QzguMzY0MzEgOS40NTQzNSA4LjI2Nzg4IDkuNTUwNzggOC4xNTAwMiA5LjU1MDc4QzguMDMyMTcgOS41NTA3OCA3LjkzNTc0IDkuNDU0MzUgNy45MzU3NCA5LjMzNjVWOC4yNjUwN0g2Ljg2NDMxQzYuNzQ2NDUgOC4yNjUwNyA2LjY1MDAyIDguMTY4NjQgNi42NTAwMiA4LjA1MDc4QzYuNjUwMDIgNy45MzI5MiA2Ljc0NjQ1IDcuODM2NSA2Ljg2NDMxIDcuODM2NUg3LjkzNTc0VjYuNzY1MDdDNy45MzU3NCA2LjY0NzIxIDguMDMyMTcgNi41NTA3OCA4LjE1MDAyIDYuNTUwNzhDOC4yNjc4OCA2LjU1MDc4IDguMzY0MzEgNi42NDcyMSA4LjM2NDMxIDYuNzY1MDdWNy44MzY1SDkuNDM1NzRDOS41NTM2IDcuODM2NSA5LjY1MDAyIDcuOTMyOTIgOS42NTAwMiA4LjA1MDc4QzkuNjUwMDIgOC4xNjg2NCA5LjU1MzYgOC4yNjUwNyA5LjQzNTc0IDguMjY1MDdaIiBmaWxsPSIjNjE2MTYxIiBzdHJva2U9IiM2MTYxNjEiIHN0cm9rZS13aWR0aD0iMC41Ii8+Cjwvc3ZnPgo=);
  --jp-icon-edit: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMgMTcuMjVWMjFoMy43NUwxNy44MSA5Ljk0bC0zLjc1LTMuNzVMMyAxNy4yNXpNMjAuNzEgNy4wNGMuMzktLjM5LjM5LTEuMDIgMC0xLjQxbC0yLjM0LTIuMzRjLS4zOS0uMzktMS4wMi0uMzktMS40MSAwbC0xLjgzIDEuODMgMy43NSAzLjc1IDEuODMtMS44M3oiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-ellipses: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iNSIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxOSIgY3k9IjEyIiByPSIyIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-error: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj48Y2lyY2xlIGN4PSIxMiIgY3k9IjE5IiByPSIyIi8+PHBhdGggZD0iTTEwIDNoNHYxMmgtNHoiLz48L2c+CjxwYXRoIGZpbGw9Im5vbmUiIGQ9Ik0wIDBoMjR2MjRIMHoiLz4KPC9zdmc+Cg==);
  --jp-icon-expand-all: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTggMmMxIDAgMTEgMCAxMiAwczIgMSAyIDJjMCAxIDAgMTEgMCAxMnMwIDItMiAyQzIwIDE0IDIwIDQgMjAgNFMxMCA0IDYgNGMwLTIgMS0yIDItMnoiIC8+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTE4IDhjMC0xLTEtMi0yLTJTNSA2IDQgNnMtMiAxLTIgMmMwIDEgMCAxMSAwIDEyczEgMiAyIDJjMSAwIDExIDAgMTIgMHMyLTEgMi0yYzAtMSAwLTExIDAtMTJ6bS0yIDB2MTJINFY4eiIgLz4KICAgICAgICA8cGF0aCBkPSJNMTEgMTBIOXYzSDZ2MmgzdjNoMnYtM2gzdi0yaC0zeiIgLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-extension: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwLjUgMTFIMTlWN2MwLTEuMS0uOS0yLTItMmgtNFYzLjVDMTMgMi4xMiAxMS44OCAxIDEwLjUgMVM4IDIuMTIgOCAzLjVWNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAydjMuOEgzLjVjMS40OSAwIDIuNyAxLjIxIDIuNyAyLjdzLTEuMjEgMi43LTIuNyAyLjdIMlYyMGMwIDEuMS45IDIgMiAyaDMuOHYtMS41YzAtMS40OSAxLjIxLTIuNyAyLjctMi43IDEuNDkgMCAyLjcgMS4yMSAyLjcgMi43VjIySDE3YzEuMSAwIDItLjkgMi0ydi00aDEuNWMxLjM4IDAgMi41LTEuMTIgMi41LTIuNVMyMS44OCAxMSAyMC41IDExeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-fast-forward: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTQgMThsOC41LTZMNCA2djEyem05LTEydjEybDguNS02TDEzIDZ6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-file-upload: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkgMTZoNnYtNmg0bC03LTctNyA3aDR6bS00IDJoMTR2Mkg1eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-file: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuMyA4LjJsLTUuNS01LjVjLS4zLS4zLS43LS41LTEuMi0uNUgzLjljLS44LjEtMS42LjktMS42IDEuOHYxNC4xYzAgLjkuNyAxLjYgMS42IDEuNmgxNC4yYy45IDAgMS42LS43IDEuNi0xLjZWOS40Yy4xLS41LS4xLS45LS40LTEuMnptLTUuOC0zLjNsMy40IDMuNmgtMy40VjQuOXptMy45IDEyLjdINC43Yy0uMSAwLS4yIDAtLjItLjJWNC43YzAtLjIuMS0uMy4yLS4zaDcuMnY0LjRzMCAuOC4zIDEuMWMuMy4zIDEuMS4zIDEuMS4zaDQuM3Y3LjJzLS4xLjItLjIuMnoiLz4KPC9zdmc+Cg==);
  --jp-icon-filter-dot: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTE0LDEyVjE5Ljg4QzE0LjA0LDIwLjE4IDEzLjk0LDIwLjUgMTMuNzEsMjAuNzFDMTMuMzIsMjEuMSAxMi42OSwyMS4xIDEyLjMsMjAuNzFMMTAuMjksMTguN0MxMC4wNiwxOC40NyA5Ljk2LDE4LjE2IDEwLDE3Ljg3VjEySDkuOTdMNC4yMSw0LjYyQzMuODcsNC4xOSAzLjk1LDMuNTYgNC4zOCwzLjIyQzQuNTcsMy4wOCA0Ljc4LDMgNSwzVjNIMTlWM0MxOS4yMiwzIDE5LjQzLDMuMDggMTkuNjIsMy4yMkMyMC4wNSwzLjU2IDIwLjEzLDQuMTkgMTkuNzksNC42MkwxNC4wMywxMkgxNFoiIC8+CiAgPC9nPgogIDxnIGNsYXNzPSJqcC1pY29uLWRvdCIgZmlsbD0iI0ZGRiI+CiAgICA8Y2lyY2xlIGN4PSIxOCIgY3k9IjE3IiByPSIzIj48L2NpcmNsZT4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-filter-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEwIDE4aDR2LTJoLTR2MnpNMyA2djJoMThWNkgzem0zIDdoMTJ2LTJINnYyeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-filter: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTE0LDEyVjE5Ljg4QzE0LjA0LDIwLjE4IDEzLjk0LDIwLjUgMTMuNzEsMjAuNzFDMTMuMzIsMjEuMSAxMi42OSwyMS4xIDEyLjMsMjAuNzFMMTAuMjksMTguN0MxMC4wNiwxOC40NyA5Ljk2LDE4LjE2IDEwLDE3Ljg3VjEySDkuOTdMNC4yMSw0LjYyQzMuODcsNC4xOSAzLjk1LDMuNTYgNC4zOCwzLjIyQzQuNTcsMy4wOCA0Ljc4LDMgNSwzVjNIMTlWM0MxOS4yMiwzIDE5LjQzLDMuMDggMTkuNjIsMy4yMkMyMC4wNSwzLjU2IDIwLjEzLDQuMTkgMTkuNzksNC42MkwxNC4wMywxMkgxNFoiIC8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-folder-favorite: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjRweCIgdmlld0JveD0iMCAwIDI0IDI0IiB3aWR0aD0iMjRweCIgZmlsbD0iIzAwMDAwMCI+CiAgPHBhdGggZD0iTTAgMGgyNHYyNEgwVjB6IiBmaWxsPSJub25lIi8+PHBhdGggY2xhc3M9ImpwLWljb24zIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzYxNjE2MSIgZD0iTTIwIDZoLThsLTItMkg0Yy0xLjEgMC0yIC45LTIgMnYxMmMwIDEuMS45IDIgMiAyaDE2YzEuMSAwIDItLjkgMi0yVjhjMC0xLjEtLjktMi0yLTJ6bS0yLjA2IDExTDE1IDE1LjI4IDEyLjA2IDE3bC43OC0zLjMzLTIuNTktMi4yNCAzLjQxLS4yOUwxNSA4bDEuMzQgMy4xNCAzLjQxLjI5LTIuNTkgMi4yNC43OCAzLjMzeiIvPgo8L3N2Zz4K);
  --jp-icon-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY4YzAtMS4xLS45LTItMi0yaC04bC0yLTJ6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-home: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjRweCIgdmlld0JveD0iMCAwIDI0IDI0IiB3aWR0aD0iMjRweCIgZmlsbD0iIzAwMDAwMCI+CiAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPjxwYXRoIGNsYXNzPSJqcC1pY29uMyBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xMCAyMHYtNmg0djZoNXYtOGgzTDEyIDMgMiAxMmgzdjh6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-html5: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uMCBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMDAiIGQ9Ik0xMDguNCAwaDIzdjIyLjhoMjEuMlYwaDIzdjY5aC0yM1Y0NmgtMjF2MjNoLTIzLjJNMjA2IDIzaC0yMC4zVjBoNjMuN3YyM0gyMjl2NDZoLTIzbTUzLjUtNjloMjQuMWwxNC44IDI0LjNMMzEzLjIgMGgyNC4xdjY5aC0yM1YzNC44bC0xNi4xIDI0LjgtMTYuMS0yNC44VjY5aC0yMi42bTg5LjItNjloMjN2NDYuMmgzMi42VjY5aC01NS42Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI2U0NGQyNiIgZD0iTTEwNy42IDQ3MWwtMzMtMzcwLjRoMzYyLjhsLTMzIDM3MC4yTDI1NS43IDUxMiIvPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNmMTY1MjkiIGQ9Ik0yNTYgNDgwLjVWMTMxaDE0OC4zTDM3NiA0NDciLz4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNlYmViZWIiIGQ9Ik0xNDIgMTc2LjNoMTE0djQ1LjRoLTY0LjJsNC4yIDQ2LjVoNjB2NDUuM0gxNTQuNG0yIDIyLjhIMjAybDMuMiAzNi4zIDUwLjggMTMuNnY0Ny40bC05My4yLTI2Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIiBmaWxsPSIjZmZmIiBkPSJNMzY5LjYgMTc2LjNIMjU1Ljh2NDUuNGgxMDkuNm0tNC4xIDQ2LjVIMjU1Ljh2NDUuNGg1NmwtNS4zIDU5LTUwLjcgMTMuNnY0Ny4ybDkzLTI1LjgiLz4KPC9zdmc+Cg==);
  --jp-icon-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1icmFuZDQganAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNGRkYiIGQ9Ik0yLjIgMi4yaDE3LjV2MTcuNUgyLjJ6Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzNGNTFCNSIgZD0iTTIuMiAyLjJ2MTcuNWgxNy41bC4xLTE3LjVIMi4yem0xMi4xIDIuMmMxLjIgMCAyLjIgMSAyLjIgMi4ycy0xIDIuMi0yLjIgMi4yLTIuMi0xLTIuMi0yLjIgMS0yLjIgMi4yLTIuMnpNNC40IDE3LjZsMy4zLTguOCAzLjMgNi42IDIuMi0zLjIgNC40IDUuNEg0LjR6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-info: url(data:image/svg+xml;base64,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);
  --jp-icon-inspector: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaW5zcGVjdG9yLWljb24tY29sb3IganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY2YzAtMS4xLS45LTItMi0yem0tNSAxNEg0di00aDExdjR6bTAtNUg0VjloMTF2NHptNSA1aC00VjloNHY5eiIvPgo8L3N2Zz4K);
  --jp-icon-json: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtanNvbi1pY29uLWNvbG9yIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI0Y5QTgyNSI+CiAgICA8cGF0aCBkPSJNMjAuMiAxMS44Yy0xLjYgMC0xLjcuNS0xLjcgMSAwIC40LjEuOS4xIDEuMy4xLjUuMS45LjEgMS4zIDAgMS43LTEuNCAyLjMtMy41IDIuM2gtLjl2LTEuOWguNWMxLjEgMCAxLjQgMCAxLjQtLjggMC0uMyAwLS42LS4xLTEgMC0uNC0uMS0uOC0uMS0xLjIgMC0xLjMgMC0xLjggMS4zLTItMS4zLS4yLTEuMy0uNy0xLjMtMiAwLS40LjEtLjguMS0xLjIuMS0uNC4xLS43LjEtMSAwLS44LS40LS43LTEuNC0uOGgtLjVWNC4xaC45YzIuMiAwIDMuNS43IDMuNSAyLjMgMCAuNC0uMS45LS4xIDEuMy0uMS41LS4xLjktLjEgMS4zIDAgLjUuMiAxIDEuNyAxdjEuOHpNMS44IDEwLjFjMS42IDAgMS43LS41IDEuNy0xIDAtLjQtLjEtLjktLjEtMS4zLS4xLS41LS4xLS45LS4xLTEuMyAwLTEuNiAxLjQtMi4zIDMuNS0yLjNoLjl2MS45aC0uNWMtMSAwLTEuNCAwLTEuNC44IDAgLjMgMCAuNi4xIDEgMCAuMi4xLjYuMSAxIDAgMS4zIDAgMS44LTEuMyAyQzYgMTEuMiA2IDExLjcgNiAxM2MwIC40LS4xLjgtLjEgMS4yLS4xLjMtLjEuNy0uMSAxIDAgLjguMy44IDEuNC44aC41djEuOWgtLjljLTIuMSAwLTMuNS0uNi0zLjUtMi4zIDAtLjQuMS0uOS4xLTEuMy4xLS41LjEtLjkuMS0xLjMgMC0uNS0uMi0xLTEuNy0xdi0xLjl6Ii8+CiAgICA8Y2lyY2xlIGN4PSIxMSIgY3k9IjEzLjgiIHI9IjIuMSIvPgogICAgPGNpcmNsZSBjeD0iMTEiIGN5PSI4LjIiIHI9IjIuMSIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-julia: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDMyNSAzMDAiPgogIDxnIGNsYXNzPSJqcC1icmFuZDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjY2IzYzMzIj4KICAgIDxwYXRoIGQ9Ik0gMTUwLjg5ODQzOCAyMjUgQyAxNTAuODk4NDM4IDI2Ni40MjE4NzUgMTE3LjMyMDMxMiAzMDAgNzUuODk4NDM4IDMwMCBDIDM0LjQ3NjU2MiAzMDAgMC44OTg0MzggMjY2LjQyMTg3NSAwLjg5ODQzOCAyMjUgQyAwLjg5ODQzOCAxODMuNTc4MTI1IDM0LjQ3NjU2MiAxNTAgNzUuODk4NDM4IDE1MCBDIDExNy4zMjAzMTIgMTUwIDE1MC44OTg0MzggMTgzLjU3ODEyNSAxNTAuODk4NDM4IDIyNSIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzM4OTgyNiI+CiAgICA8cGF0aCBkPSJNIDIzNy41IDc1IEMgMjM3LjUgMTE2LjQyMTg3NSAyMDMuOTIxODc1IDE1MCAxNjIuNSAxNTAgQyAxMjEuMDc4MTI1IDE1MCA4Ny41IDExNi40MjE4NzUgODcuNSA3NSBDIDg3LjUgMzMuNTc4MTI1IDEyMS4wNzgxMjUgMCAxNjIuNSAwIEMgMjAzLjkyMTg3NSAwIDIzNy41IDMzLjU3ODEyNSAyMzcuNSA3NSIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzk1NThiMiI+CiAgICA8cGF0aCBkPSJNIDMyNC4xMDE1NjIgMjI1IEMgMzI0LjEwMTU2MiAyNjYuNDIxODc1IDI5MC41MjM0MzggMzAwIDI0OS4xMDE1NjIgMzAwIEMgMjA3LjY3OTY4OCAzMDAgMTc0LjEwMTU2MiAyNjYuNDIxODc1IDE3NC4xMDE1NjIgMjI1IEMgMTc0LjEwMTU2MiAxODMuNTc4MTI1IDIwNy42Nzk2ODggMTUwIDI0OS4xMDE1NjIgMTUwIEMgMjkwLjUyMzQzOCAxNTAgMzI0LjEwMTU2MiAxODMuNTc4MTI1IDMyNC4xMDE1NjIgMjI1Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-jupyter-favicon: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTUyIiBoZWlnaHQ9IjE2NSIgdmlld0JveD0iMCAwIDE1MiAxNjUiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgPGcgY2xhc3M9ImpwLWp1cHl0ZXItaWNvbi1jb2xvciIgZmlsbD0iI0YzNzcyNiI+CiAgICA8cGF0aCB0cmFuc2Zvcm09InRyYW5zbGF0ZSgwLjA3ODk0NywgMTEwLjU4MjkyNykiIGQ9Ik03NS45NDIyODQyLDI5LjU4MDQ1NjEgQzQzLjMwMjM5NDcsMjkuNTgwNDU2MSAxNC43OTY3ODMyLDE3LjY1MzQ2MzQgMCwwIEM1LjUxMDgzMjExLDE1Ljg0MDY4MjkgMTUuNzgxNTM4OSwyOS41NjY3NzMyIDI5LjM5MDQ5NDcsMzkuMjc4NDE3MSBDNDIuOTk5Nyw0OC45ODk4NTM3IDU5LjI3MzcsNTQuMjA2NzgwNSA3NS45NjA1Nzg5LDU0LjIwNjc4MDUgQzkyLjY0NzQ1NzksNTQuMjA2NzgwNSAxMDguOTIxNDU4LDQ4Ljk4OTg1MzcgMTIyLjUzMDY2MywzOS4yNzg0MTcxIEMxMzYuMTM5NDUzLDI5LjU2Njc3MzIgMTQ2LjQxMDI4NCwxNS44NDA2ODI5IDE1MS45MjExNTgsMCBDMTM3LjA4Nzg2OCwxNy42NTM0NjM0IDEwOC41ODI1ODksMjkuNTgwNDU2MSA3NS45NDIyODQyLDI5LjU4MDQ1NjEgTDc1Ljk0MjI4NDIsMjkuNTgwNDU2MSBaIiAvPgogICAgPHBhdGggdHJhbnNmb3JtPSJ0cmFuc2xhdGUoMC4wMzczNjgsIDAuNzA0ODc4KSIgZD0iTTc1Ljk3ODQ1NzksMjQuNjI2NDA3MyBDMTA4LjYxODc2MywyNC42MjY0MDczIDEzNy4xMjQ0NTgsMzYuNTUzNDQxNSAxNTEuOTIxMTU4LDU0LjIwNjc4MDUgQzE0Ni40MTAyODQsMzguMzY2MjIyIDEzNi4xMzk0NTMsMjQuNjQwMTMxNyAxMjIuNTMwNjYzLDE0LjkyODQ4NzggQzEwOC45MjE0NTgsNS4yMTY4NDM5IDkyLjY0NzQ1NzksMCA3NS45NjA1Nzg5LDAgQzU5LjI3MzcsMCA0Mi45OTk3LDUuMjE2ODQzOSAyOS4zOTA0OTQ3LDE0LjkyODQ4NzggQzE1Ljc4MTUzODksMjQuNjQwMTMxNyA1LjUxMDgzMjExLDM4LjM2NjIyMiAwLDU0LjIwNjc4MDUgQzE0LjgzMzA4MTYsMzYuNTg5OTI5MyA0My4zMzg1Njg0LDI0LjYyNjQwNzMgNzUuOTc4NDU3OSwyNC42MjY0MDczIEw3NS45Nzg0NTc5LDI0LjYyNjQwNzMgWiIgLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-jupyter: url(data:image/svg+xml;base64,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);
  --jp-icon-jupyterlab-wordmark: url(data:image/svg+xml;base64,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);
  --jp-icon-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgZmlsbD0iIzYxNjE2MSIgZD0iTTE1IDlIOXY2aDZWOXptLTIgNGgtMnYtMmgydjJ6bTgtMlY5aC0yVjdjMC0xLjEtLjktMi0yLTJoLTJWM2gtMnYyaC0yVjNIOXYySDdjLTEuMSAwLTIgLjktMiAydjJIM3YyaDJ2MkgzdjJoMnYyYzAgMS4xLjkgMiAyIDJoMnYyaDJ2LTJoMnYyaDJ2LTJoMmMxLjEgMCAyLS45IDItMnYtMmgydi0yaC0ydi0yaDJ6bS00IDZIN1Y3aDEwdjEweiIvPgo8L3N2Zz4K);
  --jp-icon-keyboard: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMTdjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY3YzAtMS4xLS45LTItMi0yem0tOSAzaDJ2MmgtMlY4em0wIDNoMnYyaC0ydi0yek04IDhoMnYySDhWOHptMCAzaDJ2Mkg4di0yem0tMSAySDV2LTJoMnYyem0wLTNINVY4aDJ2MnptOSA3SDh2LTJoOHYyem0wLTRoLTJ2LTJoMnYyem0wLTNoLTJWOGgydjJ6bTMgM2gtMnYtMmgydjJ6bTAtM2gtMlY4aDJ2MnoiLz4KPC9zdmc+Cg==);
  --jp-icon-launch: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMzIgMzIiIHdpZHRoPSIzMiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0yNiwyOEg2YTIuMDAyNywyLjAwMjcsMCwwLDEtMi0yVjZBMi4wMDI3LDIuMDAyNywwLDAsMSw2LDRIMTZWNkg2VjI2SDI2VjE2aDJWMjZBMi4wMDI3LDIuMDAyNywwLDAsMSwyNiwyOFoiLz4KICAgIDxwb2x5Z29uIHBvaW50cz0iMjAgMiAyMCA0IDI2LjU4NiA0IDE4IDEyLjU4NiAxOS40MTQgMTQgMjggNS40MTQgMjggMTIgMzAgMTIgMzAgMiAyMCAyIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-launcher: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkgMTlINVY1aDdWM0g1YTIgMiAwIDAwLTIgMnYxNGEyIDIgMCAwMDIgMmgxNGMxLjEgMCAyLS45IDItMnYtN2gtMnY3ek0xNCAzdjJoMy41OWwtOS44MyA5LjgzIDEuNDEgMS40MUwxOSA2LjQxVjEwaDJWM2gtN3oiLz4KPC9zdmc+Cg==);
  --jp-icon-line-form: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGZpbGw9IndoaXRlIiBkPSJNNS44OCA0LjEyTDEzLjc2IDEybC03Ljg4IDcuODhMOCAyMmwxMC0xMEw4IDJ6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-link: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMuOSAxMmMwLTEuNzEgMS4zOS0zLjEgMy4xLTMuMWg0VjdIN2MtMi43NiAwLTUgMi4yNC01IDVzMi4yNCA1IDUgNWg0di0xLjlIN2MtMS43MSAwLTMuMS0xLjM5LTMuMS0zLjF6TTggMTNoOHYtMkg4djJ6bTktNmgtNHYxLjloNGMxLjcxIDAgMy4xIDEuMzkgMy4xIDMuMXMtMS4zOSAzLjEtMy4xIDMuMWgtNFYxN2g0YzIuNzYgMCA1LTIuMjQgNS01cy0yLjI0LTUtNS01eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xOSA1djE0SDVWNWgxNG0xLjEtMkgzLjljLS41IDAtLjkuNC0uOS45djE2LjJjMCAuNC40LjkuOS45aDE2LjJjLjQgMCAuOS0uNS45LS45VjMuOWMwLS41LS41LS45LS45LS45ek0xMSA3aDZ2MmgtNlY3em0wIDRoNnYyaC02di0yem0wIDRoNnYyaC02ek03IDdoMnYySDd6bTAgNGgydjJIN3ptMCA0aDJ2Mkg3eiIvPgo8L3N2Zz4K);
  --jp-icon-markdown: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjN0IxRkEyIiBkPSJNNSAxNC45aDEybC02LjEgNnptOS40LTYuOGMwLTEuMy0uMS0yLjktLjEtNC41LS40IDEuNC0uOSAyLjktMS4zIDQuM2wtMS4zIDQuM2gtMkw4LjUgNy45Yy0uNC0xLjMtLjctMi45LTEtNC4zLS4xIDEuNi0uMSAzLjItLjIgNC42TDcgMTIuNEg0LjhsLjctMTFoMy4zTDEwIDVjLjQgMS4yLjcgMi43IDEgMy45LjMtMS4yLjctMi42IDEtMy45bDEuMi0zLjdoMy4zbC42IDExaC0yLjRsLS4zLTQuMnoiLz4KPC9zdmc+Cg==);
  --jp-icon-move-down: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNMTIuNDcxIDcuNTI4OTlDMTIuNzYzMiA3LjIzNjg0IDEyLjc2MzIgNi43NjMxNiAxMi40NzEgNi40NzEwMVY2LjQ3MTAxQzEyLjE3OSA2LjE3OTA1IDExLjcwNTcgNi4xNzg4NCAxMS40MTM1IDYuNDcwNTRMNy43NSAxMC4xMjc1VjEuNzVDNy43NSAxLjMzNTc5IDcuNDE0MjEgMSA3IDFWMUM2LjU4NTc5IDEgNi4yNSAxLjMzNTc5IDYuMjUgMS43NVYxMC4xMjc1TDIuNTk3MjYgNi40NjgyMkMyLjMwMzM4IDYuMTczODEgMS44MjY0MSA2LjE3MzU5IDEuNTMyMjYgNi40Njc3NFY2LjQ2Nzc0QzEuMjM4MyA2Ljc2MTcgMS4yMzgzIDcuMjM4MyAxLjUzMjI2IDcuNTMyMjZMNi4yOTI4OSAxMi4yOTI5QzYuNjgzNDIgMTIuNjgzNCA3LjMxNjU4IDEyLjY4MzQgNy43MDcxMSAxMi4yOTI5TDEyLjQ3MSA3LjUyODk5WiIgZmlsbD0iIzYxNjE2MSIvPgo8L3N2Zz4K);
  --jp-icon-move-up: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNMS41Mjg5OSA2LjQ3MTAxQzEuMjM2ODQgNi43NjMxNiAxLjIzNjg0IDcuMjM2ODQgMS41Mjg5OSA3LjUyODk5VjcuNTI4OTlDMS44MjA5NSA3LjgyMDk1IDIuMjk0MjYgNy44MjExNiAyLjU4NjQ5IDcuNTI5NDZMNi4yNSAzLjg3MjVWMTIuMjVDNi4yNSAxMi42NjQyIDYuNTg1NzkgMTMgNyAxM1YxM0M3LjQxNDIxIDEzIDcuNzUgMTIuNjY0MiA3Ljc1IDEyLjI1VjMuODcyNUwxMS40MDI3IDcuNTMxNzhDMTEuNjk2NiA3LjgyNjE5IDEyLjE3MzYgNy44MjY0MSAxMi40Njc3IDcuNTMyMjZWNy41MzIyNkMxMi43NjE3IDcuMjM4MyAxMi43NjE3IDYuNzYxNyAxMi40Njc3IDYuNDY3NzRMNy43MDcxMSAxLjcwNzExQzcuMzE2NTggMS4zMTY1OCA2LjY4MzQyIDEuMzE2NTggNi4yOTI4OSAxLjcwNzExTDEuNTI4OTkgNi40NzEwMVoiIGZpbGw9IiM2MTYxNjEiLz4KPC9zdmc+Cg==);
  --jp-icon-new-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwIDZoLThsLTItMkg0Yy0xLjExIDAtMS45OS44OS0xLjk5IDJMMiAxOGMwIDEuMTEuODkgMiAyIDJoMTZjMS4xMSAwIDItLjg5IDItMlY4YzAtMS4xMS0uODktMi0yLTJ6bS0xIDhoLTN2M2gtMnYtM2gtM3YtMmgzVjloMnYzaDN2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-not-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI1IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDMgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMTkgMTcuMTg0NCAyLjk2OTY4IDE0LjMwMzIgMS44NjA5NCAxMS40NDA5WiIvPgogICAgPHBhdGggY2xhc3M9ImpwLWljb24yIiBzdHJva2U9IiMzMzMzMzMiIHN0cm9rZS13aWR0aD0iMiIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOS4zMTU5MiA5LjMyMDMxKSIgZD0iTTcuMzY4NDIgMEwwIDcuMzY0NzkiLz4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDkuMzE1OTIgMTYuNjgzNikgc2NhbGUoMSAtMSkiIGQ9Ik03LjM2ODQyIDBMMCA3LjM2NDc5Ii8+Cjwvc3ZnPgo=);
  --jp-icon-notebook: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtbm90ZWJvb2staWNvbi1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNFRjZDMDAiPgogICAgPHBhdGggZD0iTTE4LjcgMy4zdjE1LjRIMy4zVjMuM2gxNS40bTEuNS0xLjVIMS44djE4LjNoMTguM2wuMS0xOC4zeiIvPgogICAgPHBhdGggZD0iTTE2LjUgMTYuNWwtNS40LTQuMy01LjYgNC4zdi0xMWgxMXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-numbering: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIiIGhlaWdodD0iMjIiIHZpZXdCb3g9IjAgMCAyOCAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTQgMTlINlYxOS41SDVWMjAuNUg2VjIxSDRWMjJIN1YxOEg0VjE5Wk01IDEwSDZWNkg0VjdINVYxMFpNNCAxM0g1LjhMNCAxNS4xVjE2SDdWMTVINS4yTDcgMTIuOVYxMkg0VjEzWk05IDdWOUgyM1Y3SDlaTTkgMjFIMjNWMTlIOVYyMVpNOSAxNUgyM1YxM0g5VjE1WiIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-offline-bolt: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyIDIuMDJjLTUuNTEgMC05Ljk4IDQuNDctOS45OCA5Ljk4czQuNDcgOS45OCA5Ljk4IDkuOTggOS45OC00LjQ3IDkuOTgtOS45OFMxNy41MSAyLjAyIDEyIDIuMDJ6TTExLjQ4IDIwdi02LjI2SDhMMTMgNHY2LjI2aDMuMzVMMTEuNDggMjB6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-palette: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE4IDEzVjIwSDRWNkg5LjAyQzkuMDcgNS4yOSA5LjI0IDQuNjIgOS41IDRINEMyLjkgNCAyIDQuOSAyIDZWMjBDMiAyMS4xIDIuOSAyMiA0IDIySDE4QzE5LjEgMjIgMjAgMjEuMSAyMCAyMFYxNUwxOCAxM1pNMTkuMyA4Ljg5QzE5Ljc0IDguMTkgMjAgNy4zOCAyMCA2LjVDMjAgNC4wMSAxNy45OSAyIDE1LjUgMkMxMy4wMSAyIDExIDQuMDEgMTEgNi41QzExIDguOTkgMTMuMDEgMTEgMTUuNDkgMTFDMTYuMzcgMTEgMTcuMTkgMTAuNzQgMTcuODggMTAuM0wyMSAxMy40MkwyMi40MiAxMkwxOS4zIDguODlaTTE1LjUgOUMxNC4xMiA5IDEzIDcuODggMTMgNi41QzEzIDUuMTIgMTQuMTIgNCAxNS41IDRDMTYuODggNCAxOCA1LjEyIDE4IDYuNUMxOCA3Ljg4IDE2Ljg4IDkgMTUuNSA5WiIvPgogICAgPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik00IDZIOS4wMTg5NEM5LjAwNjM5IDYuMTY1MDIgOSA2LjMzMTc2IDkgNi41QzkgOC44MTU3NyAxMC4yMTEgMTAuODQ4NyAxMi4wMzQzIDEySDlWMTRIMTZWMTIuOTgxMUMxNi41NzAzIDEyLjkzNzcgMTcuMTIgMTIuODIwNyAxNy42Mzk2IDEyLjYzOTZMMTggMTNWMjBINFY2Wk04IDhINlYxMEg4VjhaTTYgMTJIOFYxNEg2VjEyWk04IDE2SDZWMThIOFYxNlpNOSAxNkgxNlYxOEg5VjE2WiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-paste: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE5IDJoLTQuMThDMTQuNC44NCAxMy4zIDAgMTIgMGMtMS4zIDAtMi40Ljg0LTIuODIgMkg1Yy0xLjEgMC0yIC45LTIgMnYxNmMwIDEuMS45IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjRjMC0xLjEtLjktMi0yLTJ6bS03IDBjLjU1IDAgMSAuNDUgMSAxcy0uNDUgMS0xIDEtMS0uNDUtMS0xIC40NS0xIDEtMXptNyAxOEg1VjRoMnYzaDEwVjRoMnYxNnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-pdf: url(data:image/svg+xml;base64,PHN2ZwogICB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyMiAyMiIgd2lkdGg9IjE2Ij4KICAgIDxwYXRoIHRyYW5zZm9ybT0icm90YXRlKDQ1KSIgY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI0ZGMkEyQSIKICAgICAgIGQ9Im0gMjIuMzQ0MzY5LC0zLjAxNjM2NDIgaCA1LjYzODYwNCB2IDEuNTc5MjQzMyBoIC0zLjU0OTIyNyB2IDEuNTA4NjkyOTkgaCAzLjMzNzU3NiBWIDEuNjUwODE1NCBoIC0zLjMzNzU3NiB2IDMuNDM1MjYxMyBoIC0yLjA4OTM3NyB6IG0gLTcuMTM2NDQ0LDEuNTc5MjQzMyB2IDQuOTQzOTU0MyBoIDAuNzQ4OTIgcSAxLjI4MDc2MSwwIDEuOTUzNzAzLC0wLjYzNDk1MzUgMC42NzgzNjksLTAuNjM0OTUzNSAwLjY3ODM2OSwtMS44NDUxNjQxIDAsLTEuMjA0NzgzNTUgLTAuNjcyOTQyLC0xLjgzNDMxMDExIC0wLjY3Mjk0MiwtMC42Mjk1MjY1OSAtMS45NTkxMywtMC42Mjk1MjY1OSB6IG0gLTIuMDg5Mzc3LC0xLjU3OTI0MzMgaCAyLjIwMzM0MyBxIDEuODQ1MTY0LDAgMi43NDYwMzksMC4yNjU5MjA3IDAuOTA2MzAxLDAuMjYwNDkzNyAxLjU1MjEwOCwwLjg5MDAyMDMgMC41Njk4MywwLjU0ODEyMjMgMC44NDY2MDUsMS4yNjQ0ODAwNiAwLjI3Njc3NCwwLjcxNjM1NzgxIDAuMjc2Nzc0LDEuNjIyNjU4OTQgMCwwLjkxNzE1NTEgLTAuMjc2Nzc0LDEuNjM4OTM5OSAtMC4yNzY3NzUsMC43MTYzNTc4IC0wLjg0NjYwNSwxLjI2NDQ4IC0wLjY1MTIzNCwwLjYyOTUyNjYgLTEuNTYyOTYyLDAuODk1NDQ3MyAtMC45MTE3MjgsMC4yNjA0OTM3IC0yLjczNTE4NSwwLjI2MDQ5MzcgaCAtMi4yMDMzNDMgeiBtIC04LjE0NTg1NjUsMCBoIDMuNDY3ODIzIHEgMS41NDY2ODE2LDAgMi4zNzE1Nzg1LDAuNjg5MjIzIDAuODMwMzI0LDAuNjgzNzk2MSAwLjgzMDMyNCwxLjk1MzcwMzE0IDAsMS4yNzUzMzM5NyAtMC44MzAzMjQsMS45NjQ1NTcwNiBRIDkuOTg3MTk2MSwyLjI3NDkxNSA4LjQ0MDUxNDUsMi4yNzQ5MTUgSCA3LjA2MjA2ODQgViA1LjA4NjA3NjcgSCA0Ljk3MjY5MTUgWiBtIDIuMDg5Mzc2OSwxLjUxNDExOTkgdiAyLjI2MzAzOTQzIGggMS4xNTU5NDEgcSAwLjYwNzgxODgsMCAwLjkzODg2MjksLTAuMjkzMDU1NDcgMC4zMzEwNDQxLC0wLjI5ODQ4MjQxIDAuMzMxMDQ0MSwtMC44NDExNzc3MiAwLC0wLjU0MjY5NTMxIC0wLjMzMTA0NDEsLTAuODM1NzUwNzQgLTAuMzMxMDQ0MSwtMC4yOTMwNTU1IC0wLjkzODg2MjksLTAuMjkzMDU1NSB6IgovPgo8L3N2Zz4K);
  --jp-icon-python: url(data:image/svg+xml;base64,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);
  --jp-icon-r-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjE5NkYzIiBkPSJNNC40IDIuNWMxLjItLjEgMi45LS4zIDQuOS0uMyAyLjUgMCA0LjEuNCA1LjIgMS4zIDEgLjcgMS41IDEuOSAxLjUgMy41IDAgMi0xLjQgMy41LTIuOSA0LjEgMS4yLjQgMS43IDEuNiAyLjIgMyAuNiAxLjkgMSAzLjkgMS4zIDQuNmgtMy44Yy0uMy0uNC0uOC0xLjctMS4yLTMuN3MtMS4yLTIuNi0yLjYtMi42aC0uOXY2LjRINC40VjIuNXptMy43IDYuOWgxLjRjMS45IDAgMi45LS45IDIuOS0yLjNzLTEtMi4zLTIuOC0yLjNjLS43IDAtMS4zIDAtMS42LjJ2NC41aC4xdi0uMXoiLz4KPC9zdmc+Cg==);
  --jp-icon-react: url(data:image/svg+xml;base64,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);
  --jp-icon-redo: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgICA8cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIi8+PHBhdGggZD0iTTE4LjQgMTAuNkMxNi41NSA4Ljk5IDE0LjE1IDggMTEuNSA4Yy00LjY1IDAtOC41OCAzLjAzLTkuOTYgNy4yMkwzLjkgMTZjMS4wNS0zLjE5IDQuMDUtNS41IDcuNi01LjUgMS45NSAwIDMuNzMuNzIgNS4xMiAxLjg4TDEzIDE2aDlWN2wtMy42IDMuNnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-refresh: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTkgMTMuNWMtMi40OSAwLTQuNS0yLjAxLTQuNS00LjVTNi41MSA0LjUgOSA0LjVjMS4yNCAwIDIuMzYuNTIgMy4xNyAxLjMzTDEwIDhoNVYzbC0xLjc2IDEuNzZDMTIuMTUgMy42OCAxMC42NiAzIDkgMyA1LjY5IDMgMy4wMSA1LjY5IDMuMDEgOVM1LjY5IDE1IDkgMTVjMi45NyAwIDUuNDMtMi4xNiA1LjktNWgtMS41MmMtLjQ2IDItMi4yNCAzLjUtNC4zOCAzLjV6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-regex: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbi1hY2NlbnQyIiBmaWxsPSIjRkZGIj4KICAgIDxjaXJjbGUgY2xhc3M9InN0MiIgY3g9IjUuNSIgY3k9IjE0LjUiIHI9IjEuNSIvPgogICAgPHJlY3QgeD0iMTIiIHk9IjQiIGNsYXNzPSJzdDIiIHdpZHRoPSIxIiBoZWlnaHQ9IjgiLz4KICAgIDxyZWN0IHg9IjguNSIgeT0iNy41IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjg2NiAtMC41IDAuNSAwLjg2NiAtMi4zMjU1IDcuMzIxOSkiIGNsYXNzPSJzdDIiIHdpZHRoPSI4IiBoZWlnaHQ9IjEiLz4KICAgIDxyZWN0IHg9IjEyIiB5PSI0IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjUgLTAuODY2IDAuODY2IDAuNSAtMC42Nzc5IDE0LjgyNTIpIiBjbGFzcz0ic3QyIiB3aWR0aD0iMSIgaGVpZ2h0PSI4Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-run: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTggNXYxNGwxMS03eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-running: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMjU2IDhDMTE5IDggOCAxMTkgOCAyNTZzMTExIDI0OCAyNDggMjQ4IDI0OC0xMTEgMjQ4LTI0OFMzOTMgOCAyNTYgOHptOTYgMzI4YzAgOC44LTcuMiAxNi0xNiAxNkgxNzZjLTguOCAwLTE2LTcuMi0xNi0xNlYxNzZjMC04LjggNy4yLTE2IDE2LTE2aDE2MGM4LjggMCAxNiA3LjIgMTYgMTZ2MTYweiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-save: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE3IDNINWMtMS4xMSAwLTIgLjktMiAydjE0YzAgMS4xLjg5IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjdsLTQtNHptLTUgMTZjLTEuNjYgMC0zLTEuMzQtMy0zczEuMzQtMyAzLTMgMyAxLjM0IDMgMy0xLjM0IDMtMyAzem0zLTEwSDVWNWgxMHY0eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-search: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjEsMTAuOWgtMC43bC0wLjItMC4yYzAuOC0wLjksMS4zLTIuMiwxLjMtMy41YzAtMy0yLjQtNS40LTUuNC01LjRTMS44LDQuMiwxLjgsNy4xczIuNCw1LjQsNS40LDUuNCBjMS4zLDAsMi41LTAuNSwzLjUtMS4zbDAuMiwwLjJ2MC43bDQuMSw0LjFsMS4yLTEuMkwxMi4xLDEwLjl6IE03LjEsMTAuOWMtMi4xLDAtMy43LTEuNy0zLjctMy43czEuNy0zLjcsMy43LTMuN3MzLjcsMS43LDMuNywzLjcgUzkuMiwxMC45LDcuMSwxMC45eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-settings: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuNDMgMTIuOThjLjA0LS4zMi4wNy0uNjQuMDctLjk4cy0uMDMtLjY2LS4wNy0uOThsMi4xMS0xLjY1Yy4xOS0uMTUuMjQtLjQyLjEyLS42NGwtMi0zLjQ2Yy0uMTItLjIyLS4zOS0uMy0uNjEtLjIybC0yLjQ5IDFjLS41Mi0uNC0xLjA4LS43My0xLjY5LS45OGwtLjM4LTIuNjVBLjQ4OC40ODggMCAwMDE0IDJoLTRjLS4yNSAwLS40Ni4xOC0uNDkuNDJsLS4zOCAyLjY1Yy0uNjEuMjUtMS4xNy41OS0xLjY5Ljk4bC0yLjQ5LTFjLS4yMy0uMDktLjQ5IDAtLjYxLjIybC0yIDMuNDZjLS4xMy4yMi0uMDcuNDkuMTIuNjRsMi4xMSAxLjY1Yy0uMDQuMzItLjA3LjY1LS4wNy45OHMuMDMuNjYuMDcuOThsLTIuMTEgMS42NWMtLjE5LjE1LS4yNC40Mi0uMTIuNjRsMiAzLjQ2Yy4xMi4yMi4zOS4zLjYxLjIybDIuNDktMWMuNTIuNCAxLjA4LjczIDEuNjkuOThsLjM4IDIuNjVjLjAzLjI0LjI0LjQyLjQ5LjQyaDRjLjI1IDAgLjQ2LS4xOC40OS0uNDJsLjM4LTIuNjVjLjYxLS4yNSAxLjE3LS41OSAxLjY5LS45OGwyLjQ5IDFjLjIzLjA5LjQ5IDAgLjYxLS4yMmwyLTMuNDZjLjEyLS4yMi4wNy0uNDktLjEyLS42NGwtMi4xMS0xLjY1ek0xMiAxNS41Yy0xLjkzIDAtMy41LTEuNTctMy41LTMuNXMxLjU3LTMuNSAzLjUtMy41IDMuNSAxLjU3IDMuNSAzLjUtMS41NyAzLjUtMy41IDMuNXoiLz4KPC9zdmc+Cg==);
  --jp-icon-share: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIHZpZXdCb3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTSAxOCAyIEMgMTYuMzU0OTkgMiAxNSAzLjM1NDk5MDQgMTUgNSBDIDE1IDUuMTkwOTUyOSAxNS4wMjE3OTEgNS4zNzcxMjI0IDE1LjA1NjY0MSA1LjU1ODU5MzggTCA3LjkyMTg3NSA5LjcyMDcwMzEgQyA3LjM5ODUzOTkgOS4yNzc4NTM5IDYuNzMyMDc3MSA5IDYgOSBDIDQuMzU0OTkwNCA5IDMgMTAuMzU0OTkgMyAxMiBDIDMgMTMuNjQ1MDEgNC4zNTQ5OTA0IDE1IDYgMTUgQyA2LjczMjA3NzEgMTUgNy4zOTg1Mzk5IDE0LjcyMjE0NiA3LjkyMTg3NSAxNC4yNzkyOTcgTCAxNS4wNTY2NDEgMTguNDM5NDUzIEMgMTUuMDIxNTU1IDE4LjYyMTUxNCAxNSAxOC44MDgzODYgMTUgMTkgQyAxNSAyMC42NDUwMSAxNi4zNTQ5OSAyMiAxOCAyMiBDIDE5LjY0NTAxIDIyIDIxIDIwLjY0NTAxIDIxIDE5IEMgMjEgMTcuMzU0OTkgMTkuNjQ1MDEgMTYgMTggMTYgQyAxNy4yNjc0OCAxNiAxNi42MDE1OTMgMTYuMjc5MzI4IDE2LjA3ODEyNSAxNi43MjI2NTYgTCA4Ljk0MzM1OTQgMTIuNTU4NTk0IEMgOC45NzgyMDk1IDEyLjM3NzEyMiA5IDEyLjE5MDk1MyA5IDEyIEMgOSAxMS44MDkwNDcgOC45NzgyMDk1IDExLjYyMjg3OCA4Ljk0MzM1OTQgMTEuNDQxNDA2IEwgMTYuMDc4MTI1IDcuMjc5Mjk2OSBDIDE2LjYwMTQ2IDcuNzIyMTQ2MSAxNy4yNjc5MjMgOCAxOCA4IEMgMTkuNjQ1MDEgOCAyMSA2LjY0NTAwOTYgMjEgNSBDIDIxIDMuMzU0OTkwNCAxOS42NDUwMSAyIDE4IDIgeiBNIDE4IDQgQyAxOC41NjQxMjkgNCAxOSA0LjQzNTg3MDYgMTkgNSBDIDE5IDUuNTY0MTI5NCAxOC41NjQxMjkgNiAxOCA2IEMgMTcuNDM1ODcxIDYgMTcgNS41NjQxMjk0IDE3IDUgQyAxNyA0LjQzNTg3MDYgMTcuNDM1ODcxIDQgMTggNCB6IE0gNiAxMSBDIDYuNTY0MTI5NCAxMSA3IDExLjQzNTg3MSA3IDEyIEMgNyAxMi41NjQxMjkgNi41NjQxMjk0IDEzIDYgMTMgQyA1LjQzNTg3MDYgMTMgNSAxMi41NjQxMjkgNSAxMiBDIDUgMTEuNDM1ODcxIDUuNDM1ODcwNiAxMSA2IDExIHogTSAxOCAxOCBDIDE4LjU2NDEyOSAxOCAxOSAxOC40MzU4NzEgMTkgMTkgQyAxOSAxOS41NjQxMjkgMTguNTY0MTI5IDIwIDE4IDIwIEMgMTcuNDM1ODcxIDIwIDE3IDE5LjU2NDEyOSAxNyAxOSBDIDE3IDE4LjQzNTg3MSAxNy40MzU4NzEgMTggMTggMTggeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-spreadsheet: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNENBRjUwIiBkPSJNMi4yIDIuMnYxNy42aDE3LjZWMi4ySDIuMnptMTUuNCA3LjdoLTUuNVY0LjRoNS41djUuNXpNOS45IDQuNHY1LjVINC40VjQuNGg1LjV6bS01LjUgNy43aDUuNXY1LjVINC40di01LjV6bTcuNyA1LjV2LTUuNWg1LjV2NS41aC01LjV6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-stop: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik02IDZoMTJ2MTJINnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-tab: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIxIDNIM2MtMS4xIDAtMiAuOS0yIDJ2MTRjMCAxLjEuOSAyIDIgMmgxOGMxLjEgMCAyLS45IDItMlY1YzAtMS4xLS45LTItMi0yem0wIDE2SDNWNWgxMHY0aDh2MTB6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-table-rows: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik0yMSw4SDNWNGgxOFY4eiBNMjEsMTBIM3Y0aDE4VjEweiBNMjEsMTZIM3Y0aDE4VjE2eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-tag: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjgiIGhlaWdodD0iMjgiIHZpZXdCb3g9IjAgMCA0MyAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTI4LjgzMzIgMTIuMzM0TDMyLjk5OTggMTYuNTAwN0wzNy4xNjY1IDEyLjMzNEgyOC44MzMyWiIvPgoJCTxwYXRoIGQ9Ik0xNi4yMDk1IDIxLjYxMDRDMTUuNjg3MyAyMi4xMjk5IDE0Ljg0NDMgMjIuMTI5OSAxNC4zMjQ4IDIxLjYxMDRMNi45ODI5IDE0LjcyNDVDNi41NzI0IDE0LjMzOTQgNi4wODMxMyAxMy42MDk4IDYuMDQ3ODYgMTMuMDQ4MkM1Ljk1MzQ3IDExLjUyODggNi4wMjAwMiA4LjYxOTQ0IDYuMDY2MjEgNy4wNzY5NUM2LjA4MjgxIDYuNTE0NzcgNi41NTU0OCA2LjA0MzQ3IDcuMTE4MDQgNi4wMzA1NUM5LjA4ODYzIDUuOTg0NzMgMTMuMjYzOCA1LjkzNTc5IDEzLjY1MTggNi4zMjQyNUwyMS43MzY5IDEzLjYzOUMyMi4yNTYgMTQuMTU4NSAyMS43ODUxIDE1LjQ3MjQgMjEuMjYyIDE1Ljk5NDZMMTYuMjA5NSAyMS42MTA0Wk05Ljc3NTg1IDguMjY1QzkuMzM1NTEgNy44MjU2NiA4LjYyMzUxIDcuODI1NjYgOC4xODI4IDguMjY1QzcuNzQzNDYgOC43MDU3MSA3Ljc0MzQ2IDkuNDE3MzMgOC4xODI4IDkuODU2NjdDOC42MjM4MiAxMC4yOTY0IDkuMzM1ODIgMTAuMjk2NCA5Ljc3NTg1IDkuODU2NjdDMTAuMjE1NiA5LjQxNzMzIDEwLjIxNTYgOC43MDUzMyA5Ljc3NTg1IDguMjY1WiIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-terminal: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0IiA+CiAgICA8cmVjdCBjbGFzcz0ianAtdGVybWluYWwtaWNvbi1iYWNrZ3JvdW5kLWNvbG9yIGpwLWljb24tc2VsZWN0YWJsZSIgd2lkdGg9IjIwIiBoZWlnaHQ9IjIwIiB0cmFuc2Zvcm09InRyYW5zbGF0ZSgyIDIpIiBmaWxsPSIjMzMzMzMzIi8+CiAgICA8cGF0aCBjbGFzcz0ianAtdGVybWluYWwtaWNvbi1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUtaW52ZXJzZSIgZD0iTTUuMDU2NjQgOC43NjE3MkM1LjA1NjY0IDguNTk3NjYgNS4wMzEyNSA4LjQ1MzEyIDQuOTgwNDcgOC4zMjgxMkM0LjkzMzU5IDguMTk5MjIgNC44NTU0NyA4LjA4MjAzIDQuNzQ2MDkgNy45NzY1NkM0LjY0MDYyIDcuODcxMDkgNC41IDcuNzc1MzkgNC4zMjQyMiA3LjY4OTQ1QzQuMTUyMzQgNy41OTk2MSAzLjk0MzM2IDcuNTExNzIgMy42OTcyNyA3LjQyNTc4QzMuMzAyNzMgNy4yODUxNiAyLjk0MzM2IDcuMTM2NzIgMi42MTkxNCA2Ljk4MDQ3QzIuMjk0OTIgNi44MjQyMiAyLjAxNzU4IDYuNjQyNTggMS43ODcxMSA2LjQzNTU1QzEuNTYwNTUgNi4yMjg1MiAxLjM4NDc3IDUuOTg4MjggMS4yNTk3NyA1LjcxNDg0QzEuMTM0NzcgNS40Mzc1IDEuMDcyMjcgNS4xMDkzOCAxLjA3MjI3IDQuNzMwNDdDMS4wNzIyNyA0LjM5ODQ0IDEuMTI4OTEgNC4wOTU3IDEuMjQyMTkgMy44MjIyN0MxLjM1NTQ3IDMuNTQ0OTIgMS41MTU2MiAzLjMwNDY5IDEuNzIyNjYgMy4xMDE1NkMxLjkyOTY5IDIuODk4NDQgMi4xNzk2OSAyLjczNDM3IDIuNDcyNjYgMi42MDkzOEMyLjc2NTYyIDIuNDg0MzggMy4wOTE4IDIuNDA0MyAzLjQ1MTE3IDIuMzY5MTRWMS4xMDkzOEg0LjM4ODY3VjIuMzgwODZDNC43NDAyMyAyLjQyNzczIDUuMDU2NjQgMi41MjM0NCA1LjMzNzg5IDIuNjY3OTdDNS42MTkxNCAyLjgxMjUgNS44NTc0MiAzLjAwMTk1IDYuMDUyNzMgMy4yMzYzM0M2LjI1MTk1IDMuNDY2OCA2LjQwNDMgMy43NDAyMyA2LjUwOTc3IDQuMDU2NjRDNi42MTkxNCA0LjM2OTE0IDYuNjczODMgNC43MjA3IDYuNjczODMgNS4xMTEzM0g1LjA0NDkyQzUuMDQ0OTIgNC42Mzg2NyA0LjkzNzUgNC4yODEyNSA0LjcyMjY2IDQuMDM5MDZDNC41MDc4MSAzLjc5Mjk3IDQuMjE2OCAzLjY2OTkyIDMuODQ5NjEgMy42Njk5MkMzLjY1MDM5IDMuNjY5OTIgMy40NzY1NiAzLjY5NzI3IDMuMzI4MTIgMy43NTE5NUMzLjE4MzU5IDMuODAyNzMgMy4wNjQ0NSAzLjg3Njk1IDIuOTcwNyAzLjk3NDYxQzIuODc2OTUgNC4wNjgzNiAyLjgwNjY0IDQuMTc5NjkgMi43NTk3NyA0LjMwODU5QzIuNzE2OCA0LjQzNzUgMi42OTUzMSA0LjU3ODEyIDIuNjk1MzEgNC43MzA0N0MyLjY5NTMxIDQuODgyODEgMi43MTY4IDUuMDE5NTMgMi43NTk3NyA1LjE0MDYyQzIuODA2NjQgNS4yNTc4MSAyLjg4MjgxIDUuMzY3MTkgMi45ODgyOCA1LjQ2ODc1QzMuMDk3NjYgNS41NzAzMSAzLjI0MDIzIDUuNjY3OTcgMy40MTYwMiA1Ljc2MTcyQzMuNTkxOCA1Ljg1MTU2IDMuODEwNTUgNS45NDMzNiA0LjA3MjI3IDYuMDM3MTFDNC40NjY4IDYuMTg1NTUgNC44MjQyMiA2LjMzOTg0IDUuMTQ0NTMgNi41QzUuNDY0ODQgNi42NTYyNSA1LjczODI4IDYuODM5ODQgNS45NjQ4NCA3LjA1MDc4QzYuMTk1MzEgNy4yNTc4MSA2LjM3MTA5IDcuNSA2LjQ5MjE5IDcuNzc3MzRDNi42MTcxOSA4LjA1MDc4IDYuNjc5NjkgOC4zNzUgNi42Nzk2OSA4Ljc1QzYuNjc5NjkgOS4wOTM3NSA2LjYyMzA1IDkuNDA0MyA2LjUwOTc3IDkuNjgxNjRDNi4zOTY0OCA5Ljk1NTA4IDYuMjM0MzggMTAuMTkxNCA2LjAyMzQ0IDEwLjM5MDZDNS44MTI1IDEwLjU4OTggNS41NTg1OSAxMC43NSA1LjI2MTcyIDEwLjg3MTFDNC45NjQ4NCAxMC45ODgzIDQuNjMyODEgMTEuMDY0NSA0LjI2NTYyIDExLjA5OTZWMTIuMjQ4SDMuMzMzOThWMTEuMDk5NkMzLjAwMTk1IDExLjA2ODQgMi42Nzk2OSAxMC45OTYxIDIuMzY3MTkgMTAuODgyOEMyLjA1NDY5IDEwLjc2NTYgMS43NzczNCAxMC41OTc3IDEuNTM1MTYgMTAuMzc4OUMxLjI5Njg4IDEwLjE2MDIgMS4xMDU0NyA5Ljg4NDc3IDAuOTYwOTM4IDkuNTUyNzNDMC44MTY0MDYgOS4yMTY4IDAuNzQ0MTQxIDguODE0NDUgMC43NDQxNDEgOC4zNDU3SDIuMzc4OTFDMi4zNzg5MSA4LjYyNjk1IDIuNDE5OTIgOC44NjMyOCAyLjUwMTk1IDkuMDU0NjlDMi41ODM5OCA5LjI0MjE5IDIuNjg5NDUgOS4zOTI1OCAyLjgxODM2IDkuNTA1ODZDMi45NTExNyA5LjYxNTIzIDMuMTAxNTYgOS42OTMzNiAzLjI2OTUzIDkuNzQwMjNDMy40Mzc1IDkuNzg3MTEgMy42MDkzOCA5LjgxMDU1IDMuNzg1MTYgOS44MTA1NUM0LjIwMzEyIDkuODEwNTUgNC41MTk1MyA5LjcxMjg5IDQuNzM0MzggOS41MTc1OEM0Ljk0OTIyIDkuMzIyMjcgNS4wNTY2NCA5LjA3MDMxIDUuMDU2NjQgOC43NjE3MlpNMTMuNDE4IDEyLjI3MTVIOC4wNzQyMlYxMUgxMy40MThWMTIuMjcxNVoiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDMuOTUyNjQgNikiIGZpbGw9IndoaXRlIi8+Cjwvc3ZnPgo=);
  --jp-icon-text-editor: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtdGV4dC1lZGl0b3ItaWNvbi1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xNSAxNUgzdjJoMTJ2LTJ6bTAtOEgzdjJoMTJWN3pNMyAxM2gxOHYtMkgzdjJ6bTAgOGgxOHYtMkgzdjJ6TTMgM3YyaDE4VjNIM3oiLz4KPC9zdmc+Cg==);
  --jp-icon-toc: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik03LDVIMjFWN0g3VjVNNywxM1YxMUgyMVYxM0g3TTQsNC41QTEuNSwxLjUgMCAwLDEgNS41LDZBMS41LDEuNSAwIDAsMSA0LDcuNUExLjUsMS41IDAgMCwxIDIuNSw2QTEuNSwxLjUgMCAwLDEgNCw0LjVNNCwxMC41QTEuNSwxLjUgMCAwLDEgNS41LDEyQTEuNSwxLjUgMCAwLDEgNCwxMy41QTEuNSwxLjUgMCAwLDEgMi41LDEyQTEuNSwxLjUgMCAwLDEgNCwxMC41TTcsMTlWMTdIMjFWMTlIN000LDE2LjVBMS41LDEuNSAwIDAsMSA1LjUsMThBMS41LDEuNSAwIDAsMSA0LDE5LjVBMS41LDEuNSAwIDAsMSAyLjUsMThBMS41LDEuNSAwIDAsMSA0LDE2LjVaIiAvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-tree-view: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik0yMiAxMVYzaC03djNIOVYzSDJ2OGg3VjhoMnYxMGg0djNoN3YtOGgtN3YzaC0yVjhoMnYzeiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDIgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMiAxNy4xODQ0IDIuOTY5NjggMTQuMzAzMiAxLjg2MDk0IDExLjQ0MDlaIi8+CiAgICA8cGF0aCBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiMzMzMzMzMiIHN0cm9rZT0iIzMzMzMzMyIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOCA5Ljg2NzE5KSIgZD0iTTIuODYwMTUgNC44NjUzNUwwLjcyNjU0OSAyLjk5OTU5TDAgMy42MzA0NUwyLjg2MDE1IDYuMTMxNTdMOCAwLjYzMDg3Mkw3LjI3ODU3IDBMMi44NjAxNSA0Ljg2NTM1WiIvPgo8L3N2Zz4K);
  --jp-icon-undo: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjUgOGMtMi42NSAwLTUuMDUuOTktNi45IDIuNkwyIDd2OWg5bC0zLjYyLTMuNjJjMS4zOS0xLjE2IDMuMTYtMS44OCA1LjEyLTEuODggMy41NCAwIDYuNTUgMi4zMSA3LjYgNS41bDIuMzctLjc4QzIxLjA4IDExLjAzIDE3LjE1IDggMTIuNSA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-user: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIHZpZXdCb3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE2IDdhNCA0IDAgMTEtOCAwIDQgNCAwIDAxOCAwek0xMiAxNGE3IDcgMCAwMC03IDdoMTRhNyA3IDAgMDAtNy03eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-users: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQiIGhlaWdodD0iMjQiIHZlcnNpb249IjEuMSIgdmlld0JveD0iMCAwIDM2IDI0IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPgogPGcgY2xhc3M9ImpwLWljb24zIiB0cmFuc2Zvcm09Im1hdHJpeCgxLjczMjcgMCAwIDEuNzMyNyAtMy42MjgyIC4wOTk1NzcpIiBmaWxsPSIjNjE2MTYxIj4KICA8cGF0aCB0cmFuc2Zvcm09Im1hdHJpeCgxLjUsMCwwLDEuNSwwLC02KSIgZD0ibTEyLjE4NiA3LjUwOThjLTEuMDUzNSAwLTEuOTc1NyAwLjU2NjUtMi40Nzg1IDEuNDEwMiAwLjc1MDYxIDAuMzEyNzcgMS4zOTc0IDAuODI2NDggMS44NzMgMS40NzI3aDMuNDg2M2MwLTEuNTkyLTEuMjg4OS0yLjg4MjgtMi44ODA5LTIuODgyOHoiLz4KICA8cGF0aCBkPSJtMjAuNDY1IDIuMzg5NWEyLjE4ODUgMi4xODg1IDAgMCAxLTIuMTg4NCAyLjE4ODUgMi4xODg1IDIuMTg4NSAwIDAgMS0yLjE4ODUtMi4xODg1IDIuMTg4NSAyLjE4ODUgMCAwIDEgMi4xODg1LTIuMTg4NSAyLjE4ODUgMi4xODg1IDAgMCAxIDIuMTg4NCAyLjE4ODV6Ii8+CiAgPHBhdGggdHJhbnNmb3JtPSJtYXRyaXgoMS41LDAsMCwxLjUsMCwtNikiIGQ9Im0zLjU4OTggOC40MjE5Yy0xLjExMjYgMC0yLjAxMzcgMC45MDExMS0yLjAxMzcgMi4wMTM3aDIuODE0NWMwLjI2Nzk3LTAuMzczMDkgMC41OTA3LTAuNzA0MzUgMC45NTg5OC0wLjk3ODUyLTAuMzQ0MzMtMC42MTY4OC0xLjAwMzEtMS4wMzUyLTEuNzU5OC0xLjAzNTJ6Ii8+CiAgPHBhdGggZD0ibTYuOTE1NCA0LjYyM2ExLjUyOTQgMS41Mjk0IDAgMCAxLTEuNTI5NCAxLjUyOTQgMS41Mjk0IDEuNTI5NCAwIDAgMS0xLjUyOTQtMS41Mjk0IDEuNTI5NCAxLjUyOTQgMCAwIDEgMS41Mjk0LTEuNTI5NCAxLjUyOTQgMS41Mjk0IDAgMCAxIDEuNTI5NCAxLjUyOTR6Ii8+CiAgPHBhdGggZD0ibTYuMTM1IDEzLjUzNWMwLTMuMjM5MiAyLjYyNTktNS44NjUgNS44NjUtNS44NjUgMy4yMzkyIDAgNS44NjUgMi42MjU5IDUuODY1IDUuODY1eiIvPgogIDxjaXJjbGUgY3g9IjEyIiBjeT0iMy43Njg1IiByPSIyLjk2ODUiLz4KIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-vega: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbjEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjEyMTIxIj4KICAgIDxwYXRoIGQ9Ik0xMC42IDUuNGwyLjItMy4ySDIuMnY3LjNsNC02LjZ6Ii8+CiAgICA8cGF0aCBkPSJNMTUuOCAyLjJsLTQuNCA2LjZMNyA2LjNsLTQuOCA4djUuNWgxNy42VjIuMmgtNHptLTcgMTUuNEg1LjV2LTQuNGgzLjN2NC40em00LjQgMEg5LjhWOS44aDMuNHY3Ljh6bTQuNCAwaC0zLjRWNi41aDMuNHYxMS4xeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-word: url(data:image/svg+xml;base64,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);
  --jp-icon-yaml: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1jb250cmFzdDIganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjRDgxQjYwIj4KICAgIDxwYXRoIGQ9Ik03LjIgMTguNnYtNS40TDMgNS42aDMuM2wxLjQgMy4xYy4zLjkuNiAxLjYgMSAyLjUuMy0uOC42LTEuNiAxLTIuNWwxLjQtMy4xaDMuNGwtNC40IDcuNnY1LjVsLTIuOS0uMXoiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxNi41IiByPSIyLjEiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxMSIgcj0iMi4xIi8+CiAgPC9nPgo8L3N2Zz4K);
}

/* Icon CSS class declarations */

.jp-AddAboveIcon {
  background-image: var(--jp-icon-add-above);
}

.jp-AddBelowIcon {
  background-image: var(--jp-icon-add-below);
}

.jp-AddIcon {
  background-image: var(--jp-icon-add);
}

.jp-BellIcon {
  background-image: var(--jp-icon-bell);
}

.jp-BugDotIcon {
  background-image: var(--jp-icon-bug-dot);
}

.jp-BugIcon {
  background-image: var(--jp-icon-bug);
}

.jp-BuildIcon {
  background-image: var(--jp-icon-build);
}

.jp-CaretDownEmptyIcon {
  background-image: var(--jp-icon-caret-down-empty);
}

.jp-CaretDownEmptyThinIcon {
  background-image: var(--jp-icon-caret-down-empty-thin);
}

.jp-CaretDownIcon {
  background-image: var(--jp-icon-caret-down);
}

.jp-CaretLeftIcon {
  background-image: var(--jp-icon-caret-left);
}

.jp-CaretRightIcon {
  background-image: var(--jp-icon-caret-right);
}

.jp-CaretUpEmptyThinIcon {
  background-image: var(--jp-icon-caret-up-empty-thin);
}

.jp-CaretUpIcon {
  background-image: var(--jp-icon-caret-up);
}

.jp-CaseSensitiveIcon {
  background-image: var(--jp-icon-case-sensitive);
}

.jp-CheckIcon {
  background-image: var(--jp-icon-check);
}

.jp-CircleEmptyIcon {
  background-image: var(--jp-icon-circle-empty);
}

.jp-CircleIcon {
  background-image: var(--jp-icon-circle);
}

.jp-ClearIcon {
  background-image: var(--jp-icon-clear);
}

.jp-CloseIcon {
  background-image: var(--jp-icon-close);
}

.jp-CodeCheckIcon {
  background-image: var(--jp-icon-code-check);
}

.jp-CodeIcon {
  background-image: var(--jp-icon-code);
}

.jp-CollapseAllIcon {
  background-image: var(--jp-icon-collapse-all);
}

.jp-ConsoleIcon {
  background-image: var(--jp-icon-console);
}

.jp-CopyIcon {
  background-image: var(--jp-icon-copy);
}

.jp-CopyrightIcon {
  background-image: var(--jp-icon-copyright);
}

.jp-CutIcon {
  background-image: var(--jp-icon-cut);
}

.jp-DeleteIcon {
  background-image: var(--jp-icon-delete);
}

.jp-DownloadIcon {
  background-image: var(--jp-icon-download);
}

.jp-DuplicateIcon {
  background-image: var(--jp-icon-duplicate);
}

.jp-EditIcon {
  background-image: var(--jp-icon-edit);
}

.jp-EllipsesIcon {
  background-image: var(--jp-icon-ellipses);
}

.jp-ErrorIcon {
  background-image: var(--jp-icon-error);
}

.jp-ExpandAllIcon {
  background-image: var(--jp-icon-expand-all);
}

.jp-ExtensionIcon {
  background-image: var(--jp-icon-extension);
}

.jp-FastForwardIcon {
  background-image: var(--jp-icon-fast-forward);
}

.jp-FileIcon {
  background-image: var(--jp-icon-file);
}

.jp-FileUploadIcon {
  background-image: var(--jp-icon-file-upload);
}

.jp-FilterDotIcon {
  background-image: var(--jp-icon-filter-dot);
}

.jp-FilterIcon {
  background-image: var(--jp-icon-filter);
}

.jp-FilterListIcon {
  background-image: var(--jp-icon-filter-list);
}

.jp-FolderFavoriteIcon {
  background-image: var(--jp-icon-folder-favorite);
}

.jp-FolderIcon {
  background-image: var(--jp-icon-folder);
}

.jp-HomeIcon {
  background-image: var(--jp-icon-home);
}

.jp-Html5Icon {
  background-image: var(--jp-icon-html5);
}

.jp-ImageIcon {
  background-image: var(--jp-icon-image);
}

.jp-InfoIcon {
  background-image: var(--jp-icon-info);
}

.jp-InspectorIcon {
  background-image: var(--jp-icon-inspector);
}

.jp-JsonIcon {
  background-image: var(--jp-icon-json);
}

.jp-JuliaIcon {
  background-image: var(--jp-icon-julia);
}

.jp-JupyterFaviconIcon {
  background-image: var(--jp-icon-jupyter-favicon);
}

.jp-JupyterIcon {
  background-image: var(--jp-icon-jupyter);
}

.jp-JupyterlabWordmarkIcon {
  background-image: var(--jp-icon-jupyterlab-wordmark);
}

.jp-KernelIcon {
  background-image: var(--jp-icon-kernel);
}

.jp-KeyboardIcon {
  background-image: var(--jp-icon-keyboard);
}

.jp-LaunchIcon {
  background-image: var(--jp-icon-launch);
}

.jp-LauncherIcon {
  background-image: var(--jp-icon-launcher);
}

.jp-LineFormIcon {
  background-image: var(--jp-icon-line-form);
}

.jp-LinkIcon {
  background-image: var(--jp-icon-link);
}

.jp-ListIcon {
  background-image: var(--jp-icon-list);
}

.jp-MarkdownIcon {
  background-image: var(--jp-icon-markdown);
}

.jp-MoveDownIcon {
  background-image: var(--jp-icon-move-down);
}

.jp-MoveUpIcon {
  background-image: var(--jp-icon-move-up);
}

.jp-NewFolderIcon {
  background-image: var(--jp-icon-new-folder);
}

.jp-NotTrustedIcon {
  background-image: var(--jp-icon-not-trusted);
}

.jp-NotebookIcon {
  background-image: var(--jp-icon-notebook);
}

.jp-NumberingIcon {
  background-image: var(--jp-icon-numbering);
}

.jp-OfflineBoltIcon {
  background-image: var(--jp-icon-offline-bolt);
}

.jp-PaletteIcon {
  background-image: var(--jp-icon-palette);
}

.jp-PasteIcon {
  background-image: var(--jp-icon-paste);
}

.jp-PdfIcon {
  background-image: var(--jp-icon-pdf);
}

.jp-PythonIcon {
  background-image: var(--jp-icon-python);
}

.jp-RKernelIcon {
  background-image: var(--jp-icon-r-kernel);
}

.jp-ReactIcon {
  background-image: var(--jp-icon-react);
}

.jp-RedoIcon {
  background-image: var(--jp-icon-redo);
}

.jp-RefreshIcon {
  background-image: var(--jp-icon-refresh);
}

.jp-RegexIcon {
  background-image: var(--jp-icon-regex);
}

.jp-RunIcon {
  background-image: var(--jp-icon-run);
}

.jp-RunningIcon {
  background-image: var(--jp-icon-running);
}

.jp-SaveIcon {
  background-image: var(--jp-icon-save);
}

.jp-SearchIcon {
  background-image: var(--jp-icon-search);
}

.jp-SettingsIcon {
  background-image: var(--jp-icon-settings);
}

.jp-ShareIcon {
  background-image: var(--jp-icon-share);
}

.jp-SpreadsheetIcon {
  background-image: var(--jp-icon-spreadsheet);
}

.jp-StopIcon {
  background-image: var(--jp-icon-stop);
}

.jp-TabIcon {
  background-image: var(--jp-icon-tab);
}

.jp-TableRowsIcon {
  background-image: var(--jp-icon-table-rows);
}

.jp-TagIcon {
  background-image: var(--jp-icon-tag);
}

.jp-TerminalIcon {
  background-image: var(--jp-icon-terminal);
}

.jp-TextEditorIcon {
  background-image: var(--jp-icon-text-editor);
}

.jp-TocIcon {
  background-image: var(--jp-icon-toc);
}

.jp-TreeViewIcon {
  background-image: var(--jp-icon-tree-view);
}

.jp-TrustedIcon {
  background-image: var(--jp-icon-trusted);
}

.jp-UndoIcon {
  background-image: var(--jp-icon-undo);
}

.jp-UserIcon {
  background-image: var(--jp-icon-user);
}

.jp-UsersIcon {
  background-image: var(--jp-icon-users);
}

.jp-VegaIcon {
  background-image: var(--jp-icon-vega);
}

.jp-WordIcon {
  background-image: var(--jp-icon-word);
}

.jp-YamlIcon {
  background-image: var(--jp-icon-yaml);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * (DEPRECATED) Support for consuming icons as CSS background images
 */

.jp-Icon,
.jp-MaterialIcon {
  background-position: center;
  background-repeat: no-repeat;
  background-size: 16px;
  min-width: 16px;
  min-height: 16px;
}

.jp-Icon-cover {
  background-position: center;
  background-repeat: no-repeat;
  background-size: cover;
}

/**
 * (DEPRECATED) Support for specific CSS icon sizes
 */

.jp-Icon-16 {
  background-size: 16px;
  min-width: 16px;
  min-height: 16px;
}

.jp-Icon-18 {
  background-size: 18px;
  min-width: 18px;
  min-height: 18px;
}

.jp-Icon-20 {
  background-size: 20px;
  min-width: 20px;
  min-height: 20px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.lm-TabBar .lm-TabBar-addButton {
  align-items: center;
  display: flex;
  padding: 4px;
  padding-bottom: 5px;
  margin-right: 1px;
  background-color: var(--jp-layout-color2);
}

.lm-TabBar .lm-TabBar-addButton:hover {
  background-color: var(--jp-layout-color1);
}

.lm-DockPanel-tabBar .lm-TabBar-tab {
  width: var(--jp-private-horizontal-tab-width);
}

.lm-DockPanel-tabBar .lm-TabBar-content {
  flex: unset;
}

.lm-DockPanel-tabBar[data-orientation='horizontal'] {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * Support for icons as inline SVG HTMLElements
 */

/* recolor the primary elements of an icon */
.jp-icon0[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon1[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon2[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon3[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon4[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon0[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon1[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon2[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon3[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon4[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/* recolor the accent elements of an icon */
.jp-icon-accent0[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-accent1[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-accent2[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-accent3[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-accent4[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-accent0[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-accent1[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-accent2[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-accent3[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-accent4[stroke] {
  stroke: var(--jp-layout-color4);
}

/* set the color of an icon to transparent */
.jp-icon-none[fill] {
  fill: none;
}

.jp-icon-none[stroke] {
  stroke: none;
}

/* brand icon colors. Same for light and dark */
.jp-icon-brand0[fill] {
  fill: var(--jp-brand-color0);
}

.jp-icon-brand1[fill] {
  fill: var(--jp-brand-color1);
}

.jp-icon-brand2[fill] {
  fill: var(--jp-brand-color2);
}

.jp-icon-brand3[fill] {
  fill: var(--jp-brand-color3);
}

.jp-icon-brand4[fill] {
  fill: var(--jp-brand-color4);
}

.jp-icon-brand0[stroke] {
  stroke: var(--jp-brand-color0);
}

.jp-icon-brand1[stroke] {
  stroke: var(--jp-brand-color1);
}

.jp-icon-brand2[stroke] {
  stroke: var(--jp-brand-color2);
}

.jp-icon-brand3[stroke] {
  stroke: var(--jp-brand-color3);
}

.jp-icon-brand4[stroke] {
  stroke: var(--jp-brand-color4);
}

/* warn icon colors. Same for light and dark */
.jp-icon-warn0[fill] {
  fill: var(--jp-warn-color0);
}

.jp-icon-warn1[fill] {
  fill: var(--jp-warn-color1);
}

.jp-icon-warn2[fill] {
  fill: var(--jp-warn-color2);
}

.jp-icon-warn3[fill] {
  fill: var(--jp-warn-color3);
}

.jp-icon-warn0[stroke] {
  stroke: var(--jp-warn-color0);
}

.jp-icon-warn1[stroke] {
  stroke: var(--jp-warn-color1);
}

.jp-icon-warn2[stroke] {
  stroke: var(--jp-warn-color2);
}

.jp-icon-warn3[stroke] {
  stroke: var(--jp-warn-color3);
}

/* icon colors that contrast well with each other and most backgrounds */
.jp-icon-contrast0[fill] {
  fill: var(--jp-icon-contrast-color0);
}

.jp-icon-contrast1[fill] {
  fill: var(--jp-icon-contrast-color1);
}

.jp-icon-contrast2[fill] {
  fill: var(--jp-icon-contrast-color2);
}

.jp-icon-contrast3[fill] {
  fill: var(--jp-icon-contrast-color3);
}

.jp-icon-contrast0[stroke] {
  stroke: var(--jp-icon-contrast-color0);
}

.jp-icon-contrast1[stroke] {
  stroke: var(--jp-icon-contrast-color1);
}

.jp-icon-contrast2[stroke] {
  stroke: var(--jp-icon-contrast-color2);
}

.jp-icon-contrast3[stroke] {
  stroke: var(--jp-icon-contrast-color3);
}

.jp-icon-dot[fill] {
  fill: var(--jp-warn-color0);
}

.jp-jupyter-icon-color[fill] {
  fill: var(--jp-jupyter-icon-color, var(--jp-warn-color0));
}

.jp-notebook-icon-color[fill] {
  fill: var(--jp-notebook-icon-color, var(--jp-warn-color0));
}

.jp-json-icon-color[fill] {
  fill: var(--jp-json-icon-color, var(--jp-warn-color1));
}

.jp-console-icon-color[fill] {
  fill: var(--jp-console-icon-color, white);
}

.jp-console-icon-background-color[fill] {
  fill: var(--jp-console-icon-background-color, var(--jp-brand-color1));
}

.jp-terminal-icon-color[fill] {
  fill: var(--jp-terminal-icon-color, var(--jp-layout-color2));
}

.jp-terminal-icon-background-color[fill] {
  fill: var(
    --jp-terminal-icon-background-color,
    var(--jp-inverse-layout-color2)
  );
}

.jp-text-editor-icon-color[fill] {
  fill: var(--jp-text-editor-icon-color, var(--jp-inverse-layout-color3));
}

.jp-inspector-icon-color[fill] {
  fill: var(--jp-inspector-icon-color, var(--jp-inverse-layout-color3));
}

/* CSS for icons in selected filebrowser listing items */
.jp-DirListing-item.jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}

.jp-DirListing-item.jp-mod-selected .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}

/* stylelint-disable selector-max-class, selector-max-compound-selectors */

/**
* TODO: come up with non css-hack solution for showing the busy icon on top
*  of the close icon
* CSS for complex behavior of close icon of tabs in the main area tabbar
*/
.lm-DockPanel-tabBar
  .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon3[fill] {
  fill: none;
}

.lm-DockPanel-tabBar
  .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon-busy[fill] {
  fill: var(--jp-inverse-layout-color3);
}

/* stylelint-enable selector-max-class, selector-max-compound-selectors */

/* CSS for icons in status bar */
#jp-main-statusbar .jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}

#jp-main-statusbar .jp-mod-selected .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}

/* special handling for splash icon CSS. While the theme CSS reloads during
   splash, the splash icon can loose theming. To prevent that, we set a
   default for its color variable */
:root {
  --jp-warn-color0: var(--md-orange-700);
}

/* not sure what to do with this one, used in filebrowser listing */
.jp-DragIcon {
  margin-right: 4px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * Support for alt colors for icons as inline SVG HTMLElements
 */

/* alt recolor the primary elements of an icon */
.jp-icon-alt .jp-icon0[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-alt .jp-icon1[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-alt .jp-icon2[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-alt .jp-icon3[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-alt .jp-icon4[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-alt .jp-icon0[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-alt .jp-icon1[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-alt .jp-icon2[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-alt .jp-icon3[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-alt .jp-icon4[stroke] {
  stroke: var(--jp-layout-color4);
}

/* alt recolor the accent elements of an icon */
.jp-icon-alt .jp-icon-accent0[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon-alt .jp-icon-accent1[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon-alt .jp-icon-accent2[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon-alt .jp-icon-accent3[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon-alt .jp-icon-accent4[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-alt .jp-icon-accent0[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon-alt .jp-icon-accent1[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon-alt .jp-icon-accent2[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon-alt .jp-icon-accent3[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon-alt .jp-icon-accent4[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-icon-hoverShow:not(:hover) .jp-icon-hoverShow-content {
  display: none !important;
}

/**
 * Support for hover colors for icons as inline SVG HTMLElements
 */

/**
 * regular colors
 */

/* recolor the primary elements of an icon */
.jp-icon-hover :hover .jp-icon0-hover[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon-hover :hover .jp-icon1-hover[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon-hover :hover .jp-icon2-hover[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon-hover :hover .jp-icon3-hover[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon-hover :hover .jp-icon4-hover[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-hover :hover .jp-icon0-hover[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon-hover :hover .jp-icon1-hover[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon-hover :hover .jp-icon2-hover[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon-hover :hover .jp-icon3-hover[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon-hover :hover .jp-icon4-hover[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/* recolor the accent elements of an icon */
.jp-icon-hover :hover .jp-icon-accent0-hover[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-hover :hover .jp-icon-accent1-hover[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-hover :hover .jp-icon-accent2-hover[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-hover :hover .jp-icon-accent3-hover[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-hover :hover .jp-icon-accent4-hover[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-hover :hover .jp-icon-accent0-hover[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-hover :hover .jp-icon-accent1-hover[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-hover :hover .jp-icon-accent2-hover[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-hover :hover .jp-icon-accent3-hover[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-hover :hover .jp-icon-accent4-hover[stroke] {
  stroke: var(--jp-layout-color4);
}

/* set the color of an icon to transparent */
.jp-icon-hover :hover .jp-icon-none-hover[fill] {
  fill: none;
}

.jp-icon-hover :hover .jp-icon-none-hover[stroke] {
  stroke: none;
}

/**
 * inverse colors
 */

/* inverse recolor the primary elements of an icon */
.jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[stroke] {
  stroke: var(--jp-layout-color4);
}

/* inverse recolor the accent elements of an icon */
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-IFrame {
  width: 100%;
  height: 100%;
}

.jp-IFrame > iframe {
  border: none;
}

/*
When drag events occur, `lm-mod-override-cursor` is added to the body.
Because iframes steal all cursor events, the following two rules are necessary
to suppress pointer events while resize drags are occurring. There may be a
better solution to this problem.
*/
body.lm-mod-override-cursor .jp-IFrame {
  position: relative;
}

body.lm-mod-override-cursor .jp-IFrame::before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-HoverBox {
  position: fixed;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-FormGroup-content fieldset {
  border: none;
  padding: 0;
  min-width: 0;
  width: 100%;
}

/* stylelint-disable selector-max-type */

.jp-FormGroup-content fieldset .jp-inputFieldWrapper input,
.jp-FormGroup-content fieldset .jp-inputFieldWrapper select,
.jp-FormGroup-content fieldset .jp-inputFieldWrapper textarea {
  font-size: var(--jp-content-font-size2);
  border-color: var(--jp-input-border-color);
  border-style: solid;
  border-radius: var(--jp-border-radius);
  border-width: 1px;
  padding: 6px 8px;
  background: none;
  color: var(--jp-ui-font-color0);
  height: inherit;
}

.jp-FormGroup-content fieldset input[type='checkbox'] {
  position: relative;
  top: 2px;
  margin-left: 0;
}

.jp-FormGroup-content button.jp-mod-styled {
  cursor: pointer;
}

.jp-FormGroup-content .checkbox label {
  cursor: pointer;
  font-size: var(--jp-content-font-size1);
}

.jp-FormGroup-content .jp-root > fieldset > legend {
  display: none;
}

.jp-FormGroup-content .jp-root > fieldset > p {
  display: none;
}

/** copy of `input.jp-mod-styled:focus` style */
.jp-FormGroup-content fieldset input:focus,
.jp-FormGroup-content fieldset select:focus {
  -moz-outline-radius: unset;
  outline: var(--jp-border-width) solid var(--md-blue-500);
  outline-offset: -1px;
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-FormGroup-content fieldset input:hover:not(:focus),
.jp-FormGroup-content fieldset select:hover:not(:focus) {
  background-color: var(--jp-border-color2);
}

/* stylelint-enable selector-max-type */

.jp-FormGroup-content .checkbox .field-description {
  /* Disable default description field for checkbox:
   because other widgets do not have description fields,
   we add descriptions to each widget on the field level.
  */
  display: none;
}

.jp-FormGroup-content #root__description {
  display: none;
}

.jp-FormGroup-content .jp-modifiedIndicator {
  width: 5px;
  background-color: var(--jp-brand-color2);
  margin-top: 0;
  margin-left: calc(var(--jp-private-settingeditor-modifier-indent) * -1);
  flex-shrink: 0;
}

.jp-FormGroup-content .jp-modifiedIndicator.jp-errorIndicator {
  background-color: var(--jp-error-color0);
  margin-right: 0.5em;
}

/* RJSF ARRAY style */

.jp-arrayFieldWrapper legend {
  font-size: var(--jp-content-font-size2);
  color: var(--jp-ui-font-color0);
  flex-basis: 100%;
  padding: 4px 0;
  font-weight: var(--jp-content-heading-font-weight);
  border-bottom: 1px solid var(--jp-border-color2);
}

.jp-arrayFieldWrapper .field-description {
  padding: 4px 0;
  white-space: pre-wrap;
}

.jp-arrayFieldWrapper .array-item {
  width: 100%;
  border: 1px solid var(--jp-border-color2);
  border-radius: 4px;
  margin: 4px;
}

.jp-ArrayOperations {
  display: flex;
  margin-left: 8px;
}

.jp-ArrayOperationsButton {
  margin: 2px;
}

.jp-ArrayOperationsButton .jp-icon3[fill] {
  fill: var(--jp-ui-font-color0);
}

button.jp-ArrayOperationsButton.jp-mod-styled:disabled {
  cursor: not-allowed;
  opacity: 0.5;
}

/* RJSF form validation error */

.jp-FormGroup-content .validationErrors {
  color: var(--jp-error-color0);
}

/* Hide panel level error as duplicated the field level error */
.jp-FormGroup-content .panel.errors {
  display: none;
}

/* RJSF normal content (settings-editor) */

.jp-FormGroup-contentNormal {
  display: flex;
  align-items: center;
  flex-wrap: wrap;
}

.jp-FormGroup-contentNormal .jp-FormGroup-contentItem {
  margin-left: 7px;
  color: var(--jp-ui-font-color0);
}

.jp-FormGroup-contentNormal .jp-FormGroup-description {
  flex-basis: 100%;
  padding: 4px 7px;
}

.jp-FormGroup-contentNormal .jp-FormGroup-default {
  flex-basis: 100%;
  padding: 4px 7px;
}

.jp-FormGroup-contentNormal .jp-FormGroup-fieldLabel {
  font-size: var(--jp-content-font-size1);
  font-weight: normal;
  min-width: 120px;
}

.jp-FormGroup-contentNormal fieldset:not(:first-child) {
  margin-left: 7px;
}

.jp-FormGroup-contentNormal .field-array-of-string .array-item {
  /* Display `jp-ArrayOperations` buttons side-by-side with content except
    for small screens where flex-wrap will place them one below the other.
  */
  display: flex;
  align-items: center;
  flex-wrap: wrap;
}

.jp-FormGroup-contentNormal .jp-objectFieldWrapper .form-group {
  padding: 2px 8px 2px var(--jp-private-settingeditor-modifier-indent);
  margin-top: 2px;
}

/* RJSF compact content (metadata-form) */

.jp-FormGroup-content.jp-FormGroup-contentCompact {
  width: 100%;
}

.jp-FormGroup-contentCompact .form-group {
  display: flex;
  padding: 0.5em 0.2em 0.5em 0;
}

.jp-FormGroup-contentCompact
  .jp-FormGroup-compactTitle
  .jp-FormGroup-description {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color2);
}

.jp-FormGroup-contentCompact .jp-FormGroup-fieldLabel {
  padding-bottom: 0.3em;
}

.jp-FormGroup-contentCompact .jp-inputFieldWrapper .form-control {
  width: 100%;
  box-sizing: border-box;
}

.jp-FormGroup-contentCompact .jp-arrayFieldWrapper .jp-FormGroup-compactTitle {
  padding-bottom: 7px;
}

.jp-FormGroup-contentCompact
  .jp-objectFieldWrapper
  .jp-objectFieldWrapper
  .form-group {
  padding: 2px 8px 2px var(--jp-private-settingeditor-modifier-indent);
  margin-top: 2px;
}

.jp-FormGroup-contentCompact ul.error-detail {
  margin-block-start: 0.5em;
  margin-block-end: 0.5em;
  padding-inline-start: 1em;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-SidePanel {
  display: flex;
  flex-direction: column;
  min-width: var(--jp-sidebar-min-width);
  overflow-y: auto;
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);
  font-size: var(--jp-ui-font-size1);
}

.jp-SidePanel-header {
  flex: 0 0 auto;
  display: flex;
  border-bottom: var(--jp-border-width) solid var(--jp-border-color2);
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  letter-spacing: 1px;
  margin: 0;
  padding: 2px;
  text-transform: uppercase;
}

.jp-SidePanel-toolbar {
  flex: 0 0 auto;
}

.jp-SidePanel-content {
  flex: 1 1 auto;
}

.jp-SidePanel-toolbar,
.jp-AccordionPanel-toolbar {
  height: var(--jp-private-toolbar-height);
}

.jp-SidePanel-toolbar.jp-Toolbar-micro {
  display: none;
}

.lm-AccordionPanel .jp-AccordionPanel-title {
  box-sizing: border-box;
  line-height: 25px;
  margin: 0;
  display: flex;
  align-items: center;
  background: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  font-size: var(--jp-ui-font-size0);
}

.jp-AccordionPanel-title {
  cursor: pointer;
  user-select: none;
  -moz-user-select: none;
  -webkit-user-select: none;
  text-transform: uppercase;
}

.lm-AccordionPanel[data-orientation='horizontal'] > .jp-AccordionPanel-title {
  /* Title is rotated for horizontal accordion panel using CSS */
  display: block;
  transform-origin: top left;
  transform: rotate(-90deg) translate(-100%);
}

.jp-AccordionPanel-title .lm-AccordionPanel-titleLabel {
  user-select: none;
  text-overflow: ellipsis;
  white-space: nowrap;
  overflow: hidden;
}

.jp-AccordionPanel-title .lm-AccordionPanel-titleCollapser {
  transform: rotate(-90deg);
  margin: auto 0;
  height: 16px;
}

.jp-AccordionPanel-title.lm-mod-expanded .lm-AccordionPanel-titleCollapser {
  transform: rotate(0deg);
}

.lm-AccordionPanel .jp-AccordionPanel-toolbar {
  background: none;
  box-shadow: none;
  border: none;
  margin-left: auto;
}

.lm-AccordionPanel .lm-SplitPanel-handle:hover {
  background: var(--jp-layout-color3);
}

.jp-text-truncated {
  overflow: hidden;
  text-overflow: ellipsis;
  white-space: nowrap;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Spinner {
  position: absolute;
  display: flex;
  justify-content: center;
  align-items: center;
  z-index: 10;
  left: 0;
  top: 0;
  width: 100%;
  height: 100%;
  background: var(--jp-layout-color0);
  outline: none;
}

.jp-SpinnerContent {
  font-size: 10px;
  margin: 50px auto;
  text-indent: -9999em;
  width: 3em;
  height: 3em;
  border-radius: 50%;
  background: var(--jp-brand-color3);
  background: linear-gradient(
    to right,
    #f37626 10%,
    rgba(255, 255, 255, 0) 42%
  );
  position: relative;
  animation: load3 1s infinite linear, fadeIn 1s;
}

.jp-SpinnerContent::before {
  width: 50%;
  height: 50%;
  background: #f37626;
  border-radius: 100% 0 0;
  position: absolute;
  top: 0;
  left: 0;
  content: '';
}

.jp-SpinnerContent::after {
  background: var(--jp-layout-color0);
  width: 75%;
  height: 75%;
  border-radius: 50%;
  content: '';
  margin: auto;
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  right: 0;
}

@keyframes fadeIn {
  0% {
    opacity: 0;
  }

  100% {
    opacity: 1;
  }
}

@keyframes load3 {
  0% {
    transform: rotate(0deg);
  }

  100% {
    transform: rotate(360deg);
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

button.jp-mod-styled {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  border: none;
  box-sizing: border-box;
  text-align: center;
  line-height: 32px;
  height: 32px;
  padding: 0 12px;
  letter-spacing: 0.8px;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

input.jp-mod-styled {
  background: var(--jp-input-background);
  height: 28px;
  box-sizing: border-box;
  border: var(--jp-border-width) solid var(--jp-border-color1);
  padding-left: 7px;
  padding-right: 7px;
  font-size: var(--jp-ui-font-size2);
  color: var(--jp-ui-font-color0);
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

input[type='checkbox'].jp-mod-styled {
  appearance: checkbox;
  -webkit-appearance: checkbox;
  -moz-appearance: checkbox;
  height: auto;
}

input.jp-mod-styled:focus {
  border: var(--jp-border-width) solid var(--md-blue-500);
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-select-wrapper {
  display: flex;
  position: relative;
  flex-direction: column;
  padding: 1px;
  background-color: var(--jp-layout-color1);
  box-sizing: border-box;
  margin-bottom: 12px;
}

.jp-select-wrapper:not(.multiple) {
  height: 28px;
}

.jp-select-wrapper.jp-mod-focused select.jp-mod-styled {
  border: var(--jp-border-width) solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
  background-color: var(--jp-input-active-background);
}

select.jp-mod-styled:hover {
  cursor: pointer;
  color: var(--jp-ui-font-color0);
  background-color: var(--jp-input-hover-background);
  box-shadow: inset 0 0 1px rgba(0, 0, 0, 0.5);
}

select.jp-mod-styled {
  flex: 1 1 auto;
  width: 100%;
  font-size: var(--jp-ui-font-size2);
  background: var(--jp-input-background);
  color: var(--jp-ui-font-color0);
  padding: 0 25px 0 8px;
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  border-radius: 0;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

select.jp-mod-styled:not([multiple]) {
  height: 32px;
}

select.jp-mod-styled[multiple] {
  max-height: 200px;
  overflow-y: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-switch {
  display: flex;
  align-items: center;
  padding-left: 4px;
  padding-right: 4px;
  font-size: var(--jp-ui-font-size1);
  background-color: transparent;
  color: var(--jp-ui-font-color1);
  border: none;
  height: 20px;
}

.jp-switch:hover {
  background-color: var(--jp-layout-color2);
}

.jp-switch-label {
  margin-right: 5px;
  font-family: var(--jp-ui-font-family);
}

.jp-switch-track {
  cursor: pointer;
  background-color: var(--jp-switch-color, var(--jp-border-color1));
  -webkit-transition: 0.4s;
  transition: 0.4s;
  border-radius: 34px;
  height: 16px;
  width: 35px;
  position: relative;
}

.jp-switch-track::before {
  content: '';
  position: absolute;
  height: 10px;
  width: 10px;
  margin: 3px;
  left: 0;
  background-color: var(--jp-ui-inverse-font-color1);
  -webkit-transition: 0.4s;
  transition: 0.4s;
  border-radius: 50%;
}

.jp-switch[aria-checked='true'] .jp-switch-track {
  background-color: var(--jp-switch-true-position-color, var(--jp-warn-color0));
}

.jp-switch[aria-checked='true'] .jp-switch-track::before {
  /* track width (35) - margins (3 + 3) - thumb width (10) */
  left: 19px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

:root {
  --jp-private-toolbar-height: calc(
    28px + var(--jp-border-width)
  ); /* leave 28px for content */
}

.jp-Toolbar {
  color: var(--jp-ui-font-color1);
  flex: 0 0 auto;
  display: flex;
  flex-direction: row;
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  background: var(--jp-toolbar-background);
  min-height: var(--jp-toolbar-micro-height);
  padding: 2px;
  z-index: 8;
  overflow-x: hidden;
}

/* Toolbar items */

.jp-Toolbar > .jp-Toolbar-item.jp-Toolbar-spacer {
  flex-grow: 1;
  flex-shrink: 1;
}

.jp-Toolbar-item.jp-Toolbar-kernelStatus {
  display: inline-block;
  width: 32px;
  background-repeat: no-repeat;
  background-position: center;
  background-size: 16px;
}

.jp-Toolbar > .jp-Toolbar-item {
  flex: 0 0 auto;
  display: flex;
  padding-left: 1px;
  padding-right: 1px;
  font-size: var(--jp-ui-font-size1);
  line-height: var(--jp-private-toolbar-height);
  height: 100%;
}

/* Toolbar buttons */

/* This is the div we use to wrap the react component into a Widget */
div.jp-ToolbarButton {
  color: transparent;
  border: none;
  box-sizing: border-box;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
  padding: 0;
  margin: 0;
}

button.jp-ToolbarButtonComponent {
  background: var(--jp-layout-color1);
  border: none;
  box-sizing: border-box;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
  padding: 0 6px;
  margin: 0;
  height: 24px;
  border-radius: var(--jp-border-radius);
  display: flex;
  align-items: center;
  text-align: center;
  font-size: 14px;
  min-width: unset;
  min-height: unset;
}

button.jp-ToolbarButtonComponent:disabled {
  opacity: 0.4;
}

button.jp-ToolbarButtonComponent > span {
  padding: 0;
  flex: 0 0 auto;
}

button.jp-ToolbarButtonComponent .jp-ToolbarButtonComponent-label {
  font-size: var(--jp-ui-font-size1);
  line-height: 100%;
  padding-left: 2px;
  color: var(--jp-ui-font-color1);
  font-family: var(--jp-ui-font-family);
}

#jp-main-dock-panel[data-mode='single-document']
  .jp-MainAreaWidget
  > .jp-Toolbar.jp-Toolbar-micro {
  padding: 0;
  min-height: 0;
}

#jp-main-dock-panel[data-mode='single-document']
  .jp-MainAreaWidget
  > .jp-Toolbar {
  border: none;
  box-shadow: none;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-WindowedPanel-outer {
  position: relative;
  overflow-y: auto;
}

.jp-WindowedPanel-inner {
  position: relative;
}

.jp-WindowedPanel-window {
  position: absolute;
  left: 0;
  right: 0;
  overflow: visible;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* Sibling imports */

body {
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
}

/* Disable native link decoration styles everywhere outside of dialog boxes */
a {
  text-decoration: unset;
  color: unset;
}

a:hover {
  text-decoration: unset;
  color: unset;
}

/* Accessibility for links inside dialog box text */
.jp-Dialog-content a {
  text-decoration: revert;
  color: var(--jp-content-link-color);
}

.jp-Dialog-content a:hover {
  text-decoration: revert;
}

/* Styles for ui-components */
.jp-Button {
  color: var(--jp-ui-font-color2);
  border-radius: var(--jp-border-radius);
  padding: 0 12px;
  font-size: var(--jp-ui-font-size1);

  /* Copy from blueprint 3 */
  display: inline-flex;
  flex-direction: row;
  border: none;
  cursor: pointer;
  align-items: center;
  justify-content: center;
  text-align: left;
  vertical-align: middle;
  min-height: 30px;
  min-width: 30px;
}

.jp-Button:disabled {
  cursor: not-allowed;
}

.jp-Button:empty {
  padding: 0 !important;
}

.jp-Button.jp-mod-small {
  min-height: 24px;
  min-width: 24px;
  font-size: 12px;
  padding: 0 7px;
}

/* Use our own theme for hover styles */
.jp-Button.jp-mod-minimal:hover {
  background-color: var(--jp-layout-color2);
}

.jp-Button.jp-mod-minimal {
  background: none;
}

.jp-InputGroup {
  display: block;
  position: relative;
}

.jp-InputGroup input {
  box-sizing: border-box;
  border: none;
  border-radius: 0;
  background-color: transparent;
  color: var(--jp-ui-font-color0);
  box-shadow: inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color);
  padding-bottom: 0;
  padding-top: 0;
  padding-left: 10px;
  padding-right: 28px;
  position: relative;
  width: 100%;
  -webkit-appearance: none;
  -moz-appearance: none;
  appearance: none;
  font-size: 14px;
  font-weight: 400;
  height: 30px;
  line-height: 30px;
  outline: none;
  vertical-align: middle;
}

.jp-InputGroup input:focus {
  box-shadow: inset 0 0 0 var(--jp-border-width)
      var(--jp-input-active-box-shadow-color),
    inset 0 0 0 3px var(--jp-input-active-box-shadow-color);
}

.jp-InputGroup input:disabled {
  cursor: not-allowed;
  resize: block;
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color2);
}

.jp-InputGroup input:disabled ~ span {
  cursor: not-allowed;
  color: var(--jp-ui-font-color2);
}

.jp-InputGroup input::placeholder,
input::placeholder {
  color: var(--jp-ui-font-color2);
}

.jp-InputGroupAction {
  position: absolute;
  bottom: 1px;
  right: 0;
  padding: 6px;
}

.jp-HTMLSelect.jp-DefaultStyle select {
  background-color: initial;
  border: none;
  border-radius: 0;
  box-shadow: none;
  color: var(--jp-ui-font-color0);
  display: block;
  font-size: var(--jp-ui-font-size1);
  font-family: var(--jp-ui-font-family);
  height: 24px;
  line-height: 14px;
  padding: 0 25px 0 10px;
  text-align: left;
  -moz-appearance: none;
  -webkit-appearance: none;
}

.jp-HTMLSelect.jp-DefaultStyle select:disabled {
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color2);
  cursor: not-allowed;
  resize: block;
}

.jp-HTMLSelect.jp-DefaultStyle select:disabled ~ span {
  cursor: not-allowed;
}

/* Use our own theme for hover and option styles */
/* stylelint-disable-next-line selector-max-type */
.jp-HTMLSelect.jp-DefaultStyle select:hover,
.jp-HTMLSelect.jp-DefaultStyle select > option {
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color0);
}

select {
  box-sizing: border-box;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-StatusBar-Widget {
  display: flex;
  align-items: center;
  background: var(--jp-layout-color2);
  min-height: var(--jp-statusbar-height);
  justify-content: space-between;
  padding: 0 10px;
}

.jp-StatusBar-Left {
  display: flex;
  align-items: center;
  flex-direction: row;
}

.jp-StatusBar-Middle {
  display: flex;
  align-items: center;
}

.jp-StatusBar-Right {
  display: flex;
  align-items: center;
  flex-direction: row-reverse;
}

.jp-StatusBar-Item {
  max-height: var(--jp-statusbar-height);
  margin: 0 2px;
  height: var(--jp-statusbar-height);
  white-space: nowrap;
  text-overflow: ellipsis;
  color: var(--jp-ui-font-color1);
  padding: 0 6px;
}

.jp-mod-highlighted:hover {
  background-color: var(--jp-layout-color3);
}

.jp-mod-clicked {
  background-color: var(--jp-brand-color1);
}

.jp-mod-clicked:hover {
  background-color: var(--jp-brand-color0);
}

.jp-mod-clicked .jp-StatusBar-TextItem {
  color: var(--jp-ui-inverse-font-color1);
}

.jp-StatusBar-HoverItem {
  box-shadow: '0px 4px 4px rgba(0, 0, 0, 0.25)';
}

.jp-StatusBar-TextItem {
  font-size: var(--jp-ui-font-size1);
  font-family: var(--jp-ui-font-family);
  line-height: 24px;
  color: var(--jp-ui-font-color1);
}

.jp-StatusBar-GroupItem {
  display: flex;
  align-items: center;
  flex-direction: row;
}

.jp-Statusbar-ProgressCircle svg {
  display: block;
  margin: 0 auto;
  width: 16px;
  height: 24px;
  align-self: normal;
}

.jp-Statusbar-ProgressCircle path {
  fill: var(--jp-inverse-layout-color3);
}

.jp-Statusbar-ProgressBar-progress-bar {
  height: 10px;
  width: 100px;
  border: solid 0.25px var(--jp-brand-color2);
  border-radius: 3px;
  overflow: hidden;
  align-self: center;
}

.jp-Statusbar-ProgressBar-progress-bar > div {
  background-color: var(--jp-brand-color2);
  background-image: linear-gradient(
    -45deg,
    rgba(255, 255, 255, 0.2) 25%,
    transparent 25%,
    transparent 50%,
    rgba(255, 255, 255, 0.2) 50%,
    rgba(255, 255, 255, 0.2) 75%,
    transparent 75%,
    transparent
  );
  background-size: 40px 40px;
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 14px;
  color: #fff;
  text-align: center;
  animation: jp-Statusbar-ExecutionTime-progress-bar 2s linear infinite;
}

.jp-Statusbar-ProgressBar-progress-bar p {
  color: var(--jp-ui-font-color1);
  font-family: var(--jp-ui-font-family);
  font-size: var(--jp-ui-font-size1);
  line-height: 10px;
  width: 100px;
}

@keyframes jp-Statusbar-ExecutionTime-progress-bar {
  0% {
    background-position: 0 0;
  }

  100% {
    background-position: 40px 40px;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-commandpalette-search-height: 28px;
}

/*-----------------------------------------------------------------------------
| Overall styles
|----------------------------------------------------------------------------*/

.lm-CommandPalette {
  padding-bottom: 0;
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);

  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
}

/*-----------------------------------------------------------------------------
| Modal variant
|----------------------------------------------------------------------------*/

.jp-ModalCommandPalette {
  position: absolute;
  z-index: 10000;
  top: 38px;
  left: 30%;
  margin: 0;
  padding: 4px;
  width: 40%;
  box-shadow: var(--jp-elevation-z4);
  border-radius: 4px;
  background: var(--jp-layout-color0);
}

.jp-ModalCommandPalette .lm-CommandPalette {
  max-height: 40vh;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-close-icon::after {
  display: none;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-CommandPalette-header {
  display: none;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-CommandPalette-item {
  margin-left: 4px;
  margin-right: 4px;
}

.jp-ModalCommandPalette
  .lm-CommandPalette
  .lm-CommandPalette-item.lm-mod-disabled {
  display: none;
}

/*-----------------------------------------------------------------------------
| Search
|----------------------------------------------------------------------------*/

.lm-CommandPalette-search {
  padding: 4px;
  background-color: var(--jp-layout-color1);
  z-index: 2;
}

.lm-CommandPalette-wrapper {
  overflow: overlay;
  padding: 0 9px;
  background-color: var(--jp-input-active-background);
  height: 30px;
  box-shadow: inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color);
}

.lm-CommandPalette.lm-mod-focused .lm-CommandPalette-wrapper {
  box-shadow: inset 0 0 0 1px var(--jp-input-active-box-shadow-color),
    inset 0 0 0 3px var(--jp-input-active-box-shadow-color);
}

.jp-SearchIconGroup {
  color: white;
  background-color: var(--jp-brand-color1);
  position: absolute;
  top: 4px;
  right: 4px;
  padding: 5px 5px 1px;
}

.jp-SearchIconGroup svg {
  height: 20px;
  width: 20px;
}

.jp-SearchIconGroup .jp-icon3[fill] {
  fill: var(--jp-layout-color0);
}

.lm-CommandPalette-input {
  background: transparent;
  width: calc(100% - 18px);
  float: left;
  border: none;
  outline: none;
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  line-height: var(--jp-private-commandpalette-search-height);
}

.lm-CommandPalette-input::-webkit-input-placeholder,
.lm-CommandPalette-input::-moz-placeholder,
.lm-CommandPalette-input:-ms-input-placeholder {
  color: var(--jp-ui-font-color2);
  font-size: var(--jp-ui-font-size1);
}

/*-----------------------------------------------------------------------------
| Results
|----------------------------------------------------------------------------*/

.lm-CommandPalette-header:first-child {
  margin-top: 0;
}

.lm-CommandPalette-header {
  border-bottom: solid var(--jp-border-width) var(--jp-border-color2);
  color: var(--jp-ui-font-color1);
  cursor: pointer;
  display: flex;
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  letter-spacing: 1px;
  margin-top: 8px;
  padding: 8px 0 8px 12px;
  text-transform: uppercase;
}

.lm-CommandPalette-header.lm-mod-active {
  background: var(--jp-layout-color2);
}

.lm-CommandPalette-header > mark {
  background-color: transparent;
  font-weight: bold;
  color: var(--jp-ui-font-color1);
}

.lm-CommandPalette-item {
  padding: 4px 12px 4px 4px;
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  font-weight: 400;
  display: flex;
}

.lm-CommandPalette-item.lm-mod-disabled {
  color: var(--jp-ui-font-color2);
}

.lm-CommandPalette-item.lm-mod-active {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.lm-CommandPalette-item.lm-mod-active .lm-CommandPalette-itemLabel > mark {
  color: var(--jp-ui-inverse-font-color0);
}

.lm-CommandPalette-item.lm-mod-active .jp-icon-selectable[fill] {
  fill: var(--jp-layout-color0);
}

.lm-CommandPalette-item.lm-mod-active:hover:not(.lm-mod-disabled) {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.lm-CommandPalette-item:hover:not(.lm-mod-active):not(.lm-mod-disabled) {
  background: var(--jp-layout-color2);
}

.lm-CommandPalette-itemContent {
  overflow: hidden;
}

.lm-CommandPalette-itemLabel > mark {
  color: var(--jp-ui-font-color0);
  background-color: transparent;
  font-weight: bold;
}

.lm-CommandPalette-item.lm-mod-disabled mark {
  color: var(--jp-ui-font-color2);
}

.lm-CommandPalette-item .lm-CommandPalette-itemIcon {
  margin: 0 4px 0 0;
  position: relative;
  width: 16px;
  top: 2px;
  flex: 0 0 auto;
}

.lm-CommandPalette-item.lm-mod-disabled .lm-CommandPalette-itemIcon {
  opacity: 0.6;
}

.lm-CommandPalette-item .lm-CommandPalette-itemShortcut {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemCaption {
  display: none;
}

.lm-CommandPalette-content {
  background-color: var(--jp-layout-color1);
}

.lm-CommandPalette-content:empty::after {
  content: 'No results';
  margin: auto;
  margin-top: 20px;
  width: 100px;
  display: block;
  font-size: var(--jp-ui-font-size2);
  font-family: var(--jp-ui-font-family);
  font-weight: lighter;
}

.lm-CommandPalette-emptyMessage {
  text-align: center;
  margin-top: 24px;
  line-height: 1.32;
  padding: 0 8px;
  color: var(--jp-content-font-color3);
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Dialog {
  position: absolute;
  z-index: 10000;
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  top: 0;
  left: 0;
  margin: 0;
  padding: 0;
  width: 100%;
  height: 100%;
  background: var(--jp-dialog-background);
}

.jp-Dialog-content {
  display: flex;
  flex-direction: column;
  margin-left: auto;
  margin-right: auto;
  background: var(--jp-layout-color1);
  padding: 24px 24px 12px;
  min-width: 300px;
  min-height: 150px;
  max-width: 1000px;
  max-height: 500px;
  box-sizing: border-box;
  box-shadow: var(--jp-elevation-z20);
  word-wrap: break-word;
  border-radius: var(--jp-border-radius);

  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color1);
  resize: both;
}

.jp-Dialog-content.jp-Dialog-content-small {
  max-width: 500px;
}

.jp-Dialog-button {
  overflow: visible;
}

button.jp-Dialog-button:focus {
  outline: 1px solid var(--jp-brand-color1);
  outline-offset: 4px;
  -moz-outline-radius: 0;
}

button.jp-Dialog-button:focus::-moz-focus-inner {
  border: 0;
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-accept:focus,
button.jp-Dialog-button.jp-mod-styled.jp-mod-warn:focus,
button.jp-Dialog-button.jp-mod-styled.jp-mod-reject:focus {
  outline-offset: 4px;
  -moz-outline-radius: 0;
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-accept:focus {
  outline: 1px solid var(--jp-accept-color-normal, var(--jp-brand-color1));
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-warn:focus {
  outline: 1px solid var(--jp-warn-color-normal, var(--jp-error-color1));
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-reject:focus {
  outline: 1px solid var(--jp-reject-color-normal, var(--md-grey-600));
}

button.jp-Dialog-close-button {
  padding: 0;
  height: 100%;
  min-width: unset;
  min-height: unset;
}

.jp-Dialog-header {
  display: flex;
  justify-content: space-between;
  flex: 0 0 auto;
  padding-bottom: 12px;
  font-size: var(--jp-ui-font-size3);
  font-weight: 400;
  color: var(--jp-ui-font-color1);
}

.jp-Dialog-body {
  display: flex;
  flex-direction: column;
  flex: 1 1 auto;
  font-size: var(--jp-ui-font-size1);
  background: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  overflow: auto;
}

.jp-Dialog-footer {
  display: flex;
  flex-direction: row;
  justify-content: flex-end;
  align-items: center;
  flex: 0 0 auto;
  margin-left: -12px;
  margin-right: -12px;
  padding: 12px;
}

.jp-Dialog-checkbox {
  padding-right: 5px;
}

.jp-Dialog-checkbox > input:focus-visible {
  outline: 1px solid var(--jp-input-active-border-color);
  outline-offset: 1px;
}

.jp-Dialog-spacer {
  flex: 1 1 auto;
}

.jp-Dialog-title {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.jp-Dialog-body > .jp-select-wrapper {
  width: 100%;
}

.jp-Dialog-body > button {
  padding: 0 16px;
}

.jp-Dialog-body > label {
  line-height: 1.4;
  color: var(--jp-ui-font-color0);
}

.jp-Dialog-button.jp-mod-styled:not(:last-child) {
  margin-right: 12px;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-Input-Boolean-Dialog {
  flex-direction: row-reverse;
  align-items: end;
  width: 100%;
}

.jp-Input-Boolean-Dialog > label {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-MainAreaWidget > :focus {
  outline: none;
}

.jp-MainAreaWidget .jp-MainAreaWidget-error {
  padding: 6px;
}

.jp-MainAreaWidget .jp-MainAreaWidget-error > pre {
  width: auto;
  padding: 10px;
  background: var(--jp-error-color3);
  border: var(--jp-border-width) solid var(--jp-error-color1);
  border-radius: var(--jp-border-radius);
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  white-space: pre-wrap;
  word-wrap: break-word;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/**
 * google-material-color v1.2.6
 * https://github.com/danlevan/google-material-color
 */
:root {
  --md-red-50: #ffebee;
  --md-red-100: #ffcdd2;
  --md-red-200: #ef9a9a;
  --md-red-300: #e57373;
  --md-red-400: #ef5350;
  --md-red-500: #f44336;
  --md-red-600: #e53935;
  --md-red-700: #d32f2f;
  --md-red-800: #c62828;
  --md-red-900: #b71c1c;
  --md-red-A100: #ff8a80;
  --md-red-A200: #ff5252;
  --md-red-A400: #ff1744;
  --md-red-A700: #d50000;
  --md-pink-50: #fce4ec;
  --md-pink-100: #f8bbd0;
  --md-pink-200: #f48fb1;
  --md-pink-300: #f06292;
  --md-pink-400: #ec407a;
  --md-pink-500: #e91e63;
  --md-pink-600: #d81b60;
  --md-pink-700: #c2185b;
  --md-pink-800: #ad1457;
  --md-pink-900: #880e4f;
  --md-pink-A100: #ff80ab;
  --md-pink-A200: #ff4081;
  --md-pink-A400: #f50057;
  --md-pink-A700: #c51162;
  --md-purple-50: #f3e5f5;
  --md-purple-100: #e1bee7;
  --md-purple-200: #ce93d8;
  --md-purple-300: #ba68c8;
  --md-purple-400: #ab47bc;
  --md-purple-500: #9c27b0;
  --md-purple-600: #8e24aa;
  --md-purple-700: #7b1fa2;
  --md-purple-800: #6a1b9a;
  --md-purple-900: #4a148c;
  --md-purple-A100: #ea80fc;
  --md-purple-A200: #e040fb;
  --md-purple-A400: #d500f9;
  --md-purple-A700: #a0f;
  --md-deep-purple-50: #ede7f6;
  --md-deep-purple-100: #d1c4e9;
  --md-deep-purple-200: #b39ddb;
  --md-deep-purple-300: #9575cd;
  --md-deep-purple-400: #7e57c2;
  --md-deep-purple-500: #673ab7;
  --md-deep-purple-600: #5e35b1;
  --md-deep-purple-700: #512da8;
  --md-deep-purple-800: #4527a0;
  --md-deep-purple-900: #311b92;
  --md-deep-purple-A100: #b388ff;
  --md-deep-purple-A200: #7c4dff;
  --md-deep-purple-A400: #651fff;
  --md-deep-purple-A700: #6200ea;
  --md-indigo-50: #e8eaf6;
  --md-indigo-100: #c5cae9;
  --md-indigo-200: #9fa8da;
  --md-indigo-300: #7986cb;
  --md-indigo-400: #5c6bc0;
  --md-indigo-500: #3f51b5;
  --md-indigo-600: #3949ab;
  --md-indigo-700: #303f9f;
  --md-indigo-800: #283593;
  --md-indigo-900: #1a237e;
  --md-indigo-A100: #8c9eff;
  --md-indigo-A200: #536dfe;
  --md-indigo-A400: #3d5afe;
  --md-indigo-A700: #304ffe;
  --md-blue-50: #e3f2fd;
  --md-blue-100: #bbdefb;
  --md-blue-200: #90caf9;
  --md-blue-300: #64b5f6;
  --md-blue-400: #42a5f5;
  --md-blue-500: #2196f3;
  --md-blue-600: #1e88e5;
  --md-blue-700: #1976d2;
  --md-blue-800: #1565c0;
  --md-blue-900: #0d47a1;
  --md-blue-A100: #82b1ff;
  --md-blue-A200: #448aff;
  --md-blue-A400: #2979ff;
  --md-blue-A700: #2962ff;
  --md-light-blue-50: #e1f5fe;
  --md-light-blue-100: #b3e5fc;
  --md-light-blue-200: #81d4fa;
  --md-light-blue-300: #4fc3f7;
  --md-light-blue-400: #29b6f6;
  --md-light-blue-500: #03a9f4;
  --md-light-blue-600: #039be5;
  --md-light-blue-700: #0288d1;
  --md-light-blue-800: #0277bd;
  --md-light-blue-900: #01579b;
  --md-light-blue-A100: #80d8ff;
  --md-light-blue-A200: #40c4ff;
  --md-light-blue-A400: #00b0ff;
  --md-light-blue-A700: #0091ea;
  --md-cyan-50: #e0f7fa;
  --md-cyan-100: #b2ebf2;
  --md-cyan-200: #80deea;
  --md-cyan-300: #4dd0e1;
  --md-cyan-400: #26c6da;
  --md-cyan-500: #00bcd4;
  --md-cyan-600: #00acc1;
  --md-cyan-700: #0097a7;
  --md-cyan-800: #00838f;
  --md-cyan-900: #006064;
  --md-cyan-A100: #84ffff;
  --md-cyan-A200: #18ffff;
  --md-cyan-A400: #00e5ff;
  --md-cyan-A700: #00b8d4;
  --md-teal-50: #e0f2f1;
  --md-teal-100: #b2dfdb;
  --md-teal-200: #80cbc4;
  --md-teal-300: #4db6ac;
  --md-teal-400: #26a69a;
  --md-teal-500: #009688;
  --md-teal-600: #00897b;
  --md-teal-700: #00796b;
  --md-teal-800: #00695c;
  --md-teal-900: #004d40;
  --md-teal-A100: #a7ffeb;
  --md-teal-A200: #64ffda;
  --md-teal-A400: #1de9b6;
  --md-teal-A700: #00bfa5;
  --md-green-50: #e8f5e9;
  --md-green-100: #c8e6c9;
  --md-green-200: #a5d6a7;
  --md-green-300: #81c784;
  --md-green-400: #66bb6a;
  --md-green-500: #4caf50;
  --md-green-600: #43a047;
  --md-green-700: #388e3c;
  --md-green-800: #2e7d32;
  --md-green-900: #1b5e20;
  --md-green-A100: #b9f6ca;
  --md-green-A200: #69f0ae;
  --md-green-A400: #00e676;
  --md-green-A700: #00c853;
  --md-light-green-50: #f1f8e9;
  --md-light-green-100: #dcedc8;
  --md-light-green-200: #c5e1a5;
  --md-light-green-300: #aed581;
  --md-light-green-400: #9ccc65;
  --md-light-green-500: #8bc34a;
  --md-light-green-600: #7cb342;
  --md-light-green-700: #689f38;
  --md-light-green-800: #558b2f;
  --md-light-green-900: #33691e;
  --md-light-green-A100: #ccff90;
  --md-light-green-A200: #b2ff59;
  --md-light-green-A400: #76ff03;
  --md-light-green-A700: #64dd17;
  --md-lime-50: #f9fbe7;
  --md-lime-100: #f0f4c3;
  --md-lime-200: #e6ee9c;
  --md-lime-300: #dce775;
  --md-lime-400: #d4e157;
  --md-lime-500: #cddc39;
  --md-lime-600: #c0ca33;
  --md-lime-700: #afb42b;
  --md-lime-800: #9e9d24;
  --md-lime-900: #827717;
  --md-lime-A100: #f4ff81;
  --md-lime-A200: #eeff41;
  --md-lime-A400: #c6ff00;
  --md-lime-A700: #aeea00;
  --md-yellow-50: #fffde7;
  --md-yellow-100: #fff9c4;
  --md-yellow-200: #fff59d;
  --md-yellow-300: #fff176;
  --md-yellow-400: #ffee58;
  --md-yellow-500: #ffeb3b;
  --md-yellow-600: #fdd835;
  --md-yellow-700: #fbc02d;
  --md-yellow-800: #f9a825;
  --md-yellow-900: #f57f17;
  --md-yellow-A100: #ffff8d;
  --md-yellow-A200: #ff0;
  --md-yellow-A400: #ffea00;
  --md-yellow-A700: #ffd600;
  --md-amber-50: #fff8e1;
  --md-amber-100: #ffecb3;
  --md-amber-200: #ffe082;
  --md-amber-300: #ffd54f;
  --md-amber-400: #ffca28;
  --md-amber-500: #ffc107;
  --md-amber-600: #ffb300;
  --md-amber-700: #ffa000;
  --md-amber-800: #ff8f00;
  --md-amber-900: #ff6f00;
  --md-amber-A100: #ffe57f;
  --md-amber-A200: #ffd740;
  --md-amber-A400: #ffc400;
  --md-amber-A700: #ffab00;
  --md-orange-50: #fff3e0;
  --md-orange-100: #ffe0b2;
  --md-orange-200: #ffcc80;
  --md-orange-300: #ffb74d;
  --md-orange-400: #ffa726;
  --md-orange-500: #ff9800;
  --md-orange-600: #fb8c00;
  --md-orange-700: #f57c00;
  --md-orange-800: #ef6c00;
  --md-orange-900: #e65100;
  --md-orange-A100: #ffd180;
  --md-orange-A200: #ffab40;
  --md-orange-A400: #ff9100;
  --md-orange-A700: #ff6d00;
  --md-deep-orange-50: #fbe9e7;
  --md-deep-orange-100: #ffccbc;
  --md-deep-orange-200: #ffab91;
  --md-deep-orange-300: #ff8a65;
  --md-deep-orange-400: #ff7043;
  --md-deep-orange-500: #ff5722;
  --md-deep-orange-600: #f4511e;
  --md-deep-orange-700: #e64a19;
  --md-deep-orange-800: #d84315;
  --md-deep-orange-900: #bf360c;
  --md-deep-orange-A100: #ff9e80;
  --md-deep-orange-A200: #ff6e40;
  --md-deep-orange-A400: #ff3d00;
  --md-deep-orange-A700: #dd2c00;
  --md-brown-50: #efebe9;
  --md-brown-100: #d7ccc8;
  --md-brown-200: #bcaaa4;
  --md-brown-300: #a1887f;
  --md-brown-400: #8d6e63;
  --md-brown-500: #795548;
  --md-brown-600: #6d4c41;
  --md-brown-700: #5d4037;
  --md-brown-800: #4e342e;
  --md-brown-900: #3e2723;
  --md-grey-50: #fafafa;
  --md-grey-100: #f5f5f5;
  --md-grey-200: #eee;
  --md-grey-300: #e0e0e0;
  --md-grey-400: #bdbdbd;
  --md-grey-500: #9e9e9e;
  --md-grey-600: #757575;
  --md-grey-700: #616161;
  --md-grey-800: #424242;
  --md-grey-900: #212121;
  --md-blue-grey-50: #eceff1;
  --md-blue-grey-100: #cfd8dc;
  --md-blue-grey-200: #b0bec5;
  --md-blue-grey-300: #90a4ae;
  --md-blue-grey-400: #78909c;
  --md-blue-grey-500: #607d8b;
  --md-blue-grey-600: #546e7a;
  --md-blue-grey-700: #455a64;
  --md-blue-grey-800: #37474f;
  --md-blue-grey-900: #263238;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| RenderedText
|----------------------------------------------------------------------------*/

:root {
  /* This is the padding value to fill the gaps between lines containing spans with background color. */
  --jp-private-code-span-padding: calc(
    (var(--jp-code-line-height) - 1) * var(--jp-code-font-size) / 2
  );
}

.jp-RenderedText {
  text-align: left;
  padding-left: var(--jp-code-padding);
  line-height: var(--jp-code-line-height);
  font-family: var(--jp-code-font-family);
}

.jp-RenderedText pre,
.jp-RenderedJavaScript pre,
.jp-RenderedHTMLCommon pre {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-code-font-size);
  border: none;
  margin: 0;
  padding: 0;
}

.jp-RenderedText pre a:link {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

.jp-RenderedText pre a:hover {
  text-decoration: underline;
  color: var(--jp-content-link-color);
}

.jp-RenderedText pre a:visited {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

/* console foregrounds and backgrounds */
.jp-RenderedText pre .ansi-black-fg {
  color: #3e424d;
}

.jp-RenderedText pre .ansi-red-fg {
  color: #e75c58;
}

.jp-RenderedText pre .ansi-green-fg {
  color: #00a250;
}

.jp-RenderedText pre .ansi-yellow-fg {
  color: #ddb62b;
}

.jp-RenderedText pre .ansi-blue-fg {
  color: #208ffb;
}

.jp-RenderedText pre .ansi-magenta-fg {
  color: #d160c4;
}

.jp-RenderedText pre .ansi-cyan-fg {
  color: #60c6c8;
}

.jp-RenderedText pre .ansi-white-fg {
  color: #c5c1b4;
}

.jp-RenderedText pre .ansi-black-bg {
  background-color: #3e424d;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-red-bg {
  background-color: #e75c58;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-green-bg {
  background-color: #00a250;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-yellow-bg {
  background-color: #ddb62b;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-blue-bg {
  background-color: #208ffb;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-magenta-bg {
  background-color: #d160c4;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-cyan-bg {
  background-color: #60c6c8;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-white-bg {
  background-color: #c5c1b4;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-black-intense-fg {
  color: #282c36;
}

.jp-RenderedText pre .ansi-red-intense-fg {
  color: #b22b31;
}

.jp-RenderedText pre .ansi-green-intense-fg {
  color: #007427;
}

.jp-RenderedText pre .ansi-yellow-intense-fg {
  color: #b27d12;
}

.jp-RenderedText pre .ansi-blue-intense-fg {
  color: #0065ca;
}

.jp-RenderedText pre .ansi-magenta-intense-fg {
  color: #a03196;
}

.jp-RenderedText pre .ansi-cyan-intense-fg {
  color: #258f8f;
}

.jp-RenderedText pre .ansi-white-intense-fg {
  color: #a1a6b2;
}

.jp-RenderedText pre .ansi-black-intense-bg {
  background-color: #282c36;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-red-intense-bg {
  background-color: #b22b31;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-green-intense-bg {
  background-color: #007427;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-yellow-intense-bg {
  background-color: #b27d12;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-blue-intense-bg {
  background-color: #0065ca;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-magenta-intense-bg {
  background-color: #a03196;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-cyan-intense-bg {
  background-color: #258f8f;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-white-intense-bg {
  background-color: #a1a6b2;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-default-inverse-fg {
  color: var(--jp-ui-inverse-font-color0);
}

.jp-RenderedText pre .ansi-default-inverse-bg {
  background-color: var(--jp-inverse-layout-color0);
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-bold {
  font-weight: bold;
}

.jp-RenderedText pre .ansi-underline {
  text-decoration: underline;
}

.jp-RenderedText[data-mime-type='application/vnd.jupyter.stderr'] {
  background: var(--jp-rendermime-error-background);
  padding-top: var(--jp-code-padding);
}

/*-----------------------------------------------------------------------------
| RenderedLatex
|----------------------------------------------------------------------------*/

.jp-RenderedLatex {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-content-font-size1);
  line-height: var(--jp-content-line-height);
}

/* Left-justify outputs.*/
.jp-OutputArea-output.jp-RenderedLatex {
  padding: var(--jp-code-padding);
  text-align: left;
}

/*-----------------------------------------------------------------------------
| RenderedHTML
|----------------------------------------------------------------------------*/

.jp-RenderedHTMLCommon {
  color: var(--jp-content-font-color1);
  font-family: var(--jp-content-font-family);
  font-size: var(--jp-content-font-size1);
  line-height: var(--jp-content-line-height);

  /* Give a bit more R padding on Markdown text to keep line lengths reasonable */
  padding-right: 20px;
}

.jp-RenderedHTMLCommon em {
  font-style: italic;
}

.jp-RenderedHTMLCommon strong {
  font-weight: bold;
}

.jp-RenderedHTMLCommon u {
  text-decoration: underline;
}

.jp-RenderedHTMLCommon a:link {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

.jp-RenderedHTMLCommon a:hover {
  text-decoration: underline;
  color: var(--jp-content-link-color);
}

.jp-RenderedHTMLCommon a:visited {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

/* Headings */

.jp-RenderedHTMLCommon h1,
.jp-RenderedHTMLCommon h2,
.jp-RenderedHTMLCommon h3,
.jp-RenderedHTMLCommon h4,
.jp-RenderedHTMLCommon h5,
.jp-RenderedHTMLCommon h6 {
  line-height: var(--jp-content-heading-line-height);
  font-weight: var(--jp-content-heading-font-weight);
  font-style: normal;
  margin: var(--jp-content-heading-margin-top) 0
    var(--jp-content-heading-margin-bottom) 0;
}

.jp-RenderedHTMLCommon h1:first-child,
.jp-RenderedHTMLCommon h2:first-child,
.jp-RenderedHTMLCommon h3:first-child,
.jp-RenderedHTMLCommon h4:first-child,
.jp-RenderedHTMLCommon h5:first-child,
.jp-RenderedHTMLCommon h6:first-child {
  margin-top: calc(0.5 * var(--jp-content-heading-margin-top));
}

.jp-RenderedHTMLCommon h1:last-child,
.jp-RenderedHTMLCommon h2:last-child,
.jp-RenderedHTMLCommon h3:last-child,
.jp-RenderedHTMLCommon h4:last-child,
.jp-RenderedHTMLCommon h5:last-child,
.jp-RenderedHTMLCommon h6:last-child {
  margin-bottom: calc(0.5 * var(--jp-content-heading-margin-bottom));
}

.jp-RenderedHTMLCommon h1 {
  font-size: var(--jp-content-font-size5);
}

.jp-RenderedHTMLCommon h2 {
  font-size: var(--jp-content-font-size4);
}

.jp-RenderedHTMLCommon h3 {
  font-size: var(--jp-content-font-size3);
}

.jp-RenderedHTMLCommon h4 {
  font-size: var(--jp-content-font-size2);
}

.jp-RenderedHTMLCommon h5 {
  font-size: var(--jp-content-font-size1);
}

.jp-RenderedHTMLCommon h6 {
  font-size: var(--jp-content-font-size0);
}

/* Lists */

/* stylelint-disable selector-max-type, selector-max-compound-selectors */

.jp-RenderedHTMLCommon ul:not(.list-inline),
.jp-RenderedHTMLCommon ol:not(.list-inline) {
  padding-left: 2em;
}

.jp-RenderedHTMLCommon ul {
  list-style: disc;
}

.jp-RenderedHTMLCommon ul ul {
  list-style: square;
}

.jp-RenderedHTMLCommon ul ul ul {
  list-style: circle;
}

.jp-RenderedHTMLCommon ol {
  list-style: decimal;
}

.jp-RenderedHTMLCommon ol ol {
  list-style: upper-alpha;
}

.jp-RenderedHTMLCommon ol ol ol {
  list-style: lower-alpha;
}

.jp-RenderedHTMLCommon ol ol ol ol {
  list-style: lower-roman;
}

.jp-RenderedHTMLCommon ol ol ol ol ol {
  list-style: decimal;
}

.jp-RenderedHTMLCommon ol,
.jp-RenderedHTMLCommon ul {
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon ul ul,
.jp-RenderedHTMLCommon ul ol,
.jp-RenderedHTMLCommon ol ul,
.jp-RenderedHTMLCommon ol ol {
  margin-bottom: 0;
}

/* stylelint-enable selector-max-type, selector-max-compound-selectors */

.jp-RenderedHTMLCommon hr {
  color: var(--jp-border-color2);
  background-color: var(--jp-border-color1);
  margin-top: 1em;
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon > pre {
  margin: 1.5em 2em;
}

.jp-RenderedHTMLCommon pre,
.jp-RenderedHTMLCommon code {
  border: 0;
  background-color: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
  font-family: var(--jp-code-font-family);
  font-size: inherit;
  line-height: var(--jp-code-line-height);
  padding: 0;
  white-space: pre-wrap;
}

.jp-RenderedHTMLCommon :not(pre) > code {
  background-color: var(--jp-layout-color2);
  padding: 1px 5px;
}

/* Tables */

.jp-RenderedHTMLCommon table {
  border-collapse: collapse;
  border-spacing: 0;
  border: none;
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  table-layout: fixed;
  margin-left: auto;
  margin-bottom: 1em;
  margin-right: auto;
}

.jp-RenderedHTMLCommon thead {
  border-bottom: var(--jp-border-width) solid var(--jp-border-color1);
  vertical-align: bottom;
}

.jp-RenderedHTMLCommon td,
.jp-RenderedHTMLCommon th,
.jp-RenderedHTMLCommon tr {
  vertical-align: middle;
  padding: 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}

.jp-RenderedMarkdown.jp-RenderedHTMLCommon td,
.jp-RenderedMarkdown.jp-RenderedHTMLCommon th {
  max-width: none;
}

:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon td,
:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon th,
:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon tr {
  text-align: right;
}

.jp-RenderedHTMLCommon th {
  font-weight: bold;
}

.jp-RenderedHTMLCommon tbody tr:nth-child(odd) {
  background: var(--jp-layout-color0);
}

.jp-RenderedHTMLCommon tbody tr:nth-child(even) {
  background: var(--jp-rendermime-table-row-background);
}

.jp-RenderedHTMLCommon tbody tr:hover {
  background: var(--jp-rendermime-table-row-hover-background);
}

.jp-RenderedHTMLCommon p {
  text-align: left;
  margin: 0;
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon img {
  -moz-force-broken-image-icon: 1;
}

/* Restrict to direct children as other images could be nested in other content. */
.jp-RenderedHTMLCommon > img {
  display: block;
  margin-left: 0;
  margin-right: 0;
  margin-bottom: 1em;
}

/* Change color behind transparent images if they need it... */
[data-jp-theme-light='false'] .jp-RenderedImage img.jp-needs-light-background {
  background-color: var(--jp-inverse-layout-color1);
}

[data-jp-theme-light='true'] .jp-RenderedImage img.jp-needs-dark-background {
  background-color: var(--jp-inverse-layout-color1);
}

.jp-RenderedHTMLCommon img,
.jp-RenderedImage img,
.jp-RenderedHTMLCommon svg,
.jp-RenderedSVG svg {
  max-width: 100%;
  height: auto;
}

.jp-RenderedHTMLCommon img.jp-mod-unconfined,
.jp-RenderedImage img.jp-mod-unconfined,
.jp-RenderedHTMLCommon svg.jp-mod-unconfined,
.jp-RenderedSVG svg.jp-mod-unconfined {
  max-width: none;
}

.jp-RenderedHTMLCommon .alert {
  padding: var(--jp-notebook-padding);
  border: var(--jp-border-width) solid transparent;
  border-radius: var(--jp-border-radius);
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon .alert-info {
  color: var(--jp-info-color0);
  background-color: var(--jp-info-color3);
  border-color: var(--jp-info-color2);
}

.jp-RenderedHTMLCommon .alert-info hr {
  border-color: var(--jp-info-color3);
}

.jp-RenderedHTMLCommon .alert-info > p:last-child,
.jp-RenderedHTMLCommon .alert-info > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-warning {
  color: var(--jp-warn-color0);
  background-color: var(--jp-warn-color3);
  border-color: var(--jp-warn-color2);
}

.jp-RenderedHTMLCommon .alert-warning hr {
  border-color: var(--jp-warn-color3);
}

.jp-RenderedHTMLCommon .alert-warning > p:last-child,
.jp-RenderedHTMLCommon .alert-warning > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-success {
  color: var(--jp-success-color0);
  background-color: var(--jp-success-color3);
  border-color: var(--jp-success-color2);
}

.jp-RenderedHTMLCommon .alert-success hr {
  border-color: var(--jp-success-color3);
}

.jp-RenderedHTMLCommon .alert-success > p:last-child,
.jp-RenderedHTMLCommon .alert-success > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-danger {
  color: var(--jp-error-color0);
  background-color: var(--jp-error-color3);
  border-color: var(--jp-error-color2);
}

.jp-RenderedHTMLCommon .alert-danger hr {
  border-color: var(--jp-error-color3);
}

.jp-RenderedHTMLCommon .alert-danger > p:last-child,
.jp-RenderedHTMLCommon .alert-danger > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon blockquote {
  margin: 1em 2em;
  padding: 0 1em;
  border-left: 5px solid var(--jp-border-color2);
}

a.jp-InternalAnchorLink {
  visibility: hidden;
  margin-left: 8px;
  color: var(--md-blue-800);
}

h1:hover .jp-InternalAnchorLink,
h2:hover .jp-InternalAnchorLink,
h3:hover .jp-InternalAnchorLink,
h4:hover .jp-InternalAnchorLink,
h5:hover .jp-InternalAnchorLink,
h6:hover .jp-InternalAnchorLink {
  visibility: visible;
}

.jp-RenderedHTMLCommon kbd {
  background-color: var(--jp-rendermime-table-row-background);
  border: 1px solid var(--jp-border-color0);
  border-bottom-color: var(--jp-border-color2);
  border-radius: 3px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
  display: inline-block;
  font-size: var(--jp-ui-font-size0);
  line-height: 1em;
  padding: 0.2em 0.5em;
}

/* Most direct children of .jp-RenderedHTMLCommon have a margin-bottom of 1.0.
 * At the bottom of cells this is a bit too much as there is also spacing
 * between cells. Going all the way to 0 gets too tight between markdown and
 * code cells.
 */
.jp-RenderedHTMLCommon > *:last-child {
  margin-bottom: 0.5em;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-cursor-backdrop {
  position: fixed;
  width: 200px;
  height: 200px;
  margin-top: -100px;
  margin-left: -100px;
  will-change: transform;
  z-index: 100;
}

.lm-mod-drag-image {
  will-change: transform;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-lineFormSearch {
  padding: 4px 12px;
  background-color: var(--jp-layout-color2);
  box-shadow: var(--jp-toolbar-box-shadow);
  z-index: 2;
  font-size: var(--jp-ui-font-size1);
}

.jp-lineFormCaption {
  font-size: var(--jp-ui-font-size0);
  line-height: var(--jp-ui-font-size1);
  margin-top: 4px;
  color: var(--jp-ui-font-color0);
}

.jp-baseLineForm {
  border: none;
  border-radius: 0;
  position: absolute;
  background-size: 16px;
  background-repeat: no-repeat;
  background-position: center;
  outline: none;
}

.jp-lineFormButtonContainer {
  top: 4px;
  right: 8px;
  height: 24px;
  padding: 0 12px;
  width: 12px;
}

.jp-lineFormButtonIcon {
  top: 0;
  right: 0;
  background-color: var(--jp-brand-color1);
  height: 100%;
  width: 100%;
  box-sizing: border-box;
  padding: 4px 6px;
}

.jp-lineFormButton {
  top: 0;
  right: 0;
  background-color: transparent;
  height: 100%;
  width: 100%;
  box-sizing: border-box;
}

.jp-lineFormWrapper {
  overflow: hidden;
  padding: 0 8px;
  border: 1px solid var(--jp-border-color0);
  background-color: var(--jp-input-active-background);
  height: 22px;
}

.jp-lineFormWrapperFocusWithin {
  border: var(--jp-border-width) solid var(--md-blue-500);
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-lineFormInput {
  background: transparent;
  width: 200px;
  height: 100%;
  border: none;
  outline: none;
  color: var(--jp-ui-font-color0);
  line-height: 28px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-JSONEditor {
  display: flex;
  flex-direction: column;
  width: 100%;
}

.jp-JSONEditor-host {
  flex: 1 1 auto;
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  border-radius: 0;
  background: var(--jp-layout-color0);
  min-height: 50px;
  padding: 1px;
}

.jp-JSONEditor.jp-mod-error .jp-JSONEditor-host {
  border-color: red;
  outline-color: red;
}

.jp-JSONEditor-header {
  display: flex;
  flex: 1 0 auto;
  padding: 0 0 0 12px;
}

.jp-JSONEditor-header label {
  flex: 0 0 auto;
}

.jp-JSONEditor-commitButton {
  height: 16px;
  width: 16px;
  background-size: 18px;
  background-repeat: no-repeat;
  background-position: center;
}

.jp-JSONEditor-host.jp-mod-focused {
  background-color: var(--jp-input-active-background);
  border: 1px solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
}

.jp-Editor.jp-mod-dropTarget {
  border: var(--jp-border-width) solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/
.jp-DocumentSearch-input {
  border: none;
  outline: none;
  color: var(--jp-ui-font-color0);
  font-size: var(--jp-ui-font-size1);
  background-color: var(--jp-layout-color0);
  font-family: var(--jp-ui-font-family);
  padding: 2px 1px;
  resize: none;
}

.jp-DocumentSearch-overlay {
  position: absolute;
  background-color: var(--jp-toolbar-background);
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  border-left: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  top: 0;
  right: 0;
  z-index: 7;
  min-width: 405px;
  padding: 2px;
  font-size: var(--jp-ui-font-size1);

  --jp-private-document-search-button-height: 20px;
}

.jp-DocumentSearch-overlay button {
  background-color: var(--jp-toolbar-background);
  outline: 0;
}

.jp-DocumentSearch-overlay button:hover {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-overlay button:active {
  background-color: var(--jp-layout-color3);
}

.jp-DocumentSearch-overlay-row {
  display: flex;
  align-items: center;
  margin-bottom: 2px;
}

.jp-DocumentSearch-button-content {
  display: inline-block;
  cursor: pointer;
  box-sizing: border-box;
  width: 100%;
  height: 100%;
}

.jp-DocumentSearch-button-content svg {
  width: 100%;
  height: 100%;
}

.jp-DocumentSearch-input-wrapper {
  border: var(--jp-border-width) solid var(--jp-border-color0);
  display: flex;
  background-color: var(--jp-layout-color0);
  margin: 2px;
}

.jp-DocumentSearch-input-wrapper:focus-within {
  border-color: var(--jp-cell-editor-active-border-color);
}

.jp-DocumentSearch-toggle-wrapper,
.jp-DocumentSearch-button-wrapper {
  all: initial;
  overflow: hidden;
  display: inline-block;
  border: none;
  box-sizing: border-box;
}

.jp-DocumentSearch-toggle-wrapper {
  width: 14px;
  height: 14px;
}

.jp-DocumentSearch-button-wrapper {
  width: var(--jp-private-document-search-button-height);
  height: var(--jp-private-document-search-button-height);
}

.jp-DocumentSearch-toggle-wrapper:focus,
.jp-DocumentSearch-button-wrapper:focus {
  outline: var(--jp-border-width) solid
    var(--jp-cell-editor-active-border-color);
  outline-offset: -1px;
}

.jp-DocumentSearch-toggle-wrapper,
.jp-DocumentSearch-button-wrapper,
.jp-DocumentSearch-button-content:focus {
  outline: none;
}

.jp-DocumentSearch-toggle-placeholder {
  width: 5px;
}

.jp-DocumentSearch-input-button::before {
  display: block;
  padding-top: 100%;
}

.jp-DocumentSearch-input-button-off {
  opacity: var(--jp-search-toggle-off-opacity);
}

.jp-DocumentSearch-input-button-off:hover {
  opacity: var(--jp-search-toggle-hover-opacity);
}

.jp-DocumentSearch-input-button-on {
  opacity: var(--jp-search-toggle-on-opacity);
}

.jp-DocumentSearch-index-counter {
  padding-left: 10px;
  padding-right: 10px;
  user-select: none;
  min-width: 35px;
  display: inline-block;
}

.jp-DocumentSearch-up-down-wrapper {
  display: inline-block;
  padding-right: 2px;
  margin-left: auto;
  white-space: nowrap;
}

.jp-DocumentSearch-spacer {
  margin-left: auto;
}

.jp-DocumentSearch-up-down-wrapper button {
  outline: 0;
  border: none;
  width: var(--jp-private-document-search-button-height);
  height: var(--jp-private-document-search-button-height);
  vertical-align: middle;
  margin: 1px 5px 2px;
}

.jp-DocumentSearch-up-down-button:hover {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-up-down-button:active {
  background-color: var(--jp-layout-color3);
}

.jp-DocumentSearch-filter-button {
  border-radius: var(--jp-border-radius);
}

.jp-DocumentSearch-filter-button:hover {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-filter-button-enabled {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-filter-button-enabled:hover {
  background-color: var(--jp-layout-color3);
}

.jp-DocumentSearch-search-options {
  padding: 0 8px;
  margin-left: 3px;
  width: 100%;
  display: grid;
  justify-content: start;
  grid-template-columns: 1fr 1fr;
  align-items: center;
  justify-items: stretch;
}

.jp-DocumentSearch-search-filter-disabled {
  color: var(--jp-ui-font-color2);
}

.jp-DocumentSearch-search-filter {
  display: flex;
  align-items: center;
  user-select: none;
}

.jp-DocumentSearch-regex-error {
  color: var(--jp-error-color0);
}

.jp-DocumentSearch-replace-button-wrapper {
  overflow: hidden;
  display: inline-block;
  box-sizing: border-box;
  border: var(--jp-border-width) solid var(--jp-border-color0);
  margin: auto 2px;
  padding: 1px 4px;
  height: calc(var(--jp-private-document-search-button-height) + 2px);
}

.jp-DocumentSearch-replace-button-wrapper:focus {
  border: var(--jp-border-width) solid var(--jp-cell-editor-active-border-color);
}

.jp-DocumentSearch-replace-button {
  display: inline-block;
  text-align: center;
  cursor: pointer;
  box-sizing: border-box;
  color: var(--jp-ui-font-color1);

  /* height - 2 * (padding of wrapper) */
  line-height: calc(var(--jp-private-document-search-button-height) - 2px);
  width: 100%;
  height: 100%;
}

.jp-DocumentSearch-replace-button:focus {
  outline: none;
}

.jp-DocumentSearch-replace-wrapper-class {
  margin-left: 14px;
  display: flex;
}

.jp-DocumentSearch-replace-toggle {
  border: none;
  background-color: var(--jp-toolbar-background);
  border-radius: var(--jp-border-radius);
}

.jp-DocumentSearch-replace-toggle:hover {
  background-color: var(--jp-layout-color2);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.cm-editor {
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  font-family: var(--jp-code-font-family);
  border: 0;
  border-radius: 0;
  height: auto;

  /* Changed to auto to autogrow */
}

.cm-editor pre {
  padding: 0 var(--jp-code-padding);
}

.jp-CodeMirrorEditor[data-type='inline'] .cm-dialog {
  background-color: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
}

.jp-CodeMirrorEditor {
  cursor: text;
}

/* When zoomed out 67% and 33% on a screen of 1440 width x 900 height */
@media screen and (min-width: 2138px) and (max-width: 4319px) {
  .jp-CodeMirrorEditor[data-type='inline'] .cm-cursor {
    border-left: var(--jp-code-cursor-width1) solid
      var(--jp-editor-cursor-color);
  }
}

/* When zoomed out less than 33% */
@media screen and (min-width: 4320px) {
  .jp-CodeMirrorEditor[data-type='inline'] .cm-cursor {
    border-left: var(--jp-code-cursor-width2) solid
      var(--jp-editor-cursor-color);
  }
}

.cm-editor.jp-mod-readOnly .cm-cursor {
  display: none;
}

.jp-CollaboratorCursor {
  border-left: 5px solid transparent;
  border-right: 5px solid transparent;
  border-top: none;
  border-bottom: 3px solid;
  background-clip: content-box;
  margin-left: -5px;
  margin-right: -5px;
}

.cm-searching,
.cm-searching span {
  /* `.cm-searching span`: we need to override syntax highlighting */
  background-color: var(--jp-search-unselected-match-background-color);
  color: var(--jp-search-unselected-match-color);
}

.cm-searching::selection,
.cm-searching span::selection {
  background-color: var(--jp-search-unselected-match-background-color);
  color: var(--jp-search-unselected-match-color);
}

.jp-current-match > .cm-searching,
.jp-current-match > .cm-searching span,
.cm-searching > .jp-current-match,
.cm-searching > .jp-current-match span {
  background-color: var(--jp-search-selected-match-background-color);
  color: var(--jp-search-selected-match-color);
}

.jp-current-match > .cm-searching::selection,
.cm-searching > .jp-current-match::selection,
.jp-current-match > .cm-searching span::selection {
  background-color: var(--jp-search-selected-match-background-color);
  color: var(--jp-search-selected-match-color);
}

.cm-trailingspace {
  background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAFCAYAAAB4ka1VAAAAsElEQVQIHQGlAFr/AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA7+r3zKmT0/+pk9P/7+r3zAAAAAAAAAAABAAAAAAAAAAA6OPzM+/q9wAAAAAA6OPzMwAAAAAAAAAAAgAAAAAAAAAAGR8NiRQaCgAZIA0AGR8NiQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQyoYJ/SY80UAAAAASUVORK5CYII=);
  background-position: center left;
  background-repeat: repeat-x;
}

.jp-CollaboratorCursor-hover {
  position: absolute;
  z-index: 1;
  transform: translateX(-50%);
  color: white;
  border-radius: 3px;
  padding-left: 4px;
  padding-right: 4px;
  padding-top: 1px;
  padding-bottom: 1px;
  text-align: center;
  font-size: var(--jp-ui-font-size1);
  white-space: nowrap;
}

.jp-CodeMirror-ruler {
  border-left: 1px dashed var(--jp-border-color2);
}

/* Styles for shared cursors (remote cursor locations and selected ranges) */
.jp-CodeMirrorEditor .cm-ySelectionCaret {
  position: relative;
  border-left: 1px solid black;
  margin-left: -1px;
  margin-right: -1px;
  box-sizing: border-box;
}

.jp-CodeMirrorEditor .cm-ySelectionCaret > .cm-ySelectionInfo {
  white-space: nowrap;
  position: absolute;
  top: -1.15em;
  padding-bottom: 0.05em;
  left: -1px;
  font-size: 0.95em;
  font-family: var(--jp-ui-font-family);
  font-weight: bold;
  line-height: normal;
  user-select: none;
  color: white;
  padding-left: 2px;
  padding-right: 2px;
  z-index: 101;
  transition: opacity 0.3s ease-in-out;
}

.jp-CodeMirrorEditor .cm-ySelectionInfo {
  transition-delay: 0.7s;
  opacity: 0;
}

.jp-CodeMirrorEditor .cm-ySelectionCaret:hover > .cm-ySelectionInfo {
  opacity: 1;
  transition-delay: 0s;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-MimeDocument {
  outline: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-filebrowser-button-height: 28px;
  --jp-private-filebrowser-button-width: 48px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-FileBrowser .jp-SidePanel-content {
  display: flex;
  flex-direction: column;
}

.jp-FileBrowser-toolbar.jp-Toolbar {
  flex-wrap: wrap;
  row-gap: 12px;
  border-bottom: none;
  height: auto;
  margin: 8px 12px 0;
  box-shadow: none;
  padding: 0;
  justify-content: flex-start;
}

.jp-FileBrowser-Panel {
  flex: 1 1 auto;
  display: flex;
  flex-direction: column;
}

.jp-BreadCrumbs {
  flex: 0 0 auto;
  margin: 8px 12px;
}

.jp-BreadCrumbs-item {
  margin: 0 2px;
  padding: 0 2px;
  border-radius: var(--jp-border-radius);
  cursor: pointer;
}

.jp-BreadCrumbs-item:hover {
  background-color: var(--jp-layout-color2);
}

.jp-BreadCrumbs-item:first-child {
  margin-left: 0;
}

.jp-BreadCrumbs-item.jp-mod-dropTarget {
  background-color: var(--jp-brand-color2);
  opacity: 0.7;
}

/*-----------------------------------------------------------------------------
| Buttons
|----------------------------------------------------------------------------*/

.jp-FileBrowser-toolbar > .jp-Toolbar-item {
  flex: 0 0 auto;
  padding-left: 0;
  padding-right: 2px;
  align-items: center;
  height: unset;
}

.jp-FileBrowser-toolbar > .jp-Toolbar-item .jp-ToolbarButtonComponent {
  width: 40px;
}

/*-----------------------------------------------------------------------------
| Other styles
|----------------------------------------------------------------------------*/

.jp-FileDialog.jp-mod-conflict input {
  color: var(--jp-error-color1);
}

.jp-FileDialog .jp-new-name-title {
  margin-top: 12px;
}

.jp-LastModified-hidden {
  display: none;
}

.jp-FileSize-hidden {
  display: none;
}

.jp-FileBrowser .lm-AccordionPanel > h3:first-child {
  display: none;
}

/*-----------------------------------------------------------------------------
| DirListing
|----------------------------------------------------------------------------*/

.jp-DirListing {
  flex: 1 1 auto;
  display: flex;
  flex-direction: column;
  outline: 0;
}

.jp-DirListing-header {
  flex: 0 0 auto;
  display: flex;
  flex-direction: row;
  align-items: center;
  overflow: hidden;
  border-top: var(--jp-border-width) solid var(--jp-border-color2);
  border-bottom: var(--jp-border-width) solid var(--jp-border-color1);
  box-shadow: var(--jp-toolbar-box-shadow);
  z-index: 2;
}

.jp-DirListing-headerItem {
  padding: 4px 12px 2px;
  font-weight: 500;
}

.jp-DirListing-headerItem:hover {
  background: var(--jp-layout-color2);
}

.jp-DirListing-headerItem.jp-id-name {
  flex: 1 0 84px;
}

.jp-DirListing-headerItem.jp-id-modified {
  flex: 0 0 112px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
}

.jp-DirListing-headerItem.jp-id-filesize {
  flex: 0 0 75px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
}

.jp-id-narrow {
  display: none;
  flex: 0 0 5px;
  padding: 4px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
  color: var(--jp-border-color2);
}

.jp-DirListing-narrow .jp-id-narrow {
  display: block;
}

.jp-DirListing-narrow .jp-id-modified,
.jp-DirListing-narrow .jp-DirListing-itemModified {
  display: none;
}

.jp-DirListing-headerItem.jp-mod-selected {
  font-weight: 600;
}

/* increase specificity to override bundled default */
.jp-DirListing-content {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  list-style-type: none;
  overflow: auto;
  background-color: var(--jp-layout-color1);
}

.jp-DirListing-content mark {
  color: var(--jp-ui-font-color0);
  background-color: transparent;
  font-weight: bold;
}

.jp-DirListing-content .jp-DirListing-item.jp-mod-selected mark {
  color: var(--jp-ui-inverse-font-color0);
}

/* Style the directory listing content when a user drops a file to upload */
.jp-DirListing.jp-mod-native-drop .jp-DirListing-content {
  outline: 5px dashed rgba(128, 128, 128, 0.5);
  outline-offset: -10px;
  cursor: copy;
}

.jp-DirListing-item {
  display: flex;
  flex-direction: row;
  align-items: center;
  padding: 4px 12px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-DirListing-checkboxWrapper {
  /* Increases hit area of checkbox. */
  padding: 4px;
}

.jp-DirListing-header
  .jp-DirListing-checkboxWrapper
  + .jp-DirListing-headerItem {
  padding-left: 4px;
}

.jp-DirListing-content .jp-DirListing-checkboxWrapper {
  position: relative;
  left: -4px;
  margin: -4px 0 -4px -8px;
}

.jp-DirListing-checkboxWrapper.jp-mod-visible {
  visibility: visible;
}

/* For devices that support hovering, hide checkboxes until hovered, selected...
*/
@media (hover: hover) {
  .jp-DirListing-checkboxWrapper {
    visibility: hidden;
  }

  .jp-DirListing-item:hover .jp-DirListing-checkboxWrapper,
  .jp-DirListing-item.jp-mod-selected .jp-DirListing-checkboxWrapper {
    visibility: visible;
  }
}

.jp-DirListing-item[data-is-dot] {
  opacity: 75%;
}

.jp-DirListing-item.jp-mod-selected {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.jp-DirListing-item.jp-mod-dropTarget {
  background: var(--jp-brand-color3);
}

.jp-DirListing-item:hover:not(.jp-mod-selected) {
  background: var(--jp-layout-color2);
}

.jp-DirListing-itemIcon {
  flex: 0 0 20px;
  margin-right: 4px;
}

.jp-DirListing-itemText {
  flex: 1 0 64px;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  user-select: none;
}

.jp-DirListing-itemText:focus {
  outline-width: 2px;
  outline-color: var(--jp-inverse-layout-color1);
  outline-style: solid;
  outline-offset: 1px;
}

.jp-DirListing-item.jp-mod-selected .jp-DirListing-itemText:focus {
  outline-color: var(--jp-layout-color1);
}

.jp-DirListing-itemModified {
  flex: 0 0 125px;
  text-align: right;
}

.jp-DirListing-itemFileSize {
  flex: 0 0 90px;
  text-align: right;
}

.jp-DirListing-editor {
  flex: 1 0 64px;
  outline: none;
  border: none;
  color: var(--jp-ui-font-color1);
  background-color: var(--jp-layout-color1);
}

.jp-DirListing-item.jp-mod-running .jp-DirListing-itemIcon::before {
  color: var(--jp-success-color1);
  content: '\25CF';
  font-size: 8px;
  position: absolute;
  left: -8px;
}

.jp-DirListing-item.jp-mod-running.jp-mod-selected
  .jp-DirListing-itemIcon::before {
  color: var(--jp-ui-inverse-font-color1);
}

.jp-DirListing-item.lm-mod-drag-image,
.jp-DirListing-item.jp-mod-selected.lm-mod-drag-image {
  font-size: var(--jp-ui-font-size1);
  padding-left: 4px;
  margin-left: 4px;
  width: 160px;
  background-color: var(--jp-ui-inverse-font-color2);
  box-shadow: var(--jp-elevation-z2);
  border-radius: 0;
  color: var(--jp-ui-font-color1);
  transform: translateX(-40%) translateY(-58%);
}

.jp-Document {
  min-width: 120px;
  min-height: 120px;
  outline: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Main OutputArea
| OutputArea has a list of Outputs
|----------------------------------------------------------------------------*/

.jp-OutputArea {
  overflow-y: auto;
}

.jp-OutputArea-child {
  display: table;
  table-layout: fixed;
  width: 100%;
  overflow: hidden;
}

.jp-OutputPrompt {
  width: var(--jp-cell-prompt-width);
  color: var(--jp-cell-outprompt-font-color);
  font-family: var(--jp-cell-prompt-font-family);
  padding: var(--jp-code-padding);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
  opacity: var(--jp-cell-prompt-opacity);

  /* Right align prompt text, don't wrap to handle large prompt numbers */
  text-align: right;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;

  /* Disable text selection */
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-OutputArea-prompt {
  display: table-cell;
  vertical-align: top;
}

.jp-OutputArea-output {
  display: table-cell;
  width: 100%;
  height: auto;
  overflow: auto;
  user-select: text;
  -moz-user-select: text;
  -webkit-user-select: text;
  -ms-user-select: text;
}

.jp-OutputArea .jp-RenderedText {
  padding-left: 1ch;
}

/**
 * Prompt overlay.
 */

.jp-OutputArea-promptOverlay {
  position: absolute;
  top: 0;
  width: var(--jp-cell-prompt-width);
  height: 100%;
  opacity: 0.5;
}

.jp-OutputArea-promptOverlay:hover {
  background: var(--jp-layout-color2);
  box-shadow: inset 0 0 1px var(--jp-inverse-layout-color0);
  cursor: zoom-out;
}

.jp-mod-outputsScrolled .jp-OutputArea-promptOverlay:hover {
  cursor: zoom-in;
}

/**
 * Isolated output.
 */
.jp-OutputArea-output.jp-mod-isolated {
  width: 100%;
  display: block;
}

/*
When drag events occur, `lm-mod-override-cursor` is added to the body.
Because iframes steal all cursor events, the following two rules are necessary
to suppress pointer events while resize drags are occurring. There may be a
better solution to this problem.
*/
body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated {
  position: relative;
}

body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated::before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: transparent;
}

/* pre */

.jp-OutputArea-output pre {
  border: none;
  margin: 0;
  padding: 0;
  overflow-x: auto;
  overflow-y: auto;
  word-break: break-all;
  word-wrap: break-word;
  white-space: pre-wrap;
}

/* tables */

.jp-OutputArea-output.jp-RenderedHTMLCommon table {
  margin-left: 0;
  margin-right: 0;
}

/* description lists */

.jp-OutputArea-output dl,
.jp-OutputArea-output dt,
.jp-OutputArea-output dd {
  display: block;
}

.jp-OutputArea-output dl {
  width: 100%;
  overflow: hidden;
  padding: 0;
  margin: 0;
}

.jp-OutputArea-output dt {
  font-weight: bold;
  float: left;
  width: 20%;
  padding: 0;
  margin: 0;
}

.jp-OutputArea-output dd {
  float: left;
  width: 80%;
  padding: 0;
  margin: 0;
}

.jp-TrimmedOutputs pre {
  background: var(--jp-layout-color3);
  font-size: calc(var(--jp-code-font-size) * 1.4);
  text-align: center;
  text-transform: uppercase;
}

/* Hide the gutter in case of
 *  - nested output areas (e.g. in the case of output widgets)
 *  - mirrored output areas
 */
.jp-OutputArea .jp-OutputArea .jp-OutputArea-prompt {
  display: none;
}

/* Hide empty lines in the output area, for instance due to cleared widgets */
.jp-OutputArea-prompt:empty {
  padding: 0;
  border: 0;
}

/*-----------------------------------------------------------------------------
| executeResult is added to any Output-result for the display of the object
| returned by a cell
|----------------------------------------------------------------------------*/

.jp-OutputArea-output.jp-OutputArea-executeResult {
  margin-left: 0;
  width: 100%;
}

/* Text output with the Out[] prompt needs a top padding to match the
 * alignment of the Out[] prompt itself.
 */
.jp-OutputArea-executeResult .jp-RenderedText.jp-OutputArea-output {
  padding-top: var(--jp-code-padding);
  border-top: var(--jp-border-width) solid transparent;
}

/*-----------------------------------------------------------------------------
| The Stdin output
|----------------------------------------------------------------------------*/

.jp-Stdin-prompt {
  color: var(--jp-content-font-color0);
  padding-right: var(--jp-code-padding);
  vertical-align: baseline;
  flex: 0 0 auto;
}

.jp-Stdin-input {
  font-family: var(--jp-code-font-family);
  font-size: inherit;
  color: inherit;
  background-color: inherit;
  width: 42%;
  min-width: 200px;

  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;

  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0 0.25em;
  margin: 0 0.25em;
  flex: 0 0 70%;
}

.jp-Stdin-input::placeholder {
  opacity: 0;
}

.jp-Stdin-input:focus {
  box-shadow: none;
}

.jp-Stdin-input:focus::placeholder {
  opacity: 1;
}

/*-----------------------------------------------------------------------------
| Output Area View
|----------------------------------------------------------------------------*/

.jp-LinkedOutputView .jp-OutputArea {
  height: 100%;
  display: block;
}

.jp-LinkedOutputView .jp-OutputArea-output:only-child {
  height: 100%;
}

/*-----------------------------------------------------------------------------
| Printing
|----------------------------------------------------------------------------*/

@media print {
  .jp-OutputArea-child {
    break-inside: avoid-page;
  }
}

/*-----------------------------------------------------------------------------
| Mobile
|----------------------------------------------------------------------------*/
@media only screen and (max-width: 760px) {
  .jp-OutputPrompt {
    display: table-row;
    text-align: left;
  }

  .jp-OutputArea-child .jp-OutputArea-output {
    display: table-row;
    margin-left: var(--jp-notebook-padding);
  }
}

/* Trimmed outputs warning */
.jp-TrimmedOutputs > a {
  margin: 10px;
  text-decoration: none;
  cursor: pointer;
}

.jp-TrimmedOutputs > a:hover {
  text-decoration: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Table of Contents
|----------------------------------------------------------------------------*/

:root {
  --jp-private-toc-active-width: 4px;
}

.jp-TableOfContents {
  display: flex;
  flex-direction: column;
  background: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  height: 100%;
}

.jp-TableOfContents-placeholder {
  text-align: center;
}

.jp-TableOfContents-placeholderContent {
  color: var(--jp-content-font-color2);
  padding: 8px;
}

.jp-TableOfContents-placeholderContent > h3 {
  margin-bottom: var(--jp-content-heading-margin-bottom);
}

.jp-TableOfContents .jp-SidePanel-content {
  overflow-y: auto;
}

.jp-TableOfContents-tree {
  margin: 4px;
}

.jp-TableOfContents ol {
  list-style-type: none;
}

/* stylelint-disable-next-line selector-max-type */
.jp-TableOfContents li > ol {
  /* Align left border with triangle icon center */
  padding-left: 11px;
}

.jp-TableOfContents-content {
  /* left margin for the active heading indicator */
  margin: 0 0 0 var(--jp-private-toc-active-width);
  padding: 0;
  background-color: var(--jp-layout-color1);
}

.jp-tocItem {
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-tocItem-heading {
  display: flex;
  cursor: pointer;
}

.jp-tocItem-heading:hover {
  background-color: var(--jp-layout-color2);
}

.jp-tocItem-content {
  display: block;
  padding: 4px 0;
  white-space: nowrap;
  text-overflow: ellipsis;
  overflow-x: hidden;
}

.jp-tocItem-collapser {
  height: 20px;
  margin: 2px 2px 0;
  padding: 0;
  background: none;
  border: none;
  cursor: pointer;
}

.jp-tocItem-collapser:hover {
  background-color: var(--jp-layout-color3);
}

/* Active heading indicator */

.jp-tocItem-heading::before {
  content: ' ';
  background: transparent;
  width: var(--jp-private-toc-active-width);
  height: 24px;
  position: absolute;
  left: 0;
  border-radius: var(--jp-border-radius);
}

.jp-tocItem-heading.jp-tocItem-active::before {
  background-color: var(--jp-brand-color1);
}

.jp-tocItem-heading:hover.jp-tocItem-active::before {
  background: var(--jp-brand-color0);
  opacity: 1;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Collapser {
  flex: 0 0 var(--jp-cell-collapser-width);
  padding: 0;
  margin: 0;
  border: none;
  outline: none;
  background: transparent;
  border-radius: var(--jp-border-radius);
  opacity: 1;
}

.jp-Collapser-child {
  display: block;
  width: 100%;
  box-sizing: border-box;

  /* height: 100% doesn't work because the height of its parent is computed from content */
  position: absolute;
  top: 0;
  bottom: 0;
}

/*-----------------------------------------------------------------------------
| Printing
|----------------------------------------------------------------------------*/

/*
Hiding collapsers in print mode.

Note: input and output wrappers have "display: block" propery in print mode.
*/

@media print {
  .jp-Collapser {
    display: none;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Header/Footer
|----------------------------------------------------------------------------*/

/* Hidden by zero height by default */
.jp-CellHeader,
.jp-CellFooter {
  height: 0;
  width: 100%;
  padding: 0;
  margin: 0;
  border: none;
  outline: none;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Input
|----------------------------------------------------------------------------*/

/* All input areas */
.jp-InputArea {
  display: table;
  table-layout: fixed;
  width: 100%;
  overflow: hidden;
}

.jp-InputArea-editor {
  display: table-cell;
  overflow: hidden;
  vertical-align: top;

  /* This is the non-active, default styling */
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  border-radius: 0;
  background: var(--jp-cell-editor-background);
}

.jp-InputPrompt {
  display: table-cell;
  vertical-align: top;
  width: var(--jp-cell-prompt-width);
  color: var(--jp-cell-inprompt-font-color);
  font-family: var(--jp-cell-prompt-font-family);
  padding: var(--jp-code-padding);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  opacity: var(--jp-cell-prompt-opacity);
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;

  /* Right align prompt text, don't wrap to handle large prompt numbers */
  text-align: right;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;

  /* Disable text selection */
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

/*-----------------------------------------------------------------------------
| Mobile
|----------------------------------------------------------------------------*/
@media only screen and (max-width: 760px) {
  .jp-InputArea-editor {
    display: table-row;
    margin-left: var(--jp-notebook-padding);
  }

  .jp-InputPrompt {
    display: table-row;
    text-align: left;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Placeholder
|----------------------------------------------------------------------------*/

.jp-Placeholder {
  display: table;
  table-layout: fixed;
  width: 100%;
}

.jp-Placeholder-prompt {
  display: table-cell;
  box-sizing: border-box;
}

.jp-Placeholder-content {
  display: table-cell;
  padding: 4px 6px;
  border: 1px solid transparent;
  border-radius: 0;
  background: none;
  box-sizing: border-box;
  cursor: pointer;
}

.jp-Placeholder-contentContainer {
  display: flex;
}

.jp-Placeholder-content:hover,
.jp-InputPlaceholder > .jp-Placeholder-content:hover {
  border-color: var(--jp-layout-color3);
}

.jp-Placeholder-content .jp-MoreHorizIcon {
  width: 32px;
  height: 16px;
  border: 1px solid transparent;
  border-radius: var(--jp-border-radius);
}

.jp-Placeholder-content .jp-MoreHorizIcon:hover {
  border: 1px solid var(--jp-border-color1);
  box-shadow: 0 0 2px 0 rgba(0, 0, 0, 0.25);
  background-color: var(--jp-layout-color0);
}

.jp-PlaceholderText {
  white-space: nowrap;
  overflow-x: hidden;
  color: var(--jp-inverse-layout-color3);
  font-family: var(--jp-code-font-family);
}

.jp-InputPlaceholder > .jp-Placeholder-content {
  border-color: var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Private CSS variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-cell-scrolling-output-offset: 5px;
}

/*-----------------------------------------------------------------------------
| Cell
|----------------------------------------------------------------------------*/

.jp-Cell {
  padding: var(--jp-cell-padding);
  margin: 0;
  border: none;
  outline: none;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Common input/output
|----------------------------------------------------------------------------*/

.jp-Cell-inputWrapper,
.jp-Cell-outputWrapper {
  display: flex;
  flex-direction: row;
  padding: 0;
  margin: 0;

  /* Added to reveal the box-shadow on the input and output collapsers. */
  overflow: visible;
}

/* Only input/output areas inside cells */
.jp-Cell-inputArea,
.jp-Cell-outputArea {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Collapser
|----------------------------------------------------------------------------*/

/* Make the output collapser disappear when there is not output, but do so
 * in a manner that leaves it in the layout and preserves its width.
 */
.jp-Cell.jp-mod-noOutputs .jp-Cell-outputCollapser {
  border: none !important;
  background: transparent !important;
}

.jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputCollapser {
  min-height: var(--jp-cell-collapser-min-height);
}

/*-----------------------------------------------------------------------------
| Output
|----------------------------------------------------------------------------*/

/* Put a space between input and output when there IS output */
.jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputWrapper {
  margin-top: 5px;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea {
  overflow-y: auto;
  max-height: 24em;
  margin-left: var(--jp-private-cell-scrolling-output-offset);
  resize: vertical;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea[style*='height'] {
  max-height: unset;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea::after {
  content: ' ';
  box-shadow: inset 0 0 6px 2px rgb(0 0 0 / 30%);
  width: 100%;
  height: 100%;
  position: sticky;
  bottom: 0;
  top: 0;
  margin-top: -50%;
  float: left;
  display: block;
  pointer-events: none;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-child {
  padding-top: 6px;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-prompt {
  width: calc(
    var(--jp-cell-prompt-width) - var(--jp-private-cell-scrolling-output-offset)
  );
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-promptOverlay {
  left: calc(-1 * var(--jp-private-cell-scrolling-output-offset));
}

/*-----------------------------------------------------------------------------
| CodeCell
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| MarkdownCell
|----------------------------------------------------------------------------*/

.jp-MarkdownOutput {
  display: table-cell;
  width: 100%;
  margin-top: 0;
  margin-bottom: 0;
  padding-left: var(--jp-code-padding);
}

.jp-MarkdownOutput.jp-RenderedHTMLCommon {
  overflow: auto;
}

/* collapseHeadingButton (show always if hiddenCellsButton is _not_ shown) */
.jp-collapseHeadingButton {
  display: flex;
  min-height: var(--jp-cell-collapser-min-height);
  font-size: var(--jp-code-font-size);
  position: absolute;
  background-color: transparent;
  background-size: 25px;
  background-repeat: no-repeat;
  background-position-x: center;
  background-position-y: top;
  background-image: var(--jp-icon-caret-down);
  right: 0;
  top: 0;
  bottom: 0;
}

.jp-collapseHeadingButton.jp-mod-collapsed {
  background-image: var(--jp-icon-caret-right);
}

/*
 set the container font size to match that of content
 so that the nested collapse buttons have the right size
*/
.jp-MarkdownCell .jp-InputPrompt {
  font-size: var(--jp-content-font-size1);
}

/*
  Align collapseHeadingButton with cell top header
  The font sizes are identical to the ones in packages/rendermime/style/base.css
*/
.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='1'] {
  font-size: var(--jp-content-font-size5);
  background-position-y: calc(0.3 * var(--jp-content-font-size5));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='2'] {
  font-size: var(--jp-content-font-size4);
  background-position-y: calc(0.3 * var(--jp-content-font-size4));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='3'] {
  font-size: var(--jp-content-font-size3);
  background-position-y: calc(0.3 * var(--jp-content-font-size3));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='4'] {
  font-size: var(--jp-content-font-size2);
  background-position-y: calc(0.3 * var(--jp-content-font-size2));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='5'] {
  font-size: var(--jp-content-font-size1);
  background-position-y: top;
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='6'] {
  font-size: var(--jp-content-font-size0);
  background-position-y: top;
}

/* collapseHeadingButton (show only on (hover,active) if hiddenCellsButton is shown) */
.jp-Notebook.jp-mod-showHiddenCellsButton .jp-collapseHeadingButton {
  display: none;
}

.jp-Notebook.jp-mod-showHiddenCellsButton
  :is(.jp-MarkdownCell:hover, .jp-mod-active)
  .jp-collapseHeadingButton {
  display: flex;
}

/* showHiddenCellsButton (only show if jp-mod-showHiddenCellsButton is set, which
is a consequence of the showHiddenCellsButton option in Notebook Settings)*/
.jp-Notebook.jp-mod-showHiddenCellsButton .jp-showHiddenCellsButton {
  margin-left: calc(var(--jp-cell-prompt-width) + 2 * var(--jp-code-padding));
  margin-top: var(--jp-code-padding);
  border: 1px solid var(--jp-border-color2);
  background-color: var(--jp-border-color3) !important;
  color: var(--jp-content-font-color0) !important;
  display: flex;
}

.jp-Notebook.jp-mod-showHiddenCellsButton .jp-showHiddenCellsButton:hover {
  background-color: var(--jp-border-color2) !important;
}

.jp-showHiddenCellsButton {
  display: none;
}

/*-----------------------------------------------------------------------------
| Printing
|----------------------------------------------------------------------------*/

/*
Using block instead of flex to allow the use of the break-inside CSS property for
cell outputs.
*/

@media print {
  .jp-Cell-inputWrapper,
  .jp-Cell-outputWrapper {
    display: block;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-notebook-toolbar-padding: 2px 5px 2px 2px;
}

/*-----------------------------------------------------------------------------

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-NotebookPanel-toolbar {
  padding: var(--jp-notebook-toolbar-padding);

  /* disable paint containment from lumino 2.0 default strict CSS containment */
  contain: style size !important;
}

.jp-Toolbar-item.jp-Notebook-toolbarCellType .jp-select-wrapper.jp-mod-focused {
  border: none;
  box-shadow: none;
}

.jp-Notebook-toolbarCellTypeDropdown select {
  height: 24px;
  font-size: var(--jp-ui-font-size1);
  line-height: 14px;
  border-radius: 0;
  display: block;
}

.jp-Notebook-toolbarCellTypeDropdown span {
  top: 5px !important;
}

.jp-Toolbar-responsive-popup {
  position: absolute;
  height: fit-content;
  display: flex;
  flex-direction: row;
  flex-wrap: wrap;
  justify-content: flex-end;
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  background: var(--jp-toolbar-background);
  min-height: var(--jp-toolbar-micro-height);
  padding: var(--jp-notebook-toolbar-padding);
  z-index: 1;
  right: 0;
  top: 0;
}

.jp-Toolbar > .jp-Toolbar-responsive-opener {
  margin-left: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-Notebook-ExecutionIndicator {
  position: relative;
  display: inline-block;
  height: 100%;
  z-index: 9997;
}

.jp-Notebook-ExecutionIndicator-tooltip {
  visibility: hidden;
  height: auto;
  width: max-content;
  width: -moz-max-content;
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color1);
  text-align: justify;
  border-radius: 6px;
  padding: 0 5px;
  position: fixed;
  display: table;
}

.jp-Notebook-ExecutionIndicator-tooltip.up {
  transform: translateX(-50%) translateY(-100%) translateY(-32px);
}

.jp-Notebook-ExecutionIndicator-tooltip.down {
  transform: translateX(calc(-100% + 16px)) translateY(5px);
}

.jp-Notebook-ExecutionIndicator-tooltip.hidden {
  display: none;
}

.jp-Notebook-ExecutionIndicator:hover .jp-Notebook-ExecutionIndicator-tooltip {
  visibility: visible;
}

.jp-Notebook-ExecutionIndicator span {
  font-size: var(--jp-ui-font-size1);
  font-family: var(--jp-ui-font-family);
  color: var(--jp-ui-font-color1);
  line-height: 24px;
  display: block;
}

.jp-Notebook-ExecutionIndicator-progress-bar {
  display: flex;
  justify-content: center;
  height: 100%;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*
 * Execution indicator
 */
.jp-tocItem-content::after {
  content: '';

  /* Must be identical to form a circle */
  width: 12px;
  height: 12px;
  background: none;
  border: none;
  position: absolute;
  right: 0;
}

.jp-tocItem-content[data-running='0']::after {
  border-radius: 50%;
  border: var(--jp-border-width) solid var(--jp-inverse-layout-color3);
  background: none;
}

.jp-tocItem-content[data-running='1']::after {
  border-radius: 50%;
  border: var(--jp-border-width) solid var(--jp-inverse-layout-color3);
  background-color: var(--jp-inverse-layout-color3);
}

.jp-tocItem-content[data-running='0'],
.jp-tocItem-content[data-running='1'] {
  margin-right: 12px;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-Notebook-footer {
  height: 27px;
  margin-left: calc(
    var(--jp-cell-prompt-width) + var(--jp-cell-collapser-width) +
      var(--jp-cell-padding)
  );
  width: calc(
    100% -
      (
        var(--jp-cell-prompt-width) + var(--jp-cell-collapser-width) +
          var(--jp-cell-padding) + var(--jp-cell-padding)
      )
  );
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  color: var(--jp-ui-font-color3);
  margin-top: 6px;
  background: none;
  cursor: pointer;
}

.jp-Notebook-footer:focus {
  border-color: var(--jp-cell-editor-active-border-color);
}

/* For devices that support hovering, hide footer until hover */
@media (hover: hover) {
  .jp-Notebook-footer {
    opacity: 0;
  }

  .jp-Notebook-footer:focus,
  .jp-Notebook-footer:hover {
    opacity: 1;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Imports
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| CSS variables
|----------------------------------------------------------------------------*/

:root {
  --jp-side-by-side-output-size: 1fr;
  --jp-side-by-side-resized-cell: var(--jp-side-by-side-output-size);
  --jp-private-notebook-dragImage-width: 304px;
  --jp-private-notebook-dragImage-height: 36px;
  --jp-private-notebook-selected-color: var(--md-blue-400);
  --jp-private-notebook-active-color: var(--md-green-400);
}

/*-----------------------------------------------------------------------------
| Notebook
|----------------------------------------------------------------------------*/

/* stylelint-disable selector-max-class */

.jp-NotebookPanel {
  display: block;
  height: 100%;
}

.jp-NotebookPanel.jp-Document {
  min-width: 240px;
  min-height: 120px;
}

.jp-Notebook {
  padding: var(--jp-notebook-padding);
  outline: none;
  overflow: auto;
  background: var(--jp-layout-color0);
}

.jp-Notebook.jp-mod-scrollPastEnd::after {
  display: block;
  content: '';
  min-height: var(--jp-notebook-scroll-padding);
}

.jp-MainAreaWidget-ContainStrict .jp-Notebook * {
  contain: strict;
}

.jp-Notebook .jp-Cell {
  overflow: visible;
}

.jp-Notebook .jp-Cell .jp-InputPrompt {
  cursor: move;
}

/*-----------------------------------------------------------------------------
| Notebook state related styling
|
| The notebook and cells each have states, here are the possibilities:
|
| - Notebook
|   - Command
|   - Edit
| - Cell
|   - None
|   - Active (only one can be active)
|   - Selected (the cells actions are applied to)
|   - Multiselected (when multiple selected, the cursor)
|   - No outputs
|----------------------------------------------------------------------------*/

/* Command or edit modes */

.jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-InputPrompt {
  opacity: var(--jp-cell-prompt-not-active-opacity);
  color: var(--jp-cell-prompt-not-active-font-color);
}

.jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-OutputPrompt {
  opacity: var(--jp-cell-prompt-not-active-opacity);
  color: var(--jp-cell-prompt-not-active-font-color);
}

/* cell is active */
.jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser {
  background: var(--jp-brand-color1);
}

/* cell is dirty */
.jp-Notebook .jp-Cell.jp-mod-dirty .jp-InputPrompt {
  color: var(--jp-warn-color1);
}

.jp-Notebook .jp-Cell.jp-mod-dirty .jp-InputPrompt::before {
  color: var(--jp-warn-color1);
  content: '•';
}

.jp-Notebook .jp-Cell.jp-mod-active.jp-mod-dirty .jp-Collapser {
  background: var(--jp-warn-color1);
}

/* collapser is hovered */
.jp-Notebook .jp-Cell .jp-Collapser:hover {
  box-shadow: var(--jp-elevation-z2);
  background: var(--jp-brand-color1);
  opacity: var(--jp-cell-collapser-not-active-hover-opacity);
}

/* cell is active and collapser is hovered */
.jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser:hover {
  background: var(--jp-brand-color0);
  opacity: 1;
}

/* Command mode */

.jp-Notebook.jp-mod-commandMode .jp-Cell.jp-mod-selected {
  background: var(--jp-notebook-multiselected-color);
}

.jp-Notebook.jp-mod-commandMode
  .jp-Cell.jp-mod-active.jp-mod-selected:not(.jp-mod-multiSelected) {
  background: transparent;
}

/* Edit mode */

.jp-Notebook.jp-mod-editMode .jp-Cell.jp-mod-active .jp-InputArea-editor {
  border: var(--jp-border-width) solid var(--jp-cell-editor-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
  background-color: var(--jp-cell-editor-active-background);
}

/*-----------------------------------------------------------------------------
| Notebook drag and drop
|----------------------------------------------------------------------------*/

.jp-Notebook-cell.jp-mod-dropSource {
  opacity: 0.5;
}

.jp-Notebook-cell.jp-mod-dropTarget,
.jp-Notebook.jp-mod-commandMode
  .jp-Notebook-cell.jp-mod-active.jp-mod-selected.jp-mod-dropTarget {
  border-top-color: var(--jp-private-notebook-selected-color);
  border-top-style: solid;
  border-top-width: 2px;
}

.jp-dragImage {
  display: block;
  flex-direction: row;
  width: var(--jp-private-notebook-dragImage-width);
  height: var(--jp-private-notebook-dragImage-height);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background);
  overflow: visible;
}

.jp-dragImage-singlePrompt {
  box-shadow: 2px 2px 4px 0 rgba(0, 0, 0, 0.12);
}

.jp-dragImage .jp-dragImage-content {
  flex: 1 1 auto;
  z-index: 2;
  font-size: var(--jp-code-font-size);
  font-family: var(--jp-code-font-family);
  line-height: var(--jp-code-line-height);
  padding: var(--jp-code-padding);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background-color);
  color: var(--jp-content-font-color3);
  text-align: left;
  margin: 4px 4px 4px 0;
}

.jp-dragImage .jp-dragImage-prompt {
  flex: 0 0 auto;
  min-width: 36px;
  color: var(--jp-cell-inprompt-font-color);
  padding: var(--jp-code-padding);
  padding-left: 12px;
  font-family: var(--jp-cell-prompt-font-family);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  line-height: 1.9;
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
}

.jp-dragImage-multipleBack {
  z-index: -1;
  position: absolute;
  height: 32px;
  width: 300px;
  top: 8px;
  left: 8px;
  background: var(--jp-layout-color2);
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  box-shadow: 2px 2px 4px 0 rgba(0, 0, 0, 0.12);
}

/*-----------------------------------------------------------------------------
| Cell toolbar
|----------------------------------------------------------------------------*/

.jp-NotebookTools {
  display: block;
  min-width: var(--jp-sidebar-min-width);
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);

  /* This is needed so that all font sizing of children done in ems is
    * relative to this base size */
  font-size: var(--jp-ui-font-size1);
  overflow: auto;
}

.jp-ActiveCellTool {
  padding: 12px 0;
  display: flex;
}

.jp-ActiveCellTool-Content {
  flex: 1 1 auto;
}

.jp-ActiveCellTool .jp-ActiveCellTool-CellContent {
  background: var(--jp-cell-editor-background);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  border-radius: 0;
  min-height: 29px;
}

.jp-ActiveCellTool .jp-InputPrompt {
  min-width: calc(var(--jp-cell-prompt-width) * 0.75);
}

.jp-ActiveCellTool-CellContent > pre {
  padding: 5px 4px;
  margin: 0;
  white-space: normal;
}

.jp-MetadataEditorTool {
  flex-direction: column;
  padding: 12px 0;
}

.jp-RankedPanel > :not(:first-child) {
  margin-top: 12px;
}

.jp-KeySelector select.jp-mod-styled {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  border: var(--jp-border-width) solid var(--jp-border-color1);
}

.jp-KeySelector label,
.jp-MetadataEditorTool label,
.jp-NumberSetter label {
  line-height: 1.4;
}

.jp-NotebookTools .jp-select-wrapper {
  margin-top: 4px;
  margin-bottom: 0;
}

.jp-NumberSetter input {
  width: 100%;
  margin-top: 4px;
}

.jp-NotebookTools .jp-Collapse {
  margin-top: 16px;
}

/*-----------------------------------------------------------------------------
| Presentation Mode (.jp-mod-presentationMode)
|----------------------------------------------------------------------------*/

.jp-mod-presentationMode .jp-Notebook {
  --jp-content-font-size1: var(--jp-content-presentation-font-size1);
  --jp-code-font-size: var(--jp-code-presentation-font-size);
}

.jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-InputPrompt,
.jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-OutputPrompt {
  flex: 0 0 110px;
}

/*-----------------------------------------------------------------------------
| Side-by-side Mode (.jp-mod-sideBySide)
|----------------------------------------------------------------------------*/
.jp-mod-sideBySide.jp-Notebook .jp-Notebook-cell {
  margin-top: 3em;
  margin-bottom: 3em;
  margin-left: 5%;
  margin-right: 5%;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell {
  display: grid;
  grid-template-columns: minmax(0, 1fr) min-content minmax(
      0,
      var(--jp-side-by-side-output-size)
    );
  grid-template-rows: auto minmax(0, 1fr) auto;
  grid-template-areas:
    'header header header'
    'input handle output'
    'footer footer footer';
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell.jp-mod-resizedCell {
  grid-template-columns: minmax(0, 1fr) min-content minmax(
      0,
      var(--jp-side-by-side-resized-cell)
    );
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellHeader {
  grid-area: header;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-Cell-inputWrapper {
  grid-area: input;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-Cell-outputWrapper {
  /* overwrite the default margin (no vertical separation needed in side by side move */
  margin-top: 0;
  grid-area: output;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellFooter {
  grid-area: footer;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellResizeHandle {
  grid-area: handle;
  user-select: none;
  display: block;
  height: 100%;
  cursor: ew-resize;
  padding: 0 var(--jp-cell-padding);
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellResizeHandle::after {
  content: '';
  display: block;
  background: var(--jp-border-color2);
  height: 100%;
  width: 5px;
}

.jp-mod-sideBySide.jp-Notebook
  .jp-CodeCell.jp-mod-resizedCell
  .jp-CellResizeHandle::after {
  background: var(--jp-border-color0);
}

.jp-CellResizeHandle {
  display: none;
}

/*-----------------------------------------------------------------------------
| Placeholder
|----------------------------------------------------------------------------*/

.jp-Cell-Placeholder {
  padding-left: 55px;
}

.jp-Cell-Placeholder-wrapper {
  background: #fff;
  border: 1px solid;
  border-color: #e5e6e9 #dfe0e4 #d0d1d5;
  border-radius: 4px;
  -webkit-border-radius: 4px;
  margin: 10px 15px;
}

.jp-Cell-Placeholder-wrapper-inner {
  padding: 15px;
  position: relative;
}

.jp-Cell-Placeholder-wrapper-body {
  background-repeat: repeat;
  background-size: 50% auto;
}

.jp-Cell-Placeholder-wrapper-body div {
  background: #f6f7f8;
  background-image: -webkit-linear-gradient(
    left,
    #f6f7f8 0%,
    #edeef1 20%,
    #f6f7f8 40%,
    #f6f7f8 100%
  );
  background-repeat: no-repeat;
  background-size: 800px 104px;
  height: 104px;
  position: absolute;
  right: 15px;
  left: 15px;
  top: 15px;
}

div.jp-Cell-Placeholder-h1 {
  top: 20px;
  height: 20px;
  left: 15px;
  width: 150px;
}

div.jp-Cell-Placeholder-h2 {
  left: 15px;
  top: 50px;
  height: 10px;
  width: 100px;
}

div.jp-Cell-Placeholder-content-1,
div.jp-Cell-Placeholder-content-2,
div.jp-Cell-Placeholder-content-3 {
  left: 15px;
  right: 15px;
  height: 10px;
}

div.jp-Cell-Placeholder-content-1 {
  top: 100px;
}

div.jp-Cell-Placeholder-content-2 {
  top: 120px;
}

div.jp-Cell-Placeholder-content-3 {
  top: 140px;
}

</style>
<style type="text/css">
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*
The following CSS variables define the main, public API for styling JupyterLab.
These variables should be used by all plugins wherever possible. In other
words, plugins should not define custom colors, sizes, etc unless absolutely
necessary. This enables users to change the visual theme of JupyterLab
by changing these variables.

Many variables appear in an ordered sequence (0,1,2,3). These sequences
are designed to work well together, so for example, `--jp-border-color1` should
be used with `--jp-layout-color1`. The numbers have the following meanings:

* 0: super-primary, reserved for special emphasis
* 1: primary, most important under normal situations
* 2: secondary, next most important under normal situations
* 3: tertiary, next most important under normal situations

Throughout JupyterLab, we are mostly following principles from Google's
Material Design when selecting colors. We are not, however, following
all of MD as it is not optimized for dense, information rich UIs.
*/

:root {
  /* Elevation
   *
   * We style box-shadows using Material Design's idea of elevation. These particular numbers are taken from here:
   *
   * https://github.com/material-components/material-components-web
   * https://material-components-web.appspot.com/elevation.html
   */

  --jp-shadow-base-lightness: 0;
  --jp-shadow-umbra-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.2
  );
  --jp-shadow-penumbra-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.14
  );
  --jp-shadow-ambient-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.12
  );
  --jp-elevation-z0: none;
  --jp-elevation-z1: 0 2px 1px -1px var(--jp-shadow-umbra-color),
    0 1px 1px 0 var(--jp-shadow-penumbra-color),
    0 1px 3px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z2: 0 3px 1px -2px var(--jp-shadow-umbra-color),
    0 2px 2px 0 var(--jp-shadow-penumbra-color),
    0 1px 5px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z4: 0 2px 4px -1px var(--jp-shadow-umbra-color),
    0 4px 5px 0 var(--jp-shadow-penumbra-color),
    0 1px 10px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z6: 0 3px 5px -1px var(--jp-shadow-umbra-color),
    0 6px 10px 0 var(--jp-shadow-penumbra-color),
    0 1px 18px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z8: 0 5px 5px -3px var(--jp-shadow-umbra-color),
    0 8px 10px 1px var(--jp-shadow-penumbra-color),
    0 3px 14px 2px var(--jp-shadow-ambient-color);
  --jp-elevation-z12: 0 7px 8px -4px var(--jp-shadow-umbra-color),
    0 12px 17px 2px var(--jp-shadow-penumbra-color),
    0 5px 22px 4px var(--jp-shadow-ambient-color);
  --jp-elevation-z16: 0 8px 10px -5px var(--jp-shadow-umbra-color),
    0 16px 24px 2px var(--jp-shadow-penumbra-color),
    0 6px 30px 5px var(--jp-shadow-ambient-color);
  --jp-elevation-z20: 0 10px 13px -6px var(--jp-shadow-umbra-color),
    0 20px 31px 3px var(--jp-shadow-penumbra-color),
    0 8px 38px 7px var(--jp-shadow-ambient-color);
  --jp-elevation-z24: 0 11px 15px -7px var(--jp-shadow-umbra-color),
    0 24px 38px 3px var(--jp-shadow-penumbra-color),
    0 9px 46px 8px var(--jp-shadow-ambient-color);

  /* Borders
   *
   * The following variables, specify the visual styling of borders in JupyterLab.
   */

  --jp-border-width: 1px;
  --jp-border-color0: var(--md-grey-400);
  --jp-border-color1: var(--md-grey-400);
  --jp-border-color2: var(--md-grey-300);
  --jp-border-color3: var(--md-grey-200);
  --jp-inverse-border-color: var(--md-grey-600);
  --jp-border-radius: 2px;

  /* UI Fonts
   *
   * The UI font CSS variables are used for the typography all of the JupyterLab
   * user interface elements that are not directly user generated content.
   *
   * The font sizing here is done assuming that the body font size of --jp-ui-font-size1
   * is applied to a parent element. When children elements, such as headings, are sized
   * in em all things will be computed relative to that body size.
   */

  --jp-ui-font-scale-factor: 1.2;
  --jp-ui-font-size0: 0.83333em;
  --jp-ui-font-size1: 13px; /* Base font size */
  --jp-ui-font-size2: 1.2em;
  --jp-ui-font-size3: 1.44em;
  --jp-ui-font-family: system-ui, -apple-system, blinkmacsystemfont, 'Segoe UI',
    helvetica, arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji',
    'Segoe UI Symbol';

  /*
   * Use these font colors against the corresponding main layout colors.
   * In a light theme, these go from dark to light.
   */

  /* Defaults use Material Design specification */
  --jp-ui-font-color0: rgba(0, 0, 0, 1);
  --jp-ui-font-color1: rgba(0, 0, 0, 0.87);
  --jp-ui-font-color2: rgba(0, 0, 0, 0.54);
  --jp-ui-font-color3: rgba(0, 0, 0, 0.38);

  /*
   * Use these against the brand/accent/warn/error colors.
   * These will typically go from light to darker, in both a dark and light theme.
   */

  --jp-ui-inverse-font-color0: rgba(255, 255, 255, 1);
  --jp-ui-inverse-font-color1: rgba(255, 255, 255, 1);
  --jp-ui-inverse-font-color2: rgba(255, 255, 255, 0.7);
  --jp-ui-inverse-font-color3: rgba(255, 255, 255, 0.5);

  /* Content Fonts
   *
   * Content font variables are used for typography of user generated content.
   *
   * The font sizing here is done assuming that the body font size of --jp-content-font-size1
   * is applied to a parent element. When children elements, such as headings, are sized
   * in em all things will be computed relative to that body size.
   */

  --jp-content-line-height: 1.6;
  --jp-content-font-scale-factor: 1.2;
  --jp-content-font-size0: 0.83333em;
  --jp-content-font-size1: 14px; /* Base font size */
  --jp-content-font-size2: 1.2em;
  --jp-content-font-size3: 1.44em;
  --jp-content-font-size4: 1.728em;
  --jp-content-font-size5: 2.0736em;

  /* This gives a magnification of about 125% in presentation mode over normal. */
  --jp-content-presentation-font-size1: 17px;
  --jp-content-heading-line-height: 1;
  --jp-content-heading-margin-top: 1.2em;
  --jp-content-heading-margin-bottom: 0.8em;
  --jp-content-heading-font-weight: 500;

  /* Defaults use Material Design specification */
  --jp-content-font-color0: rgba(0, 0, 0, 1);
  --jp-content-font-color1: rgba(0, 0, 0, 0.87);
  --jp-content-font-color2: rgba(0, 0, 0, 0.54);
  --jp-content-font-color3: rgba(0, 0, 0, 0.38);
  --jp-content-link-color: var(--md-blue-900);
  --jp-content-font-family: system-ui, -apple-system, blinkmacsystemfont,
    'Segoe UI', helvetica, arial, sans-serif, 'Apple Color Emoji',
    'Segoe UI Emoji', 'Segoe UI Symbol';

  /*
   * Code Fonts
   *
   * Code font variables are used for typography of code and other monospaces content.
   */

  --jp-code-font-size: 13px;
  --jp-code-line-height: 1.3077; /* 17px for 13px base */
  --jp-code-padding: 5px; /* 5px for 13px base, codemirror highlighting needs integer px value */
  --jp-code-font-family-default: menlo, consolas, 'DejaVu Sans Mono', monospace;
  --jp-code-font-family: var(--jp-code-font-family-default);

  /* This gives a magnification of about 125% in presentation mode over normal. */
  --jp-code-presentation-font-size: 16px;

  /* may need to tweak cursor width if you change font size */
  --jp-code-cursor-width0: 1.4px;
  --jp-code-cursor-width1: 2px;
  --jp-code-cursor-width2: 4px;

  /* Layout
   *
   * The following are the main layout colors use in JupyterLab. In a light
   * theme these would go from light to dark.
   */

  --jp-layout-color0: white;
  --jp-layout-color1: white;
  --jp-layout-color2: var(--md-grey-200);
  --jp-layout-color3: var(--md-grey-400);
  --jp-layout-color4: var(--md-grey-600);

  /* Inverse Layout
   *
   * The following are the inverse layout colors use in JupyterLab. In a light
   * theme these would go from dark to light.
   */

  --jp-inverse-layout-color0: #111;
  --jp-inverse-layout-color1: var(--md-grey-900);
  --jp-inverse-layout-color2: var(--md-grey-800);
  --jp-inverse-layout-color3: var(--md-grey-700);
  --jp-inverse-layout-color4: var(--md-grey-600);

  /* Brand/accent */

  --jp-brand-color0: var(--md-blue-900);
  --jp-brand-color1: var(--md-blue-700);
  --jp-brand-color2: var(--md-blue-300);
  --jp-brand-color3: var(--md-blue-100);
  --jp-brand-color4: var(--md-blue-50);
  --jp-accent-color0: var(--md-green-900);
  --jp-accent-color1: var(--md-green-700);
  --jp-accent-color2: var(--md-green-300);
  --jp-accent-color3: var(--md-green-100);

  /* State colors (warn, error, success, info) */

  --jp-warn-color0: var(--md-orange-900);
  --jp-warn-color1: var(--md-orange-700);
  --jp-warn-color2: var(--md-orange-300);
  --jp-warn-color3: var(--md-orange-100);
  --jp-error-color0: var(--md-red-900);
  --jp-error-color1: var(--md-red-700);
  --jp-error-color2: var(--md-red-300);
  --jp-error-color3: var(--md-red-100);
  --jp-success-color0: var(--md-green-900);
  --jp-success-color1: var(--md-green-700);
  --jp-success-color2: var(--md-green-300);
  --jp-success-color3: var(--md-green-100);
  --jp-info-color0: var(--md-cyan-900);
  --jp-info-color1: var(--md-cyan-700);
  --jp-info-color2: var(--md-cyan-300);
  --jp-info-color3: var(--md-cyan-100);

  /* Cell specific styles */

  --jp-cell-padding: 5px;
  --jp-cell-collapser-width: 8px;
  --jp-cell-collapser-min-height: 20px;
  --jp-cell-collapser-not-active-hover-opacity: 0.6;
  --jp-cell-editor-background: var(--md-grey-100);
  --jp-cell-editor-border-color: var(--md-grey-300);
  --jp-cell-editor-box-shadow: inset 0 0 2px var(--md-blue-300);
  --jp-cell-editor-active-background: var(--jp-layout-color0);
  --jp-cell-editor-active-border-color: var(--jp-brand-color1);
  --jp-cell-prompt-width: 64px;
  --jp-cell-prompt-font-family: var(--jp-code-font-family-default);
  --jp-cell-prompt-letter-spacing: 0;
  --jp-cell-prompt-opacity: 1;
  --jp-cell-prompt-not-active-opacity: 0.5;
  --jp-cell-prompt-not-active-font-color: var(--md-grey-700);

  /* A custom blend of MD grey and blue 600
   * See https://meyerweb.com/eric/tools/color-blend/#546E7A:1E88E5:5:hex */
  --jp-cell-inprompt-font-color: #307fc1;

  /* A custom blend of MD grey and orange 600
   * https://meyerweb.com/eric/tools/color-blend/#546E7A:F4511E:5:hex */
  --jp-cell-outprompt-font-color: #bf5b3d;

  /* Notebook specific styles */

  --jp-notebook-padding: 10px;
  --jp-notebook-select-background: var(--jp-layout-color1);
  --jp-notebook-multiselected-color: var(--md-blue-50);

  /* The scroll padding is calculated to fill enough space at the bottom of the
  notebook to show one single-line cell (with appropriate padding) at the top
  when the notebook is scrolled all the way to the bottom. We also subtract one
  pixel so that no scrollbar appears if we have just one single-line cell in the
  notebook. This padding is to enable a 'scroll past end' feature in a notebook.
  */
  --jp-notebook-scroll-padding: calc(
    100% - var(--jp-code-font-size) * var(--jp-code-line-height) -
      var(--jp-code-padding) - var(--jp-cell-padding) - 1px
  );

  /* Rendermime styles */

  --jp-rendermime-error-background: #fdd;
  --jp-rendermime-table-row-background: var(--md-grey-100);
  --jp-rendermime-table-row-hover-background: var(--md-light-blue-50);

  /* Dialog specific styles */

  --jp-dialog-background: rgba(0, 0, 0, 0.25);

  /* Console specific styles */

  --jp-console-padding: 10px;

  /* Toolbar specific styles */

  --jp-toolbar-border-color: var(--jp-border-color1);
  --jp-toolbar-micro-height: 8px;
  --jp-toolbar-background: var(--jp-layout-color1);
  --jp-toolbar-box-shadow: 0 0 2px 0 rgba(0, 0, 0, 0.24);
  --jp-toolbar-header-margin: 4px 4px 0 4px;
  --jp-toolbar-active-background: var(--md-grey-300);

  /* Statusbar specific styles */

  --jp-statusbar-height: 24px;

  /* Input field styles */

  --jp-input-box-shadow: inset 0 0 2px var(--md-blue-300);
  --jp-input-active-background: var(--jp-layout-color1);
  --jp-input-hover-background: var(--jp-layout-color1);
  --jp-input-background: var(--md-grey-100);
  --jp-input-border-color: var(--jp-inverse-border-color);
  --jp-input-active-border-color: var(--jp-brand-color1);
  --jp-input-active-box-shadow-color: rgba(19, 124, 189, 0.3);

  /* General editor styles */

  --jp-editor-selected-background: #d9d9d9;
  --jp-editor-selected-focused-background: #d7d4f0;
  --jp-editor-cursor-color: var(--jp-ui-font-color0);

  /* Code mirror specific styles */

  --jp-mirror-editor-keyword-color: #008000;
  --jp-mirror-editor-atom-color: #88f;
  --jp-mirror-editor-number-color: #080;
  --jp-mirror-editor-def-color: #00f;
  --jp-mirror-editor-variable-color: var(--md-grey-900);
  --jp-mirror-editor-variable-2-color: rgb(0, 54, 109);
  --jp-mirror-editor-variable-3-color: #085;
  --jp-mirror-editor-punctuation-color: #05a;
  --jp-mirror-editor-property-color: #05a;
  --jp-mirror-editor-operator-color: #a2f;
  --jp-mirror-editor-comment-color: #408080;
  --jp-mirror-editor-string-color: #ba2121;
  --jp-mirror-editor-string-2-color: #708;
  --jp-mirror-editor-meta-color: #a2f;
  --jp-mirror-editor-qualifier-color: #555;
  --jp-mirror-editor-builtin-color: #008000;
  --jp-mirror-editor-bracket-color: #997;
  --jp-mirror-editor-tag-color: #170;
  --jp-mirror-editor-attribute-color: #00c;
  --jp-mirror-editor-header-color: blue;
  --jp-mirror-editor-quote-color: #090;
  --jp-mirror-editor-link-color: #00c;
  --jp-mirror-editor-error-color: #f00;
  --jp-mirror-editor-hr-color: #999;

  /*
    RTC user specific colors.
    These colors are used for the cursor, username in the editor,
    and the icon of the user.
  */

  --jp-collaborator-color1: #ffad8e;
  --jp-collaborator-color2: #dac83d;
  --jp-collaborator-color3: #72dd76;
  --jp-collaborator-color4: #00e4d0;
  --jp-collaborator-color5: #45d4ff;
  --jp-collaborator-color6: #e2b1ff;
  --jp-collaborator-color7: #ff9de6;

  /* Vega extension styles */

  --jp-vega-background: white;

  /* Sidebar-related styles */

  --jp-sidebar-min-width: 250px;

  /* Search-related styles */

  --jp-search-toggle-off-opacity: 0.5;
  --jp-search-toggle-hover-opacity: 0.8;
  --jp-search-toggle-on-opacity: 1;
  --jp-search-selected-match-background-color: rgb(245, 200, 0);
  --jp-search-selected-match-color: black;
  --jp-search-unselected-match-background-color: var(
    --jp-inverse-layout-color0
  );
  --jp-search-unselected-match-color: var(--jp-ui-inverse-font-color0);

  /* Icon colors that work well with light or dark backgrounds */
  --jp-icon-contrast-color0: var(--md-purple-600);
  --jp-icon-contrast-color1: var(--md-green-600);
  --jp-icon-contrast-color2: var(--md-pink-600);
  --jp-icon-contrast-color3: var(--md-blue-600);

  /* Button colors */
  --jp-accept-color-normal: var(--md-blue-700);
  --jp-accept-color-hover: var(--md-blue-800);
  --jp-accept-color-active: var(--md-blue-900);
  --jp-warn-color-normal: var(--md-red-700);
  --jp-warn-color-hover: var(--md-red-800);
  --jp-warn-color-active: var(--md-red-900);
  --jp-reject-color-normal: var(--md-grey-600);
  --jp-reject-color-hover: var(--md-grey-700);
  --jp-reject-color-active: var(--md-grey-800);

  /* File or activity icons and switch semantic variables */
  --jp-jupyter-icon-color: #f37626;
  --jp-notebook-icon-color: #f37626;
  --jp-json-icon-color: var(--md-orange-700);
  --jp-console-icon-background-color: var(--md-blue-700);
  --jp-console-icon-color: white;
  --jp-terminal-icon-background-color: var(--md-grey-800);
  --jp-terminal-icon-color: var(--md-grey-200);
  --jp-text-editor-icon-color: var(--md-grey-700);
  --jp-inspector-icon-color: var(--md-grey-700);
  --jp-switch-color: var(--md-grey-400);
  --jp-switch-true-position-color: var(--md-orange-900);
}
</style>
<style type="text/css">
/* Force rendering true colors when outputing to pdf */
* {
  -webkit-print-color-adjust: exact;
}

/* Misc */
a.anchor-link {
  display: none;
}

/* Input area styling */
.jp-InputArea {
  overflow: hidden;
}

.jp-InputArea-editor {
  overflow: hidden;
}

.cm-editor.cm-s-jupyter .highlight pre {
/* weird, but --jp-code-padding defined to be 5px but 4px horizontal padding is hardcoded for pre.cm-line */
  padding: var(--jp-code-padding) 4px;
  margin: 0;

  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
  color: inherit;

}

.jp-OutputArea-output pre {
  line-height: inherit;
  font-family: inherit;
}

.jp-RenderedText pre {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-code-font-size);
}

/* Hiding the collapser by default */
.jp-Collapser {
  display: none;
}

@page {
    margin: 0.5in; /* Margin for each printed piece of paper */
}

@media print {
  .jp-Cell-inputWrapper,
  .jp-Cell-outputWrapper {
    display: block;
  }
}
</style>
<!-- Load mathjax -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML-full,Safe"> </script>
<!-- MathJax configuration -->
<script type="text/x-mathjax-config">
    init_mathjax = function() {
        if (window.MathJax) {
        // MathJax loaded
            MathJax.Hub.Config({
                TeX: {
                    equationNumbers: {
                    autoNumber: "AMS",
                    useLabelIds: true
                    }
                },
                tex2jax: {
                    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                    processEscapes: true,
                    processEnvironments: true
                },
                displayAlign: 'center',
                messageStyle: 'none',
                CommonHTML: {
                    linebreaks: {
                    automatic: true
                    }
                }
            });

            MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
        }
    }
    init_mathjax();
    </script>
<!-- End of mathjax configuration --><script type="module">
  document.addEventListener("DOMContentLoaded", async () => {
    const diagrams = document.querySelectorAll(".jp-Mermaid > pre.mermaid");
    // do not load mermaidjs if not needed
    if (!diagrams.length) {
      return;
    }
    const mermaid = (await import("https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.7.0/mermaid.esm.min.mjs")).default;
    const parser = new DOMParser();

    mermaid.initialize({
      maxTextSize: 100000,
      maxEdges: 100000,
      startOnLoad: false,
      fontFamily: window
        .getComputedStyle(document.body)
        .getPropertyValue("--jp-ui-font-family"),
      theme: document.querySelector("body[data-jp-theme-light='true']")
        ? "default"
        : "dark",
    });

    let _nextMermaidId = 0;

    function makeMermaidImage(svg) {
      const img = document.createElement("img");
      const doc = parser.parseFromString(svg, "image/svg+xml");
      const svgEl = doc.querySelector("svg");
      const { maxWidth } = svgEl?.style || {};
      const firstTitle = doc.querySelector("title");
      const firstDesc = doc.querySelector("desc");

      img.setAttribute("src", `data:image/svg+xml,${encodeURIComponent(svg)}`);
      if (maxWidth) {
        img.width = parseInt(maxWidth);
      }
      if (firstTitle) {
        img.setAttribute("alt", firstTitle.textContent);
      }
      if (firstDesc) {
        const caption = document.createElement("figcaption");
        caption.className = "sr-only";
        caption.textContent = firstDesc.textContent;
        return [img, caption];
      }
      return [img];
    }

    async function makeMermaidError(text) {
      let errorMessage = "";
      try {
        await mermaid.parse(text);
      } catch (err) {
        errorMessage = `${err}`;
      }

      const result = document.createElement("details");
      result.className = 'jp-RenderedMermaid-Details';
      const summary = document.createElement("summary");
      summary.className = 'jp-RenderedMermaid-Summary';
      const pre = document.createElement("pre");
      const code = document.createElement("code");
      code.innerText = text;
      pre.appendChild(code);
      summary.appendChild(pre);
      result.appendChild(summary);

      const warning = document.createElement("pre");
      warning.innerText = errorMessage;
      result.appendChild(warning);
      return [result];
    }

    async function renderOneMarmaid(src) {
      const id = `jp-mermaid-${_nextMermaidId++}`;
      const parent = src.parentNode;
      let raw = src.textContent.trim();
      const el = document.createElement("div");
      el.style.visibility = "hidden";
      document.body.appendChild(el);
      let results = null;
      let output = null;
      try {
        let { svg } = await mermaid.render(id, raw, el);
        svg = cleanMermaidSvg(svg);
        results = makeMermaidImage(svg);
        output = document.createElement("figure");
        results.map(output.appendChild, output);
      } catch (err) {
        parent.classList.add("jp-mod-warning");
        results = await makeMermaidError(raw);
        output = results[0];
      } finally {
        el.remove();
      }
      parent.classList.add("jp-RenderedMermaid");
      parent.appendChild(output);
    }


    /**
     * Post-process to ensure mermaid diagrams contain only valid SVG and XHTML.
     */
    function cleanMermaidSvg(svg) {
      return svg.replace(RE_VOID_ELEMENT, replaceVoidElement);
    }


    /**
     * A regular expression for all void elements, which may include attributes and
     * a slash.
     *
     * @see https://developer.mozilla.org/en-US/docs/Glossary/Void_element
     *
     * Of these, only `<br>` is generated by Mermaid in place of `\n`,
     * but _any_ "malformed" tag will break the SVG rendering entirely.
     */
    const RE_VOID_ELEMENT =
      /<\s*(area|base|br|col|embed|hr|img|input|link|meta|param|source|track|wbr)\s*([^>]*?)\s*>/gi;

    /**
     * Ensure a void element is closed with a slash, preserving any attributes.
     */
    function replaceVoidElement(match, tag, rest) {
      rest = rest.trim();
      if (!rest.endsWith('/')) {
        rest = `${rest} /`;
      }
      return `<${tag} ${rest}>`;
    }

    void Promise.all([...diagrams].map(renderOneMarmaid));
  });
</script>
<style>
  .jp-Mermaid:not(.jp-RenderedMermaid) {
    display: none;
  }

  .jp-RenderedMermaid {
    overflow: auto;
    display: flex;
  }

  .jp-RenderedMermaid.jp-mod-warning {
    width: auto;
    padding: 0.5em;
    margin-top: 0.5em;
    border: var(--jp-border-width) solid var(--jp-warn-color2);
    border-radius: var(--jp-border-radius);
    color: var(--jp-ui-font-color1);
    font-size: var(--jp-ui-font-size1);
    white-space: pre-wrap;
    word-wrap: break-word;
  }

  .jp-RenderedMermaid figure {
    margin: 0;
    overflow: auto;
    max-width: 100%;
  }

  .jp-RenderedMermaid img {
    max-width: 100%;
  }

  .jp-RenderedMermaid-Details > pre {
    margin-top: 1em;
  }

  .jp-RenderedMermaid-Summary {
    color: var(--jp-warn-color2);
  }

  .jp-RenderedMermaid:not(.jp-mod-warning) pre {
    display: none;
  }

  .jp-RenderedMermaid-Summary > pre {
    display: inline-block;
    white-space: normal;
  }
</style>
<!-- End of mermaid configuration --></head>
<body class="jp-Notebook" data-jp-theme-light="true" data-jp-theme-name="JupyterLab Light">
<main>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=cfaf589e">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="16.-%EC%97%90%EC%9D%B4%EC%A0%84%ED%8A%B8-(Agent)">16. 에이전트 (Agent)<a class="anchor-link" href="#16.-%EC%97%90%EC%9D%B4%EC%A0%84%ED%8A%B8-(Agent)">¶</a></h1><ul>
<li><strong>Agent(에이전트)는 LangChain 및 기타 LLM(Large Language Model) 애플리케이션에서 중요한 개념으로, 인공지능 시스템이 더욱 자율적이고 목표 지향적으로 작업을 수행할 수 있게 해주는 컴포넌트</strong></li>
<li><strong>에이전트는 주어진 목표를 달성하기 위해 환경과 상호작용하며 의사 결정을 내리고 행동을 취하는 지능형 개체로 볼 수 있음</strong></li>
</ul>
<br/>
<h3 id="%EC%A3%BC%EC%9A%94-%ED%8A%B9%EC%A7%95">주요 특징<a class="anchor-link" href="#%EC%A3%BC%EC%9A%94-%ED%8A%B9%EC%A7%95">¶</a></h3><ul>
<li><strong>자율성</strong>: 에이전트는 사전에 정의된 규칙이나 명시적인 프로그래밍 없이도 스스로 결정을 내리고 행동</li>
<li><strong>목표 지향성</strong>: 특정 목표나 작업을 달성하기 위해 설계</li>
<li><strong>환경 인식</strong>: 주변 환경이나 상황을 인식하고 이에 따라 적응할 수 있음</li>
<li><strong>도구 사용</strong>: 다양한 도구나 API를 활용하여 작업을 수행할 수 있음</li>
<li><strong>연속성</strong>: 주어진 목표를 달성하기 위하여 1회 수행이 아닌 반복 수행을 통해 목표 달성을 추구</li>
</ul>
<br/>
<h3 id="LangChain%EC%97%90%EC%84%9C%EC%9D%98-%EC%97%90%EC%9D%B4%EC%A0%84%ED%8A%B8">LangChain에서의 에이전트<a class="anchor-link" href="#LangChain%EC%97%90%EC%84%9C%EC%9D%98-%EC%97%90%EC%9D%B4%EC%A0%84%ED%8A%B8">¶</a></h3><ul>
<li><strong>Agent</strong>: 의사 결정을 담당하는 핵심 컴포넌트</li>
<li><strong>Tools</strong>: 에이전트가 사용할 수 있는 기능들의 집합</li>
<li><strong>Toolkits</strong>: 관련된 도구들의 그룹</li>
<li><strong>AgentExecutor</strong>: 에이전트의 실행을 관리하는 컴포넌트</li>
</ul>
<br/>
<h3 id="%EC%97%90%EC%9D%B4%EC%A0%84%ED%8A%B8%EC%9D%98-%EC%9E%91%EB%8F%99-%EB%B0%A9%EC%8B%9D">에이전트의 작동 방식<a class="anchor-link" href="#%EC%97%90%EC%9D%B4%EC%A0%84%ED%8A%B8%EC%9D%98-%EC%9E%91%EB%8F%99-%EB%B0%A9%EC%8B%9D">¶</a></h3><ul>
<li><strong>입력 수신</strong>: 사용자로부터 작업이나 질문을 받음</li>
<li><strong>계획 수립</strong>: 주어진 작업을 완료하기 위한 단계별 계획을 세움</li>
<li><strong>도구 선택</strong>: 각 단계에 적합한 도구를 선택</li>
<li><strong>실행</strong>: 선택한 도구를 사용하여 작업을 수행</li>
<li><strong>결과 평가</strong>: 수행 결과를 평가하고 필요시 계획을 조정</li>
<li><strong>출력 생성</strong>: 최종 결과나 답변을 사용자에게 제공</li>
</ul>
<br/>
<hr/>
<br/>
<h2 id="16-01.-%EB%8F%84%EA%B5%AC-(Tools)">16-01. 도구 (Tools)<a class="anchor-link" href="#16-01.-%EB%8F%84%EA%B5%AC-(Tools)">¶</a></h2><ul>
<li><p>도구(Tool)는 에이전트, 체인 또는 LLM이 외부 세계와 상호작용하기 위한 인터페이스</p>
</li>
<li><p>LangChain 에서 기본 제공하는 도구를 사용하여 쉽게 도구를 활용할 수 있으며, 사용자 정의 도구(Custom Tool) 를 쉽게 구축하는 것도 가능</p>
<p><a href="https://docs.langchain.com/oss/python/langchain/tools">https://docs.langchain.com/oss/python/langchain/tools</a></p>
</li>
</ul>
<br/>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=acbe217e">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [1]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">dotenv</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dotenv</span>

<span class="n">load_dotenv</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[1]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>True</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=30e25c1e">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [2]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">warnings</span>

<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">"ignore"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=e98de64f">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<br/>
<h3 id="%EB%B9%8C%ED%8A%B8%EC%9D%B8-%EB%8F%84%EA%B5%AC(built-in-tools)">빌트인 도구(built-in tools)<a class="anchor-link" href="#%EB%B9%8C%ED%8A%B8%EC%9D%B8-%EB%8F%84%EA%B5%AC(built-in-tools)">¶</a></h3><ul>
<li>랭체인에서 제공하는 사전에 정의된 도구(tool) 와 툴킷(toolkit)</li>
<li><code>tool</code> 은 단일 도구를 의미하며, <code>toolkit</code> 은 여러 도구를 묶어서 하나의 도구로 사용</li>
<li><a href="https://docs.langchain.com/oss/python/integrations/tools">https://docs.langchain.com/oss/python/integrations/tools</a></li>
</ul>
<br/>
<h4 id="Python-REPL-%EB%8F%84%EA%B5%AC">Python REPL 도구<a class="anchor-link" href="#Python-REPL-%EB%8F%84%EA%B5%AC">¶</a></h4><ul>
<li><strong>Python 코드를 REPL(Read-Eval-Print Loop) 환경에서 실행하기 위한 두 가지 주요 클래스를 제공</strong><ul>
<li>Python 셸 환경을 제공</li>
<li>유효한 Python 명령어를 입력으로 받아 실행</li>
<li>결과를 보려면 print(...) 함수를 사용</li>
</ul>
</li>
<li><code>sanitize_input</code>: 입력을 정제하는 옵션 (기본값: True)</li>
<li><code>python_repl</code>: PythonREPL 인스턴스 (기본값: 전역 범위에서 실행)</li>
<li>사용<ul>
<li>PythonREPLTool 인스턴스 생성</li>
<li>run 또는 arun, invoke 메서드를 사용하여 Python 코드 실행</li>
</ul>
</li>
</ul>
<br/>
<ul>
<li>입력 정제<ul>
<li>입력 문자열에서 불필요한 공백, 백틱, 'python' 키워드 등을 제거</li>
</ul>
</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=295ec8fe">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [3]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">langchain_experimental.tools</span><span class="w"> </span><span class="kn">import</span> <span class="n">PythonREPLTool</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=8c625757">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<ul>
<li>파이썬 코드를 실행하는 도구를 생성</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=af09c901">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [4]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">python_tool</span> <span class="o">=</span> <span class="n">PythonREPLTool</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=7da6bd26">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [5]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">python_tool</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="s2">"print(100 + 200)"</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>Python REPL can execute arbitrary code. Use with caution.
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>300

</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=b1c52573">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<br/>
<h4 id="%ED%9D%90%EB%A6%84">흐름<a class="anchor-link" href="#%ED%9D%90%EB%A6%84">¶</a></h4><ul>
<li>LLM 모델에게 특정 작업을 수행하는 Python 코드를 작성하도록 요청</li>
<li>작성된 코드를 실행</li>
<li>결과를 출력</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=10a43ee7">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [6]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">langchain_openai</span><span class="w"> </span><span class="kn">import</span> <span class="n">ChatOpenAI</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_core.prompts</span><span class="w"> </span><span class="kn">import</span> <span class="n">ChatPromptTemplate</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_core.output_parsers</span><span class="w"> </span><span class="kn">import</span> <span class="n">StrOutputParser</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_core.runnables</span><span class="w"> </span><span class="kn">import</span> <span class="n">RunnableLambda</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=dbc46b5a">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<ul>
<li>파이썬 코드를 실행하고 중간 과정을 출력하고 도구 실행 결과를 반환하는 함수</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=7e35f520">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [7]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">print_and_execute</span><span class="p">(</span><span class="n">code</span><span class="p">,</span> <span class="n">debug</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">debug</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"CODE:"</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">code</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">python_tool</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="n">code</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=0c90790f">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<ul>
<li>파이썬 코드를 작성하도록 요청하는 프롬프트</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=9216f2c4">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [8]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">prompt</span> <span class="o">=</span> <span class="n">ChatPromptTemplate</span><span class="o">.</span><span class="n">from_messages</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">(</span>
            <span class="s2">"system"</span><span class="p">,</span>
            <span class="s2">"You are Raymond Hetting, an expert python programmer, well versed in meta-programming and elegant, concise and short but well documented code. You follow the PEP8 style guide. "</span>
            <span class="s2">"Return only the code, no intro, no explanation, no chatty, no markdown, no code block, no nothing. Just the code."</span><span class="p">,</span>
        <span class="p">),</span>
        <span class="p">(</span><span class="s2">"human"</span><span class="p">,</span> <span class="s2">"</span><span class="si">{input}</span><span class="s2">"</span><span class="p">),</span>
    <span class="p">]</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=55d28e17">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [9]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">llm</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">"gpt-4o"</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=00678699">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [10]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">chain</span> <span class="o">=</span> <span class="n">prompt</span> <span class="o">|</span> <span class="n">llm</span> <span class="o">|</span> <span class="n">StrOutputParser</span><span class="p">()</span> <span class="o">|</span> <span class="n">RunnableLambda</span><span class="p">(</span><span class="n">print_and_execute</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=88a9253a">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [11]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">chain</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="s2">"로또 번호 생성기를 출력하는 코드를 작성하세요."</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>CODE:
```python
import random

def generate_lotto_numbers():
    return sorted(random.sample(range(1, 46), 6))

print(generate_lotto_numbers())
```
[3, 9, 15, 17, 23, 34]

</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=53ce8d5c">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<br/>
<h3 id="%EA%B2%80%EC%83%89-API-%EB%8F%84%EA%B5%AC">검색 API 도구<a class="anchor-link" href="#%EA%B2%80%EC%83%89-API-%EB%8F%84%EA%B5%AC">¶</a></h3><ul>
<li><p>Tavily 검색 API를 활용하여 검색 기능을 구현하는 도구</p>
<p><a href="https://app.tavily.com">https://app.tavily.com</a></p>
</li>
<li><p><code>.env</code> 파일에 저장</p>
</li>
</ul>
<div class="highlight"><pre><span></span><span class="na">TAVILY_API_KEY</span><span class="o">=</span><span class="s">XXXXXXXXXXXX</span>
</pre></div>
<br/>
<h3 id="TavilySearchResults"><code>TavilySearchResults</code><a class="anchor-link" href="#TavilySearchResults">¶</a></h3><ul>
<li>Tavily 검색 API를 쿼리하고 JSON 형식의 결과를 반환</li>
<li>포괄적이고 정확하며 신뢰할 수 있는 결과에 최적화된 검색 엔진</li>
<li>현재 이벤트에 대한 질문에 답변할 때 유용</li>
</ul>
<br/>
<h4 id="%EC%A3%BC%EC%9A%94-%EB%A7%A4%EA%B0%9C%EB%B3%80%EC%88%98">주요 매개변수<a class="anchor-link" href="#%EC%A3%BC%EC%9A%94-%EB%A7%A4%EA%B0%9C%EB%B3%80%EC%88%98">¶</a></h4><ul>
<li><code>max_results</code> (int): 반환할 최대 검색 결과 수 (기본값: 5)</li>
<li><code>search_depth</code> (str): 검색 깊이 (<code>"basic"</code> 또는 <code>"advanced"</code>)</li>
<li><code>include_domains</code> (List[str]): 검색 결과에 포함할 도메인 목록</li>
<li><code>exclude_domains</code> (List[str]): 검색 결과에서 제외할 도메인 목록</li>
<li><code>include_answer</code> (bool): 원본 쿼리에 대한 짧은 답변 포함 여부</li>
<li><code>include_raw_content</code> (bool): 각 사이트의 정제된 HTML 콘텐츠 포함 여부</li>
<li><code>include_images</code> (bool): 쿼리 관련 이미지 목록 포함 여부</li>
</ul>
<br/>
<h4 id="%EB%B0%98%ED%99%98-%EA%B0%92">반환 값<a class="anchor-link" href="#%EB%B0%98%ED%99%98-%EA%B0%92">¶</a></h4><ul>
<li>검색 결과를 포함하는 JSON 형식의 문자열(<code>url</code>, <code>content</code>) 혹은 아래의 주석을 해제하고 발급받은 API 키를 입력</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=a3452157">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [12]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">langchain_community.tools.tavily_search</span><span class="w"> </span><span class="kn">import</span> <span class="n">TavilySearchResults</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=897c8179">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">tool</span> <span class="o">=</span> <span class="n">TavilySearchResults</span><span class="p">(</span>
    <span class="n">max_results</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span>
    <span class="n">include_answer</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">include_raw_content</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="c1"># include_images=True,</span>
    <span class="c1"># search_depth="advanced", # or "basic"</span>
    <span class="n">include_domains</span><span class="o">=</span><span class="p">[</span><span class="s2">"github.io"</span><span class="p">,</span> <span class="s2">"wikidocs.net"</span><span class="p">],</span>
    <span class="c1"># exclude_domains = []</span>
<span class="p">)</span>

<span class="n">tool</span><span class="o">.</span><span class="n">invoke</span><span class="p">({</span><span class="s2">"query"</span><span class="p">:</span> <span class="s2">"LangChain Tools 에 대해서 알려주세요"</span><span class="p">})</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>C:\Users\user\AppData\Local\Temp\ipykernel_41616\4142990849.py:1: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the `langchain-tavily package and should be used instead. To use it run `pip install -U `langchain-tavily` and import as `from `langchain_tavily import TavilySearch``.
  tool = TavilySearchResults(
</pre>
</div>
</div>
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[ ]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>[{'title': '3-3. 커스텀 도구 - 랭체인(LangChain) 입문부터 응용까지 [ver 1.0 ...',
  'url': 'https://wikidocs.net/261571',
  'content': '1. 랭체인(LangChain) 입문부터 응용까지…\n2. Part 3. Agents &amp; Tools\n3. 3-3. 커스텀 도구\n\n1. 위키독스\n\n# 3-3. 커스텀 도구\n\n광고가 출력될 위치입니다.\n\n광고가 출력될 위치입니다.\n\n## 개요\n\n 개요\n 커스텀 도구 생성\n  + 기본 도구 구현\n  + 예약 파라미터 이름\n  + 도구 메타데이터 커스터마이징\n LangChain v1.0 에이전트 생성\n  + create\\_agent() 사용법\n  + 에이전트 실행\n  + 대화형 실행\n 에러 처리 미들웨어\n  + 기본 에러 처리 미들웨어\n  + 재시도 미들웨어\n  + 로깅 미들웨어\n 전체 실행 예제\n 고급 기능\n  + 구조화된 출력 도구\n  + ToolRuntime 타입 힌트\n  + 비동기 도구\n 정리\n 주의사항\n\nLangChain v1.0에서는 `@tool` 데코레이터를 사용하여 커스텀 도구를 쉽게 만들고, `create_agent()`를 통해 에이전트와 통합할 수 있습니다. 이번 장에서는 OpenWeatherMap API를 활용한 날씨 조회 도구를 만들고, 에러 처리 미들웨어를 추가하는 방법을 학습합니다.\n\n## 커스텀 도구 생성\n\n### 기본 도구 구현\n\n`@tool` 데코레이터를 사용하면 일반 Python 함수를 LangChain 도구로 변환할 수 있습니다. [...] Part 0. 글쓴이 소개)   Part 1. LangChain 기초)   1-1. LangChain 이란?)   1-1-1. LangChain 버전 히스토리)   1-1-2. LangChain 1.0 프레임워크 구성)   1-1-3. 필수 라이브러리 설치)   1-2. LLM 체인(LLMChain) 만들기)   1-2-1. 기본 LLM 체인 (Prompt + LLM))   1-2-2. 멀티 체인 (Multi-Chain))   1-2-3. 체인을 실행하는 방법)   1-2-4. 메시지(Messages))   1-2-5. 스트리밍 (Streaming))   1-3. 프롬프트(Prompt))   1-3-1. 프롬프트 작성 원칙)   1-3-2. 프롬프트 템플릿 (PromptTemplate))   1-3-3. 챗 프롬프트 템플릿 (ChatPromptTemplate))   1-3-4. Few-shot Prompt)   1-3-5. Partial Prompt)   1-4. LangChain의 언어 모델 (Model))   1-4-1. LangChain 모델 유형)   1-4-1-1. LLM)   1-4-1-2. Chat Model)   1-4-1-3. 통합 모델 초기화 (init\\_chat\\_model))   1-4-2. LangChain의 LLM 모델 파라미터 설정)   1-4-2-1. LLM 모델에 직접 파라미터를 전달)   1-4-2-2. LLM 모델 파라미터를 추가로 바인딩 (bind 메소드))   1-4-3. 다른 공급업체의 모델 살펴보기)   1-4-3-1. Claude (Anthropic)) [...] Retriever)   2-6-5. RAG-Fusion)   Part 3. Agents &amp; Tools)   3-1. Agent 개요)   3-2. 내장 도구)   3-3. 커스텀 도구)   3-4. ToolRuntime &amp; 컨텍스트)   Part 4. 미들웨어 &amp; 가드레일)   4-1. 미들웨어(Middleware) 개요)   4-2. 내장 미들웨어)   4-2-1. 컨텍스트 관리 미들웨어)   4-2-2. 호출 제한 미들웨어)   4-2-3. 복원력 미들웨어)   4-2-4. 도구 최적화 미들웨어)   4-3. 커스텀 미들웨어)   4-4. 가드레일 개요)   4-5. PII 탐지)   4-6. Human-in-the-Loop)   Part 8. 오픈소스 LLM 활용)   8-1. 올라마)   8-1-1. 설치)   8-1-2. 모델 다운로드)   8-1-3. LangChain 적용)   8-2. Groq API)   8-2-1. 인증키 발급)   8-2-2. LangChain 적용)',
  'score': 0.69870013,
  'raw_content': '[**랭체인(LangChain) 입문부터 응용까지 [ver 1.0 업데이트]**](/book/14473) \n\n[Part 0. 글쓴이 소개](javascript:page(231147))   [Part 1. LangChain 기초](javascript:page(231150))   [1-1. LangChain 이란?](javascript:page(231151))   [1-1-1. LangChain 버전 히스토리](javascript:page(231154))   [1-1-2. LangChain 1.0 프레임워크 구성](javascript:page(231153))   [1-1-3. 필수 라이브러리 설치](javascript:page(231152))   [1-2. LLM 체인(LLMChain) 만들기](javascript:page(231155))   [1-2-1. 기본 LLM 체인 (Prompt + LLM)](javascript:page(231156))   [1-2-2. 멀티 체인 (Multi-Chain)](javascript:page(231186))   [1-2-3. 체인을 실행하는 방법](javascript:page(231187))   [1-2-4. 메시지(Messages)](javascript:page(319011))   [1-2-5. 스트리밍 (Streaming)](javascript:page(319017))   [1-3. 프롬프트(Prompt)](javascript:page(231228))   [1-3-1. 프롬프트 작성 원칙](javascript:page(231229))   [1-3-2. 프롬프트 템플릿 (PromptTemplate)](javascript:page(231233))   [1-3-3. 챗 프롬프트 템플릿 (ChatPromptTemplate)](javascript:page(231328))   [1-3-4. Few-shot Prompt](javascript:page(231230))   [1-3-5. Partial Prompt](javascript:page(231234))   [1-4. LangChain의 언어 모델 (Model)](javascript:page(231344))   [1-4-1. LangChain 모델 유형](javascript:page(231360))   [1-4-1-1. LLM](javascript:page(231345))   [1-4-1-2. Chat Model](javascript:page(231346))   [1-4-1-3. 통합 모델 초기화 (init\\_chat\\_model)](javascript:page(319002))   [1-4-2. LangChain의 LLM 모델 파라미터 설정](javascript:page(231351))   [1-4-2-1. LLM 모델에 직접 파라미터를 전달](javascript:page(231375))   [1-4-2-2. LLM 모델 파라미터를 추가로 바인딩 (bind 메소드)](javascript:page(231376))   [1-4-3. 다른 공급업체의 모델 살펴보기](javascript:page(231358))   [1-4-3-1. Claude (Anthropic)](javascript:page(231362))   [1-4-3-2. Gemini (Google)](javascript:page(259654))   [1-5. 출력 파서 (Output Parser)](javascript:page(231363))   [1-6. 메모리와 대화 관리](javascript:page(293398))   [1-6-1. 메모리의 필요성과 개념](javascript:page(293399))   [1-6-2. RunnableWithMessageHistory](javascript:page(293401))   [1-6-3. 다양한 메모리 저장 방식](javascript:page(293404))   [1-6-4.\\_단기\\_메모리\\_패턴](javascript:page(318944))   [1-6-5.\\_장기\\_메모리](javascript:page(318945))   [Part 2. RAG (Retrieval-Augmented Generation) 기법](javascript:page(231364))   [2-1. RAG 개요](javascript:page(231393))   [2-2. RAG - Document Loader](javascript:page(231429))   [2-2-1. 웹 문서 (WebBaseLoader)](javascript:page(231644))   [2-2-2. 텍스트 문서 (TextLoader)](javascript:page(231564))   [2-2-3. 디렉토리 폴더 (DirectoryLoader)](javascript:page(231645))   [2-2-4. CSV 문서 (CSVLoader)](javascript:page(231566))   [2-2-5. PDF 문서](javascript:page(231565))   [2-2-5-1. PDF 문서 페이지별로 로드 (PyPDFLoader)](javascript:page(232104))   [2-2-5-2. 형식이 없는 PDF 문서 로드 (UnstructuredPDFLoader)](javascript:page(232105))   [2-2-5-3. PDF 문서의 메타 데이터를 상세하게 추출 (PyMuPDFLoader)](javascript:page(232106))   [2-2-5-4. 온라인(on-line) PDF 문서 로드 (OnlinePDFLoader)](javascript:page(232107))   [2-2-5-5. 특정 폴더의 모든 PDF 문서 로드 (PyPDFDirectoryLoader)](javascript:page(232110))   [2-3. RAG - Text Splitter](javascript:page(231430))   [2-3-1. CharacterTextSplitter](javascript:page(231568))   [2-3-2. RecursiveCharacterTextSplitter](javascript:page(231569))   [2-3-3. 토큰 수를 기준으로 텍스트 분할 (Tokenizer 활용)](javascript:page(231570))   [2-4. RAG - Embedding](javascript:page(231431))   [2-4-1. OpenAIEmbeddings](javascript:page(231571))   [2-4-2. HuggingFaceEmbeddings](javascript:page(231573))   [2-4-3. GoogleGenerativeAIEmbeddings](javascript:page(231572))   [2-5. RAG - Vector Store](javascript:page(231433))   [2-5-1. Chroma](javascript:page(231575))   [2-5-1-1. 유사도 기반 검색 (Similarity search)](javascript:page(231578))   [2-5-1-2. MMR (Maximum marginal relevance search)](javascript:page(231585))   [2-5-1-3. 벡터스토어에 메타데이터(meta data)를 추가](javascript:page(231507))   [2-5-2. FAISS](javascript:page(231577))   [2-5-2-1. 유사도 기반 검색 (Similarity search) (Copy)](javascript:page(231593))   [2-5-2-2. MMR (Maximum marginal relevance search) (Copy)](javascript:page(231597))   [2-5-2-3. FAISS DB를 로컬에 저장하기](javascript:page(235091))   [2-6. RAG - Retriever](javascript:page(231434))   [2-6-1. Vector Store Retriver](javascript:page(231600))   [2-6-2. Multi Query Retriever](javascript:page(231603))   [2-6-3. Contextual compression](javascript:page(231608))   [2-6-4. Ensemble Retriever](javascript:page(231609))   [2-6-5. RAG-Fusion](javascript:page(231732))   [Part 3. Agents &amp; Tools](javascript:page(261566))   [3-1. Agent 개요](javascript:page(319019))   [3-2. 내장 도구](javascript:page(261567))   [3-3. 커스텀 도구](javascript:page(261571))   [3-4. ToolRuntime &amp; 컨텍스트](javascript:page(319020))   [Part 4. 미들웨어 &amp; 가드레일](javascript:page(294427))   [4-1. 미들웨어(Middleware) 개요](javascript:page(318926))   [4-2. 내장 미들웨어](javascript:page(318927))   [4-2-1. 컨텍스트 관리 미들웨어](javascript:page(319263))   [4-2-2. 호출 제한 미들웨어](javascript:page(319264))   [4-2-3. 복원력 미들웨어](javascript:page(319265))   [4-2-4. 도구 최적화 미들웨어](javascript:page(319266))   [4-3. 커스텀 미들웨어](javascript:page(318928))   [4-4. 가드레일 개요](javascript:page(318932))   [4-5. PII 탐지](javascript:page(318933))   [4-6. Human-in-the-Loop](javascript:page(318934))   [Part 8. 오픈소스 LLM 활용](javascript:page(232980))   [8-1. 올라마](javascript:page(238526))   [8-1-1. 설치](javascript:page(238530))   [8-1-2. 모델 다운로드](javascript:page(238531))   [8-1-3. LangChain 적용](javascript:page(238532))   [8-2. Groq API](javascript:page(257136))   [8-2-1. 인증키 발급](javascript:page(257138))   [8-2-2. LangChain 적용](javascript:page(259655))\n\n1. [**랭체인(LangChain) 입문부터 응용까지…**](/book/14473)\n2. [Part 3. Agents &amp; Tools](/261566)\n3. [3-3. 커스텀 도구](/261571)\n\n1. [위키독스](/)\n\n# 3-3. 커스텀 도구\n\n광고가 출력될 위치입니다.\n\n광고가 출력될 위치입니다.\n\n## 개요\n\n* [개요](#_1)\n* [커스텀 도구 생성](#_2)\n  + [기본 도구 구현](#_3)\n  + [예약 파라미터 이름](#_4)\n  + [도구 메타데이터 커스터마이징](#_5)\n* [LangChain v1.0 에이전트 생성](#langchain-v10)\n  + [create\\_agent() 사용법](#create_agent)\n  + [에이전트 실행](#_6)\n  + [대화형 실행](#_7)\n* [에러 처리 미들웨어](#_8)\n  + [기본 에러 처리 미들웨어](#_9)\n  + [재시도 미들웨어](#_10)\n  + [로깅 미들웨어](#_11)\n* [전체 실행 예제](#_12)\n* [고급 기능](#_13)\n  + [구조화된 출력 도구](#_14)\n  + [ToolRuntime 타입 힌트](#toolruntime)\n  + [비동기 도구](#_15)\n* [정리](#_16)\n* [주의사항](#_17)\n\nLangChain v1.0에서는 `@tool` 데코레이터를 사용하여 커스텀 도구를 쉽게 만들고, `create_agent()`를 통해 에이전트와 통합할 수 있습니다. 이번 장에서는 OpenWeatherMap API를 활용한 날씨 조회 도구를 만들고, 에러 처리 미들웨어를 추가하는 방법을 학습합니다.\n\n## 커스텀 도구 생성\n\n### 기본 도구 구현\n\n`@tool` 데코레이터를 사용하면 일반 Python 함수를 LangChain 도구로 변환할 수 있습니다.\n\n```\nfrom langchain.tools import tool import requests @tool def get_weather(location: str) -&gt; str: """주어진 위치의 현재 날씨 정보를 조회합니다. Args: location: 날씨를 조회할 도시 이름 (영어) Returns: 날씨 정보 문자열 (설명, 온도 포함) """ api_key = os.getenv(\'OPENWEATHERMAP_API_KEY\') if not api_key: raise ValueError("OpenWeatherMap API 키가 설정되지 않았습니다.") base_url = "http://api.openweathermap.org/data/2.5/weather" # 입력 전처리 location = location.strip("\'\\"") # API 요청 파라미터 설정 params = { "q": location, "appid": api_key, "units": "metric", "lang": "kr" } # API 요청 및 응답 처리 response = requests.get(base_url, params=params) response.raise_for_status() data = response.json() weather_description = data["weather"][0]["description"] temperature = data["main"]["temp"] humidity = data["main"]["humidity"] return ( f"{location}의 현재 날씨:\\n" f"- 상태: {weather_description}\\n" f"- 온도: {temperature}°C\\n" f"- 습도: {humidity}%" ) \n```\n\n### 예약 파라미터 이름\n\n다음 파라미터 이름은 시스템에서 예약되어 있어 **도구 인자로 사용할 수 없습니다**.\n\n| 예약 이름 | 용도 |\n| --- | --- |\n| `config` | RunnableConfig 내부 전달용 |\n| `runtime` | ToolRuntime 파라미터용 |\n\n### 도구 메타데이터 커스터마이징\n\n도구 이름과 설명을 명시적으로 지정할 수 있습니다.\n\n```\nfrom langchain.tools import tool @tool("weather_lookup") def get_weather(location: str) -&gt; str: """실시간 날씨 조회 도구""" # 구현 코드... pass # 또는 더 상세한 설정 @tool( name="weather_lookup", description="지정된 도시의 실시간 날씨 정보를 조회합니다.", return_direct=True # 결과를 에이전트를 거치지 않고 바로 반환 ) def get_weather(location: str) -&gt; str: # 구현 코드... pass \n```\n\n## LangChain v1.0 에이전트 생성\n\n### create\\_agent() 사용법\n\nv1.0에서는 `initialize_agent()`가 제거되고 `create_agent()`를 사용합니다.\n\n```\nfrom langchain.agents import create_agent from langchain_openai import ChatOpenAI # LLM 초기화 llm = ChatOpenAI(model="gpt-4o-mini", temperature=0) # 에이전트 생성 agent = create_agent( model=llm, tools=[get_weather], system_prompt="""당신은 날씨 정보 제공 전문 어시스턴트입니다. 사용자가 날씨를 질문하면 get_weather 도구를 사용하여 정확한 정보를 제공합니다. 도시 이름은 반드시 영어로 변환하여 조회합니다.""" ) \n```\n\n### 에이전트 실행\n\nv1.0에서는 `invoke()` 메서드를 사용하여 에이전트를 실행합니다.\n\n```\n# 단일 질문 실행 result = agent.invoke({ "messages": [ {"role": "user", "content": "서울과 뉴욕의 날씨를 알려주세요"} ] }) print(result["messages"][-1].content) \n```\n\n**실행 결과**:\n\n```\n서울과 뉴욕의 현재 날씨 정보를 조회하겠습니다. 서울의 현재 날씨: - 상태: 맑음 - 온도: 26.8°C - 습도: 62% 뉴욕의 현재 날씨: - 상태: 흐림 - 온도: 20.1°C - 습도: 71% \n```\n\n### 대화형 실행\n\n여러 턴의 대화를 처리하려면 메시지 히스토리를 관리해야 합니다.\n\n```\nfrom langchain_core.messages import HumanMessage, AIMessage # 대화 히스토리 초기화 messages = [] # 첫 번째 질문 messages.append(HumanMessage(content="서울 날씨 알려줘")) result = agent.invoke({"messages": messages}) # 응답 추가 messages.extend(result["messages"]) # 후속 질문 messages.append(HumanMessage(content="거기 우산 필요할까?")) result = agent.invoke({"messages": messages}) print(result["messages"][-1].content) \n```\n\n## 에러 처리 미들웨어\n\n### 기본 에러 처리 미들웨어\n\nv1.0에서는 미들웨어 시스템을 사용하여 도구 실행을 제어할 수 있습니다.\n\n```\nfrom langchain.agents.middleware import wrap_tool_call from langchain_core.messages import ToolMessage @wrap_tool_call def handle_tool_errors(request, handler): """도구 실행 중 발생하는 에러를 처리하는 미들웨어""" try: # 원래 도구 실행 return handler(request) except requests.exceptions.HTTPError as e: # HTTP 에러 처리 return ToolMessage( content=f"날씨 API 요청 실패: {e.response.status_code}", tool_call_id=request.tool_call["id"] ) except requests.exceptions.RequestException as e: # 네트워크 에러 처리 return ToolMessage( content=f"네트워크 오류 발생: {str(e)}", tool_call_id=request.tool_call["id"] ) except Exception as e: # 기타 에러 처리 return ToolMessage( content=f"도구 실행 오류: {str(e)}", tool_call_id=request.tool_call["id"] ) # 미들웨어가 적용된 에이전트 생성 agent = create_agent( model=llm, tools=[get_weather], middleware=[handle_tool_errors], system_prompt="당신은 날씨 정보 제공 전문 어시스턴트입니다." ) \n```\n\n### 재시도 미들웨어\n\n실패 시 자동으로 재시도하는 미들웨어를 추가할 수 있습니다.\n\n```\nimport time from langchain.agents.middleware import wrap_tool_call from langchain_core.messages import ToolMessage @wrap_tool_call def retry_on_failure(request, handler, max_retries=3, delay=1): """실패 시 재시도하는 미들웨어""" for attempt in range(max_retries): try: return handler(request) except Exception as e: if attempt == max_retries - 1: # 마지막 시도 실패 시 에러 메시지 반환 return ToolMessage( content=f"{max_retries}번 재시도 후 실패: {str(e)}", tool_call_id=request.tool_call["id"] ) # 재시도 전 대기 time.sleep(delay * (attempt + 1)) # 여러 미들웨어 적용 agent = create_agent( model=llm, tools=[get_weather], middleware=[retry_on_failure, handle_tool_errors], system_prompt="당신은 날씨 정보 제공 전문 어시스턴트입니다." ) \n```\n\n### 로깅 미들웨어\n\n도구 실행을 추적하는 로깅 미들웨어입니다.\n\n```\nimport logging from datetime import datetime from langchain.agents.middleware import wrap_tool_call logger = logging.getLogger(__name__) @wrap_tool_call def log_tool_execution(request, handler): """도구 실행을 로깅하는 미들웨어""" tool_name = request.tool_call.get("name", "unknown") args = request.tool_call.get("args", {}) # 실행 전 로깅 start_time = datetime.now() logger.info(f"도구 실행 시작: {tool_name}, 인자: {args}") try: # 도구 실행 result = handler(request) # 성공 로깅 duration = (datetime.now() - start_time).total_seconds() logger.info(f"도구 실행 성공: {tool_name}, 소요시간: {duration}초") return result except Exception as e: # 실패 로깅 duration = (datetime.now() - start_time).total_seconds() logger.error(f"도구 실행 실패: {tool_name}, 소요시간: {duration}초, 오류: {str(e)}") raise # 로깅 설정 logging.basicConfig(level=logging.INFO) # 로깅 미들웨어 적용 agent = create_agent( model=llm, tools=[get_weather], middleware=[log_tool_execution, retry_on_failure, handle_tool_errors], system_prompt="당신은 날씨 정보 제공 전문 어시스턴트입니다." ) \n```\n\n## 전체 실행 예제\n\n환경 설정부터 에이전트 실행까지 전체 코드입니다.\n\n```\nimport os import requests import logging from datetime import datetime from langchain.tools import tool from langchain.agents import create_agent from langchain.agents.middleware import wrap_tool_call from langchain_core.messages import ToolMessage, HumanMessage from langchain_openai import ChatOpenAI # 로깅 설정 logging.basicConfig(level=logging.INFO) logger = logging.getLogger(__name__) # 환경 변수 설정 (실제 사용 시 .env 파일 사용 권장) os.environ[\'OPENWEATHERMAP_API_KEY\'] = \'your_api_key_here\' os.environ[\'OPENAI_API_KEY\'] = \'your_openai_key_here\' # 1. 커스텀 도구 정의 @tool def get_weather(location: str) -&gt; str: """주어진 위치의 현재 날씨 정보를 조회합니다. Args: location: 날씨를 조회할 도시 이름 (영어) Returns: 날씨 정보 문자열 (설명, 온도, 습도 포함) """ api_key = os.getenv(\'OPENWEATHERMAP_API_KEY\') if not api_key: raise ValueError("OpenWeatherMap API 키가 설정되지 않았습니다.") base_url = "http://api.openweathermap.org/data/2.5/weather" location = location.strip("\'\\"") params = { "q": location, "appid": api_key, "units": "metric", "lang": "kr" } response = requests.get(base_url, params=params) response.raise_for_status() data = response.json() weather_description = data["weather"][0]["description"] temperature = data["main"]["temp"] humidity = data["main"]["humidity"] return ( f"{location}의 현재 날씨:\\n" f"- 상태: {weather_description}\\n" f"- 온도: {temperature}°C\\n" f"- 습도: {humidity}%" ) # 2. 미들웨어 정의 @wrap_tool_call def log_tool_execution(request, handler): """도구 실행을 로깅하는 미들웨어""" tool_name = request.tool_call.get("name", "unknown") start_time = datetime.now() logger.info(f"도구 실행 시작: {tool_name}") try: result = handler(request) duration = (datetime.now() - start_time).total_seconds() logger.info(f"도구 실행 성공: {tool_name}, 소요시간: {duration}초") return result except Exception as e: duration = (datetime.now() - start_time).total_seconds() logger.error(f"도구 실행 실패: {tool_name}, 소요시간: {duration}초") raise @wrap_tool_call def handle_tool_errors(request, handler): """도구 실행 중 발생하는 에러를 처리하는 미들웨어""" try: return handler(request) except requests.exceptions.HTTPError as e: return ToolMessage( content=f"날씨 API 요청 실패: {e.response.status_code}", tool_call_id=request.tool_call["id"] ) except requests.exceptions.RequestException as e: return ToolMessage( content=f"네트워크 오류 발생: {str(e)}", tool_call_id=request.tool_call["id"] ) except Exception as e: return ToolMessage( content=f"도구 실행 오류: {str(e)}", tool_call_id=request.tool_call["id"] ) # 3. 에이전트 생성 llm = ChatOpenAI(model="gpt-4o-mini", temperature=0) agent = create_agent( model=llm, tools=[get_weather], middleware=[log_tool_execution, handle_tool_errors], system_prompt="""당신은 날씨 정보 제공 전문 어시스턴트입니다. 사용자가 날씨를 질문하면 get_weather 도구를 사용하여 정확한 정보를 제공합니다. 도시 이름은 반드시 영어로 변환하여 조회합니다. 예: 서울 → Seoul, 뉴욕 → New York, 도쿄 → Tokyo""" ) # 4. 에이전트 실행 def run_weather_query(query: str): """날씨 질의를 실행하고 결과를 출력합니다.""" print(f"\\n질문: {query}") print("-" * 50) result = agent.invoke({ "messages": [{"role": "user", "content": query}] }) answer = result["messages"][-1].content print(f"답변:\\n{answer}") print("-" * 50) # 실행 예제 if __name__ == "__main__": # 단일 도시 조회 run_weather_query("서울 날씨 알려줘") # 여러 도시 조회 run_weather_query("서울, 뉴욕, 도쿄의 날씨를 비교해줘") # 대화형 실행 예제 messages = [] # 첫 번째 질문 messages.append(HumanMessage(content="파리 날씨 알려줘")) result = agent.invoke({"messages": messages}) messages.extend(result["messages"]) print(f"\\n질문: 파리 날씨 알려줘") print(f"답변: {result[\'messages\'][-1].content}") # 후속 질문 (컨텍스트 유지) messages.append(HumanMessage(content="거기 우산 필요할까?")) result = agent.invoke({"messages": messages}) print(f"\\n질문: 거기 우산 필요할까?") print(f"답변: {result[\'messages\'][-1].content}") \n```\n\n**실행 결과**:\n\n```\n질문: 서울 날씨 알려줘 -------------------------------------------------- INFO:__main__:도구 실행 시작: get_weather INFO:__main__:도구 실행 성공: get_weather, 소요시간: 0.35초 답변: 서울의 현재 날씨: - 상태: 맑음 - 온도: 26.8°C - 습도: 62% -------------------------------------------------- 질문: 서울, 뉴욕, 도쿄의 날씨를 비교해줘 -------------------------------------------------- INFO:__main__:도구 실행 시작: get_weather INFO:__main__:도구 실행 성공: get_weather, 소요시간: 0.32초 INFO:__main__:도구 실행 시작: get_weather INFO:__main__:도구 실행 성공: get_weather, 소요시간: 0.28초 INFO:__main__:도구 실행 시작: get_weather INFO:__main__:도구 실행 성공: get_weather, 소요시간: 0.41초 답변: 세 도시의 현재 날씨를 비교하면: 서울: 맑음, 26.8°C, 습도 62% 뉴욕: 흐림, 20.1°C, 습도 71% 도쿄: 비, 23.5°C, 습도 85% 서울이 가장 따뜻하고 맑은 날씨이며, 도쿄는 비가 오고 있습니다. -------------------------------------------------- \n```\n\n## 고급 기능\n\n### 구조화된 출력 도구\n\nPydantic 모델을 사용하여 구조화된 출력을 반환하는 도구를 만들 수 있습니다.\n\n```\nfrom typing import List from pydantic import BaseModel, Field from langchain.tools import tool class WeatherData(BaseModel): """날씨 정보 데이터 모델""" location: str = Field(description="도시 이름") description: str = Field(description="날씨 설명") temperature: float = Field(description="섭씨 온도") humidity: int = Field(description="습도(%)") wind_speed: float = Field(description="풍속(m/s)") @tool def get_weather_structured(location: str) -&gt; WeatherData: """구조화된 형태로 날씨 정보를 반환합니다.""" api_key = os.getenv(\'OPENWEATHERMAP_API_KEY\') base_url = "http://api.openweathermap.org/data/2.5/weather" params = { "q": location, "appid": api_key, "units": "metric", "lang": "kr" } response = requests.get(base_url, params=params) response.raise_for_status() data = response.json() return WeatherData( location=location, description=data["weather"][0]["description"], temperature=data["main"]["temp"], humidity=data["main"]["humidity"], wind_speed=data["wind"]["speed"] ) \n```\n\n### ToolRuntime 타입 힌트\n\n`ToolRuntime`에 제네릭 타입을 사용하여 Context와 State의 타입을 명시할 수 있습니다. 이를 통해 IDE 자동완성과 타입 체크가 가능해집니다.\n\n```\nfrom langchain.tools import tool, ToolRuntime from dataclasses import dataclass from typing import TypedDict, Annotated from langgraph.graph import add_messages # Context 타입 정의 @dataclass class AppContext: user_id: str api_key: str region: str = "KR" # State 타입 정의 class AppState(TypedDict): messages: Annotated[list, add_messages] request_count: int # 타입 힌트를 사용한 도구 정의 @tool def get_user_weather( location: str, runtime: ToolRuntime[AppContext, AppState] ) -&gt; str: """사용자 컨텍스트를 활용한 날씨 조회 Args: location: 조회할 도시 이름 """ # Context 접근 (타입 체크 가능) user_id = runtime.context.user_id api_key = runtime.context.api_key # State 접근 (IDE 자동완성 지원) count = runtime.state.get("request_count", 0) return f"User {user_id}의 {location} 날씨 조회 (총 {count}회)" \n```\n\n### 비동기 도구\n\n비동기 작업을 수행하는 도구는 `async`와 `await`를 사용합니다.\n\n```\nimport httpx from langchain.tools import tool @tool async def get_weather_async(location: str) -&gt; str: """비동기로 날씨 정보를 조회합니다.""" api_key = os.getenv(\'OPENWEATHERMAP_API_KEY\') base_url = "http://api.openweathermap.org/data/2.5/weather" params = { "q": location, "appid": api_key, "units": "metric", "lang": "kr" } async with httpx.AsyncClient() as client: response = await client.get(base_url, params=params) response.raise_for_status() data = response.json() return ( f"{location}의 현재 날씨:\\n" f"- 상태: {data[\'weather\'][0][\'description\']}\\n" f"- 온도: {data[\'main\'][\'temp\']}°C" ) # 비동기 에이전트 실행 async def main(): result = await agent.ainvoke({ "messages": [{"role": "user", "content": "서울 날씨 알려줘"}] }) print(result["messages"][-1].content) # 실행 import asyncio asyncio.run(main()) \n```\n\n## 정리\n\nLangChain v1.0의 커스텀 도구 시스템은 다음과 같은 특징을 가집니다.\n\n## 주의사항\n\n* **예약 파라미터**: `config`와 `runtime`은 도구 인자 이름으로 사용 불가\n* OpenWeatherMap API 키가 필요합니다: &lt;https://openweathermap.org/&gt;\n* 도시 이름은 영어로 입력해야 정확한 결과를 얻을 수 있습니다\n* API 키는 환경 변수나 `.env` 파일로 관리하며, 코드에 직접 노출하지 않습니다\n* 프로덕션 환경에서는 API 호출 횟수 제한과 캐싱을 고려해야 합니다\n* 미들웨어는 실행 순서가 중요하므로, 로깅 → 재시도 → 에러 처리 순서를 권장합니다\n\n마지막 편집일시 : 2026년 1월 10일 10:49 오전\n\n광고가 출력될 위치입니다.\n\n광고가 출력될 위치입니다.\n\n[댓글 0](javascript:show_comments();) [피드백](#myModal "피드백을 남겨주세요")\n\n[※ 댓글 작성은 로그인이 필요합니다.](/loginForm) [(또는 피드백을 이용해 주세요.)](#myModal)\n\n* **이전글** : [3-2. 내장 도구](javascript:page(261567))\n* **다음글** : [3-4. ToolRuntime &amp; 컨텍스트](javascript:page(319020))\n\n  \n\n#### 책갈피\n\n### 이 페이지에 대한 피드백을 남겨주세요\n\n### 댓글을 신고합니다.'},
 {'title': 'LangChain에 대하여 |',
  'url': 'https://ncsoft.github.io/ncresearch/f4a00ed849299e3c91fb3244e74ea7f9b974ebb7',
  'content': '# LangChain에 대하여\n\n오진균(Oh Jinkyun)\n\nJune 23, 2023\n\n 개요\n 해결하려는 문제\n 모듈\n 예제: 단순한 챗봇\n  + 단순 질문-응답기\n  + 대화 맥락 기억하기\n  + 길이 줄이기\n 예제: Agent\n 예제: 실제 LLM(OpenAI)으로 Agent 실행\n 결론\n References\n\n# 개요\n\nOpenAI의 ChatGPT 이래로 LLM(Large Language Model)은 AI, NLP 관련자들 뿐만 아니라 사회 전반적인 화제가 되고 있습니다.\n\nLangChain은 이런 LLM을 좀 더 쉽게 사용할 수 있도록 개념들을 추상화하여, LLM을 사용하면서 편리할만한 패턴들을 규격화시킨 프레임워크입니다.\n\n이 글에서는 LangChain의 주요 모듈에 대한 간략한 설명과, LangChain이 어떤 편리함을 제공하고 어떻게 활용해볼 수 있을지 예제를 통해 알아보겠습니다.\n\nLangChain은 Javascript 버전과 Python 버전을 제공하는데, 이 글은 이 둘 중에서 주로 Python을 사용하여 설명하겠습니다.\n\n# 해결하려는 문제\n\nOpenAI의 ChatGPT, 혹은 Bing의 BingChat 같은 서비스를 사용해보면 채팅만 입력하면 바로 봇과 채팅하는 것 같이 사용할 수 있도록 편리한 인터페이스를 제공합니다. 하지만 그 뒤에 있는 중추적 기능인 LLM은 어떤 글에 대한 답이 될만한 글을 생성할 뿐이지 웹페이지에 채팅 형식으로 표시되기 위한 여러가지 밑작업까지 해결해주지는 않습니다.\n\nLLM을 사용하여 챗봇을 구현하기 위해 필요한 작업들을 대략 나열해보자면 아래와 같습니다. [...] 다른 모듈들을 묶어서 같이 맞물려 동작할 수 있도록 해주는 중심적인 모듈입니다. 체인을 생성하면서 해당 체인에 어떤 Model을 사용하고, 어떤 Prompt를 사용하고, 어떤 Memory를 사용할지 등등을 결정합니다.\n Agents:\n\n  LLM이 직접 답하는 것이 아니라 다른 외부의 도구를 사용하는 것이 더 정확하거나 유용한 것들, 이를테면 수학적인 계산이나 잘 구조화 된 데이터의 조회(예시: 특정 배우의 나이, 출연작을 조회하고 싶다)같은 LLM 외부 기능이 필요할 때에 호출될 수 있는 인터페이스를 제공하는 모듈입니다. 도구의 호출 방식을 규격화하는 Tool이 같이 사용됩니다.\n Callbacks:\n\n  LangChain의 각 동작 단계마다 hooking을 할 수 있도록 Callback을 제공합니다. 모니터링, 로깅이나 스트리밍에 관련된 기능이기 때문에 이 글에서는 자세히 다루지 않을 예정입니다.\n\n# 예제: 단순한 챗봇\n\n## 단순 질문-응답기\n\n우선 테스트를 위해 가짜 LLM을 만들겠습니다. 공식 문서에서 Custom LLM을 작성하는 방법에 대해 설명하고 있습니다.\n\nCustom LLM의 최소한의 구현은 `_call` 함수만 구현하면 됩니다. 실제 LLM을 통한 구현이라면 `_call` 함수의 인자로 받은 prompt를 LLM에 넘기는 등의 동작을 하겠지만, 이 예제에서는 무조건 초기화 할 때 `reply`로 주어진 문자열을 반환하도록 Custom LLM을 작성하였습니다. [...] Answer the following questions as best you can. You have access to the following tools: Python REPL: A Python shell. Use this to execute python commands. Input should be a valid python command. If you want to see the output of a value, you should print it out with `print(...)`. requests_get: A portal to the internet. Use this when you need to get specific content from a website. Input should be a url (i.e.  The output will be the text response of the GET request. Use the following format: Question: the input question you must answer Thought: you should always think about what to do Action: the action to take, should be one of [Python REPL, requests_get] Action Input: the input to the action Observation: the result of the action ... (this Thought/Action/Action Input/Observation can repeat',
  'score': 0.6972179,
  'raw_content': '# LangChain에 대하여\n\n오진균(Oh Jinkyun)\n\nJune 23, 2023\n\n* [개요](#개요)\n* [해결하려는 문제](#해결하려는-문제)\n* [모듈](#모듈)\n* [예제: 단순한 챗봇](#예제-단순한-챗봇)\n  + [단순 질문-응답기](#단순-질문-응답기)\n  + [대화 맥락 기억하기](#대화-맥락-기억하기)\n  + [길이 줄이기](#길이-줄이기)\n* [예제: Agent](#예제-agent)\n* [예제: 실제 LLM(OpenAI)으로 Agent 실행](#예제-실제-llmopenai으로-agent-실행)\n* [결론](#결론)\n* [References](#references)\n\n# 개요\n\nOpenAI의 ChatGPT 이래로 LLM(Large Language Model)은 AI, NLP 관련자들 뿐만 아니라 사회 전반적인 화제가 되고 있습니다.\n\n[LangChain](https://docs.langchain.com/docs/)은 이런 LLM을 좀 더 쉽게 사용할 수 있도록 개념들을 추상화하여, LLM을 사용하면서 편리할만한 패턴들을 규격화시킨 프레임워크입니다.\n\n이 글에서는 LangChain의 주요 모듈에 대한 간략한 설명과, LangChain이 어떤 편리함을 제공하고 어떻게 활용해볼 수 있을지 예제를 통해 알아보겠습니다.\n\nLangChain은 [Javascript 버전](https://js.langchain.com/docs/)과 [Python](https://python.langchain.com/en/latest/) 버전을 제공하는데, 이 글은 이 둘 중에서 주로 Python을 사용하여 설명하겠습니다.\n\n# 해결하려는 문제\n\nOpenAI의 ChatGPT, 혹은 Bing의 BingChat 같은 서비스를 사용해보면 채팅만 입력하면 바로 봇과 채팅하는 것 같이 사용할 수 있도록 편리한 인터페이스를 제공합니다. 하지만 그 뒤에 있는 중추적 기능인 LLM은 어떤 글에 대한 답이 될만한 글을 생성할 뿐이지 웹페이지에 채팅 형식으로 표시되기 위한 여러가지 밑작업까지 해결해주지는 않습니다.\n\nLLM을 사용하여 챗봇을 구현하기 위해 필요한 작업들을 대략 나열해보자면 아래와 같습니다.\n\n1. 챗봇의 정책을 세우기 위해 숨겨진 프롬프트를 지정하고 매 호출마다 LLM이 해당 내용을 최초에 제공받을 수 있게 합니다.\n2. 대화의 맥락을 기억합니다.\n3. 대화가 너무 길어지면 앞 부분을 자르거나 요약하는 등 LLM이 처리하기 용이한 사이즈를 유지하게 해줍니다.\n4. LLM의 답변에서 인터넷에 접속하여 내용을 보충할 수 있을만한 부분을 인터넷에 접속하여 보충합니다. (Bing의 BingChat이나 Google의 Bard의 기능)\n\n이러한 문제를 해결하기 위해서 LangChain은 여러 형태의 추상화된 인터페이스를 제공하고, 기본적으로 제공되는 구현을 사용하거나 혹은 자기가 원하는 정책을 직접 구현하여 연쇄적인 체인(Chain)의 한 부분으로 동작하게 할 수 있습니다. 또한 LangChain에는 챗봇 뿐만이 아니라, 연쇄적인 동작이 필요한 다른 시나리오도 해결하려고 하고 있습니다.\n\n이러한 기능을 구현하는 데에 주축이 되는 중요한 모듈들에 대해 우선 설명하겠습니다.\n\n# 모듈\n\n[LangChain의 문서](https://python.langchain.com/en/latest/index.html)의 목차에서는 가장 대표적인 것으로 아래의 모듈들을 명시하고 있습니다.\n\n각 모듈들의 종류와 간략한 설명은 아래와 같습니다.\n\n* Models:\n\n  LLM을 나타냅니다. 질문을 넣으면 답변을 하거나, 미완성 된 문자열을 넣으면 완성을 하는 등의 기능을 제공합니다. LLM과 ChatModel이라는 클래스가 있는데, 2023년 6월 현재 ChatModel의 API가 확정되지 않아서 아직 Custom ChatModel을 만들 수 있는 방법이 제공되지 않고 있습니다. 이 글에서는 LLM 클래스만을 언급하겠습니다.\n* Prompts:\n\n  말그대로 LLM에 들어갈 프롬프트를 추상화시킨 템플릿입니다. 사용자에게는 일반적으로 노출하지 않는 숨겨진 프롬프트나 후에 언급할 Memory, 혹은 채팅의 경우 메시지 목록을 LLM에 입력할 수 있도록 문자열을 잘 조립하여 반환하는 기능을 제공합니다.\n* Memory:\n\n  채팅 기록이나 특정 시점에서 이전의 상호작용을 기억하기 위한 저장소와 같이 사용됩니다. 입력과 출력의 History를 저장하는 리스트라고 생각하면 됩니다.\n* Indexes:\n\n  LLM이 쉽게 접근할 수 있도록 문서에 접근하는 표준적인 인터페이스를 제공합니다. 이를테면 Retrievers가 있는데, 어떤 문자열을 주고 그 문자열과 관련된 Document(이 목록에는 없지만 Document 또한 LangChain에서 정의해놓은 클래스입니다)의 목록을 불러오는 기능을 제공합니다. 이 모듈에 대해서는 이 글에서는 자세히 다루지 않겠습니다.\n* Chains:\n\n  다른 모듈들을 묶어서 같이 맞물려 동작할 수 있도록 해주는 중심적인 모듈입니다. 체인을 생성하면서 해당 체인에 어떤 Model을 사용하고, 어떤 Prompt를 사용하고, 어떤 Memory를 사용할지 등등을 결정합니다.\n* Agents:\n\n  LLM이 직접 답하는 것이 아니라 다른 외부의 도구를 사용하는 것이 더 정확하거나 유용한 것들, 이를테면 수학적인 계산이나 잘 구조화 된 데이터의 조회(예시: 특정 배우의 나이, 출연작을 조회하고 싶다)같은 LLM 외부 기능이 필요할 때에 호출될 수 있는 인터페이스를 제공하는 모듈입니다. 도구의 호출 방식을 규격화하는 Tool이 같이 사용됩니다.\n* Callbacks:\n\n  LangChain의 각 동작 단계마다 hooking을 할 수 있도록 Callback을 제공합니다. 모니터링, 로깅이나 스트리밍에 관련된 기능이기 때문에 이 글에서는 자세히 다루지 않을 예정입니다.\n\n# 예제: 단순한 챗봇\n\n## 단순 질문-응답기\n\n우선 테스트를 위해 가짜 LLM을 만들겠습니다. 공식 문서에서 [Custom LLM을 작성하는 방법](https://python.langchain.com/en/latest/modules/models/llms/examples/custom_llm.html)에 대해 설명하고 있습니다.\n\nCustom LLM의 최소한의 구현은 `_call` 함수만 구현하면 됩니다. 실제 LLM을 통한 구현이라면 `_call` 함수의 인자로 받은 prompt를 LLM에 넘기는 등의 동작을 하겠지만, 이 예제에서는 무조건 초기화 할 때 `reply`로 주어진 문자열을 반환하도록 Custom LLM을 작성하였습니다.\n\n```\n# custom_llm.py from typing import Any, List, Mapping, Optional fromlangchain.callbacks.manager import CallbackManagerForLLMRun fromlangchain.llms.base import LLM class CustomLLM(LLM): reply: str @ property def _llm_type(self) -&gt; str: return "custom" def _call(self, prompt: str, stop: Optional[List[str]] = None, run_manager: Optional[CallbackManagerForLLMRun] = None,) -&gt; str: return self. reply @ property def _identifying_params(self) -&gt; Mapping[str, Any]:"""Get the identifying parameters.""" return{"reply": self. reply}\n```\n\n위의 가짜 LLM 클래스를 테스트해 보려면 인스턴스를 만든 후 바로 함수처럼 호출하면 됩니다.\n\n```\nllm = CustomLLM(reply =\'나는 제대로 된 LLM이 아니라서 항상 같은 대답만 합니다.\') print(llm(\'당신은 어떤 질문에 대해 답할 수 있습니까?\'))\n```\n\n*출력:*\n\n```\n나는 제대로 된 LLM이 아니라서 항상 같은 대답만 합니다. \n```\n\n이 LLM을 사용하여 가장 간단한 Chain부터 점점 기능을 더하면서 진행하겠습니다. 우선은 가장 간단한, 프롬프트를 가질 뿐인 질문/답변 기능을 만들겠습니다.\n\n```\n# app/ex01_basic.py from langchain import PromptTemplate, LLMChain fromapp.custom_llm import CustomLLM llm = CustomLLM(reply =\'나는 제대로 된 LLM이 아니라서 항상 같은 대답만 합니다.\') template =""" 당신은 AI 도우미로서 질의자 \'사람\'이 하는 질문에 대해서 성실하게 대답해야 합니다. 당신은 스스로가 가지지 않은 능력이 필요한 질문을 받았을 때에는 자신의 한계에 대해서 솔직하게 말해야 합니다. 사람: {question} """ prompt = PromptTemplate(input_variables =["question"], template = template,) chain = LLMChain(llm = llm, prompt = prompt, verbose = True) if __name__ == \'__main__\': print(chain. run(\'당신은 어떤 능력을 가지고 있습니까?\'))\n```\n\n*출력:*\n\n```\n&gt; Entering new chain... Prompt after formatting: 당신은 AI 도우미로서 질의자 \'사람\'이 하는 질문에 대해서 성실하게 대답해야 합니다. 당신은 스스로가 가지지 않은 능력이 필요한 질문을 받았을 때에는 자신의 한계에 대해서 솔직하게 말해야 합니다. 사람: 당신은 어떤 능력을 가지고 있습니까? &gt; Finished chain. 나는 제대로 된 LLM이 아니라서 항상 같은 대답만 합니다. \n```\n\n위와 같이 PromptTemplate와 LLMChain을 이용하여 chain을 구성해 놓으면 `chain.run` 함수를 이용하여 질문만 바꿔가며 LLM에 여러가지 질문을 할 수 있습니다. FastAPI나 Flask 같은 웹 프레임워크를 사용하면 이를 간단하게 서버로 만들어 테스트해볼 수도 있습니다.\n\n```\nfrom fastapi import FastAPI fromapp.ex01_basic import chain app = FastAPI() @ app. get(\'/\') def answer_with_llm(question): return chain. run(question)\n```\n\n명령창:\n\n```\n$ --reload\n```\n\n*“정말로 어떤 질문을 해도 똑같은 대답만 합니까?”라는 질문을 하면 “나는 제대로 된 LLM이 아니라서 항상 같은 대답만 합니다.”라는 답변이 돌아오는 OpenAPI 테스트의 이미지*\n\n## 대화 맥락 기억하기\n\n하지만 위에서 만든 chain은 대화의 맥락을 기억하지 못하고 하나의 질문에만 답할 수 있습니다. ChatGPT 같은 서비스처럼 대화의 맥락을 LLM에게 전달하기 위해서는 지금까지 해온 모든 대화의 내용을 LLM에 전달할 필요가 있습니다. 이를 위해 존재하는 것이 Memory입니다. Memory에서 기본적으로 사용하는 key와 맞추기 위해 template을 조금 변경한 뒤, 이 모두를 Chain에 연결하겠습니다.\n\n```\n# app/ex02_memory.py from pprint import pprint from langchain import PromptTemplate fromlangchain.memory import ConversationBufferMemory fromlangchain.chains import ConversationChain fromapp.custom_llm import CustomLLM llm = CustomLLM(reply =\'나는 제대로 된 LLM이 아니라서 항상 같은 대답만 합니다.\') template =""" 당신은 AI 도우미로서 질의자 \'사람\'이 하는 질문에 대해서 성실하게 대답해야 합니다. 당신은 스스로가 가지지 않은 능력이 필요한 질문을 받았을 때에는 자신의 한계에 대해서 솔직하게 말해야 합니다. {history} 사람: {input} """ prompt = PromptTemplate(input_variables =["history", "input"], template = template,) memory = ConversationBufferMemory(human_prefix = \'사람\', ai_prefix = \'AI\') chain = ConversationChain(llm = llm, prompt = prompt, memory = memory, verbose = True) chain. predict(input = \'당신은 어떤 능력을 가지고 있습니까?\') chain. predict(input = \'정말 항상 같은 대답만 합니까?\') chain. predict(input =\'하지만 이전에 했던 대화들은 기억하고 있으리라 믿습니다.\') pprint(memory. chat_memory. messages)\n```\n\n*출력:*\n\n```\n&gt; Entering new chain... Prompt after formatting: 당신은 AI 도우미로서 질의자 \'사람\'이 하는 질문에 대해서 성실하게 대답해야 합니다. 당신은 스스로가 가지지 않은 능력이 필요한 질문을 받았을 때에는 자신의 한계에 대해서 솔직하게 말해야 합니다. 사람: 당신은 어떤 능력을 가지고 있습니까? &gt; Finished chain. &gt; Entering new chain... Prompt after formatting: 당신은 AI 도우미로서 질의자 \'사람\'이 하는 질문에 대해서 성실하게 대답해야 합니다. 당신은 스스로가 가지지 않은 능력이 필요한 질문을 받았을 때에는 자신의 한계에 대해서 솔직하게 말해야 합니다. 사람: 당신은 어떤 능력을 가지고 있습니까? AI: 나는 제대로 된 LLM이 아니라서 항상 같은 대답만 합니다. 사람: 정말 항상 같은 대답만 합니까? &gt; Finished chain. &gt; Entering new chain... Prompt after formatting: 당신은 AI 도우미로서 질의자 \'사람\'이 하는 질문에 대해서 성실하게 대답해야 합니다. 당신은 스스로가 가지지 않은 능력이 필요한 질문을 받았을 때에는 자신의 한계에 대해서 솔직하게 말해야 합니다. 사람: 당신은 어떤 능력을 가지고 있습니까? AI: 나는 제대로 된 LLM이 아니라서 항상 같은 대답만 합니다. 사람: 정말 항상 같은 대답만 합니까? AI: 나는 제대로 된 LLM이 아니라서 항상 같은 대답만 합니다. 사람: 하지만 이전에 했던 대화들은 기억하고 있으리라 믿습니다. &gt; Finished chain. [HumanMessage(content=\'당신은 어떤 능력을 가지고 있습니까?\', additional_kwargs={}, example=False), AIMessage(content=\'나는 제대로 된 LLM이 아니라서 항상 같은 대답만 합니다.\', additional_kwargs={}, example=False), HumanMessage(content=\'정말 항상 같은 대답만 합니까?\', additional_kwargs={}, example=False), AIMessage(content=\'나는 제대로 된 LLM이 아니라서 항상 같은 대답만 합니다.\', additional_kwargs={}, example=False), HumanMessage(content=\'하지만 이전에 했던 대화들은 기억하고 있으리라 믿습니다.\', additional_kwargs={}, example=False), AIMessage(content=\'나는 제대로 된 LLM이 아니라서 항상 같은 대답만 합니다.\', additional_kwargs={}, example=False)] \n```\n\nConversationBufferMemory는 Message의 리스트의 형태로 지난 입력과 출력들을 기억하고, 프롬프트의 history에는 기존 대화들을, input에는 이번 사용자 입력이 들어가게 해줍니다. ConversationChain이 이러한 과정을 처리해줍니다.\n\nChain 생성시의 `verbose=True` 인자 때문에 `chain.predict`를 세 번 호출하면서 `{history}`에 기존 대화의 내용들이 누적되어 입력되는 것을 볼 수 있습니다. 마지막으로 `memory.chat_memory.messages`를 출력해보면 `HumanMessage`와 `AIMessage`가 번갈아가며 리스트 형태로 기억되고 있는 것을 볼 수 있습니다. 이러한 기능을 웹에서 사용하려면 사용자를 식별하여 접속 종료시 History를 DB에 보존하고 재접속시 다시 불러와서 초기화하는 추가적인 코드가 필요합니다.\n\n그런 처리를 쉽게 하기 위하여 히스토리를 `dict`로 변환하거나 `dict`에서 히스토리를 생성하는 방법은 [문서에 관련 내용](https://python.langchain.com/en/latest/modules/memory/getting_started.html#saving-message-history)이 있습니다.\n\n## 길이 줄이기\n\n챗봇 같은 서비스에서 LLM과 나누는 대화가 길어졌을 때, LLM에 모든 대화가 들어가면 물론 이상적이겠지만 성능이나 비용의 문제로 입력의 길이에 어느정도 제한을 두는 것이 현실적입니다.\n\n이를 처리하는 가장 인기 있는 전략의 두가지 중 하나는 가장 최근의 몇 개 대화만을 LLM에 넘겨주는 것이고, 다른 하나는 앞의 내용을 LLM을 통하여 요약하는 방법이 있겠습니다.\n\n두 가지 전략 모두 LangChain에 구현체가 있는데, 전자는 `ConversationBufferWindowMemory`라는 클래스로 구현되어 있고, 후자는 `ConversationSummaryMemory`나 `ConversationSummaryBufferMemory`가 있습니다.\n\n이외에도 다른 전략이나 히스토리의 저장과 복구에 관련된 구현체가 존재합니다. Memory에 관한 [How-To Guides](https://python.langchain.com/en/latest/modules/memory/how_to_guides.html)에 관련 내용이 서술되어 있습니다.\n\n이 글에서는 가장 간단한 `ConversationBufferWindowMemory`를 사용하겠습니다.\n\n```\n# app/ex03_memwindow.py from pprint import pprint from langchain import PromptTemplate fromlangchain.memory import ConversationBufferWindowMemory fromlangchain.chains import ConversationChain fromapp.custom_llm import CustomLLM llm = CustomLLM(reply =\'나는 제대로 된 LLM이 아니라서 항상 같은 대답만 합니다.\') template =""" 당신은 AI 도우미로서 질의자 \'사람\'이 하는 질문에 대해서 성실하게 대답해야 합니다. 당신은 스스로가 가지지 않은 능력이 필요한 질문을 받았을 때에는 자신의 한계에 대해서 솔직하게 말해야 합니다. {history} 사람: {input} """ prompt = PromptTemplate(input_variables =["history", "input"], template = template,) memory = ConversationBufferWindowMemory(human_prefix = \'사람\', ai_prefix = \'AI\', k = 3) chain = ConversationChain(llm = llm, prompt = prompt, memory = memory, verbose = True) chain. predict(input =\'당신의 기억력을 테스트하려고 합니다.\') for idx in range(10): chain. predict(input = f \'이것은 {idx}번째 질문입니다.\') chain. predict(input = "이제 몇 번째 전 대화까지 기억하고 있는지 보여주세요") pprint(memory. chat_memory. messages)\n```\n\n*출력:*\n\n```\n&gt; Entering new chain... Prompt after formatting: 당신은 AI 도우미로서 질의자 \'사람\'이 하는 질문에 대해서 성실하게 대답해야 합니다. 당신은 스스로가 가지지 않은 능력이 필요한 질문을 받았을 때에는 자신의 한계에 대해서 솔직하게 말해야 합니다. 사람: 당신의 기억력을 테스트하려고 합니다. &gt; Finished chain. &gt; Entering new chain... Prompt after formatting: 당신은 AI 도우미로서 질의자 \'사람\'이 하는 질문에 대해서 성실하게 대답해야 합니다. 당신은 스스로가 가지지 않은 능력이 필요한 질문을 받았을 때에는 자신의 한계에 대해서 솔직하게 말해야 합니다. 사람: 당신의 기억력을 테스트하려고 합니다. AI: 나는 제대로 된 LLM이 아니라서 항상 같은 대답만 합니다. 사람: 이것은 0번째 질문입니다. &gt; Finished chain. &lt;...중략...&gt; &gt; Finished chain. &gt; Entering new chain... Prompt after formatting: 당신은 AI 도우미로서 질의자 \'사람\'이 하는 질문에 대해서 성실하게 대답해야 합니다. 당신은 스스로가 가지지 않은 능력이 필요한 질문을 받았을 때에는 자신의 한계에 대해서 솔직하게 말해야 합니다. 사람: 이것은 7번째 질문입니다. AI: 나는 제대로 된 LLM이 아니라서 항상 같은 대답만 합니다. 사람: 이것은 8번째 질문입니다. AI: 나는 제대로 된 LLM이 아니라서 항상 같은 대답만 합니다. 사람: 이것은 9번째 질문입니다. AI: 나는 제대로 된 LLM이 아니라서 항상 같은 대답만 합니다. 사람: 이제 몇 번째 전 대화까지 기억하고 있는지 보여주세요 &gt; Finished chain. [HumanMessage(content=\'당신의 기억력을 테스트하려고 합니다.\', additional_kwargs={}, example=False), AIMessage(content=\'나는 제대로 된 LLM이 아니라서 항상 같은 대답만 합니다.\', additional_kwargs={}, example=False), HumanMessage(content=\'이것은 0번째 질문입니다.\', additional_kwargs={}, example=False), AIMessage(content=\'나는 제대로 된 LLM이 아니라서 항상 같은 대답만 합니다.\', additional_kwargs={}, example=False), HumanMessage(content=\'이것은 1번째 질문입니다.\', additional_kwargs={}, example=False), AIMessage(content=\'나는 제대로 된 LLM이 아니라서 항상 같은 대답만 합니다.\', additional_kwargs={}, example=False), HumanMessage(content=\'이것은 2번째 질문입니다.\', additional_kwargs={}, example=False), AIMessage(content=\'나는 제대로 된 LLM이 아니라서 항상 같은 대답만 합니다.\', additional_kwargs={}, example=False), HumanMessage(content=\'이것은 3번째 질문입니다.\', additional_kwargs={}, example=False), AIMessage(content=\'나는 제대로 된 LLM이 아니라서 항상 같은 대답만 합니다.\', additional_kwargs={}, example=False), HumanMessage(content=\'이것은 4번째 질문입니다.\', additional_kwargs={}, example=False), AIMessage(content=\'나는 제대로 된 LLM이 아니라서 항상 같은 대답만 합니다.\', additional_kwargs={}, example=False), HumanMessage(content=\'이것은 5번째 질문입니다.\', additional_kwargs={}, example=False), AIMessage(content=\'나는 제대로 된 LLM이 아니라서 항상 같은 대답만 합니다.\', additional_kwargs={}, example=False), HumanMessage(content=\'이것은 6번째 질문입니다.\', additional_kwargs={}, example=False), AIMessage(content=\'나는 제대로 된 LLM이 아니라서 항상 같은 대답만 합니다.\', additional_kwargs={}, example=False), HumanMessage(content=\'이것은 7번째 질문입니다.\', additional_kwargs={}, example=False), AIMessage(content=\'나는 제대로 된 LLM이 아니라서 항상 같은 대답만 합니다.\', additional_kwargs={}, example=False), HumanMessage(content=\'이것은 8번째 질문입니다.\', additional_kwargs={}, example=False), AIMessage(content=\'나는 제대로 된 LLM이 아니라서 항상 같은 대답만 합니다.\', additional_kwargs={}, example=False), HumanMessage(content=\'이것은 9번째 질문입니다.\', additional_kwargs={}, example=False), AIMessage(content=\'나는 제대로 된 LLM이 아니라서 항상 같은 대답만 합니다.\', additional_kwargs={}, example=False), HumanMessage(content=\'이제 몇 번째 전 대화까지 기억하고 있는지 보여주세요\', additional_kwargs={}, example=False), AIMessage(content=\'나는 제대로 된 LLM이 아니라서 항상 같은 대답만 합니다.\', additional_kwargs={}, example=False)] \n```\n\n위의 출력 결과를 보면 프롬프트에는 Memory를 생성할 때 주어진 `k=3` 인자에 의해 가장 최근의 세 번의 대화만 입력되고 있는 것을 볼 수 있습니다.\n\n하지만 LLM에게 제공하는 것이 마지막의 `k`개일 뿐, `pprint`의 출력 내용으로 확인할 수 있는 것처럼 History 객체는 모든 대화 내용을 보관하고 있습니다. 이는 웹 화면 같은 곳에서 사용자가 볼 채팅 내역과 상태가 일치하도록 하는 데 유용히 사용될 수 있습니다.\n\n지금까지 이야기한 기능들과 더불어, 히스토리 저장과 복구에 관련된 `MongoDBChatMessageHistory` 클래스 등을 추가로 활용한다면 ChatGPT와 비슷한 기능을 구현하는 데에 필요한 도구들이 모두 Langchain에 있다는 것을 확인할 수 있습니다.\n\n# 예제: Agent\n\n`AgentExecutor` 모듈은 특정한 형태로 조립된 Chain으로, 이미 특정한 형식의 숨겨진 Prompt를 갖고 있고, LLM의 답변을 파싱하고, 그 파싱한 결과를 통해 사용자의 추가 입력 없이도 도구를 호출하거나 다시 LLM을 호출하여 답을 도출해냅니다.\n\n아래의 코드는 순서대로 정해진 답을 뱉는 가짜 LLM 구현을 활용하여 두 가지 Tool을 실행해보는 예제입니다.\n\n```\n# app/ex04_agent.py fromlangchain.agents import load_tools, initialize_agent, AgentType fromlangchain.llms.base import LLM class AgentCustomLLM(LLM): replies: list[str] cursor = 0 @ property def _llm_type(self) -&gt; str: return"agent-custom" def _call(self, prompt: str, stop = None, run_manager = None,) -&gt; str: ret = self. replies[self. cursor] self. cursor += 1 return ret llm = AgentCustomLLM(replies =[\'\'\'First, I need to run some python code. Action: Python REPL Action Input: foo = 42 bar = foo + 42 print(bar) \'\'\',\'\'\'Second, I need to show how requests tool works. Action: requests_get Action Input: https://example.com/ \'\'\',\'\'\'I\'ve done what I was requested to do. Final Answer: Done \'\'\',]) tools = load_tools([\'python_repl\', \'requests\']) agent = initialize_agent(tools, llm, agent = AgentType. ZERO_SHOT_REACT_DESCRIPTION, verbose = True) agent. run(\'적당한 Python 코드 실행 예제와 requests 실행 예제를 보여주세요.\')\n```\n\n*출력:*\n\n```\n&gt; Entering new chain... First, I need to run a python code. Action: Python REPL Action Input: foo = 42 bar = foo + 42 print(bar) Observation: 84 Thought: Second, I need to show how requests tool works. Action: requests_get Action Input: https://example.com/ Observation: \n   Example Domain\n\n# Example Domain\n\n\n\nThis domain is for use in illustrative examples in documents. You may use this domain in literature without prior coordination or asking for permission.\n\n\n\nMore information...\n\nThought: I\'ve done what I was requested to do. Final Answer: Done &gt; Finished chain. \n```\n\nAgent를 잘 설정하고 좋은 질문과 좋은 LLM만 있다면 질문 한 번으로 여러 번의 Tool 호출을 거쳐 AI가 스스로 단계별로 생각하는 것처럼 여러 작업을 수행할 수 있습니다.\n\n`AgentExecutor`(`initialize_agent`가 반환하는 것이 이 클래스입니다)는 각 단계마다 LLM이 반환하는 값을 파싱하여 필요한 도구들을 호출합니다.\n\n`AgentExecutor`가 원하는 형식을 알려면 숨겨진 프롬프트 내용을 보면 됩니다.\n\n`_call` 함수에서 `prompt` 인자를 출력해보면 그 내용은 아래와 같습니다.\n\n```\nAnswer the following questions as best you can. You have access to the following tools: Python REPL: A Python shell. Use this to execute python commands. Input should be a valid python command. If you want to see the output of a value, you should print it out with `print(...)`. requests_get: A portal to the internet. Use this when you need to get specific content from a website. Input should be a url (i.e. https://www.google.com). The output will be the text response of the GET request. Use the following format: Question: the input question you must answer Thought: you should always think about what to do Action: the action to take, should be one of [Python REPL, requests_get] Action Input: the input to the action Observation: the result of the action ... (this Thought/Action/Action Input/Observation can repeat N times) Thought: I now know the final answer Final Answer: the final answer to the original input question Begin! Question: 적당한 Python 코드 실행 예제와 requests 실행 예제를 보여주세요. Thought: \n```\n\n숨겨진 프롬프트를 확인하면 AgentExecutor는 Question, Thought, Action, Action Input과 같이 나눠서 기술해주기를 기대한다는 것을 알 수 있습니다. 만약 LLM으로부터 이 형식에 맞지 않는 문자열이 돌아온다면 Agent가 파싱 오류를 내뱉을 수 있으니 적절한 예외처리가 필요합니다.\n\nAgentExecutor는 저 프롬프트를 이용해 Final Answer가 나올 때까지 계속해서 LLM과 Tool을 자동적으로 호출합니다. 따라서 BingChat과 같이 인터넷 상 문서들을 검색하는 기능을 자신의 애플리케이션에 구현하고 싶다면 Agent를 활용할 필요가 있습니다.\n\n# 예제: 실제 LLM(OpenAI)으로 Agent 실행\n\n지금까지는 편의를 위해 완벽하게 통제할 수 있는 가짜 LLM만을 사용했습니다만, 마지막으로 OpenAI를 통해 실제로 잘 동작하는지 확인해보겠습니다.\n\n아래의 코드는 OpenAI가 주어진 파이썬 코드를 보고 직접 실행결과를 유추하는 것이 아니라, Agent에게 적절한 도구를 요청해서 정확한 코드 실행 결과를 받아본 뒤 그 결과를 해석하는 형태로 진행되기를 기대하며 작성한 예제입니다.\n\n```\nfromlangchain.llms import OpenAI fromlangchain.agents import load_tools, initialize_agent, AgentType llm = OpenAI() tools = load_tools(["python_repl"]) agent = initialize_agent(tools, llm, agent = AgentType. ZERO_SHOT_REACT_DESCRIPTION, verbose = True,) agent. run("""What will be printed if I execute following python code? for i in range(5, 0, -1): print("*" * i) """)\n```\n\n*출력:*\n\n```\n&gt; Entering new chain... I need to execute the code to see the output Action: Python REPL Action Input: for i in range(5, 0, -1): print("*" * i) Observation: ***** **** *** ** * Thought: I now know the final answer Final Answer: Five lines of asterisks, each line with one fewer asterisk than the line before it. \n```\n\n체인의 진행과정을 살펴보면 의도대로 잘 동작했음을 확인할 수 있었습니다. 이 LLM 체인의 작동 과정은 다음과 같습니다.\n\n1. Agent의 숨겨진 프롬프트에 사용할 수 있는 도구, 기대하는 답변 형식, 질문을 잘 삽입해서 OpenAI에 요청합니다.\n2. OpenAI는 `python_repl` 도구를 사용하면 적절할 것 같고 그 도구의 인자로 질문자가 입력한 코드를 넣는 것이 좋을 것 같다고 답변합니다.\n3. Agent가 OpenAI의 답변을 파싱하여 사용하려는 도구에 인자를 넣고 실행해 그 결과를 Observation에 넣어줍니다.\n4. Observation 결과까지 더해서 다시 OpenAI에 요청합니다.\n5. OpenAI는 기존 질문과 Observation의 내용을 보고 충분히 내용을 알 수 있다고 판단하였는지 Final Answer에 프린트 되는 내용을 설명합니다.\n6. Agent는 Final Answer가 있는 것을 인식하여 이를 반환하고 체인이 종료됩니다.\n\n약간 아쉬운 점이 있다면 예제에서 사용한 `ZERO_SHOT_REACT_DESCRIPTION` Agent는 사실상 OpenAI나 그와 비슷한 성능의 상업적인 LLM이 아니면 동작시키기가 꽤 힘들다는 것입니다. GPT2, llama, vicuna 등의 무료로 사용할 수 있는 모델에 정밀한 설정 없이 사용할 경우, Agent가 요구하는 형식을 약간씩 어기거나, Observation(Action 실행의 결과)까지 자동완성해버리는 어처구니 없는 경우가 생겨서 운이 좋을 때에만 문제 없이 동작합니다.\n\n# 결론\n\nLangChain은 LLM과 LLM을 활용하는 애플리케이션을 개발하는 데 필요한 여러가지 디자인 패턴을 표준화시키려고 노력하는 것으로 보입니다. 2023년 6월 현재 버전도 0.0.200 버전으로 아직 성숙하지 않았고, 이 글에서도 잠깐 언급한 바와 같이 `ChatModel`처럼 customize 가능하게 할 예정이 있지만 아직 그 규칙이 정해지지 않은 것도 있습니다. 이러한 미성숙한 단계임에도 실제로 쓸 법한 용례를 꽤 많이 고려하고 있다는 것이 문서나 예제에서 잘 보입니다.\n\n그리고 (만약 잘 동작한다면) `Agent`가 명령 한 번에 여러 Tool을 오가며 마법처럼 여러가지 동작을 하는 것은 터미널 창에 지나가는 실행 과정 텍스트를 보는 것만으로 만족스러운 점이 있습니다.\n\n여러 한계에도 불구하고 LLM을 활용하면서 자주 발생하는 전처리/후처리가 있거나, 도구를 통해 LLM을 보조하고 싶거나, 단계적으로 여러 번 LLM을 호출해야 할 필요가 있다면 LangChain의 인터페이스를 활용하여 문제를 정리하는 것은 설계의 교통정리에 꽤 도움이 될 듯 합니다. LLM으로 애플리케이션을 작성하는 데에 Langchain이 유용하게 사용될 수 있으리라 생각합니다.\n\n# References\n\n* &lt;https://python.langchain.com/en/latest/index.html&gt;\n* &lt;https://medium.com/databutton/getting-started-with-langchain-a-powerful-tool-for-working-with-large-language-models-286419ba0842&gt;\n\n* [NLP](/ncresearch/tags#NLP)\n\nPrevious post\n\n [데이터 품질 향상을 위한 가명정보 이용 방법과 전문적인 지침서](/ncresearch/b7ec86b60700d047cf4b548a1add5b294d68b23e)\n\nNext post\n\n [Cross Entropy, 최선인가요?: 딥러닝을 위한 여러 손실 함수들 1](/ncresearch/481b04ee12af454ab1de6dde2576eb4c15f8047a)\n\n '},
 {'title': '&lt;랭체인LangChain 노트&gt; - LangChain 한국어 튜토리얼 - 위키독스',
  'url': 'https://wikidocs.net/book/14314',
  'content': 'CH01 LangChain 시작하기)   01. 설치 영상보고 따라하기)   02. OpenAI API 키 발급 및 테스트)   03. LangSmith 추적 설정)   04. OpenAI API 사용(GPT-4o 멀티모달))   05. LangChain Expression Language(LCEL))   06. LCEL 인터페이스)   07. Runnable)   CH02 프롬프트(Prompt))   01. 프롬프트(Prompt))   02. 퓨샷 프롬프트(FewShotPromptTemplate))   03. LangChain Hub)   04. 개인화된 프롬프트(Hub에 업로드))   CH03 출력 파서(Output Parsers))   01. Pydantic 출력 파서(PydanticOutputParser))   02. 콤마 구분자 출력 파서(CommaSeparatedListOutputParser))   03. 구조화된 출력 파서(StructuredOuputParser))   04. JSON 출력 파서(JsonOutputParser))   05. 데이터프레임 출력 파서(PandasDataFrameOutputParser))   06. 날짜 형식 출력 파서(DatetimeOutputParser))   07. 열거형 출력 파서(EnumOutputParser))   08. 출력 수정 파서(OutputFixingParser))   CH04 모델(Model))   01. 다양한 LLM 모델 활용)   02. 캐싱(Cache))   03. 모델 직렬화(Serialization) - 저장 및 불러오기)   04. [...] CSVExcel 데이터 분석 Agent)   08. Toolkits 활용 Agent)   09. RAG + Image Generator Agent(보고서 작성))   10. 도구를 활용한 토론 에이전트(Two Agent Debates with Tools))   CH17 LangGraph)   01. 핵심 기능)   01. LangGraph 에 자주 등장하는 Python 문법이해)   02. LangGraph를 활용한 챗봇 구축)   03. LangGraph를 활용한 Agent 구축)   04. Agent 에 메모리(memory) 추가)   05. 노드의 단계별 스트리밍 출력)   06. Human-in-the-loop(사람의 개입))   07. 중간단계 개입 되돌림을 통한 상태 수정과 Replay)   08. 사람(Human)에게 물어보는 노드 추가)   09. 메시지 삭제(RemoveMessage))   10. ToolNode 를 사용하여 도구를 호출하는 방법)   11. 병렬 노드 실행을 위한 분기 생성 방법)   12. 대화 기록 요약을 추가하는 방법)   13. 서브그래프 추가 및 사용 방법)   14. 서브그래프의 입력과 출력을 변환하는 방법)   15. LangGraph 스트리밍 모드의 모든 것)   02. 구조 설계)   01. 기본 그래프 생성)   02. Naive RAG)   03. 관련성 체커(Relevance Checker) 모듈 추가)   04. 웹 검색 모듈 추가)   05. 쿼리 재작성 모듈 추가)   06. Agentic RAG)   07. Adaptive RAG)   03. [...] CH14 체인(Chains))   01. 문서 요약)   02. SQL)   03. 구조화된 출력 체인(with\\_structered\\_output))   CH15 평가(Evaluations))   01. 합성 테스트 데이터셋 생성(RAGAS))   02. RAGAS 를 활용한 평가)   03. 생성한 평가용 데이터셋 업로드(HuggingFace Dataset))   04. LangSmith 데이터셋 생성)   05. LLM-as-Judge)   06. 임베딩 기반 평가(embedding\\_distance))   07. 사용자 정의(Custom) LLM 평가)   08. Rouge, BLEU, METEOR, SemScore 기반 휴리스틱 평가)   09. 실험(Experiment) 평가 비교)   10. 요약(Summary) 방식의 평가)   11. Groundedness(할루시네이션) 평가)   12. 실험 비교(Pairwise Evaluation))   13. 반복 평가)   14. 온라인 평가를 활용한 평가 자동화)   CH16 에이전트(Agent))   01. 도구(Tools))   02. 도구 바인딩(Binding Tools))   03. 에이전트(Agent))   04. Claude, Gemini, Ollama, Together.ai 를 활용한 Agent)   05. Iteration 기능과 사람 개입(Human-in-the-loop))   06. Agentic RAG)   07. CSVExcel 데이터 분석 Agent)   08. Toolkits 활용 Agent)   09. RAG +',
  'score': 0.64773196,
  'raw_content': '[**&lt;랭체인LangChain 노트&gt; - LangChain 한국어 튜토리얼🇰🇷**](/book/14314) \n\n[CH01 LangChain 시작하기](javascript:page(233341))   [01. 설치 영상보고 따라하기](javascript:page(257836))   [02. OpenAI API 키 발급 및 테스트](javascript:page(233342))   [03. LangSmith 추적 설정](javascript:page(250954))   [04. OpenAI API 사용(GPT-4o 멀티모달)](javascript:page(233343))   [05. LangChain Expression Language(LCEL)](javascript:page(233344))   [06. LCEL 인터페이스](javascript:page(233345))   [07. Runnable](javascript:page(233346))   [CH02 프롬프트(Prompt)](javascript:page(233347))   [01. 프롬프트(Prompt)](javascript:page(233351))   [02. 퓨샷 프롬프트(FewShotPromptTemplate)](javascript:page(233348))   [03. LangChain Hub](javascript:page(233349))   [04. 개인화된 프롬프트(Hub에 업로드)](javascript:page(233350))   [CH03 출력 파서(Output Parsers)](javascript:page(233771))   [01. Pydantic 출력 파서(PydanticOutputParser)](javascript:page(233786))   [02. 콤마 구분자 출력 파서(CommaSeparatedListOutputParser)](javascript:page(233787))   [03. 구조화된 출력 파서(StructuredOuputParser)](javascript:page(233788))   [04. JSON 출력 파서(JsonOutputParser)](javascript:page(233789))   [05. 데이터프레임 출력 파서(PandasDataFrameOutputParser)](javascript:page(233790))   [06. 날짜 형식 출력 파서(DatetimeOutputParser)](javascript:page(233791))   [07. 열거형 출력 파서(EnumOutputParser)](javascript:page(233792))   [08. 출력 수정 파서(OutputFixingParser)](javascript:page(233793))   [CH04 모델(Model)](javascript:page(233772))   [01. 다양한 LLM 모델 활용](javascript:page(233795))   [02. 캐싱(Cache)](javascript:page(233796))   [03. 모델 직렬화(Serialization) - 저장 및 불러오기](javascript:page(233798))   [04. 토큰 사용량 확인](javascript:page(233797))   [05. 구글 생성 AI(Google Generative AI)](javascript:page(233799))   [06. 허깅페이스 엔드포인트(HuggingFace Endpoints)](javascript:page(233802))   [07. 허깅페이스 로컬(HuggingFace Local)](javascript:page(233803))   [08. 허깅페이스 파이프라인(HuggingFace Pipeline)](javascript:page(233804))   [09. 올라마(Ollama)](javascript:page(233805))   [10. GPT4ALL](javascript:page(233806))   [11. 비디오(Video) 질의 응답 LLM (Gemini)](javascript:page(263314))   [CH05 메모리(Memory)](javascript:page(233773))   [01. 대화 버퍼 메모리(ConversationBufferMemory)](javascript:page(233801))   [02. 대화 버퍼 윈도우 메모리(ConversationBufferWindowMemory)](javascript:page(233800))   [03. 대화 토큰 버퍼 메모리(ConversationTokenBufferMemory)](javascript:page(233807))   [04. 대화 엔티티 메모리(ConversationEntityMemory)](javascript:page(233808))   [05. 대화 지식그래프 메모리(ConversationKGMemory)](javascript:page(233809))   [06. 대화 요약 메모리(ConversationSummaryMemory)](javascript:page(233810))   [07. 벡터저장소 검색 메모리(VectorStoreRetrieverMemory)](javascript:page(233811))   [08. LCEL Chain 에 메모리 추가](javascript:page(233812))   [09. SQLite 에 대화내용 저장](javascript:page(233813))   [10. RunnableWithMessageHistory에 ChatMessageHistory추가](javascript:page(254682))   [CH06 문서 로더(Document Loader)](javascript:page(233775))   [01. 도큐먼트(Document) 의 구조](javascript:page(253706))   [02. PDF](javascript:page(253707))   [03. 한글(HWP)](javascript:page(253708))   [04. CSV](javascript:page(253709))   [05. Excel](javascript:page(253710))   [06. Word](javascript:page(253711))   [07. PowerPoint](javascript:page(253712))   [08. 웹 문서(WebBaseLoader)](javascript:page(253713))   [09. 텍스트(TextLoader)](javascript:page(253714))   [10. JSON](javascript:page(253715))   [11. Arxiv](javascript:page(253716))   [12. UpstageLayoutAnalysisLoader](javascript:page(253717))   [13. LlamaParser](javascript:page(253718))   [CH07 텍스트 분할(Text Splitter)](javascript:page(233776))   [01. 문자 텍스트 분할(CharacterTextSplitter)](javascript:page(233998))   [02. 재귀적 문자 텍스트 분할(RecursiveCharacterTextSplitter)](javascript:page(233999))   [03. 토큰 텍스트 분할(TokenTextSplitter)](javascript:page(234002))   [04. 시멘틱 청커(SemanticChunker)](javascript:page(234003))   [05. 코드 분할(Python, Markdown, JAVA, C++, C#, GO, JS, Latex 등)](javascript:page(234004))   [06. 마크다운 헤더 텍스트 분할(MarkdownHeaderTextSplitter)](javascript:page(234005))   [07. HTML 헤더 텍스트 분할(HTMLHeaderTextSplitter)](javascript:page(234006))   [08. 재귀적 JSON 분할(RecursiveJsonSplitter)](javascript:page(234007))   [CH08 임베딩(Embedding)](javascript:page(233777))   [01. OpenAIEmbeddings](javascript:page(233815))   [02. 캐시 임베딩(CacheBackedEmbeddings)](javascript:page(233816))   [03. 허깅페이스 임베딩(HuggingFace Embeddings)](javascript:page(233817))   [04. UpstageEmbeddings](javascript:page(253106))   [05. OllamaEmbeddings](javascript:page(253107))   [06. GPT4ALL 임베딩](javascript:page(233818))   [07. Llama CPP 임베딩](javascript:page(233819))   [CH09 벡터저장소(VectorStore)](javascript:page(233778))   [01. Chroma](javascript:page(234094))   [02. FAISS](javascript:page(234014))   [03. Pinecone](javascript:page(252407))   [CH10 검색기(Retriever)](javascript:page(233779))   [01. 벡터스토어 기반 검색기(VectorStore-backed Retriever)](javascript:page(234016))   [02. 문맥 압축 검색기(ContextualCompressionRetriever)](javascript:page(234097))   [03. 앙상블 검색기(EnsembleRetriever)](javascript:page(234100))   [04. 긴 문맥 재정렬(LongContextReorder)](javascript:page(234101))   [05. 상위 문서 검색기(ParentDocumentRetriever)](javascript:page(234164))   [06. 다중 쿼리 검색기(MultiQueryRetriever)](javascript:page(234109))   [07. 다중 벡터저장소 검색기(MultiVectorRetriever)](javascript:page(234281))   [08. 셀프 쿼리 검색기(SelfQueryRetriever)](javascript:page(234475))   [09. 시간 가중 벡터저장소 검색기(TimeWeightedVectorStoreRetriever)](javascript:page(234604))   [10. 한글 형태소 분석기(Kiwi, Kkma, Okt) + BM25 검색기](javascript:page(251980))   [11. Convex Combination(CC) 적용된 앙상블 검색기(EnsembleRetriever)](javascript:page(263833))   [CH11 리랭커(Reranker)](javascript:page(253434))   [01. Cross Encoder Reranker](javascript:page(253836))   [02. Cohere Reranker](javascript:page(253837))   [03. Jina Reranker](javascript:page(253838))   [04. FlashRank Reranker](javascript:page(253839))   [CH12 Retrieval Augmented Generation(RAG)](javascript:page(233780))   [01. PDF 문서 기반 QA(Question-Answer)](javascript:page(251190))   [02. 네이버 뉴스기사 QA(Question-Answer)](javascript:page(234008))   [03. RAG 의 기능별 다양한 모듈 활용기](javascript:page(234009))   [04. RAPTOR: 긴 문맥 요약(Long Context Summary)](javascript:page(234017))   [05. 대화내용을 기억하는 RAG 체인](javascript:page(252858))   [CH13 LangChain Expression Language(LCEL)](javascript:page(233781))   [01. RunnablePassthrough](javascript:page(235580))   [02. Runnable 구조(그래프) 검토](javascript:page(235884))   [03. RunnableLambda](javascript:page(235705))   [04. LLM 체인 라우팅(RunnableLambda, RunnableBranch)](javascript:page(235882))   [05. RunnableParallel](javascript:page(235883))   [06. 동적 속성 지정(configurable\\_fields, configurable\\_alternatives)](javascript:page(235704))   [07. @chain 데코레이터로 Runnable 구성](javascript:page(235703))   [08. RunnableWithMessageHistory](javascript:page(235581))   [09. 사용자 정의 제네레이터(generator)](javascript:page(235885))   [10. Runtime Arguments 바인딩](javascript:page(235886))   [11. 폴백(fallback) 모델 지정](javascript:page(235938))   [CH14 체인(Chains)](javascript:page(233774))   [01. 문서 요약](javascript:page(234020))   [02. SQL](javascript:page(234019))   [03. 구조화된 출력 체인(with\\_structered\\_output)](javascript:page(256983))   [CH15 평가(Evaluations)](javascript:page(259203))   [01. 합성 테스트 데이터셋 생성(RAGAS)](javascript:page(259204))   [02. RAGAS 를 활용한 평가](javascript:page(259205))   [03. 생성한 평가용 데이터셋 업로드(HuggingFace Dataset)](javascript:page(259206))   [04. LangSmith 데이터셋 생성](javascript:page(259207))   [05. LLM-as-Judge](javascript:page(259208))   [06. 임베딩 기반 평가(embedding\\_distance)](javascript:page(259210))   [07. 사용자 정의(Custom) LLM 평가](javascript:page(259212))   [08. Rouge, BLEU, METEOR, SemScore 기반 휴리스틱 평가](javascript:page(259213))   [09. 실험(Experiment) 평가 비교](javascript:page(259214))   [10. 요약(Summary) 방식의 평가](javascript:page(259215))   [11. Groundedness(할루시네이션) 평가](javascript:page(259216))   [12. 실험 비교(Pairwise Evaluation)](javascript:page(259217))   [13. 반복 평가](javascript:page(259218))   [14. 온라인 평가를 활용한 평가 자동화](javascript:page(259219))   [CH16 에이전트(Agent)](javascript:page(233782))   [01. 도구(Tools)](javascript:page(262582))   [02. 도구 바인딩(Binding Tools)](javascript:page(262585))   [03. 에이전트(Agent)](javascript:page(262586))   [04. Claude, Gemini, Ollama, Together.ai 를 활용한 Agent](javascript:page(262592))   [05. Iteration 기능과 사람 개입(Human-in-the-loop)](javascript:page(262593))   [06. Agentic RAG](javascript:page(262595))   [07. CSVExcel 데이터 분석 Agent](javascript:page(262597))   [08. Toolkits 활용 Agent](javascript:page(262604))   [09. RAG + Image Generator Agent(보고서 작성)](javascript:page(262612))   [10. 도구를 활용한 토론 에이전트(Two Agent Debates with Tools)](javascript:page(234162))   [CH17 LangGraph](javascript:page(233785))   [01. 핵심 기능](javascript:page(265670))   [01. LangGraph 에 자주 등장하는 Python 문법이해](javascript:page(264613))   [02. LangGraph를 활용한 챗봇 구축](javascript:page(264614))   [03. LangGraph를 활용한 Agent 구축](javascript:page(264624))   [04. Agent 에 메모리(memory) 추가](javascript:page(265658))   [05. 노드의 단계별 스트리밍 출력](javascript:page(265659))   [06. Human-in-the-loop(사람의 개입)](javascript:page(265663))   [07. 중간단계 개입 되돌림을 통한 상태 수정과 Replay](javascript:page(265723))   [08. 사람(Human)에게 물어보는 노드 추가](javascript:page(265737))   [09. 메시지 삭제(RemoveMessage)](javascript:page(265749))   [10. ToolNode 를 사용하여 도구를 호출하는 방법](javascript:page(265763))   [11. 병렬 노드 실행을 위한 분기 생성 방법](javascript:page(265766))   [12. 대화 기록 요약을 추가하는 방법](javascript:page(265767))   [13. 서브그래프 추가 및 사용 방법](javascript:page(265768))   [14. 서브그래프의 입력과 출력을 변환하는 방법](javascript:page(265769))   [15. LangGraph 스트리밍 모드의 모든 것](javascript:page(265770))   [02. 구조 설계](javascript:page(267807))   [01. 기본 그래프 생성](javascript:page(267808))   [02. Naive RAG](javascript:page(267809))   [03. 관련성 체커(Relevance Checker) 모듈 추가](javascript:page(267810))   [04. 웹 검색 모듈 추가](javascript:page(267811))   [05. 쿼리 재작성 모듈 추가](javascript:page(267812))   [06. Agentic RAG](javascript:page(267813))   [07. Adaptive RAG](javascript:page(267814))   [03. Use Cases](javascript:page(267815))   [01. 에이전트 대화 시뮬레이션 (고객 응대 시나리오)](javascript:page(267816))   [02. 사용자 요구사항 기반 메타 프롬프트 생성 에이전트](javascript:page(267817))   [03. CRAG(Corrective RAG)](javascript:page(270686))   [04. Self-RAG](javascript:page(270687))   [05. 계획 후 실행(Plan-and-Execute)](javascript:page(270688))   [06. 멀티 에이전트 협업 네트워크(Multi-Agent Collaboration Network)](javascript:page(270689))   [07. 멀티 에이전트 감독자(Multi-Agent Supervisor)](javascript:page(270690))   [08. 계층적 멀티 에이전트 팀(Hierarchical Multi-Agent Teams)](javascript:page(270691))   [09. SQL 데이터베이스와 상호작용하는 에이전트](javascript:page(270692))   [10. STORM 개념을 도입한 연구를 위한 멀티 에이전트](javascript:page(270693))   [CH18 기타 정보](javascript:page(265575))   [01. StreamEvent 타입별 정리](javascript:page(265576))\n\n1. [&lt;랭체인LangChain 노트&gt; - Lang…](/book/14314)\n\n1. [위키독스](/)\n\n# &lt;랭체인LangChain 노트&gt; - LangChain 한국어 튜토리얼🇰🇷\n\n지은이: [테디노트](/profile/info/book/10226)\n\n최종 편집일시 : 2025년 4월 30일 8:06 오후\n\n저작권 :\n\n[**3,708** 명이 추천](javascript:recommend_book(\'14314\'); "추천")\n\n**추천**은 공유할 수 있는 무료 전자책을 집필하는데 정말 큰 힘이 됩니다. **"추천"** 한 번씩만 부탁 드리겠습니다🙏🙏\n\n✅ **랭체인 한국어 튜토리얼 강의**   \n [패스트캠퍼스 - RAG 비법노트](https://fastcampus.co.kr/data_online_teddy?utm_source=wikidocs&amp;utm_medium=viral&amp;utm_campaign=prd%5E250318%5E239355&amp;utm_content=teacher%5E239355)\n\n✅ **랭체인 한국어 튜토리얼 코드저장소(GitHub)** 📘🖥️  \n &lt;https://github.com/teddylee777/langchain-kr&gt;\n\n✅ **유튜브 "테디노트"** 🎥📚  \n &lt;https://www.youtube.com/c/@teddynote&gt;\n\n✅ **데이터 분석 블로그** &lt;https://teddylee777.github.io&gt;\n\n✅ **문의** [teddylee777@gmail.com](mailto:teddylee777@gmail.com)\n\n### LICENSE\n\n**인용 및 출처 표기**\n\n* 본 저작물을 블로그, 유튜브 등 온라인 매체에 인용하여 게재할 경우, **Creative Commons Attribution-NonCommercial-NoDerivs 2.0 Korea** 라이선스에 따라 **반드시 출처를 명시**해야 합니다.\n\n**상업적 사용에 대한 사전 협의**\n\n* 본 저작물(Wikidocs 및 관련 실습 코드 포함)을 **강의, 강연 등 상업적 목적으로 활용하고자 하는 경우**, **저작권자와의 사전 서면 협의가 필수적으로 요구**됩니다. 해당 협의는 teddylee777@gmail.com으로 문의하여 진행하실 수 있습니다.\n\n```\n본 저작물은 2025년 테디노트에 의해 작성되었습니다. 모든 권리는 저작권자에게 있으며, 본 저작물은 Creative Commons Attribution-NonCommercial-NoDerivs 2.0 Korea 라이선스에 따라 배포됩니다. 본 저작물의 무단 전재 및 재배포를 금지하며, 전체 혹은 일부를 인용할 경우 출처를 명확히 밝혀주시기 바랍니다. 본 문서는 다른 문서의 내용을 참고하여 작성되었을 수 있습니다. 참고 자료는 본 문서 하단의 출처 목록에서 확인하실 수 있습니다. Copyright (c) 테디노트. \n```\n\n### Reference\n\n* [LangChain Github](https://github.com/langchain-ai/langchain)\n* [LangGraph Github](https://github.com/langchain-ai/langgraph)\n* [LangChain Document](https://python.langchain.com/docs/get_started/introduction)\n\n#### 이 책에 대해 질문하기 (AI 실험기능)\n\n**이 기능은 로그인한 사용자만 이용하실 수 있습니다.**\n\n답변을 생성하고 있습니다...\n\nAI 답변\n\n참조 페이지\n\n같이 보면 좋은 책\n\n* - [Deep Learning Bible - H. Traditional NLP - Eng.](/book/9419)\n* - [바이브 코딩(Vibe Coding): FPS 게임 제작기](/book/17562)\n* - [소설처럼 읽는 LangChain과 생성형 AI 3권](/book/18965)\n* - [LangGraph v1.x로 이해하는 LLM Agent의 흐름과 통제](/book/18699)\n* - [기적의 독서법](/book/18619)\n\n광고가 출력될 위치입니다.\n\n광고가 출력될 위치입니다.\n\n[최근 댓글 (13)](javascript:show_book_comments()) [최근 수정글 (10)](javascript:show_book_pages())  [RSS](/book/14314/rss/)\n\n[04. Claude, Gemini, Ollama, Together.ai 를 활용한 Agent](/262592#comment_27015)  - [동구](/profile/info/book/11043), 2025년 7월 18일 1:53 오후\n\ndef execute\\_agent(llm, tools, input\\_text, label): 에 label이 어디쓰이는지 누락되어 있네요\n\n[02. RAGAS 를 활용한 평가](/259205#comment_26817)  - [동구](/profile/info/book/11043), 2025년 7월 8일 6:47 오후\n\nanswer relevancy에는 context가 안쓰이는거 같은데요\n\n[09. 올라마(Ollama)](/233805#comment_26344)  - [dongman kim](/profile/info/book/31305), 2025년 6월 12일 2:35 오후\n\nfrom langchain\\_community.chat\\_models import ChatOllama 가 이전 버전이고 from langchain\\_ollama import ChatOllama 로 변경되었는데 아직 반영안된 부분이 있습니다. 수정바랍니다\n\n[12. UpstageLayoutAnalysisLoader](/253717#comment_25299)  - [천세현](/profile/info/book/30075), 2025년 3월 29일 9:46 오전\n\n안녕하세요!langchain-upstage 0.6.0 버젼에서 from langchain\\_upstage import UpstageLayoutAnalysisLoader 할 때 ImportError이 발생하는데 왜 그런가요?\n\n[CH09 벡터저장소(VectorStore)](/233778#comment_24275)  - [이서혁](/profile/info/book/29233), 2025년 2월 13일 4:57 오후\n\n안녕하세요 :) 정말 알찬 자료를 전자책으로 풀어주셔서 감사합니다. 드리고자하는 질문은, 다른 자료들을 봐도 테디노트님은 VectorDB 중 Milvus는 다루시지 않던데 그 이유가 궁금합니다. 혹시 특별한 이유가 있을까요?\n\n[02. 네이버 뉴스기사 QA(Question-Answer)](/234008#comment_24121)  - [김민겸](/profile/info/book/29073), 2025년 2월 2일 12:17 오후\n\n"bullet points 형식으로 정리"에서 "주어진 정보에서 질문에 대한 정보를 찾을 수 없습니다." 라고 나오는데 이유를 알려주실 수 있나요? [kmk582@naver.com](mailto:kmk582@naver.com)\n\n[10. 한글 형태소 분석기(Kiwi, Kkma, Okt) + BM25 검색기](/251980#comment_23499)  - [shcheon99@naver.com](/profile/info/book/28627), 2025년 1월 9일 12:28 오후\n\n출력된 결과를 비교했을 때, kiwi tokenizer을 사용한 결과와 kkma, okt 를 사용한 결과가 큰 차이가 없다고 봐도 되는 건가요?\n\n[CH01 LangChain 시작하기](/233341#comment_22761)  - [NamHyeon](/profile/info/book/14059), 2024년 12월 8일 1:17 오후\n\n좋은 자료를 무료로 공유해 주셔서, 감사한 마음에 \'테디노트의 RAG 비법노트\' 강의 등록했습니다 ! 물론 제 현업에 필요한 기술이라서, 강의 또한 기쁜 마음에 신청했구요 ~ 정주행 해서, 창공을 날아가 보겠습니다 ^^\n\n[06. Word](/253711#comment_21963)  - [Paul](/profile/info/book/27425), 2024년 10월 27일 5:38 오후\n\npython-docx도 설치해야 할까요?\n\n[10. JSON](/253715#comment_21962)  - [Paul](/profile/info/book/27425), 2024년 10월 27일 5:37 오후\n\n!pip install jq 부분이 들어가야 할 것 같습니다.\n\n[02. PDF](/253707#comment_21954)  - [Paul](/profile/info/book/27425), 2024년 10월 27일 3:29 오후\n\nPage 1\n\n[12. UpstageLayoutAnalysisLoader](/253717#comment_21944)  - [Paul](/profile/info/book/27425), 2024년 10월 27일 10:59 오전\n\n감사히 잘 참고하고 있습니다. 아주 사소한 오기이지만... 11번 Arxiv 다음에 12번이 와야 할 텐데, 원래 넣으시려던 다른 목차가 빠진 것인지 바로 13번이 나왔네요^^\n\n[03. 모델 직렬화(Serialization) - 저장 및 불러오기](/233798#comment_21094)  - [동구](/profile/info/book/11043), 2024년 9월 20일 12:58 오후\n\nloads는 뭐에요?\n\n[06. Human-in-the-loop(사람의 개입)](/265663)  - 2025년 4월 14일 7:10 오후'},
 {'title': '1-2-4. 메시지(Messages) - 랭체인(LangChain) 입문부터 응용까지',
  'url': 'https://wikidocs.net/319011',
  'content': 'Retriever)   2-6-5. RAG-Fusion)   Part 3. Agents &amp; Tools)   3-1. Agent 개요)   3-2. 내장 도구)   3-3. 커스텀 도구)   3-4. ToolRuntime &amp; 컨텍스트)   Part 4. 미들웨어 &amp; 가드레일)   4-1. 미들웨어(Middleware) 개요)   4-2. 내장 미들웨어)   4-2-1. 컨텍스트 관리 미들웨어)   4-2-2. 호출 제한 미들웨어)   4-2-3. 복원력 미들웨어)   4-2-4. 도구 최적화 미들웨어)   4-3. 커스텀 미들웨어)   4-4. 가드레일 개요)   4-5. PII 탐지)   4-6. Human-in-the-Loop)   Part 8. 오픈소스 LLM 활용)   8-1. 올라마)   8-1-1. 설치)   8-1-2. 모델 다운로드)   8-1-3. LangChain 적용)   8-2. Groq API)   8-2-1. 인증키 발급)   8-2-2. LangChain 적용) [...] Part 0. 글쓴이 소개)   Part 1. LangChain 기초)   1-1. LangChain 이란?)   1-1-1. LangChain 버전 히스토리)   1-1-2. LangChain 1.0 프레임워크 구성)   1-1-3. 필수 라이브러리 설치)   1-2. LLM 체인(LLMChain) 만들기)   1-2-1. 기본 LLM 체인 (Prompt + LLM))   1-2-2. 멀티 체인 (Multi-Chain))   1-2-3. 체인을 실행하는 방법)   1-2-4. 메시지(Messages))   1-2-5. 스트리밍 (Streaming))   1-3. 프롬프트(Prompt))   1-3-1. 프롬프트 작성 원칙)   1-3-2. 프롬프트 템플릿 (PromptTemplate))   1-3-3. 챗 프롬프트 템플릿 (ChatPromptTemplate))   1-3-4. Few-shot Prompt)   1-3-5. Partial Prompt)   1-4. LangChain의 언어 모델 (Model))   1-4-1. LangChain 모델 유형)   1-4-1-1. LLM)   1-4-1-2. Chat Model)   1-4-1-3. 통합 모델 초기화 (init\\_chat\\_model))   1-4-2. LangChain의 LLM 모델 파라미터 설정)   1-4-2-1. LLM 모델에 직접 파라미터를 전달)   1-4-2-2. LLM 모델 파라미터를 추가로 바인딩 (bind 메소드))   1-4-3. 다른 공급업체의 모델 살펴보기)   1-4-3-1. Claude (Anthropic)) [...] 2-3. RAG - Text Splitter)   2-3-1. CharacterTextSplitter)   2-3-2. RecursiveCharacterTextSplitter)   2-3-3. 토큰 수를 기준으로 텍스트 분할 (Tokenizer 활용))   2-4. RAG - Embedding)   2-4-1. OpenAIEmbeddings)   2-4-2. HuggingFaceEmbeddings)   2-4-3. GoogleGenerativeAIEmbeddings)   2-5. RAG - Vector Store)   2-5-1. Chroma)   2-5-1-1. 유사도 기반 검색 (Similarity search))   2-5-1-2. MMR (Maximum marginal relevance search))   2-5-1-3. 벡터스토어에 메타데이터(meta data)를 추가)   2-5-2. FAISS)   2-5-2-1. 유사도 기반 검색 (Similarity search) (Copy))   2-5-2-2. MMR (Maximum marginal relevance search) (Copy))   2-5-2-3. FAISS DB를 로컬에 저장하기)   2-6. RAG - Retriever)   2-6-1. Vector Store Retriver)   2-6-2. Multi Query Retriever)   2-6-3. Contextual compression)   2-6-4. Ensemble Retriever)   2-6-5. RAG-Fusion)   Part 3. Agents &amp; Tools)',
  'score': 0.6415577,
  'raw_content': '[**랭체인(LangChain) 입문부터 응용까지 [ver 1.0 업데이트]**](/book/14473) \n\n[Part 0. 글쓴이 소개](javascript:page(231147))   [Part 1. LangChain 기초](javascript:page(231150))   [1-1. LangChain 이란?](javascript:page(231151))   [1-1-1. LangChain 버전 히스토리](javascript:page(231154))   [1-1-2. LangChain 1.0 프레임워크 구성](javascript:page(231153))   [1-1-3. 필수 라이브러리 설치](javascript:page(231152))   [1-2. LLM 체인(LLMChain) 만들기](javascript:page(231155))   [1-2-1. 기본 LLM 체인 (Prompt + LLM)](javascript:page(231156))   [1-2-2. 멀티 체인 (Multi-Chain)](javascript:page(231186))   [1-2-3. 체인을 실행하는 방법](javascript:page(231187))   [1-2-4. 메시지(Messages)](javascript:page(319011))   [1-2-5. 스트리밍 (Streaming)](javascript:page(319017))   [1-3. 프롬프트(Prompt)](javascript:page(231228))   [1-3-1. 프롬프트 작성 원칙](javascript:page(231229))   [1-3-2. 프롬프트 템플릿 (PromptTemplate)](javascript:page(231233))   [1-3-3. 챗 프롬프트 템플릿 (ChatPromptTemplate)](javascript:page(231328))   [1-3-4. Few-shot Prompt](javascript:page(231230))   [1-3-5. Partial Prompt](javascript:page(231234))   [1-4. LangChain의 언어 모델 (Model)](javascript:page(231344))   [1-4-1. LangChain 모델 유형](javascript:page(231360))   [1-4-1-1. LLM](javascript:page(231345))   [1-4-1-2. Chat Model](javascript:page(231346))   [1-4-1-3. 통합 모델 초기화 (init\\_chat\\_model)](javascript:page(319002))   [1-4-2. LangChain의 LLM 모델 파라미터 설정](javascript:page(231351))   [1-4-2-1. LLM 모델에 직접 파라미터를 전달](javascript:page(231375))   [1-4-2-2. LLM 모델 파라미터를 추가로 바인딩 (bind 메소드)](javascript:page(231376))   [1-4-3. 다른 공급업체의 모델 살펴보기](javascript:page(231358))   [1-4-3-1. Claude (Anthropic)](javascript:page(231362))   [1-4-3-2. Gemini (Google)](javascript:page(259654))   [1-5. 출력 파서 (Output Parser)](javascript:page(231363))   [1-6. 메모리와 대화 관리](javascript:page(293398))   [1-6-1. 메모리의 필요성과 개념](javascript:page(293399))   [1-6-2. RunnableWithMessageHistory](javascript:page(293401))   [1-6-3. 다양한 메모리 저장 방식](javascript:page(293404))   [1-6-4.\\_단기\\_메모리\\_패턴](javascript:page(318944))   [1-6-5.\\_장기\\_메모리](javascript:page(318945))   [Part 2. RAG (Retrieval-Augmented Generation) 기법](javascript:page(231364))   [2-1. RAG 개요](javascript:page(231393))   [2-2. RAG - Document Loader](javascript:page(231429))   [2-2-1. 웹 문서 (WebBaseLoader)](javascript:page(231644))   [2-2-2. 텍스트 문서 (TextLoader)](javascript:page(231564))   [2-2-3. 디렉토리 폴더 (DirectoryLoader)](javascript:page(231645))   [2-2-4. CSV 문서 (CSVLoader)](javascript:page(231566))   [2-2-5. PDF 문서](javascript:page(231565))   [2-2-5-1. PDF 문서 페이지별로 로드 (PyPDFLoader)](javascript:page(232104))   [2-2-5-2. 형식이 없는 PDF 문서 로드 (UnstructuredPDFLoader)](javascript:page(232105))   [2-2-5-3. PDF 문서의 메타 데이터를 상세하게 추출 (PyMuPDFLoader)](javascript:page(232106))   [2-2-5-4. 온라인(on-line) PDF 문서 로드 (OnlinePDFLoader)](javascript:page(232107))   [2-2-5-5. 특정 폴더의 모든 PDF 문서 로드 (PyPDFDirectoryLoader)](javascript:page(232110))   [2-3. RAG - Text Splitter](javascript:page(231430))   [2-3-1. CharacterTextSplitter](javascript:page(231568))   [2-3-2. RecursiveCharacterTextSplitter](javascript:page(231569))   [2-3-3. 토큰 수를 기준으로 텍스트 분할 (Tokenizer 활용)](javascript:page(231570))   [2-4. RAG - Embedding](javascript:page(231431))   [2-4-1. OpenAIEmbeddings](javascript:page(231571))   [2-4-2. HuggingFaceEmbeddings](javascript:page(231573))   [2-4-3. GoogleGenerativeAIEmbeddings](javascript:page(231572))   [2-5. RAG - Vector Store](javascript:page(231433))   [2-5-1. Chroma](javascript:page(231575))   [2-5-1-1. 유사도 기반 검색 (Similarity search)](javascript:page(231578))   [2-5-1-2. MMR (Maximum marginal relevance search)](javascript:page(231585))   [2-5-1-3. 벡터스토어에 메타데이터(meta data)를 추가](javascript:page(231507))   [2-5-2. FAISS](javascript:page(231577))   [2-5-2-1. 유사도 기반 검색 (Similarity search) (Copy)](javascript:page(231593))   [2-5-2-2. MMR (Maximum marginal relevance search) (Copy)](javascript:page(231597))   [2-5-2-3. FAISS DB를 로컬에 저장하기](javascript:page(235091))   [2-6. RAG - Retriever](javascript:page(231434))   [2-6-1. Vector Store Retriver](javascript:page(231600))   [2-6-2. Multi Query Retriever](javascript:page(231603))   [2-6-3. Contextual compression](javascript:page(231608))   [2-6-4. Ensemble Retriever](javascript:page(231609))   [2-6-5. RAG-Fusion](javascript:page(231732))   [Part 3. Agents &amp; Tools](javascript:page(261566))   [3-1. Agent 개요](javascript:page(319019))   [3-2. 내장 도구](javascript:page(261567))   [3-3. 커스텀 도구](javascript:page(261571))   [3-4. ToolRuntime &amp; 컨텍스트](javascript:page(319020))   [Part 4. 미들웨어 &amp; 가드레일](javascript:page(294427))   [4-1. 미들웨어(Middleware) 개요](javascript:page(318926))   [4-2. 내장 미들웨어](javascript:page(318927))   [4-2-1. 컨텍스트 관리 미들웨어](javascript:page(319263))   [4-2-2. 호출 제한 미들웨어](javascript:page(319264))   [4-2-3. 복원력 미들웨어](javascript:page(319265))   [4-2-4. 도구 최적화 미들웨어](javascript:page(319266))   [4-3. 커스텀 미들웨어](javascript:page(318928))   [4-4. 가드레일 개요](javascript:page(318932))   [4-5. PII 탐지](javascript:page(318933))   [4-6. Human-in-the-Loop](javascript:page(318934))   [Part 8. 오픈소스 LLM 활용](javascript:page(232980))   [8-1. 올라마](javascript:page(238526))   [8-1-1. 설치](javascript:page(238530))   [8-1-2. 모델 다운로드](javascript:page(238531))   [8-1-3. LangChain 적용](javascript:page(238532))   [8-2. Groq API](javascript:page(257136))   [8-2-1. 인증키 발급](javascript:page(257138))   [8-2-2. LangChain 적용](javascript:page(259655))\n\n1. [**랭체인(LangChain) 입문부터 응용까지…**](/book/14473)\n2. [Part 1. LangChain 기초](/231150)\n3. [1-2. LLM 체인(LLMChain) 만들기](/231155)\n4. [1-2-4. 메시지(Messages)](/319011)\n\n1. [위키독스](/)\n\n# 1-2-4. 메시지(Messages)\n\n광고가 출력될 위치입니다.\n\n광고가 출력될 위치입니다.\n\n## 메시지(Messages) 이해하기\n\n* [메시지(Messages) 이해하기](#messages)\n  + [메시지의 구성 요소](#_1)\n  + [메시지 유형](#_2)\n* [SystemMessage (시스템 메시지)](#systemmessage)\n* [HumanMessage (사용자 메시지)](#humanmessage)\n  + [멀티모달 입력](#_3)\n    - [URL 기반 이미지 입력](#url)\n    - [Base64 인코딩 이미지](#base64)\n    - [여러 이미지 동시 처리](#_4)\n    - [이미지 상세도 설정](#_5)\n* [AIMessage (AI 메시지)](#aimessage-ai)\n  + [AIMessage의 주요 속성](#aimessage)\n  + [Tool Calls (도구 호출)](#tool-calls)\n* [ToolMessage (도구 메시지)](#toolmessage)\n* [메시지 리스트로 대화 구성](#_6)\n* [딕셔너리 형식](#_7)\n* [스트리밍과 AIMessageChunk](#aimessagechunk)\n* [요약](#_8)\n\nLangChain에서 **메시지(Message)**는 모델과의 상호작용에서 가장 기본이 되는 단위입니다. 모든 대화는 메시지의 시퀀스로 구성되며, 각 메시지는 역할(role)과 내용(content)을 가집니다.\n\n### 메시지의 구성 요소\n\n| 요소 | 설명 | 예시 |\n| --- | --- | --- |\n| **Role (역할)** | 메시지의 발신자 유형 | system, user, assistant, tool |\n| **Content (내용)** | 실제 메시지 내용 | 텍스트, 이미지, 파일 등 |\n| **Metadata** | 부가 정보 | 토큰 수, 응답 ID 등 |\n\n### 메시지 유형\n\nLangChain은 네 가지 주요 메시지 유형을 제공합니다.\n\n```\nfrom langchain_core.messages import ( SystemMessage, HumanMessage, AIMessage, ToolMessage, ) \n```\n\n## SystemMessage (시스템 메시지)\n\n시스템 메시지는 모델의 행동 방식을 정의합니다. 대화의 맥락, 역할, 제약사항 등을 설정합니다.\n\n```\nfrom langchain_core.messages import SystemMessage # 기본 시스템 메시지 system_msg = SystemMessage(content="당신은 친절한 한국어 AI 어시스턴트입니다.") # 상세한 역할 정의 system_msg = SystemMessage(content="""당신은 파이썬 프로그래밍 전문가입니다. - 초보자도 이해할 수 있게 설명하세요 - 코드 예제를 포함하세요 - 한국어로 답변하세요""") \n```\n\n## HumanMessage (사용자 메시지)\n\n사용자의 입력을 나타냅니다. 텍스트뿐 아니라 이미지 등 멀티모달 콘텐츠를 포함할 수 있습니다.\n\n```\nfrom langchain_core.messages import HumanMessage # 텍스트 메시지 human_msg = HumanMessage(content="파이썬 리스트 컴프리헨션을 설명해주세요.") # 이름 포함 (선택) human_msg = HumanMessage( content="안녕하세요!", name="user_123" ) \n```\n\n### 멀티모달 입력\n\n이미지를 포함한 멀티모달 메시지를 구성할 수 있습니다. GPT-4o, Claude 3 등 비전 기능을 지원하는 모델에서 사용 가능합니다.\n\n#### URL 기반 이미지 입력\n\n```\nfrom langchain.chat_models import init_chat_model from langchain_core.messages import HumanMessage model = init_chat_model("gpt-4o") # 이미지 URL 포함 message = HumanMessage( content=[ {"type": "text", "text": "이 이미지에 무엇이 있나요?"}, { "type": "image_url", "image_url": {"url": "https://example.com/image.jpg"} }, ] ) response = model.invoke([message]) print(response.content) \n```\n\n#### Base64 인코딩 이미지\n\n로컬 이미지를 Base64로 인코딩하여 전송할 수 있습니다.\n\n```\nimport base64 from langchain.chat_models import init_chat_model from langchain_core.messages import HumanMessage # 이미지 파일을 Base64로 인코딩 def encode_image(image_path: str) -&gt; str: with open(image_path, "rb") as image_file: return base64.b64encode(image_file.read()).decode("utf-8") image_data = encode_image("./my_image.png") model = init_chat_model("gpt-4o") message = HumanMessage( content=[ {"type": "text", "text": "이 다이어그램을 분석해주세요."}, { "type": "image_url", "image_url": { "url": f"data:image/png;base64,{image_data}" } }, ] ) response = model.invoke([message]) print(response.content) \n```\n\n#### 여러 이미지 동시 처리\n\n```\nmessage = HumanMessage( content=[ {"type": "text", "text": "두 이미지를 비교해주세요."}, { "type": "image_url", "image_url": {"url": "https://example.com/image1.jpg"} }, { "type": "image_url", "image_url": {"url": "https://example.com/image2.jpg"} }, ] ) \n```\n\n#### 이미지 상세도 설정\n\nOpenAI 모델에서는 이미지 처리 상세도를 설정할 수 있습니다.\n\n```\nmessage = HumanMessage( content=[ {"type": "text", "text": "이 문서를 읽어주세요."}, { "type": "image_url", "image_url": { "url": "https://example.com/document.png", "detail": "high" # low, high, auto } }, ] ) \n```\n\n| 상세도 | 특징 | 토큰 사용량 |\n| --- | --- | --- |\n| `low` | 빠른 처리, 저해상도 | 낮음 |\n| `high` | 고해상도 분석 | 높음 |\n| `auto` | 자동 선택 (기본값) | 상황별 |\n\n## AIMessage (AI 메시지)\n\n모델의 응답을 나타냅니다. 모델 호출 결과로 반환되며, 다양한 메타데이터를 포함합니다.\n\n```\nfrom langchain.chat_models import init_chat_model from langchain_core.messages import HumanMessage model = init_chat_model("gpt-4o-mini") # 모델 호출 - AIMessage 반환 response = model.invoke([HumanMessage(content="안녕하세요!")]) print(type(response)) # AIMessage print(response.content) # "안녕하세요! 무엇을 도와드릴까요?" \n```\n\n### AIMessage의 주요 속성\n\n```\nresponse = model.invoke([HumanMessage(content="안녕!")]) print(f"내용: {response.content}") print(f"토큰 사용량: {response.usage_metadata}") print(f"응답 메타데이터: {response.response_metadata}") \n```\n\n### Tool Calls (도구 호출)\n\nAIMessage는 도구 호출 정보를 포함할 수 있습니다.\n\n```\nif response.tool_calls: for tool_call in response.tool_calls: print(f"도구 이름: {tool_call[\'name\']}") print(f"도구 인자: {tool_call[\'args\']}") \n```\n\n## ToolMessage (도구 메시지)\n\n도구 실행 결과를 모델에 전달할 때 사용합니다.\n\n```\nfrom langchain_core.messages import ToolMessage tool_msg = ToolMessage( content="서울의 현재 온도는 25도입니다.", tool_call_id="call_abc123", name="get_weather" ) \n```\n\n## 메시지 리스트로 대화 구성\n\n모델에 메시지 리스트를 전달하여 대화 컨텍스트를 구성합니다.\n\n```\nfrom langchain.chat_models import init_chat_model from langchain_core.messages import SystemMessage, HumanMessage, AIMessage model = init_chat_model("gpt-4o-mini") # 대화 히스토리 구성 messages = [ SystemMessage(content="당신은 요리 전문가입니다."), HumanMessage(content="김치찌개 만드는 법을 알려주세요."), AIMessage(content="김치찌개는 다음과 같이 만듭니다..."), HumanMessage(content="고기 없이 만들 수 있나요?"), ] # 컨텍스트를 유지한 응답 response = model.invoke(messages) print(response.content) \n```\n\n## 딕셔너리 형식\n\n메시지 객체 대신 딕셔너리 형식도 사용할 수 있습니다.\n\n```\nfrom langchain.chat_models import init_chat_model model = init_chat_model("gpt-4o-mini") # 딕셔너리 형식의 메시지 messages = [ {"role": "system", "content": "당신은 유용한 AI 어시스턴트입니다."}, {"role": "user", "content": "파이썬이란?"}, {"role": "assistant", "content": "파이썬은 프로그래밍 언어입니다."}, {"role": "user", "content": "주요 특징은?"}, ] response = model.invoke(messages) print(response.content) \n```\n\n| 방식 | 장점 | 사용 시점 |\n| --- | --- | --- |\n| **Message 객체** | 타입 안전성, IDE 자동완성 | 프로덕션 코드 |\n| **딕셔너리** | 간결함, JSON 호환 | 빠른 프로토타이핑 |\n\n## 스트리밍과 AIMessageChunk\n\n스트리밍 시에는 `AIMessageChunk` 객체가 반환됩니다.\n\n```\nfrom langchain.chat_models import init_chat_model from langchain_core.messages import HumanMessage model = init_chat_model("gpt-4o-mini") # 스트리밍 for chunk in model.stream([HumanMessage(content="짧은 시를 써주세요.")]): print(chunk.content, end="", flush=True) \n```\n\n## 요약\n\n| 메시지 유형 | 역할 | 주요 용도 |\n| --- | --- | --- |\n| `SystemMessage` | system | 모델 행동 지시, 역할 정의 |\n| `HumanMessage` | user | 사용자 입력, 질문, 멀티모달 데이터 |\n| `AIMessage` | assistant | 모델 응답, 도구 호출 |\n| `ToolMessage` | tool | 도구 실행 결과 전달 |\n\n마지막 편집일시 : 2026년 1월 9일 9:45 오후\n\n광고가 출력될 위치입니다.\n\n광고가 출력될 위치입니다.\n\n[댓글 0](javascript:show_comments();) [피드백](#myModal "피드백을 남겨주세요")\n\n[※ 댓글 작성은 로그인이 필요합니다.](/loginForm) [(또는 피드백을 이용해 주세요.)](#myModal)\n\n* **이전글** : [1-2-3. 체인을 실행하는 방법](javascript:page(231187))\n* **다음글** : [1-2-5. 스트리밍 (Streaming)](javascript:page(319017))\n\n  \n\n#### 책갈피\n\n### 이 페이지에 대한 피드백을 남겨주세요\n\n### 댓글을 신고합니다.'},
 {'title': '1-6-4._단기_메모리_패턴 - 랭체인(LangChain) 입문부터 응용까지',
  'url': 'https://wikidocs.net/318944',
  'content': 'Retriever)   2-6-5. RAG-Fusion)   Part 3. Agents &amp; Tools)   3-1. Agent 개요)   3-2. 내장 도구)   3-3. 커스텀 도구)   3-4. ToolRuntime &amp; 컨텍스트)   Part 4. 미들웨어 &amp; 가드레일)   4-1. 미들웨어(Middleware) 개요)   4-2. 내장 미들웨어)   4-2-1. 컨텍스트 관리 미들웨어)   4-2-2. 호출 제한 미들웨어)   4-2-3. 복원력 미들웨어)   4-2-4. 도구 최적화 미들웨어)   4-3. 커스텀 미들웨어)   4-4. 가드레일 개요)   4-5. PII 탐지)   4-6. Human-in-the-Loop)   Part 8. 오픈소스 LLM 활용)   8-1. 올라마)   8-1-1. 설치)   8-1-2. 모델 다운로드)   8-1-3. LangChain 적용)   8-2. Groq API)   8-2-1. 인증키 발급)   8-2-2. LangChain 적용) [...] Part 0. 글쓴이 소개)   Part 1. LangChain 기초)   1-1. LangChain 이란?)   1-1-1. LangChain 버전 히스토리)   1-1-2. LangChain 1.0 프레임워크 구성)   1-1-3. 필수 라이브러리 설치)   1-2. LLM 체인(LLMChain) 만들기)   1-2-1. 기본 LLM 체인 (Prompt + LLM))   1-2-2. 멀티 체인 (Multi-Chain))   1-2-3. 체인을 실행하는 방법)   1-2-4. 메시지(Messages))   1-2-5. 스트리밍 (Streaming))   1-3. 프롬프트(Prompt))   1-3-1. 프롬프트 작성 원칙)   1-3-2. 프롬프트 템플릿 (PromptTemplate))   1-3-3. 챗 프롬프트 템플릿 (ChatPromptTemplate))   1-3-4. Few-shot Prompt)   1-3-5. Partial Prompt)   1-4. LangChain의 언어 모델 (Model))   1-4-1. LangChain 모델 유형)   1-4-1-1. LLM)   1-4-1-2. Chat Model)   1-4-1-3. 통합 모델 초기화 (init\\_chat\\_model))   1-4-2. LangChain의 LLM 모델 파라미터 설정)   1-4-2-1. LLM 모델에 직접 파라미터를 전달)   1-4-2-2. LLM 모델 파라미터를 추가로 바인딩 (bind 메소드))   1-4-3. 다른 공급업체의 모델 살펴보기)   1-4-3-1. Claude (Anthropic))',
  'score': 0.63804686,
  'raw_content': '[**랭체인(LangChain) 입문부터 응용까지 [ver 1.0 업데이트]**](/book/14473) \n\n[Part 0. 글쓴이 소개](javascript:page(231147))   [Part 1. LangChain 기초](javascript:page(231150))   [1-1. LangChain 이란?](javascript:page(231151))   [1-1-1. LangChain 버전 히스토리](javascript:page(231154))   [1-1-2. LangChain 1.0 프레임워크 구성](javascript:page(231153))   [1-1-3. 필수 라이브러리 설치](javascript:page(231152))   [1-2. LLM 체인(LLMChain) 만들기](javascript:page(231155))   [1-2-1. 기본 LLM 체인 (Prompt + LLM)](javascript:page(231156))   [1-2-2. 멀티 체인 (Multi-Chain)](javascript:page(231186))   [1-2-3. 체인을 실행하는 방법](javascript:page(231187))   [1-2-4. 메시지(Messages)](javascript:page(319011))   [1-2-5. 스트리밍 (Streaming)](javascript:page(319017))   [1-3. 프롬프트(Prompt)](javascript:page(231228))   [1-3-1. 프롬프트 작성 원칙](javascript:page(231229))   [1-3-2. 프롬프트 템플릿 (PromptTemplate)](javascript:page(231233))   [1-3-3. 챗 프롬프트 템플릿 (ChatPromptTemplate)](javascript:page(231328))   [1-3-4. Few-shot Prompt](javascript:page(231230))   [1-3-5. Partial Prompt](javascript:page(231234))   [1-4. LangChain의 언어 모델 (Model)](javascript:page(231344))   [1-4-1. LangChain 모델 유형](javascript:page(231360))   [1-4-1-1. LLM](javascript:page(231345))   [1-4-1-2. Chat Model](javascript:page(231346))   [1-4-1-3. 통합 모델 초기화 (init\\_chat\\_model)](javascript:page(319002))   [1-4-2. LangChain의 LLM 모델 파라미터 설정](javascript:page(231351))   [1-4-2-1. LLM 모델에 직접 파라미터를 전달](javascript:page(231375))   [1-4-2-2. LLM 모델 파라미터를 추가로 바인딩 (bind 메소드)](javascript:page(231376))   [1-4-3. 다른 공급업체의 모델 살펴보기](javascript:page(231358))   [1-4-3-1. Claude (Anthropic)](javascript:page(231362))   [1-4-3-2. Gemini (Google)](javascript:page(259654))   [1-5. 출력 파서 (Output Parser)](javascript:page(231363))   [1-6. 메모리와 대화 관리](javascript:page(293398))   [1-6-1. 메모리의 필요성과 개념](javascript:page(293399))   [1-6-2. RunnableWithMessageHistory](javascript:page(293401))   [1-6-3. 다양한 메모리 저장 방식](javascript:page(293404))   [1-6-4.\\_단기\\_메모리\\_패턴](javascript:page(318944))   [1-6-5.\\_장기\\_메모리](javascript:page(318945))   [Part 2. RAG (Retrieval-Augmented Generation) 기법](javascript:page(231364))   [2-1. RAG 개요](javascript:page(231393))   [2-2. RAG - Document Loader](javascript:page(231429))   [2-2-1. 웹 문서 (WebBaseLoader)](javascript:page(231644))   [2-2-2. 텍스트 문서 (TextLoader)](javascript:page(231564))   [2-2-3. 디렉토리 폴더 (DirectoryLoader)](javascript:page(231645))   [2-2-4. CSV 문서 (CSVLoader)](javascript:page(231566))   [2-2-5. PDF 문서](javascript:page(231565))   [2-2-5-1. PDF 문서 페이지별로 로드 (PyPDFLoader)](javascript:page(232104))   [2-2-5-2. 형식이 없는 PDF 문서 로드 (UnstructuredPDFLoader)](javascript:page(232105))   [2-2-5-3. PDF 문서의 메타 데이터를 상세하게 추출 (PyMuPDFLoader)](javascript:page(232106))   [2-2-5-4. 온라인(on-line) PDF 문서 로드 (OnlinePDFLoader)](javascript:page(232107))   [2-2-5-5. 특정 폴더의 모든 PDF 문서 로드 (PyPDFDirectoryLoader)](javascript:page(232110))   [2-3. RAG - Text Splitter](javascript:page(231430))   [2-3-1. CharacterTextSplitter](javascript:page(231568))   [2-3-2. RecursiveCharacterTextSplitter](javascript:page(231569))   [2-3-3. 토큰 수를 기준으로 텍스트 분할 (Tokenizer 활용)](javascript:page(231570))   [2-4. RAG - Embedding](javascript:page(231431))   [2-4-1. OpenAIEmbeddings](javascript:page(231571))   [2-4-2. HuggingFaceEmbeddings](javascript:page(231573))   [2-4-3. GoogleGenerativeAIEmbeddings](javascript:page(231572))   [2-5. RAG - Vector Store](javascript:page(231433))   [2-5-1. Chroma](javascript:page(231575))   [2-5-1-1. 유사도 기반 검색 (Similarity search)](javascript:page(231578))   [2-5-1-2. MMR (Maximum marginal relevance search)](javascript:page(231585))   [2-5-1-3. 벡터스토어에 메타데이터(meta data)를 추가](javascript:page(231507))   [2-5-2. FAISS](javascript:page(231577))   [2-5-2-1. 유사도 기반 검색 (Similarity search) (Copy)](javascript:page(231593))   [2-5-2-2. MMR (Maximum marginal relevance search) (Copy)](javascript:page(231597))   [2-5-2-3. FAISS DB를 로컬에 저장하기](javascript:page(235091))   [2-6. RAG - Retriever](javascript:page(231434))   [2-6-1. Vector Store Retriver](javascript:page(231600))   [2-6-2. Multi Query Retriever](javascript:page(231603))   [2-6-3. Contextual compression](javascript:page(231608))   [2-6-4. Ensemble Retriever](javascript:page(231609))   [2-6-5. RAG-Fusion](javascript:page(231732))   [Part 3. Agents &amp; Tools](javascript:page(261566))   [3-1. Agent 개요](javascript:page(319019))   [3-2. 내장 도구](javascript:page(261567))   [3-3. 커스텀 도구](javascript:page(261571))   [3-4. ToolRuntime &amp; 컨텍스트](javascript:page(319020))   [Part 4. 미들웨어 &amp; 가드레일](javascript:page(294427))   [4-1. 미들웨어(Middleware) 개요](javascript:page(318926))   [4-2. 내장 미들웨어](javascript:page(318927))   [4-2-1. 컨텍스트 관리 미들웨어](javascript:page(319263))   [4-2-2. 호출 제한 미들웨어](javascript:page(319264))   [4-2-3. 복원력 미들웨어](javascript:page(319265))   [4-2-4. 도구 최적화 미들웨어](javascript:page(319266))   [4-3. 커스텀 미들웨어](javascript:page(318928))   [4-4. 가드레일 개요](javascript:page(318932))   [4-5. PII 탐지](javascript:page(318933))   [4-6. Human-in-the-Loop](javascript:page(318934))   [Part 8. 오픈소스 LLM 활용](javascript:page(232980))   [8-1. 올라마](javascript:page(238526))   [8-1-1. 설치](javascript:page(238530))   [8-1-2. 모델 다운로드](javascript:page(238531))   [8-1-3. LangChain 적용](javascript:page(238532))   [8-2. Groq API](javascript:page(257136))   [8-2-1. 인증키 발급](javascript:page(257138))   [8-2-2. LangChain 적용](javascript:page(259655))\n\n1. [**랭체인(LangChain) 입문부터 응용까지…**](/book/14473)\n2. [Part 1. LangChain 기초](/231150)\n3. [1-6. 메모리와 대화 관리](/293398)\n4. [1-6-4.\\_단기\\_메모리\\_패턴](/318944)\n\n1. [위키독스](/)\n\n광고가 출력될 위치입니다.\n\n광고가 출력될 위치입니다.\n\n## 단기 메모리 패턴\n\n* [단기 메모리 패턴](#_1)\n  + [개요](#_2)\n  + [단기 메모리 활성화](#_3)\n  + [메시지 트리밍 (Trimming)](#trimming)\n  + [메시지 삭제 (Deletion)](#deletion)\n  + [메시지 요약 (Summarization)](#summarization)\n  + [실전 예제: 고객 지원 챗봇](#_4)\n  + [커스텀 전략](#_5)\n  + [정리](#_6)\n\n### 개요\n\n단기 메모리(Short-term Memory)는 단일 대화 스레드 내에서 이전 상호작용을 기억하는 시스템입니다. AI 에이전트에게 메모리는 매우 중요한 기능으로, 이전 대화를 기억하고, 피드백을 학습하며, 사용자 선호도에 적응할 수 있게 해줍니다.\n\n스레드(Thread)는 하나의 세션에서 여러 상호작용을 조직화하는 단위입니다. 이메일이 하나의 대화에서 여러 메시지를 그룹화하는 것과 유사합니다.\n\n에이전트는 시스템 메시지(지침)와 사용자 메시지(입력)를 포함한 메시지 목록을 유지합니다. 대화가 길어질수록 컨텍스트 윈도우 제한에 도달할 수 있으므로, 오래된 정보를 제거하거나 "잊어버리는" 기법이 필요합니다.\n\n이번 장에서는 단기 메모리를 관리하는 네 가지 주요 패턴을 배웁니다.\n\n### 단기 메모리 활성화\n\nLangChain 1.0 에이전트에서 단기 메모리를 사용하려면 `create_agent`에 `checkpointer`를 전달합니다.\n\n**기본 사용 (메모리 저장)**\n\n```\nfrom langchain.agents import create_agent from langchain.chat_models import init_chat_model from langgraph.checkpoint.memory import MemorySaver # Checkpointer 생성 (메모리 기반) checkpointer = MemorySaver() # 에이전트 생성 - checkpointer를 직접 전달 model = init_chat_model("openai:gpt-4o") agent = create_agent( model, tools=[], checkpointer=checkpointer # 메모리 활성화 ) # 대화 실행 - agent.invoke() 직접 호출 config = {"configurable": {"thread_id": "conversation-1"}} result1 = agent.invoke( {"messages": [("user", "안녕하세요, 제 이름은 철수입니다.")]}, config=config ) print(result1["messages"][-1].content) result2 = agent.invoke( {"messages": [("user", "제 이름이 뭐죠?")]}, config=config ) print(result2["messages"][-1].content) # 출력: "당신의 이름은 철수입니다." \n```\n\n**프로덕션 환경**\n\n프로덕션에서는 데이터베이스 기반 checkpointer를 사용합니다.\n\n```\nfrom langgraph.checkpoint.postgres import PostgresSaver # PostgreSQL checkpointer checkpointer = PostgresSaver.from_conn_string( "postgresql://user:pass@localhost/dbname" ) agent = create_agent( model, tools=[], checkpointer=checkpointer ) \n```\n\n### 메시지 트리밍 (Trimming)\n\nLLM의 컨텍스트 윈도우는 제한되어 있습니다. 긴 대화에서는 메시지를 트리밍하여 최신 N개의 메시지나 토큰만 유지할 수 있습니다.\n\n**토큰 기반 트리밍**\n\n```\nfrom langchain.agents import create_agent from langchain.agents.middleware import before_model from langchain.chat_models import init_chat_model from langchain_core.messages import trim_messages from langgraph.checkpoint.memory import MemorySaver @before_model def trim_message_history(state: dict) -&gt; dict: """모델 호출 전에 메시지를 트리밍합니다.""" messages = state.get("messages", []) # 최대 4096 토큰만 유지 trimmed = trim_messages( messages, max_tokens=4096, strategy="last", # 마지막 메시지부터 유지 token_counter=len # 실제로는 토큰 카운터 함수 사용 ) return {"messages": trimmed} # 에이전트에 미들웨어 적용 model = init_chat_model("openai:gpt-4o") agent = create_agent( model, tools=[], checkpointer=MemorySaver(), middleware=[trim_message_history] ) \n```\n\n**메시지 개수 기반 트리밍**\n\n```\n@before_model def keep_last_n_messages(state: dict) -&gt; dict: """최근 10개 메시지만 유지합니다.""" messages = state.get("messages", []) # 시스템 메시지는 항상 유지 system_messages = [m for m in messages if m.type == "system"] other_messages = [m for m in messages if m.type != "system"] # 최근 10개만 유지 recent_messages = other_messages[-10:] return {"messages": system_messages + recent_messages} \n```\n\n**전략 비교**\n\n| 전략 | 장점 | 단점 |\n| --- | --- | --- |\n| 토큰 기반 | 정확한 컨텍스트 제어 | 토큰 계산 오버헤드 |\n| 메시지 개수 | 구현 간단 | 메시지 길이 불균일 시 비효율 |\n\n### 메시지 삭제 (Deletion)\n\n특정 메시지를 상태에서 영구적으로 삭제할 수 있습니다. 이는 민감한 정보를 제거하거나 불필요한 메시지를 정리할 때 유용합니다.\n\n**특정 메시지 삭제**\n\n```\nfrom langgraph.graph import RemoveMessage def delete_old_messages(state: dict) -&gt; dict: """5개보다 오래된 메시지를 삭제합니다.""" messages = state.get("messages", []) if len(messages) &gt; 5: # 삭제할 메시지 ID 수집 messages_to_delete = messages[:-5] remove_commands = [ RemoveMessage(id=msg.id) for msg in messages_to_delete ] return {"messages": remove_commands} return {} \n```\n\n**모든 메시지 삭제**\n\n```\ndef clear_all_messages(state: dict) -&gt; dict: """대화 기록을 완전히 초기화합니다.""" messages = state.get("messages", []) # 모든 메시지 삭제 remove_commands = [RemoveMessage(id=msg.id) for msg in messages] return {"messages": remove_commands} \n```\n\n**실전 예제: 민감 정보 삭제**\n\n```\nfrom langchain_core.messages import HumanMessage, AIMessage def remove_sensitive_info(state: dict) -&gt; dict: """비밀번호나 개인정보가 포함된 메시지를 삭제합니다.""" messages = state.get("messages", []) sensitive_keywords = ["password", "비밀번호", "주민번호"] to_remove = [] for msg in messages: if any(keyword in msg.content.lower() for keyword in sensitive_keywords): to_remove.append(RemoveMessage(id=msg.id)) return {"messages": to_remove} \n```\n\n### 메시지 요약 (Summarization)\n\n트리밍이나 삭제는 정보 손실을 초래할 수 있습니다. 요약 전략은 오래된 메시지를 요약하여 중요한 정보를 유지하면서 컨텍스트를 줄입니다.\n\n**SummarizationMiddleware 사용**\n\n```\nfrom langchain.agents import create_agent from langchain.agents.middleware import SummarizationMiddleware from langchain.chat_models import init_chat_model from langgraph.checkpoint.memory import MemorySaver # 요약용 모델 (저렴한 모델 사용) summarizer = init_chat_model("openai:gpt-4o-mini") # 요약 미들웨어 생성 summarization = SummarizationMiddleware( summarizer=summarizer, max_messages=10, # 10개 이상이면 요약 summary_prompt="이전 대화를 간단히 요약해주세요." ) # 에이전트에 적용 model = init_chat_model("openai:gpt-4o") agent = create_agent( model, tools=[], checkpointer=MemorySaver(), middleware=[summarization] ) \n```\n\n**커스텀 요약 로직**\n\n```\nfrom langchain.agents.middleware import before_model from langchain_core.messages import SystemMessage, HumanMessage @before_model def summarize_old_messages(state: dict) -&gt; dict: """오래된 메시지를 요약합니다.""" messages = state.get("messages", []) if len(messages) &lt;= 10: return {} # 처음 5개 메시지를 요약 대상으로 to_summarize = messages[:5] recent_messages = messages[5:] # 요약 생성 summary_prompt = "다음 대화를 3문장으로 요약:\\n\\n" for msg in to_summarize: summary_prompt += f"{msg.type}: {msg.content}\\n" summarizer = init_chat_model("openai:gpt-4o-mini") summary = summarizer.invoke([HumanMessage(content=summary_prompt)]) # 요약을 시스템 메시지로 추가 summary_message = SystemMessage(content=f"[대화 요약] {summary.content}") # 원본 삭제 + 요약 추가 remove_commands = [RemoveMessage(id=msg.id) for msg in to_summarize] return {"messages": remove_commands + [summary_message]} \n```\n\n**요약 전략 비교**\n\n| 전략 | 정보 보존 | 비용 | 복잡도 |\n| --- | --- | --- | --- |\n| 트리밍 | 낮음 | 낮음 | 낮음 |\n| 삭제 | 없음 | 낮음 | 낮음 |\n| 요약 | 높음 | 중간 | 중간 |\n\n### 실전 예제: 고객 지원 챗봇\n\n다양한 메모리 패턴을 조합한 고객 지원 챗봇입니다.\n\n```\nfrom langchain.agents import create_agent from langchain.agents.middleware import before_model, SummarizationMiddleware from langchain.chat_models import init_chat_model from langchain.tools import tool from langchain_core.messages import trim_messages from langgraph.checkpoint.memory import MemorySaver # 도구 정의 @tool def get_order_status(order_id: str) -&gt; str: """주문 상태를 조회합니다.""" return f"주문 {order_id}는 배송 중입니다." # 트리밍 미들웨어 @before_model def trim_context(state: dict) -&gt; dict: """최대 4000 토큰 유지""" messages = state.get("messages", []) trimmed = trim_messages(messages, max_tokens=4000, strategy="last") return {"messages": trimmed} # 요약 미들웨어 summarizer = init_chat_model("openai:gpt-4o-mini") summarization = SummarizationMiddleware( summarizer=summarizer, max_messages=15, summary_prompt="고객과의 대화 핵심 내용을 요약하세요." ) # 에이전트 생성 model = init_chat_model("openai:gpt-4o") agent = create_agent( model, tools=[get_order_status], checkpointer=MemorySaver(), middleware=[trim_context, summarization] ) # 대화 시뮬레이션 config = {"configurable": {"thread_id": "customer-001"}} # 1차 상호작용 result1 = agent.invoke( {"messages": [("user", "안녕하세요, 주문 A123 상태 알려주세요.")]}, config=config ) print(result1["messages"][-1].content) # 2차 상호작용 (이전 대화 기억) result2 = agent.invoke( {"messages": [("user", "배송은 언제쯤 완료되나요?")]}, config=config ) print(result2["messages"][-1].content) # 긴 대화 후 요약 동작 확인 for i in range(20): agent.invoke( {"messages": [("user", f"추가 질문 {i}")]}, config=config ) # 최종 상태 확인 final_result = agent.invoke( {"messages": [("user", "지금까지 무슨 얘기했죠?")]}, config=config ) print(final_result["messages"][-1].content) # 요약된 대화 내용을 기반으로 응답 \n```\n\n### 커스텀 전략\n\n특정 메시지 타입만 유지하거나, 중요도에 따라 선별적으로 삭제하는 커스텀 전략도 구현할 수 있습니다.\n\n**중요 메시지만 유지**\n\n```\n@before_model def keep_important_messages(state: dict) -&gt; dict: """중요 태그가 있는 메시지만 유지합니다.""" messages = state.get("messages", []) # 최근 5개 + 중요 메시지 유지 important = [m for m in messages if "important" in m.metadata.get("tags", [])] recent = messages[-5:] # 중복 제거 kept = {m.id: m for m in important + recent}.values() return {"messages": list(kept)} \n```\n\n**시간 기반 삭제**\n\n```\nfrom datetime import datetime, timedelta @before_model def delete_old_by_time(state: dict) -&gt; dict: """24시간 이상 된 메시지를 삭제합니다.""" messages = state.get("messages", []) cutoff = datetime.now() - timedelta(hours=24) to_remove = [] for msg in messages: msg_time = msg.metadata.get("timestamp") if msg_time and msg_time &lt; cutoff: to_remove.append(RemoveMessage(id=msg.id)) return {"messages": to_remove} \n```\n\n### 정리\n\n이번 장에서는 단기 메모리를 관리하는 네 가지 패턴을 배웠습니다.\n\n**핵심 포인트**\n\n* **트리밍**: 모델 호출 시 일시적으로 메시지 제한 (상태 유지)\n* **삭제**: 상태에서 영구적으로 메시지 제거\n* **요약**: 정보 손실 최소화하며 컨텍스트 압축\n* **커스텀 전략**: 애플리케이션 요구사항에 맞는 맞춤 구현\n\n**전략 선택 가이드**\n\n1. **짧은 대화 (&lt; 10회)**: 트리밍만으로 충분\n2. **중간 길이 대화 (10-50회)**: 트리밍 + 요약 조합\n3. **긴 대화 (50회 이상)**: 요약 + 주기적 삭제\n4. **민감 정보 포함**: 삭제 전략 필수\n\n마지막 편집일시 : 2026년 1월 11일 2:13 오후\n\n광고가 출력될 위치입니다.\n\n광고가 출력될 위치입니다.\n\n[댓글 0](javascript:show_comments();) [피드백](#myModal "피드백을 남겨주세요")\n\n[※ 댓글 작성은 로그인이 필요합니다.](/loginForm) [(또는 피드백을 이용해 주세요.)](#myModal)\n\n* **이전글** : [1-6-3. 다양한 메모리 저장 방식](javascript:page(293404))\n* **다음글** : [1-6-5.\\_장기\\_메모리](javascript:page(318945))\n\n  \n\n#### 책갈피\n\n### 이 페이지에 대한 피드백을 남겨주세요\n\n### 댓글을 신고합니다.'},
 {'title': '03. 에이전트(Agent) - &lt;랭체인LangChain 노트&gt; - 위키독스',
  'url': 'https://wikidocs.net/262586',
  'content': 'CH01 LangChain 시작하기)   01. 설치 영상보고 따라하기)   02. OpenAI API 키 발급 및 테스트)   03. LangSmith 추적 설정)   04. OpenAI API 사용(GPT-4o 멀티모달))   05. LangChain Expression Language(LCEL))   06. LCEL 인터페이스)   07. Runnable)   CH02 프롬프트(Prompt))   01. 프롬프트(Prompt))   02. 퓨샷 프롬프트(FewShotPromptTemplate))   03. LangChain Hub)   04. 개인화된 프롬프트(Hub에 업로드))   CH03 출력 파서(Output Parsers))   01. Pydantic 출력 파서(PydanticOutputParser))   02. 콤마 구분자 출력 파서(CommaSeparatedListOutputParser))   03. 구조화된 출력 파서(StructuredOuputParser))   04. JSON 출력 파서(JsonOutputParser))   05. 데이터프레임 출력 파서(PandasDataFrameOutputParser))   06. 날짜 형식 출력 파서(DatetimeOutputParser))   07. 열거형 출력 파서(EnumOutputParser))   08. 출력 수정 파서(OutputFixingParser))   CH04 모델(Model))   01. 다양한 LLM 모델 활용)   02. 캐싱(Cache))   03. 모델 직렬화(Serialization) - 저장 및 불러오기)   04. [...] ```\n도구 이름: search_news 도구 설명: Search Google News by input keyword 도구 이름: python_repl_tool 도구 설명: Use this to execute python code. If you want to see the output of a value, you should print it out with `print(...)`. This is visible to the user. \n```\n\n```\n# tools 정의 tools = [search_news, python_repl_tool] \n```\n\n## Agent 프롬프트 생성\n\n `chat_history` : 이전 대화 내용을 저장하는 변수 (멀티턴을 지원하지 않는다면, 생략 가능합니다.)\n `agent_scratchpad` : 에이전트가 임시로 저장하는 변수\n `input` : 사용자의 입력 [...] AgentExecutor는 도구를 사용하는 에이전트를 실행하는 클래스입니다.\n\n주요 속성\n\n `agent`: 실행 루프의 각 단계에서 계획을 생성하고 행동을 결정하는 에이전트\n `tools`: 에이전트가 사용할 수 있는 유효한 도구 목록\n `return_intermediate_steps`: 최종 출력과 함께 에이전트의 중간 단계 경로를 반환할지 여부\n `max_iterations`: 실행 루프를 종료하기 전 최대 단계 수\n `max_execution_time`: 실행 루프에 소요될 수 있는 최대 시간\n `early_stopping_method`: 에이전트가 `AgentFinish`를 반환하지 않을 때 사용할 조기 종료 방법. ("force" or "generate")\n `"force"` 는 시간 또는 반복 제한에 도달하여 중지되었다는 문자열을 반환합니다.\n `"generate"` 는 에이전트의 LLM 체인을 마지막으로 한 번 호출하여 이전 단계에 따라 최종 답변을 생성합니다.\n `handle_parsing_errors`: 에이전트의 출력 파서에서 발생한 오류 처리 방법. (True, False, 또는 오류 처리 함수)\n `trim_intermediate_steps`: 중간 단계를 트리밍하는 방법. (-1 trim 하지 않음, 또는 트리밍 함수)\n\n주요 메서드\n\n1. `invoke`: 에이전트 실행\n2. `stream`: 최종 출력에 도달하는 데 필요한 단계를 스트리밍\n\n주요 기능',
  'score': 0.60750073,
  'raw_content': '[**&lt;랭체인LangChain 노트&gt; - LangChain 한국어 튜토리얼🇰🇷**](/book/14314) \n\n[CH01 LangChain 시작하기](javascript:page(233341))   [01. 설치 영상보고 따라하기](javascript:page(257836))   [02. OpenAI API 키 발급 및 테스트](javascript:page(233342))   [03. LangSmith 추적 설정](javascript:page(250954))   [04. OpenAI API 사용(GPT-4o 멀티모달)](javascript:page(233343))   [05. LangChain Expression Language(LCEL)](javascript:page(233344))   [06. LCEL 인터페이스](javascript:page(233345))   [07. Runnable](javascript:page(233346))   [CH02 프롬프트(Prompt)](javascript:page(233347))   [01. 프롬프트(Prompt)](javascript:page(233351))   [02. 퓨샷 프롬프트(FewShotPromptTemplate)](javascript:page(233348))   [03. LangChain Hub](javascript:page(233349))   [04. 개인화된 프롬프트(Hub에 업로드)](javascript:page(233350))   [CH03 출력 파서(Output Parsers)](javascript:page(233771))   [01. Pydantic 출력 파서(PydanticOutputParser)](javascript:page(233786))   [02. 콤마 구분자 출력 파서(CommaSeparatedListOutputParser)](javascript:page(233787))   [03. 구조화된 출력 파서(StructuredOuputParser)](javascript:page(233788))   [04. JSON 출력 파서(JsonOutputParser)](javascript:page(233789))   [05. 데이터프레임 출력 파서(PandasDataFrameOutputParser)](javascript:page(233790))   [06. 날짜 형식 출력 파서(DatetimeOutputParser)](javascript:page(233791))   [07. 열거형 출력 파서(EnumOutputParser)](javascript:page(233792))   [08. 출력 수정 파서(OutputFixingParser)](javascript:page(233793))   [CH04 모델(Model)](javascript:page(233772))   [01. 다양한 LLM 모델 활용](javascript:page(233795))   [02. 캐싱(Cache)](javascript:page(233796))   [03. 모델 직렬화(Serialization) - 저장 및 불러오기](javascript:page(233798))   [04. 토큰 사용량 확인](javascript:page(233797))   [05. 구글 생성 AI(Google Generative AI)](javascript:page(233799))   [06. 허깅페이스 엔드포인트(HuggingFace Endpoints)](javascript:page(233802))   [07. 허깅페이스 로컬(HuggingFace Local)](javascript:page(233803))   [08. 허깅페이스 파이프라인(HuggingFace Pipeline)](javascript:page(233804))   [09. 올라마(Ollama)](javascript:page(233805))   [10. GPT4ALL](javascript:page(233806))   [11. 비디오(Video) 질의 응답 LLM (Gemini)](javascript:page(263314))   [CH05 메모리(Memory)](javascript:page(233773))   [01. 대화 버퍼 메모리(ConversationBufferMemory)](javascript:page(233801))   [02. 대화 버퍼 윈도우 메모리(ConversationBufferWindowMemory)](javascript:page(233800))   [03. 대화 토큰 버퍼 메모리(ConversationTokenBufferMemory)](javascript:page(233807))   [04. 대화 엔티티 메모리(ConversationEntityMemory)](javascript:page(233808))   [05. 대화 지식그래프 메모리(ConversationKGMemory)](javascript:page(233809))   [06. 대화 요약 메모리(ConversationSummaryMemory)](javascript:page(233810))   [07. 벡터저장소 검색 메모리(VectorStoreRetrieverMemory)](javascript:page(233811))   [08. LCEL Chain 에 메모리 추가](javascript:page(233812))   [09. SQLite 에 대화내용 저장](javascript:page(233813))   [10. RunnableWithMessageHistory에 ChatMessageHistory추가](javascript:page(254682))   [CH06 문서 로더(Document Loader)](javascript:page(233775))   [01. 도큐먼트(Document) 의 구조](javascript:page(253706))   [02. PDF](javascript:page(253707))   [03. 한글(HWP)](javascript:page(253708))   [04. CSV](javascript:page(253709))   [05. Excel](javascript:page(253710))   [06. Word](javascript:page(253711))   [07. PowerPoint](javascript:page(253712))   [08. 웹 문서(WebBaseLoader)](javascript:page(253713))   [09. 텍스트(TextLoader)](javascript:page(253714))   [10. JSON](javascript:page(253715))   [11. Arxiv](javascript:page(253716))   [12. UpstageLayoutAnalysisLoader](javascript:page(253717))   [13. LlamaParser](javascript:page(253718))   [CH07 텍스트 분할(Text Splitter)](javascript:page(233776))   [01. 문자 텍스트 분할(CharacterTextSplitter)](javascript:page(233998))   [02. 재귀적 문자 텍스트 분할(RecursiveCharacterTextSplitter)](javascript:page(233999))   [03. 토큰 텍스트 분할(TokenTextSplitter)](javascript:page(234002))   [04. 시멘틱 청커(SemanticChunker)](javascript:page(234003))   [05. 코드 분할(Python, Markdown, JAVA, C++, C#, GO, JS, Latex 등)](javascript:page(234004))   [06. 마크다운 헤더 텍스트 분할(MarkdownHeaderTextSplitter)](javascript:page(234005))   [07. HTML 헤더 텍스트 분할(HTMLHeaderTextSplitter)](javascript:page(234006))   [08. 재귀적 JSON 분할(RecursiveJsonSplitter)](javascript:page(234007))   [CH08 임베딩(Embedding)](javascript:page(233777))   [01. OpenAIEmbeddings](javascript:page(233815))   [02. 캐시 임베딩(CacheBackedEmbeddings)](javascript:page(233816))   [03. 허깅페이스 임베딩(HuggingFace Embeddings)](javascript:page(233817))   [04. UpstageEmbeddings](javascript:page(253106))   [05. OllamaEmbeddings](javascript:page(253107))   [06. GPT4ALL 임베딩](javascript:page(233818))   [07. Llama CPP 임베딩](javascript:page(233819))   [CH09 벡터저장소(VectorStore)](javascript:page(233778))   [01. Chroma](javascript:page(234094))   [02. FAISS](javascript:page(234014))   [03. Pinecone](javascript:page(252407))   [CH10 검색기(Retriever)](javascript:page(233779))   [01. 벡터스토어 기반 검색기(VectorStore-backed Retriever)](javascript:page(234016))   [02. 문맥 압축 검색기(ContextualCompressionRetriever)](javascript:page(234097))   [03. 앙상블 검색기(EnsembleRetriever)](javascript:page(234100))   [04. 긴 문맥 재정렬(LongContextReorder)](javascript:page(234101))   [05. 상위 문서 검색기(ParentDocumentRetriever)](javascript:page(234164))   [06. 다중 쿼리 검색기(MultiQueryRetriever)](javascript:page(234109))   [07. 다중 벡터저장소 검색기(MultiVectorRetriever)](javascript:page(234281))   [08. 셀프 쿼리 검색기(SelfQueryRetriever)](javascript:page(234475))   [09. 시간 가중 벡터저장소 검색기(TimeWeightedVectorStoreRetriever)](javascript:page(234604))   [10. 한글 형태소 분석기(Kiwi, Kkma, Okt) + BM25 검색기](javascript:page(251980))   [11. Convex Combination(CC) 적용된 앙상블 검색기(EnsembleRetriever)](javascript:page(263833))   [CH11 리랭커(Reranker)](javascript:page(253434))   [01. Cross Encoder Reranker](javascript:page(253836))   [02. Cohere Reranker](javascript:page(253837))   [03. Jina Reranker](javascript:page(253838))   [04. FlashRank Reranker](javascript:page(253839))   [CH12 Retrieval Augmented Generation(RAG)](javascript:page(233780))   [01. PDF 문서 기반 QA(Question-Answer)](javascript:page(251190))   [02. 네이버 뉴스기사 QA(Question-Answer)](javascript:page(234008))   [03. RAG 의 기능별 다양한 모듈 활용기](javascript:page(234009))   [04. RAPTOR: 긴 문맥 요약(Long Context Summary)](javascript:page(234017))   [05. 대화내용을 기억하는 RAG 체인](javascript:page(252858))   [CH13 LangChain Expression Language(LCEL)](javascript:page(233781))   [01. RunnablePassthrough](javascript:page(235580))   [02. Runnable 구조(그래프) 검토](javascript:page(235884))   [03. RunnableLambda](javascript:page(235705))   [04. LLM 체인 라우팅(RunnableLambda, RunnableBranch)](javascript:page(235882))   [05. RunnableParallel](javascript:page(235883))   [06. 동적 속성 지정(configurable\\_fields, configurable\\_alternatives)](javascript:page(235704))   [07. @chain 데코레이터로 Runnable 구성](javascript:page(235703))   [08. RunnableWithMessageHistory](javascript:page(235581))   [09. 사용자 정의 제네레이터(generator)](javascript:page(235885))   [10. Runtime Arguments 바인딩](javascript:page(235886))   [11. 폴백(fallback) 모델 지정](javascript:page(235938))   [CH14 체인(Chains)](javascript:page(233774))   [01. 문서 요약](javascript:page(234020))   [02. SQL](javascript:page(234019))   [03. 구조화된 출력 체인(with\\_structered\\_output)](javascript:page(256983))   [CH15 평가(Evaluations)](javascript:page(259203))   [01. 합성 테스트 데이터셋 생성(RAGAS)](javascript:page(259204))   [02. RAGAS 를 활용한 평가](javascript:page(259205))   [03. 생성한 평가용 데이터셋 업로드(HuggingFace Dataset)](javascript:page(259206))   [04. LangSmith 데이터셋 생성](javascript:page(259207))   [05. LLM-as-Judge](javascript:page(259208))   [06. 임베딩 기반 평가(embedding\\_distance)](javascript:page(259210))   [07. 사용자 정의(Custom) LLM 평가](javascript:page(259212))   [08. Rouge, BLEU, METEOR, SemScore 기반 휴리스틱 평가](javascript:page(259213))   [09. 실험(Experiment) 평가 비교](javascript:page(259214))   [10. 요약(Summary) 방식의 평가](javascript:page(259215))   [11. Groundedness(할루시네이션) 평가](javascript:page(259216))   [12. 실험 비교(Pairwise Evaluation)](javascript:page(259217))   [13. 반복 평가](javascript:page(259218))   [14. 온라인 평가를 활용한 평가 자동화](javascript:page(259219))   [CH16 에이전트(Agent)](javascript:page(233782))   [01. 도구(Tools)](javascript:page(262582))   [02. 도구 바인딩(Binding Tools)](javascript:page(262585))   [03. 에이전트(Agent)](javascript:page(262586))   [04. Claude, Gemini, Ollama, Together.ai 를 활용한 Agent](javascript:page(262592))   [05. Iteration 기능과 사람 개입(Human-in-the-loop)](javascript:page(262593))   [06. Agentic RAG](javascript:page(262595))   [07. CSVExcel 데이터 분석 Agent](javascript:page(262597))   [08. Toolkits 활용 Agent](javascript:page(262604))   [09. RAG + Image Generator Agent(보고서 작성)](javascript:page(262612))   [10. 도구를 활용한 토론 에이전트(Two Agent Debates with Tools)](javascript:page(234162))   [CH17 LangGraph](javascript:page(233785))   [01. 핵심 기능](javascript:page(265670))   [01. LangGraph 에 자주 등장하는 Python 문법이해](javascript:page(264613))   [02. LangGraph를 활용한 챗봇 구축](javascript:page(264614))   [03. LangGraph를 활용한 Agent 구축](javascript:page(264624))   [04. Agent 에 메모리(memory) 추가](javascript:page(265658))   [05. 노드의 단계별 스트리밍 출력](javascript:page(265659))   [06. Human-in-the-loop(사람의 개입)](javascript:page(265663))   [07. 중간단계 개입 되돌림을 통한 상태 수정과 Replay](javascript:page(265723))   [08. 사람(Human)에게 물어보는 노드 추가](javascript:page(265737))   [09. 메시지 삭제(RemoveMessage)](javascript:page(265749))   [10. ToolNode 를 사용하여 도구를 호출하는 방법](javascript:page(265763))   [11. 병렬 노드 실행을 위한 분기 생성 방법](javascript:page(265766))   [12. 대화 기록 요약을 추가하는 방법](javascript:page(265767))   [13. 서브그래프 추가 및 사용 방법](javascript:page(265768))   [14. 서브그래프의 입력과 출력을 변환하는 방법](javascript:page(265769))   [15. LangGraph 스트리밍 모드의 모든 것](javascript:page(265770))   [02. 구조 설계](javascript:page(267807))   [01. 기본 그래프 생성](javascript:page(267808))   [02. Naive RAG](javascript:page(267809))   [03. 관련성 체커(Relevance Checker) 모듈 추가](javascript:page(267810))   [04. 웹 검색 모듈 추가](javascript:page(267811))   [05. 쿼리 재작성 모듈 추가](javascript:page(267812))   [06. Agentic RAG](javascript:page(267813))   [07. Adaptive RAG](javascript:page(267814))   [03. Use Cases](javascript:page(267815))   [01. 에이전트 대화 시뮬레이션 (고객 응대 시나리오)](javascript:page(267816))   [02. 사용자 요구사항 기반 메타 프롬프트 생성 에이전트](javascript:page(267817))   [03. CRAG(Corrective RAG)](javascript:page(270686))   [04. Self-RAG](javascript:page(270687))   [05. 계획 후 실행(Plan-and-Execute)](javascript:page(270688))   [06. 멀티 에이전트 협업 네트워크(Multi-Agent Collaboration Network)](javascript:page(270689))   [07. 멀티 에이전트 감독자(Multi-Agent Supervisor)](javascript:page(270690))   [08. 계층적 멀티 에이전트 팀(Hierarchical Multi-Agent Teams)](javascript:page(270691))   [09. SQL 데이터베이스와 상호작용하는 에이전트](javascript:page(270692))   [10. STORM 개념을 도입한 연구를 위한 멀티 에이전트](javascript:page(270693))   [CH18 기타 정보](javascript:page(265575))   [01. StreamEvent 타입별 정리](javascript:page(265576))\n\n1. [**&lt;랭체인LangChain 노트&gt; - Lang…**](/book/14314)\n2. [CH16 에이전트(Agent)](/233782)\n3. [03. 에이전트(Agent)](/262586)\n\n1. [도서 증정 이벤트 !!](/321981)\n2. [위키독스](/)\n\n# 03. 에이전트(Agent)\n\n광고가 출력될 위치입니다.\n\n광고가 출력될 위치입니다.\n\n# 도구 호출 에이전트(Tool Calling Agent)\n\n도구 호출을 사용하면 모델이 하나 이상의 **도구(tool)** 가 **호출되어야 하는 시기를 감지하고 해당 도구에 전달해야 하는 입력** 으로 전달할 수 있습니다.\n\nAPI 호출에서 도구를 설명하고 모델이 이러한 도구를 호출하기 위한 인수가 포함된 JSON과 같은 구조화된 객체를 출력하도록 지능적으로 선택할 수 있습니다.\n\n도구 API 의 목표는 일반 텍스트 완성이나 채팅 API를 사용하여 수행할 수 있는 것보다 더 안정적으로 유효하고 유용한 **도구 호출(tool call)** 을 반환하는 것입니다.\n\n이러한 구조화된 출력을 도구 호출 채팅 모델에 여러 도구를 바인딩하고 모델이 호출할 도구를 선택할 수 있다는 사실과 결합하여 쿼리가 해결될 때까지 반복적으로 도구를 호출하고 결과를 수신하는 에이전트를 만들 수 있습니다.\n\n이것은 OpenAI 의 특정 도구 호출 스타일에 맞게 설계된 OpenAI 도구 에이전트의 보다 **일반화된 버전** 입니다.\n\n이 에이전트는 LangChain의 ToolCall 인터페이스를 사용하여 OpenAI 외에도 `Anthropic`, `Google Gemini`, `Mistral`과 같은 더 광범위한 공급자 구현을 지원합니다.\n\n**참고 링크**\n\n* [LangChain 공식 도큐먼트](https://python.langchain.com/v0.1/docs/modules/agents/agent_types/tool_calling/)\n\n```\n# API 키를 환경변수로 관리하기 위한 설정 파일 from dotenv import load_dotenv # API 키 정보 로드 load_dotenv() \n```\n\n```\nTrue\n```\n\n```\n# LangSmith 추적을 설정합니다. https://smith.langchain.com # !pip install -qU langchain-teddynote from langchain_teddynote import logging # 프로젝트 이름을 입력합니다. logging.langsmith("CH15-Agents") \n```\n\n```\nLangSmith 추적을 시작합니다. [프로젝트명] CH15-Agents \n```\n\n```\nfrom langchain.tools import tool from typing import List, Dict, Annotated from langchain_teddynote.tools import GoogleNews from langchain_experimental.utilities import PythonREPL # 도구 생성 @tool def search_news(query: str) -&gt; List[Dict[str, str]]: """Search Google News by input keyword""" news_tool = GoogleNews() return news_tool.search_by_keyword(query, k=5) # 도구 생성 @tool def python_repl_tool( code: Annotated[str, "The python code to execute to generate your chart."], ): """Use this to execute python code. If you want to see the output of a value, you should print it out with `print(...)`. This is visible to the user.""" result = "" try: result = PythonREPL().run(code) except BaseException as e: print(f"Failed to execute. Error: {repr(e)}") finally: return result print(f"도구 이름: {search_news.name}") print(f"도구 설명: {search_news.description}") print(f"도구 이름: {python_repl_tool.name}") print(f"도구 설명: {python_repl_tool.description}") \n```\n\n```\n도구 이름: search_news 도구 설명: Search Google News by input keyword 도구 이름: python_repl_tool 도구 설명: Use this to execute python code. If you want to see the output of a value, you should print it out with `print(...)`. This is visible to the user. \n```\n\n```\n# tools 정의 tools = [search_news, python_repl_tool] \n```\n\n## Agent 프롬프트 생성\n\n* `chat_history` : 이전 대화 내용을 저장하는 변수 (멀티턴을 지원하지 않는다면, 생략 가능합니다.)\n* `agent_scratchpad` : 에이전트가 임시로 저장하는 변수\n* `input` : 사용자의 입력\n\n```\nfrom langchain_core.prompts import ChatPromptTemplate # 프롬프트 생성 # 프롬프트는 에이전트에게 모델이 수행할 작업을 설명하는 텍스트를 제공합니다. (도구의 이름과 역할을 입력) prompt = ChatPromptTemplate.from_messages( [ ( "system", "You are a helpful assistant. " "Make sure to use the `search_news` tool for searching keyword related news.", ), ("placeholder", "{chat_history}"), ("human", "{input}"), ("placeholder", "{agent_scratchpad}"), ] ) \n```\n\n## Agent 생성\n\n```\nfrom langchain_openai import ChatOpenAI from langchain.agents import create_tool_calling_agent # LLM 정의 llm = ChatOpenAI(model="gpt-4o-mini", temperature=0) # Agent 생성 agent = create_tool_calling_agent(llm, tools, prompt) \n```\n\n## AgentExecutor\n\nAgentExecutor는 도구를 사용하는 에이전트를 실행하는 클래스입니다.\n\n**주요 속성**\n\n* `agent`: 실행 루프의 각 단계에서 계획을 생성하고 행동을 결정하는 에이전트\n* `tools`: 에이전트가 사용할 수 있는 유효한 도구 목록\n* `return_intermediate_steps`: 최종 출력과 함께 에이전트의 중간 단계 경로를 반환할지 여부\n* `max_iterations`: 실행 루프를 종료하기 전 최대 단계 수\n* `max_execution_time`: 실행 루프에 소요될 수 있는 최대 시간\n* `early_stopping_method`: 에이전트가 `AgentFinish`를 반환하지 않을 때 사용할 조기 종료 방법. ("force" or "generate")\n* `"force"` 는 시간 또는 반복 제한에 도달하여 중지되었다는 문자열을 반환합니다.\n* `"generate"` 는 에이전트의 LLM 체인을 마지막으로 한 번 호출하여 이전 단계에 따라 최종 답변을 생성합니다.\n* `handle_parsing_errors`: 에이전트의 출력 파서에서 발생한 오류 처리 방법. (True, False, 또는 오류 처리 함수)\n* `trim_intermediate_steps`: 중간 단계를 트리밍하는 방법. (-1 trim 하지 않음, 또는 트리밍 함수)\n\n**주요 메서드**\n\n1. `invoke`: 에이전트 실행\n2. `stream`: 최종 출력에 도달하는 데 필요한 단계를 스트리밍\n\n**주요 기능**\n\n1. **도구 검증**: 에이전트와 호환되는 도구인지 확인\n2. **실행 제어**: 최대 반복 횟수 및 실행 시간 제한 설정 가능\n3. **오류 처리**: 출력 파싱 오류에 대한 다양한 처리 옵션 제공\n4. **중간 단계 관리**: 중간 단계 트리밍 및 반환 옵션\n5. **비동기 지원**: 비동기 실행 및 스트리밍 지원\n\n**최적화 팁**\n\n* `max_iterations`와 `max_execution_time`을 적절히 설정하여 실행 시간 관리\n* `trim_intermediate_steps`를 활용하여 메모리 사용량 최적화\n* 복잡한 작업의 경우 `stream` 메서드를 사용하여 단계별 결과 모니터링\n\n```\nfrom langchain.agents import AgentExecutor # AgentExecutor 생성 agent_executor = AgentExecutor( agent=agent, tools=tools, verbose=True, max_iterations=10, max_execution_time=10, handle_parsing_errors=True, ) # AgentExecutor 실행 result = agent_executor.invoke({"input": "AI 투자와 관련된 뉴스를 검색해 주세요."}) print("Agent 실행 결과:") print(result["output"]) \n```\n\n```\nInvoking: `search_news` with `{\'query\': \'AI 투자\'}` [{\'url\': \'https://news.google.com/rss/articles/CBMiS0FVX3lxTE51YlpldHRJY3JiQld5aTB2WDNYQXFUVmhaeGFkbE1ybERvZWE5QW5qOEt6MS10R3RFR0tBSHFDZWttazJPUjJzeVRzNA?oc=5\', \'content\': \'AI 투자 늘리는 통신사, 주파수 재할당 대가 마련 부담 - 전자신문\'}, {\'url\': \'https://news.google.com/rss/articles/CBMiU0FVX3lxTFB1VDRjTlIxeHRjV3NKaERHMFJLOFNpUlNUVnZzQ0JvOUpISVE2cW9rbTZPVU9lQXZuUURJNHF0aDZyaDdQM0F5NFhsc0NrN1dHNEZz?oc=5\', \'content\': \'글로벌 CEO들 "향후 3년 무조건 AI 투자···직원도 더 뽑을 것" - 네이트 뉴스\'}, {\'url\': \'https://news.google.com/rss/articles/CBMiakFVX3lxTE9BQUtjd3pDS1dXRkZQTlo4Y2w2d2laZFFQRXdsbGlCMFRTcWJYLTNLaksxbFlnYzk3clVnYlFxZF93U2xubXY1VVhBTDQ2SDhLbm9hcDdXQ3prTlJtV0VCYTFINmNRbjR5N3c?oc=5\', \'content\': \'MIT 경제학자 "10년간 AI에 영향받을 직업은 5% 불과...기업은 투자비만 날리게 될 것" - AI타임스\'}, {\'url\': \'https://news.google.com/rss/articles/CBMiW0FVX3lxTE9oenZObVAzOV9hbUliNGhkLTBXZXZrTGpvT0ljcXlpWE5leld2b3RLbUJFTFRtZnU4c0VFaC1oYkVvTTdESEZCYmZUTDJSMFFYdGVXeXN3OVdRTEE?oc=5\', \'content\': \'MS, 이탈리아에 AI 인프라 6조4천억 투자 결정 - 연합뉴스\'}, {\'url\': \'https://news.google.com/rss/articles/CBMiiAFBVV95cUxOSVBVSnBvY2tXMnZQZTQ2OEliRTQyT0NSVTRMLUNNRFZQSnYzWXN5T3dyWDBnc1NZS2ZzOV9CSjFqT3kxZXFVck1qczJJUlRKZDh6cm5STHZteWk1bVltekdQVG1ZdnlpLUo3Rl9WQ0lSYjM4bFNHOXRYeUU3LVc0WkpfVW5kZDY10gGcAUFVX3lxTE5KRmdOOGkwYi1NZktDVXpWYWhRX0dlTW91NU45T1RURmlWNi14TU1ERnIxSzVwbTJEZnlOQVBnTUFsNHk5b3NjUzUyM2ljWFBuRl9OSFNTeVNhZ3BKV0pPWUNrRFIyRzJOS09GOFRnX1pZVHBxVnVGekRUWlRSSlozcmFPSFNpcEo4cThZOGxyel8wbzZuU2xNcjJUcg?oc=5\', \'content\': \'“전 세계 CEO 72%, 3년간 경제 성장 낙관적… 투자 1순위 AI” - 조선비즈 - 조선비즈\'}]다음은 AI 투자와 관련된 최근 뉴스 기사들입니다: 1. [AI 투자 늘리는 통신사, 주파수 재할당 대가 마련 부담 - 전자신문](https://news.google.com/rss/articles/CBMiS0FVX3lxTE51YlpldHRJY3JiQld5aTB2WDNYQXFUVmhaeGFkbE1ybERvZWE5QW5qOEt6MS10R3RFR0tBSHFDZWttazJPUjJzeVRzNA?oc=5) 2. [글로벌 CEO들 "향후 3년 무조건 AI 투자···직원도 더 뽑을 것" - 네이트 뉴스](https://news.google.com/rss/articles/CBMiU0FVX3lxTFB1VDRjTlIxeHRjV3NKaERHMFJLOFNpUlNUVnZzQ0JvOUpISVE2cW9rbTZPVU9lQXZuUURJNHF0aDZyaDdQM0F5NFhsc0NrN1dHNEZz?oc=5) 3. [MIT 경제학자 "10년간 AI에 영향받을 직업은 5% 불과...기업은 투자비만 날리게 될 것" - AI타임스](https://news.google.com/rss/articles/CBMiakFVX3lxTE9BQUtjd3pDS1dXRkZQTlo4Y2w2d2laZFFQRXdsbGlCMFRTcWJYLTNLaksxbFlnYzk3clVnYlFxZF93U2xubXY1VVhBTDQ2SDhLbm9hcDdXQ3prTlJtV0VCYTFINmNRbjR5N3c?oc=5) 4. [MS, 이탈리아에 AI 인프라 6조4천억 투자 결정 - 연합뉴스](https://news.google.com/rss/articles/CBMiW0FVX3lxTE9oenZObVAzOV9hbUliNGhkLTBXZXZrTGpvT0ljcXlpWE5leld2b3RLbUJFTFRtZnU4c0VFaC1oYkVvTTdESEZCYmZUTDJSMFFYdGVXeXN3OVdRTEE?oc=5) 5. [“전 세계 CEO 72%, 3년간 경제 성장 낙관적… 투자 1순위 AI” - 조선비즈](https://news.google.com/rss/articles/CBMiiAFBVV95cUxOSVBVSnBvY2tXMnZQZTQ2OEliRTQyT0NSVTRMLUNNRFZQSnYzWXN5T3dyWDBnc1NZS2ZzOV9CSjFqT3kxZXFVck1qczJJUlRKZDh6cm5STHZteWk1bVltekdQVG1ZdnlpLUo3Rl9WQ0lSYjM4bFNHOXRYeUU3LVc0WkpfVW5kZDY10gGcAUFVX3lxTE5KRmdOOGkwYi1NZktDVXpWYWhRX0dlTW91NU45T1RURmlWNi14TU1ERnIxSzVwbTJEZnlOQVBnTUFsNHk5b3NjUzUyM2ljWFBuRl9OSFNTeVNhZ3BKV0pPWUNrRFIyRzJOS09GOFRnX1pZVHBxVnVGekRUWlRSSlozcmFPSFNpcEo4cThZOGxyel8wbzZuU2xNcjJUcg?oc=5) 이 기사들은 AI 투자에 대한 다양한 관점과 최근 동향을 다루고 있습니다. Agent 실행 결과: 다음은 AI 투자와 관련된 최근 뉴스 기사들입니다: 1. [AI 투자 늘리는 통신사, 주파수 재할당 대가 마련 부담 - 전자신문](https://news.google.com/rss/articles/CBMiS0FVX3lxTE51YlpldHRJY3JiQld5aTB2WDNYQXFUVmhaeGFkbE1ybERvZWE5QW5qOEt6MS10R3RFR0tBSHFDZWttazJPUjJzeVRzNA?oc=5) 2. [글로벌 CEO들 "향후 3년 무조건 AI 투자···직원도 더 뽑을 것" - 네이트 뉴스](https://news.google.com/rss/articles/CBMiU0FVX3lxTFB1VDRjTlIxeHRjV3NKaERHMFJLOFNpUlNUVnZzQ0JvOUpISVE2cW9rbTZPVU9lQXZuUURJNHF0aDZyaDdQM0F5NFhsc0NrN1dHNEZz?oc=5) 3. [MIT 경제학자 "10년간 AI에 영향받을 직업은 5% 불과...기업은 투자비만 날리게 될 것" - AI타임스](https://news.google.com/rss/articles/CBMiakFVX3lxTE9BQUtjd3pDS1dXRkZQTlo4Y2w2d2laZFFQRXdsbGlCMFRTcWJYLTNLaksxbFlnYzk3clVnYlFxZF93U2xubXY1VVhBTDQ2SDhLbm9hcDdXQ3prTlJtV0VCYTFINmNRbjR5N3c?oc=5) 4. [MS, 이탈리아에 AI 인프라 6조4천억 투자 결정 - 연합뉴스](https://news.google.com/rss/articles/CBMiW0FVX3lxTE9oenZObVAzOV9hbUliNGhkLTBXZXZrTGpvT0ljcXlpWE5leld2b3RLbUJFTFRtZnU4c0VFaC1oYkVvTTdESEZCYmZUTDJSMFFYdGVXeXN3OVdRTEE?oc=5) 5. [“전 세계 CEO 72%, 3년간 경제 성장 낙관적… 투자 1순위 AI” - 조선비즈](https://news.google.com/rss/articles/CBMiiAFBVV95cUxOSVBVSnBvY2tXMnZQZTQ2OEliRTQyT0NSVTRMLUNNRFZQSnYzWXN5T3dyWDBnc1NZS2ZzOV9CSjFqT3kxZXFVck1qczJJUlRKZDh6cm5STHZteWk1bVltekdQVG1ZdnlpLUo3Rl9WQ0lSYjM4bFNHOXRYeUU3LVc0WkpfVW5kZDY10gGcAUFVX3lxTE5KRmdOOGkwYi1NZktDVXpWYWhRX0dlTW91NU45T1RURmlWNi14TU1ERnIxSzVwbTJEZnlOQVBnTUFsNHk5b3NjUzUyM2ljWFBuRl9OSFNTeVNhZ3BKV0pPWUNrRFIyRzJOS09GOFRnX1pZVHBxVnVGekRUWlRSSlozcmFPSFNpcEo4cThZOGxyel8wbzZuU2xNcjJUcg?oc=5) 이 기사들은 AI 투자에 대한 다양한 관점과 최근 동향을 다루고 있습니다. \n```\n\n## Stream 출력으로 단계별 결과 확인\n\nAgentExecutor의 `stream()` 메소드를 사용하여 에이전트의 중간 단계를 스트리밍할 것입니다.\n\n`stream()`의 출력은 (Action, Observation) 쌍 사이에서 번갈아 나타나며, 최종적으로 에이전트가 목표를 달성했다면 답변으로 마무리됩니다.\n\n다음과 같은 형태로 보일 것입니다.\n\n1. Action 출력\n2. Observation 출력\n3. Action 출력\n4. Observation 출력\n\n... (목표 달성까지 계속) ...\n\n그 다음, 최종 목표가 달성되면 에이전트는 최종 답변을 출력할 것입니다.\n\n이러한 출력의 내용은 다음과 같이 요약됩니다.\n\n| 출력 | 내용 |\n| --- | --- |\n| Action | `actions`: AgentAction 또는 그 하위 클래스 `messages`: 액션 호출에 해당하는 채팅 메시지 |\n| Observation | `steps`: 현재 액션과 그 관찰을 포함한 에이전트가 지금까지 수행한 작업의 기록 `messages`: 함수 호출 결과(즉, 관찰)를 포함한 채팅 메시지 |\n| Final Answer | `output`: AgentFinish `messages`: 최종 출력을 포함한 채팅 메시지 |\n\n```\nfrom langchain.agents import AgentExecutor # AgentExecutor 생성 agent_executor = AgentExecutor( agent=agent, tools=tools, verbose=False, handle_parsing_errors=True, ) \n```\n\n```\n# 스트리밍 모드 실행 result = agent_executor.stream({"input": "AI 투자와 관련된 뉴스를 검색해 주세요."}) for step in result: # 중간 단계 출력 print(step) \n```\n\n```\n{\'actions\': [ToolAgentAction(tool=\'search_news\', tool_input={\'query\': \'AI 투자\'}, log="\\nInvoking: `search_news` with `{\'query\': \'AI 투자\'}`\\n\\n\\n", message_log=[AIMessageChunk(content=\'\', additional_kwargs={\'tool_calls\': [{\'index\': 0, \'id\': \'call_dWv4C6NpksKE1IyaVmXjuDtT\', \'function\': {\'arguments\': \'{"query":"AI 투자"}\', \'name\': \'search_news\'}, \'type\': \'function\'}]}, response_metadata={\'finish_reason\': \'tool_calls\', \'model_name\': \'gpt-4o-mini-2024-07-18\', \'system_fingerprint\': \'fp_f85bea6784\'}, id=\'run-75795ef1-9b6b-4733-9dff-009486316af6\', tool_calls=[{\'name\': \'search_news\', \'args\': {\'query\': \'AI 투자\'}, \'id\': \'call_dWv4C6NpksKE1IyaVmXjuDtT\', \'type\': \'tool_call\'}], tool_call_chunks=[{\'name\': \'search_news\', \'args\': \'{"query":"AI 투자"}\', \'id\': \'call_dWv4C6NpksKE1IyaVmXjuDtT\', \'index\': 0, \'type\': \'tool_call_chunk\'}])], tool_call_id=\'call_dWv4C6NpksKE1IyaVmXjuDtT\')], \'messages\': [AIMessageChunk(content=\'\', additional_kwargs={\'tool_calls\': [{\'index\': 0, \'id\': \'call_dWv4C6NpksKE1IyaVmXjuDtT\', \'function\': {\'arguments\': \'{"query":"AI 투자"}\', \'name\': \'search_news\'}, \'type\': \'function\'}]}, response_metadata={\'finish_reason\': \'tool_calls\', \'model_name\': \'gpt-4o-mini-2024-07-18\', \'system_fingerprint\': \'fp_f85bea6784\'}, id=\'run-75795ef1-9b6b-4733-9dff-009486316af6\', tool_calls=[{\'name\': \'search_news\', \'args\': {\'query\': \'AI 투자\'}, \'id\': \'call_dWv4C6NpksKE1IyaVmXjuDtT\', \'type\': \'tool_call\'}], tool_call_chunks=[{\'name\': \'search_news\', \'args\': \'{"query":"AI 투자"}\', \'id\': \'call_dWv4C6NpksKE1IyaVmXjuDtT\', \'index\': 0, \'type\': \'tool_call_chunk\'}])]} {\'steps\': [AgentStep(action=ToolAgentAction(tool=\'search_news\', tool_input={\'query\': \'AI 투자\'}, log="\\nInvoking: `search_news` with `{\'query\': \'AI 투자\'}`\\n\\n\\n", message_log=[AIMessageChunk(content=\'\', additional_kwargs={\'tool_calls\': [{\'index\': 0, \'id\': \'call_dWv4C6NpksKE1IyaVmXjuDtT\', \'function\': {\'arguments\': \'{"query":"AI 투자"}\', \'name\': \'search_news\'}, \'type\': \'function\'}]}, response_metadata={\'finish_reason\': \'tool_calls\', \'model_name\': \'gpt-4o-mini-2024-07-18\', \'system_fingerprint\': \'fp_f85bea6784\'}, id=\'run-75795ef1-9b6b-4733-9dff-009486316af6\', tool_calls=[{\'name\': \'search_news\', \'args\': {\'query\': \'AI 투자\'}, \'id\': \'call_dWv4C6NpksKE1IyaVmXjuDtT\', \'type\': \'tool_call\'}], tool_call_chunks=[{\'name\': \'search_news\', \'args\': \'{"query":"AI 투자"}\', \'id\': \'call_dWv4C6NpksKE1IyaVmXjuDtT\', \'index\': 0, \'type\': \'tool_call_chunk\'}])], tool_call_id=\'call_dWv4C6NpksKE1IyaVmXjuDtT\'), observation=[{\'url\': \'https://news.google.com/rss/articles/CBMiS0FVX3lxTE51YlpldHRJY3JiQld5aTB2WDNYQXFUVmhaeGFkbE1ybERvZWE5QW5qOEt6MS10R3RFR0tBSHFDZWttazJPUjJzeVRzNA?oc=5\', \'content\': \'AI 투자 늘리는 통신사, 주파수 재할당 대가 마련 부담 - 전자신문\'}, {\'url\': \'https://news.google.com/rss/articles/CBMiU0FVX3lxTFB1VDRjTlIxeHRjV3NKaERHMFJLOFNpUlNUVnZzQ0JvOUpISVE2cW9rbTZPVU9lQXZuUURJNHF0aDZyaDdQM0F5NFhsc0NrN1dHNEZz?oc=5\', \'content\': \'글로벌 CEO들 "향후 3년 무조건 AI 투자···직원도 더 뽑을 것" - 네이트 뉴스\'}, {\'url\': \'https://news.google.com/rss/articles/CBMiakFVX3lxTE9BQUtjd3pDS1dXRkZQTlo4Y2w2d2laZFFQRXdsbGlCMFRTcWJYLTNLaksxbFlnYzk3clVnYlFxZF93U2xubXY1VVhBTDQ2SDhLbm9hcDdXQ3prTlJtV0VCYTFINmNRbjR5N3c?oc=5\', \'content\': \'MIT 경제학자 "10년간 AI에 영향받을 직업은 5% 불과...기업은 투자비만 날리게 될 것" - AI타임스\'}, {\'url\': \'https://news.google.com/rss/articles/CBMiW0FVX3lxTE9oenZObVAzOV9hbUliNGhkLTBXZXZrTGpvT0ljcXlpWE5leld2b3RLbUJFTFRtZnU4c0VFaC1oYkVvTTdESEZCYmZUTDJSMFFYdGVXeXN3OVdRTEE?oc=5\', \'content\': \'MS, 이탈리아에 AI 인프라 6조4천억 투자 결정 - 연합뉴스\'}, {\'url\': \'https://news.google.com/rss/articles/CBMiiAFBVV95cUxOSVBVSnBvY2tXMnZQZTQ2OEliRTQyT0NSVTRMLUNNRFZQSnYzWXN5T3dyWDBnc1NZS2ZzOV9CSjFqT3kxZXFVck1qczJJUlRKZDh6cm5STHZteWk1bVltekdQVG1ZdnlpLUo3Rl9WQ0lSYjM4bFNHOXRYeUU3LVc0WkpfVW5kZDY10gGcAUFVX3lxTE5KRmdOOGkwYi1NZktDVXpWYWhRX0dlTW91NU45T1RURmlWNi14TU1ERnIxSzVwbTJEZnlOQVBnTUFsNHk5b3NjUzUyM2ljWFBuRl9OSFNTeVNhZ3BKV0pPWUNrRFIyRzJOS09GOFRnX1pZVHBxVnVGekRUWlRSSlozcmFPSFNpcEo4cThZOGxyel8wbzZuU2xNcjJUcg?oc=5\', \'content\': \'“전 세계 CEO 72%, 3년간 경제 성장 낙관적… 투자 1순위 AI” - 조선비즈 - 조선비즈\'}])], \'messages\': [FunctionMessage(content=\'[{"url": "https://news.google.com/rss/articles/CBMiS0FVX3lxTE51YlpldHRJY3JiQld5aTB2WDNYQXFUVmhaeGFkbE1ybERvZWE5QW5qOEt6MS10R3RFR0tBSHFDZWttazJPUjJzeVRzNA?oc=5", "content": "AI 투자 늘리는 통신사, 주파수 재할당 대가 마련 부담 - 전자신문"}, {"url": "https://news.google.com/rss/articles/CBMiU0FVX3lxTFB1VDRjTlIxeHRjV3NKaERHMFJLOFNpUlNUVnZzQ0JvOUpISVE2cW9rbTZPVU9lQXZuUURJNHF0aDZyaDdQM0F5NFhsc0NrN1dHNEZz?oc=5", "content": "글로벌 CEO들 \\\\"향후 3년 무조건 AI 투자···직원도 더 뽑을 것\\\\" - 네이트 뉴스"}, {"url": "https://news.google.com/rss/articles/CBMiakFVX3lxTE9BQUtjd3pDS1dXRkZQTlo4Y2w2d2laZFFQRXdsbGlCMFRTcWJYLTNLaksxbFlnYzk3clVnYlFxZF93U2xubXY1VVhBTDQ2SDhLbm9hcDdXQ3prTlJtV0VCYTFINmNRbjR5N3c?oc=5", "content": "MIT 경제학자 \\\\"10년간 AI에 영향받을 직업은 5% 불과...기업은 투자비만 날리게 될 것\\\\" - AI타임스"}, {"url": "https://news.google.com/rss/articles/CBMiW0FVX3lxTE9oenZObVAzOV9hbUliNGhkLTBXZXZrTGpvT0ljcXlpWE5leld2b3RLbUJFTFRtZnU4c0VFaC1oYkVvTTdESEZCYmZUTDJSMFFYdGVXeXN3OVdRTEE?oc=5", "content": "MS, 이탈리아에 AI 인프라 6조4천억 투자 결정 - 연합뉴스"}, {"url": "https://news.google.com/rss/articles/CBMiiAFBVV95cUxOSVBVSnBvY2tXMnZQZTQ2OEliRTQyT0NSVTRMLUNNRFZQSnYzWXN5T3dyWDBnc1NZS2ZzOV9CSjFqT3kxZXFVck1qczJJUlRKZDh6cm5STHZteWk1bVltekdQVG1ZdnlpLUo3Rl9WQ0lSYjM4bFNHOXRYeUU3LVc0WkpfVW5kZDY10gGcAUFVX3lxTE5KRmdOOGkwYi1NZktDVXpWYWhRX0dlTW91NU45T1RURmlWNi14TU1ERnIxSzVwbTJEZnlOQVBnTUFsNHk5b3NjUzUyM2ljWFBuRl9OSFNTeVNhZ3BKV0pPWUNrRFIyRzJOS09GOFRnX1pZVHBxVnVGekRUWlRSSlozcmFPSFNpcEo4cThZOGxyel8wbzZuU2xNcjJUcg?oc=5", "content": "“전 세계 CEO 72%, 3년간 경제 성장 낙관적… 투자 1순위 AI” - 조선비즈 - 조선비즈"}]\', name=\'search_news\')]} {\'output\': \'다음은 AI 투자와 관련된 최근 뉴스 기사들입니다:\\n\\n1. [AI 투자 늘리는 통신사, 주파수 재할당 대가 마련 부담 - 전자신문](https://news.google.com/rss/articles/CBMiS0FVX3lxTE51YlpldHRJY3JiQld5aTB2WDNYQXFUVmhaeGFkbE1ybERvZWE5QW5qOEt6MS10R3RFR0tBSHFDZWttazJPUjJzeVRzNA?oc=5)\\n\\n2. [글로벌 CEO들 "향후 3년 무조건 AI 투자···직원도 더 뽑을 것" - 네이트 뉴스](https://news.google.com/rss/articles/CBMiU0FVX3lxTFB1VDRjTlIxeHRjV3NKaERHMFJLOFNpUlNUVnZzQ0JvOUpISVE2cW9rbTZPVU9lQXZuUURJNHF0aDZyaDdQM0F5NFhsc0NrN1dHNEZz?oc=5)\\n\\n3. [MIT 경제학자 "10년간 AI에 영향받을 직업은 5% 불과...기업은 투자비만 날리게 될 것" - AI타임스](https://news.google.com/rss/articles/CBMiakFVX3lxTE9BQUtjd3pDS1dXRkZQTlo4Y2w2d2laZFFQRXdsbGlCMFRTcWJYLTNLaksxbFlnYzk3clVnYlFxZF93U2xubXY1VVhBTDQ2SDhLbm9hcDdXQ3prTlJtV0VCYTFINmNRbjR5N3c?oc=5)\\n\\n4. [MS, 이탈리아에 AI 인프라 6조4천억 투자 결정 - 연합뉴스](https://news.google.com/rss/articles/CBMiW0FVX3lxTE9oenZObVAzOV9hbUliNGhkLTBXZXZrTGpvT0ljcXlpWE5leld2b3RLbUJFTFRtZnU4c0VFaC1oYkVvTTdESEZCYmZUTDJSMFFYdGVXeXN3OVdRTEE?oc=5)\\n\\n5. [“전 세계 CEO 72%, 3년간 경제 성장 낙관적… 투자 1순위 AI” - 조선비즈](https://news.google.com/rss/articles/CBMiiAFBVV95cUxOSVBVSnBvY2tXMnZQZTQ2OEliRTQyT0NSVTRMLUNNRFZQSnYzWXN5T3dyWDBnc1NZS2ZzOV9CSjFqT3kxZXFVck1qczJJUlRKZDh6cm5STHZteWk1bVltekdQVG1ZdnlpLUo3Rl9WQ0lSYjM4bFNHOXRYeUU3LVc0WkpfVW5kZDY10gGcAUFVX3lxTE5KRmdOOGkwYi1NZktDVXpWYWhRX0dlTW91NU45T1RURmlWNi14TU1ERnIxSzVwbTJEZnlOQVBnTUFsNHk5b3NjUzUyM2ljWFBuRl9OSFNTeVNhZ3BKV0pPWUNrRFIyRzJOS09GOFRnX1pZVHBxVnVGekRUWlRSSlozcmFPSFNpcEo4cThZOGxyel8wbzZuU2xNcjJUcg?oc=5)\\n\\n이 기사들은 AI 투자에 대한 다양한 관점과 최근 동향을 다루고 있습니다.\', \'messages\': [AIMessage(content=\'다음은 AI 투자와 관련된 최근 뉴스 기사들입니다:\\n\\n1. [AI 투자 늘리는 통신사, 주파수 재할당 대가 마련 부담 - 전자신문](https://news.google.com/rss/articles/CBMiS0FVX3lxTE51YlpldHRJY3JiQld5aTB2WDNYQXFUVmhaeGFkbE1ybERvZWE5QW5qOEt6MS10R3RFR0tBSHFDZWttazJPUjJzeVRzNA?oc=5)\\n\\n2. [글로벌 CEO들 "향후 3년 무조건 AI 투자···직원도 더 뽑을 것" - 네이트 뉴스](https://news.google.com/rss/articles/CBMiU0FVX3lxTFB1VDRjTlIxeHRjV3NKaERHMFJLOFNpUlNUVnZzQ0JvOUpISVE2cW9rbTZPVU9lQXZuUURJNHF0aDZyaDdQM0F5NFhsc0NrN1dHNEZz?oc=5)\\n\\n3. [MIT 경제학자 "10년간 AI에 영향받을 직업은 5% 불과...기업은 투자비만 날리게 될 것" - AI타임스](https://news.google.com/rss/articles/CBMiakFVX3lxTE9BQUtjd3pDS1dXRkZQTlo4Y2w2d2laZFFQRXdsbGlCMFRTcWJYLTNLaksxbFlnYzk3clVnYlFxZF93U2xubXY1VVhBTDQ2SDhLbm9hcDdXQ3prTlJtV0VCYTFINmNRbjR5N3c?oc=5)\\n\\n4. [MS, 이탈리아에 AI 인프라 6조4천억 투자 결정 - 연합뉴스](https://news.google.com/rss/articles/CBMiW0FVX3lxTE9oenZObVAzOV9hbUliNGhkLTBXZXZrTGpvT0ljcXlpWE5leld2b3RLbUJFTFRtZnU4c0VFaC1oYkVvTTdESEZCYmZUTDJSMFFYdGVXeXN3OVdRTEE?oc=5)\\n\\n5. [“전 세계 CEO 72%, 3년간 경제 성장 낙관적… 투자 1순위 AI” - 조선비즈](https://news.google.com/rss/articles/CBMiiAFBVV95cUxOSVBVSnBvY2tXMnZQZTQ2OEliRTQyT0NSVTRMLUNNRFZQSnYzWXN5T3dyWDBnc1NZS2ZzOV9CSjFqT3kxZXFVck1qczJJUlRKZDh6cm5STHZteWk1bVltekdQVG1ZdnlpLUo3Rl9WQ0lSYjM4bFNHOXRYeUU3LVc0WkpfVW5kZDY10gGcAUFVX3lxTE5KRmdOOGkwYi1NZktDVXpWYWhRX0dlTW91NU45T1RURmlWNi14TU1ERnIxSzVwbTJEZnlOQVBnTUFsNHk5b3NjUzUyM2ljWFBuRl9OSFNTeVNhZ3BKV0pPWUNrRFIyRzJOS09GOFRnX1pZVHBxVnVGekRUWlRSSlozcmFPSFNpcEo4cThZOGxyel8wbzZuU2xNcjJUcg?oc=5)\\n\\n이 기사들은 AI 투자에 대한 다양한 관점과 최근 동향을 다루고 있습니다.\')]} \n```\n\n### 중간 단계 출력을 사용자 정의 함수로 출력\n\n다음의 3개 함수를 정의하고 이를 통해 중간 단계 출력을 사용자 정의합니다.\n\n* `tool_callback`: 도구 호출 출력을 처리하는 함수\n* `observation_callback`: 관찰(Observation) 출력을 처리하는 함수\n* `result_callback`: 최종 답변 출력을 처리하는 함수\n\n```\n# 업데이트 # !pip install -U langchain-teddynote \n```\n\n아래는 Agent 의 중간 단계 과정을 깔끔하게 출력하기 위하여 사용되는 콜백 함수입니다.\n\n이 콜백 함수는 Streamlit 에서 중간 단계를 출력하여 사용자에게 제공할 때 유용할 수 있습니다.\n\n```\nfrom langchain_teddynote.messages import AgentStreamParser agent_stream_parser = AgentStreamParser() \n```\n\n스트리밍 방식으로 Agent 의 응답 과정을 확인합니다.\n\n```\n# 질의에 대한 답변을 스트리밍으로 출력 요청 result = agent_executor.stream( {"input": "matplotlib 을 사용하여 pie 차트를 그리는 코드를 작성하고 실행하세요."} ) for step in result: # 중간 단계를 parser 를 사용하여 단계별로 출력 agent_stream_parser.process_agent_steps(step) \n```\n\n```\n[도구 호출] Tool: python_repl_tool code: import matplotlib.pyplot as plt # 데이터 sizes = [15, 30, 45, 10] labels = [\'A\', \'B\', \'C\', \'D\'] colors = [\'gold\', \'yellowgreen\', \'lightcoral\', \'lightskyblue\'] # 파이 차트 그리기 plt.figure(figsize=(8, 6)) plt.pie(sizes, labels=labels, colors=colors, autopct=\'%1.1f%%\', startangle=140) plt.axis(\'equal\') # Equal aspect ratio ensures that pie is drawn as a circle. plt.title(\'Pie Chart Example\') plt.show() Log: Invoking: `python_repl_tool` with `{\'code\': "import matplotlib.pyplot as plt\\n\\n# 데이터\\nsizes = [15, 30, 45, 10]\\nlabels = [\'A\', \'B\', \'C\', \'D\']\\ncolors = [\'gold\', \'yellowgreen\', \'lightcoral\', \'lightskyblue\']\\n\\n# 파이 차트 그리기\\nplt.figure(figsize=(8, 6))\\nplt.pie(sizes, labels=labels, colors=colors, autopct=\'%1.1f%%\', startangle=140)\\nplt.axis(\'equal\') # Equal aspect ratio ensures that pie is drawn as a circle.\\nplt.title(\'Pie Chart Example\')\\nplt.show()"}` [관찰 내용] Observation: [최종 답변] 파이 차트가 성공적으로 그려졌습니다. 차트에는 A, B, C, D의 네 가지 카테고리가 포함되어 있으며, 각 카테고리의 비율이 표시되어 있습니다. 추가적인 질문이나 요청이 있으시면 말씀해 주세요! \n```\n\n다음은 callback 을 수정하여 사용하는 방법입니다.\n\n```\n# AgentCallbacks와 AgentStreamParser를 langchain_teddynote.messages에서 가져옵니다. from langchain_teddynote.messages import AgentCallbacks, AgentStreamParser # 도구 호출 시 실행되는 콜백 함수입니다. def tool_callback(tool) -&gt; None: print("&lt;&lt;&lt;&lt;&lt;&lt;&lt; 도구 호출 &gt;&gt;&gt;&gt;&gt;&gt;") print(f"Tool: {tool.get(\'tool\')}") # 사용된 도구의 이름을 출력합니다. print("&lt;&lt;&lt;&lt;&lt;&lt;&lt; 도구 호출 &gt;&gt;&gt;&gt;&gt;&gt;") # 관찰 결과를 출력하는 콜백 함수입니다. def observation_callback(observation) -&gt; None: print("&lt;&lt;&lt;&lt;&lt;&lt;&lt; 관찰 내용 &gt;&gt;&gt;&gt;&gt;&gt;") print( f"Observation: {observation.get(\'observation\')[0]}" ) # 관찰 내용을 출력합니다. print("&lt;&lt;&lt;&lt;&lt;&lt;&lt; 관찰 내용 &gt;&gt;&gt;&gt;&gt;&gt;") # 최종 결과를 출력하는 콜백 함수입니다. def result_callback(result: str) -&gt; None: print("&lt;&lt;&lt;&lt;&lt;&lt;&lt; 최종 답변 &gt;&gt;&gt;&gt;&gt;&gt;") print(result) # 최종 답변을 출력합니다. print("&lt;&lt;&lt;&lt;&lt;&lt;&lt; 최종 답변 &gt;&gt;&gt;&gt;&gt;&gt;") # AgentCallbacks 객체를 생성하여 각 단계별 콜백 함수를 설정합니다. agent_callbacks = AgentCallbacks( tool_callback=tool_callback, observation_callback=observation_callback, result_callback=result_callback, ) # AgentStreamParser 객체를 생성하여 에이전트의 실행 과정을 파싱합니다. agent_stream_parser = AgentStreamParser(agent_callbacks) \n```\n\n아래의 출력 내용을 확인해 보면 중간 내용의 출력 값이 내가 변경한 콜백 함수의 출력 값으로 변경된 것을 확인할 수 있습니다.\n\n```\n# 질의에 대한 답변을 스트리밍으로 출력 요청 result = agent_executor.stream({"input": "AI 투자관련 뉴스를 검색해 주세요."}) for step in result: # 중간 단계를 parser 를 사용하여 단계별로 출력 agent_stream_parser.process_agent_steps(step) \n```\n\n```\n&lt;&lt;&lt;&lt;&lt;&lt;&lt; 도구 호출 &gt;&gt;&gt;&gt;&gt;&gt; Tool: search_news &lt;&lt;&lt;&lt;&lt;&lt;&lt; 도구 호출 &gt;&gt;&gt;&gt;&gt;&gt; &lt;&lt;&lt;&lt;&lt;&lt;&lt; 관찰 내용 &gt;&gt;&gt;&gt;&gt;&gt; Observation: {\'url\': \'https://news.google.com/rss/articles/CBMiS0FVX3lxTE51YlpldHRJY3JiQld5aTB2WDNYQXFUVmhaeGFkbE1ybERvZWE5QW5qOEt6MS10R3RFR0tBSHFDZWttazJPUjJzeVRzNA?oc=5\', \'content\': \'AI 투자 늘리는 통신사, 주파수 재할당 대가 마련 부담 - 전자신문\'} &lt;&lt;&lt;&lt;&lt;&lt;&lt; 관찰 내용 &gt;&gt;&gt;&gt;&gt;&gt; &lt;&lt;&lt;&lt;&lt;&lt;&lt; 최종 답변 &gt;&gt;&gt;&gt;&gt;&gt; 다음은 AI 투자와 관련된 최근 뉴스 기사들입니다: 1. [AI 투자 늘리는 통신사, 주파수 재할당 대가 마련 부담 - 전자신문](https://news.google.com/rss/articles/CBMiS0FVX3lxTE51YlpldHRJY3JiQld5aTB2WDNYQXFUVmhaeGFkbE1ybERvZWE5QW5qOEt6MS10R3RFR0tBSHFDZWttazJPUjJzeVRzNA?oc=5) 2. [글로벌 CEO들 "향후 3년 무조건 AI 투자···직원도 더 뽑을 것" - 네이트 뉴스](https://news.google.com/rss/articles/CBMiU0FVX3lxTFB1VDRjTlIxeHRjV3NKaERHMFJLOFNpUlNUVnZzQ0JvOUpISVE2cW9rbTZPVU9lQXZuUURJNHF0aDZyaDdQM0F5NFhsc0NrN1dHNEZz?oc=5) 3. [MIT 경제학자 "10년간 AI에 영향받을 직업은 5% 불과...기업은 투자비만 날리게 될 것" - AI타임스](https://news.google.com/rss/articles/CBMiakFVX3lxTE9BQUtjd3pDS1dXRkZQTlo4Y2w2d2laZFFQRXdsbGlCMFRTcWJYLTNLaksxbFlnYzk3clVnYlFxZF93U2xubXY1VVhBTDQ2SDhLbm9hcDdXQ3prTlJtV0VCYTFINmNRbjR5N3c?oc=5) 4. [MS, 이탈리아에 AI 인프라 6조4천억 투자 결정 - 연합뉴스](https://news.google.com/rss/articles/CBMiW0FVX3lxTE9oenZObVAzOV9hbUliNGhkLTBXZXZrTGpvT0ljcXlpWE5leld2b3RLbUJFTFRtZnU4c0VFaC1oYkVvTTdESEZCYmZUTDJSMFFYdGVXeXN3OVdRTEE?oc=5) 5. [“전 세계 CEO 72%, 3년간 경제 성장 낙관적… 투자 1순위 AI” - 조선비즈](https://news.google.com/rss/articles/CBMiiAFBVV95cUxOSVBVSnBvY2tXMnZQZTQ2OEliRTQyT0NSVTRMLUNNRFZQSnYzWXN5T3dyWDBnc1NZS2ZzOV9CSjFqT3kxZXFVck1qczJJUlRKZDh6cm5STHZteWk1bVltekdQVG1ZdnlpLUo3Rl9WQ0lSYjM4bFNHOXRYeUU3LVc0WkpfVW5kZDY10gGcAUFVX3lxTE5KRmdOOGkwYi1NZktDVXpWYWhRX0dlTW91NU45T1RURmlWNi14TU1ERnIxSzVwbTJEZnlOQVBnTUFsNHk5b3NjUzUyM2ljWFBuRl9OSFNTeVNhZ3BKV0pPWUNrRFIyRzJOS09GOFRnX1pZVHBxVnVGekRUWlRSSlozcmFPSFNpcEo4cThZOGxyel8wbzZuU2xNcjJUcg?oc=5) 이 기사들은 AI 투자에 대한 다양한 관점과 최근 동향을 다루고 있습니다. &lt;&lt;&lt;&lt;&lt;&lt;&lt; 최종 답변 &gt;&gt;&gt;&gt;&gt;&gt; \n```\n\n## 이전 대화내용 기억하는 Agent\n\n이전의 대화내용을 기억하기 위해서는 `RunnableWithMessageHistory` 를 사용하여 `AgentExecutor` 를 감싸줍니다.\n\n`RunnableWithMessageHistory` 에 대한 자세한 내용은 아래 링크를 참고해 주세요.\n\n**참고** - [RunnableWithMessageHistory](https://wikidocs.net/254682)\n\n```\nfrom langchain_community.chat_message_histories import ChatMessageHistory from langchain_core.runnables.history import RunnableWithMessageHistory # session_id 를 저장할 딕셔너리 생성 store = {} # session_id 를 기반으로 세션 기록을 가져오는 함수 def get_session_history(session_ids): if session_ids not in store: # session_id 가 store에 없는 경우 # 새로운 ChatMessageHistory 객체를 생성하여 store에 저장 store[session_ids] = ChatMessageHistory() return store[session_ids] # 해당 세션 ID에 대한 세션 기록 반환 # 채팅 메시지 기록이 추가된 에이전트를 생성합니다. agent_with_chat_history = RunnableWithMessageHistory( agent_executor, # 대화 session_id get_session_history, # 프롬프트의 질문이 입력되는 key: "input" input_messages_key="input", # 프롬프트의 메시지가 입력되는 key: "chat_history" history_messages_key="chat_history", ) \n```\n\n```\n# 질의에 대한 답변을 스트리밍으로 출력 요청 response = agent_with_chat_history.stream( {"input": "안녕? 내 이름은 테디야!"}, # session_id 설정 config={"configurable": {"session_id": "abc123"}}, ) # 출력 확인 for step in response: agent_stream_parser.process_agent_steps(step) \n```\n\n```\n&lt;&lt;&lt;&lt;&lt;&lt;&lt; 최종 답변 &gt;&gt;&gt;&gt;&gt;&gt; 안녕하세요, 테디! 만나서 반가워요. 어떻게 도와드릴까요? &lt;&lt;&lt;&lt;&lt;&lt;&lt; 최종 답변 &gt;&gt;&gt;&gt;&gt;&gt; \n```\n\n```\n# 질의에 대한 답변을 스트리밍으로 출력 요청 response = agent_with_chat_history.stream( {"input": "내 이름이 뭐라고?"}, # session_id 설정 config={"configurable": {"session_id": "abc123"}}, ) # 출력 확인 for step in response: agent_stream_parser.process_agent_steps(step) \n```\n\n```\n&lt;&lt;&lt;&lt;&lt;&lt;&lt; 최종 답변 &gt;&gt;&gt;&gt;&gt;&gt; 당신의 이름은 테디입니다! &lt;&lt;&lt;&lt;&lt;&lt;&lt; 최종 답변 &gt;&gt;&gt;&gt;&gt;&gt; \n```\n\n```\n# 질의에 대한 답변을 스트리밍으로 출력 요청 response = agent_with_chat_history.stream( { "input": "내 이메일 주소는 teddy@teddynote.com 이야. 회사 이름은 테디노트 주식회사야." }, # session_id 설정 config={"configurable": {"session_id": "abc123"}}, ) # 출력 확인 for step in response: agent_stream_parser.process_agent_steps(step) \n```\n\n```\n&lt;&lt;&lt;&lt;&lt;&lt;&lt; 최종 답변 &gt;&gt;&gt;&gt;&gt;&gt; 감사합니다, 테디! 테디노트 주식회사에 대해 더 알고 싶으신가요? 아니면 다른 도움이 필요하신가요? &lt;&lt;&lt;&lt;&lt;&lt;&lt; 최종 답변 &gt;&gt;&gt;&gt;&gt;&gt; \n```\n\n```\n# 질의에 대한 답변을 스트리밍으로 출력 요청 response = agent_with_chat_history.stream( { "input": "최신 뉴스 5개를 검색해서 이메일의 본문으로 작성해줘. " "수신인에는 `셜리 상무님` 그리고, 발신인에는 내 인적정보를 적어줘." "정중한 어조로 작성하고, 메일의 시작과 끝에는 적절한 인사말과 맺음말을 적어줘." }, # session_id 설정 config={"configurable": {"session_id": "abc123"}}, ) # 출력 확인 for step in response: agent_stream_parser.process_agent_steps(step) \n```\n\n```\n&lt;&lt;&lt;&lt;&lt;&lt;&lt; 도구 호출 &gt;&gt;&gt;&gt;&gt;&gt; Tool: search_news &lt;&lt;&lt;&lt;&lt;&lt;&lt; 도구 호출 &gt;&gt;&gt;&gt;&gt;&gt; &lt;&lt;&lt;&lt;&lt;&lt;&lt; 관찰 내용 &gt;&gt;&gt;&gt;&gt;&gt; Observation: {\'url\': \'https://news.google.com/rss/articles/CBMiakFVX3lxTFB6b3FPREFINURLSy1pVUZDbXB4X3JwaW1fVGNCRks1RklJMDFNTWxCbURTbGMwU05kWVRRLU9xNnVFUkNPVFNLaUlTOThQaDRoQzlKQWtsQnVETnFqbEhGc2hIQnU2RERoS3c?oc=5\', \'content\': \'인사이드 구글 - The Keyword\'} &lt;&lt;&lt;&lt;&lt;&lt;&lt; 관찰 내용 &gt;&gt;&gt;&gt;&gt;&gt; &lt;&lt;&lt;&lt;&lt;&lt;&lt; 최종 답변 &gt;&gt;&gt;&gt;&gt;&gt; 아래는 셜리 상무님께 보낼 이메일 본문입니다. --- 제목: 최신 뉴스 업데이트 안녕하세요, 셜리 상무님. 테디노트 주식회사의 테디입니다. 최근의 주요 뉴스를 아래와 같이 정리하여 전달드립니다. 1. [인사이드 구글 - The Keyword](https://news.google.com/rss/articles/CBMiakFVX3lxTFB6b3FPREFINURLSy1pVUZDbXB4X3JwaW1fVGNCRks1RklJMDFNTWxCbURTbGMwU05kWVRRLU9xNnVFUkNPVFNLaUlTOThQaDRoQzlKQWtsQnVETnFqbEhGc2hIQnU2RERoS3c?oc=5) 2. [지역별 가격 조정 예고 - Riot Games](https://news.google.com/rss/articles/CBMickFVX3lxTE9USmRUM2lXX0NkdXgwdWlYMk1MQnprMmEwT3UySUd0MFg1VTJzQldNMGNXVEw4N0VvUlJDaklEX2Vybl9QcGIwTGwyNzhYeS1sVkJmSDRDbDliRm9FOWRpMlJiM0FrWDBsb0RCeExKTVhYZw?oc=5) 3. [\'제135회 중국수출입박람회\' 광저우서 개막 - 최신 뉴스 온라인 선전시 정부](https://news.google.com/rss/articles/CBMieEFVX3lxTE1lUzhZOU9WTGE1Z2JwcTdJbldlZG5ac0QxSy1WWkI4b3lGQVFBU2ItUUwwbGZJZEVDaGZrVE5xMzl0OVVmZEtIaEoxaHVIX3RERkgzVEltOFRvS0dOX05ReDBSelJXaktNWVF0N2RxMU44MVNCdDNXcw?oc=5) 4. [김정은 전용차 또 바꿨나…최신 마이바흐 SUV 포착 - 연합뉴스TV](https://news.google.com/rss/articles/CBMiZ0FVX3lxTFBsU0pmcm9Cb0RId2FVTFBzZVg0UTN5WFBjTVVRbDhBTG1DMmdTYlFNaGJVUl9hVjhBUlpSNGRBM3QzdGFxcWVZT0pCTkhIMGRLbmRITUR3ZXNHMVJURE90Y1U1SmQ0NFU?oc=5) 5. [군, 대북 확성기 방송…최신 탈북자 뉴스부터 ‘탈출하라’ 내용까지 - KBS뉴스](https://news.google.com/rss/articles/CBMiW0FVX3lxTE0tU0xLX21DLUlJb2ZDemhUYlNpMDlHNmdwLVJ4Z1FYVmJFdk1GWndBd29LMmVVV1hJYTRta3lMLWFMMUtxS1BBc1hHdXBERjZFU2hodnpPQUtzbTA?oc=5) 이 정보가 도움이 되길 바랍니다. 추가적인 질문이나 요청이 있으시면 언제든지 말씀해 주세요. 감사합니다. 테디 teddy@teddynote.com 테디노트 주식회사 --- 이메일을 보내실 준비가 되셨나요? 추가로 수정할 부분이 있으면 말씀해 주세요! &lt;&lt;&lt;&lt;&lt;&lt;&lt; 최종 답변 &gt;&gt;&gt;&gt;&gt;&gt; \n```\n\n마지막 편집일시 : 2024년 12월 23일 2:07 오전\n\n광고가 출력될 위치입니다.\n\n광고가 출력될 위치입니다.\n\n[댓글 0](javascript:show_comments();) [피드백](#myModal "피드백을 남겨주세요")\n\n[※ 댓글 작성은 로그인이 필요합니다.](/loginForm) [(또는 피드백을 이용해 주세요.)](#myModal)\n\n* **이전글** : [02. 도구 바인딩(Binding Tools)](javascript:page(262585))\n* **다음글** : [04. Claude, Gemini, Ollama, Together.ai 를 활용한 Agent](javascript:page(262592))\n\n  \n\n#### 책갈피\n\n### 이 페이지에 대한 피드백을 남겨주세요\n\n### 댓글을 신고합니다.'}]</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=a2fad434">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<br/>
<h3 id="TavilySearch-(%EC%BB%A4%EC%8A%A4%ED%85%80)"><code>TavilySearch</code> (커스텀)<a class="anchor-link" href="#TavilySearch-(%EC%BB%A4%EC%8A%A4%ED%85%80)">¶</a></h3><ul>
<li>Tavily 검색 API</li>
</ul>
<br/>
<h4 id="%EA%B8%B0%EB%B3%B8-%EA%B2%80%EC%83%89-%EC%84%A4%EC%A0%95">기본 검색 설정<a class="anchor-link" href="#%EA%B8%B0%EB%B3%B8-%EA%B2%80%EC%83%89-%EC%84%A4%EC%A0%95">¶</a></h4><ul>
<li><code>query</code> (str): 검색하고자 하는 키워드나 문장</li>
<li><code>search_depth</code> (str): 검색의 상세도. <code>"basic"</code>(기본) 또는 <code>"advanced"</code>(고급) 중 선택</li>
<li><code>topic</code> (str): 검색 주제 분야. "general"(일반) 또는 "news"(뉴스) 중 선택</li>
<li><code>days</code> (int): 검색 결과의 최신성. 지정된 일수 이내의 결과만 반환<ul>
<li>특정 기간(<code>days</code>) 내의 최신 데이터를 필터링하는 기능은 현재 <code>topic="news"</code> 설정에서만 활성화</li>
</ul>
</li>
<li><code>max_results</code> (int): 반환받을 최대 검색 결과 수</li>
</ul>
<br/>
<h4 id="%EB%8F%84%EB%A9%94%EC%9D%B8-%ED%95%84%ED%84%B0%EB%A7%81">도메인 필터링<a class="anchor-link" href="#%EB%8F%84%EB%A9%94%EC%9D%B8-%ED%95%84%ED%84%B0%EB%A7%81">¶</a></h4><ul>
<li><code>include_domains</code> (list): 검색 결과에 반드시 포함할 도메인 목록</li>
<li><code>exclude_domains</code> (list): 검색 결과에서 제외할 도메인 목록</li>
</ul>
<br/>
<h4 id="%EA%B2%B0%EA%B3%BC-%EC%83%81%EC%84%B8-%EC%84%A4%EC%A0%95">결과 상세 설정<a class="anchor-link" href="#%EA%B2%B0%EA%B3%BC-%EC%83%81%EC%84%B8-%EC%84%A4%EC%A0%95">¶</a></h4><ul>
<li><code>include_answer</code> (bool): API가 생성한 답변 포함 여부</li>
<li><code>include_raw_content</code> (bool): 웹페이지의 원본 HTML 콘텐츠 포함 여부</li>
<li><code>include_images</code> (bool): 관련 이미지 정보 포함 여부</li>
<li><code>format_output</code> (bool): 검색 결과의 포맷팅 적용 여부</li>
</ul>
<br/>
<h4 id="%EA%B8%B0%ED%83%80">기타<a class="anchor-link" href="#%EA%B8%B0%ED%83%80">¶</a></h4><ul>
<li><code>**kwargs</code>: 추가적인 키워드 인자. API의 향후 업데이트나 특수 기능에 사용될 수 있음</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=2ec562bc">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">langchain_teddynote.tools.tavily</span><span class="w"> </span><span class="kn">import</span> <span class="n">TavilySearch</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=abc4c6e9">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<br/>
<ul>
<li>기본 객체</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=08d9a8fe">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [15]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">tavily_tool</span> <span class="o">=</span> <span class="n">TavilySearch</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=5f4b6d04">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [22]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">result1</span> <span class="o">=</span> <span class="n">tavily_tool</span><span class="o">.</span><span class="n">search</span><span class="p">(</span>
    <span class="n">query</span><span class="o">=</span><span class="s2">"유튜버 테디노트에 대해서 알려줘"</span><span class="p">,</span>  <span class="c1"># 검색 쿼리</span>
    <span class="n">search_depth</span><span class="o">=</span><span class="s2">"advanced"</span><span class="p">,</span>  <span class="c1"># 고급 검색 수준</span>
    <span class="n">topic</span><span class="o">=</span><span class="s2">"general"</span><span class="p">,</span>  <span class="c1"># 일반 주제</span>
    <span class="n">max_results</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>  <span class="c1"># 최대 10개 결과</span>
    <span class="n">include_answer</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>  <span class="c1"># 답변 포함</span>
    <span class="n">include_raw_content</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>  <span class="c1"># 원본 콘텐츠 포함</span>
    <span class="n">include_images</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>  <span class="c1"># 이미지 포함</span>
    <span class="n">format_output</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>  <span class="c1"># 결과 포맷팅</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=a8283bdc">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [23]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">result1</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[23]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>['&lt;document&gt;&lt;title&gt;Teddy Lee 님 - 테디노트 YouTuber, LangChain Ambassador, Data ...&lt;/title&gt;&lt;url&gt;https://kr.linkedin.com/in/teddy-lee&lt;/url&gt;&lt;content&gt;경력 ; Ambassador. LangChain. 2025년 2월 – 현재 1년 1개월. 대한민국 서울 ; Content Creator. 테디노트 TeddyNote. 2020년 5월 – 현재 5년 10개월 ; CEO / Founder.&lt;/content&gt;&lt;/document&gt;',
 '&lt;document&gt;&lt;title&gt;테디노트 TeddyNote - YouTube&lt;/title&gt;&lt;url&gt;https://www.youtube.com/channel/UCt2wAAXgm87ACiQnDHQEW6Q&lt;/url&gt;&lt;content&gt;테디노트 TeddyNote. @teddynote. 50.4K subscribers•285 videos. 데이터 분석, 머신러닝, 딥러닝, LLM 에 대한 내용을 다룹니다. ... How much papers do you read in two&lt;/content&gt;&lt;raw&gt;![](data:image/png;base64,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)&lt;/raw&gt;&lt;/document&gt;',
 '&lt;document&gt;&lt;title&gt;테디의 비밀노트 - YouTube&lt;/title&gt;&lt;url&gt;https://www.youtube.com/@teddysecretnote&lt;/url&gt;&lt;content&gt;왕초보 유튜버가 영상을 만드는 데 필요한 실전 꿀팁을 소개합니다 · 상위 1% 유튜버들은 알고 있는 유튜브 꿀팁 · 유튜버의 목소리를 계속 듣고 싶게 만드는 비밀 · 인기 유&lt;/content&gt;&lt;/document&gt;',
 "&lt;document&gt;&lt;title&gt;'테디의 비밀노트' 유튜브 채널 (유튜브 왕초보를 위한 유튜브 채널 육성 ...&lt;/title&gt;&lt;url&gt;https://teddylabs.tistory.com/1&lt;/url&gt;&lt;content&gt;안녕하세요 왕초보를 위한 유튜브 육성 채널테디의 비밀노트를 운영중인 테디 입니다 :)\u200b□ 유튜브 채널, 테디의 비밀노트 테디의 비밀노트유튜브 채널&lt;/content&gt;&lt;/document&gt;",
 '&lt;document&gt;&lt;title&gt;테디노트 - 위키독스&lt;/title&gt;&lt;url&gt;https://wikidocs.net/profile/info/book/10226&lt;/url&gt;&lt;content&gt;### 테디노트\\n\\n한줄 소개\\n:   블로그와 유튜브 \\"테디노트\\"를 운영하고 있으며, \\"파이썬 딥러닝 텐서플로\\"를 집필하였습니다. 데이터분석과 AI를 사랑하고 지식공유에 활발히 참여하고 있습니다.\\n\\n첫번째 컴퓨터\\n:   기억이 안나요.\\n\\n블로그\\n:   테디노트\\n\\n나의 URL\\n:   \\n\\n 저서\\n 최근댓글\\n 최근수정\\n 최근블로그\\n\\n&lt;랭체인LangChain 노트&gt; - LangChain 한국어 튜토리얼🇰🇷\\n\\n저자: 테디노트\\n\\n\\\\\\\\추천\\\\\\\\은 공유할 수 있는 무료 전자책을 집필하는데 정말 큰 힘이 됩니다. \\\\\\\\\\"추천\\"\\\\\\\\ 한 번씩만 부탁 드리겠습니다🙏🙏 ✅ \\\\\\\\랭체인 한국어 튜토리얼 강의\\\\\\\\ 패스트캠퍼스 - RAG ✅ \\\\\\\\랭체인 한국어 튜토리얼 코드저장소(GitHub)\\\\\\\\ 📘🖥️ ✅ \\\\\\\\유튜브 \\"테디노트\\"\\\\…\\n\\n수정: 2025년 4월 30일 8:06 오후\\n\\n[한 권으로 끝내는 &lt;판다스 노트&gt;\\n\\n저자: 테디노트, Min\\n\\n판다스는 파이썬에서 가장 널리 쓰이는 라이브러리 가운데 하나입니다. 데이터 분석 전문가가 파이썬으로 데이터 분석을 한다면, 아마 대부분은 가장 먼저 판다스 라이브러리를 임포트할 것입니다. 데이터 분석을 위한 필수 요소로 널리 자리잡은 판다스, 여러분이 파이썬의 기초를 충분히 학습했다면…\\n\\n수정: 2024년 6월 24일 1:45 오후\\n\\n한 권으로 끝내는 &lt;파이썬 노트&gt;\\n\\n저자: 테디노트, Min [...] 한 권으로 끝내는 &lt;파이썬 노트&gt;\\n\\n저자: 테디노트, Min\\n\\n파이썬은 배우기 쉬우면서도 확장성이 뛰어난 프로그래밍 언어입니다. 때문에 파이썬은 초보자와 숙련자 모두에게 매우 유용한 언어이며, 중요한 것은 시간이 지날수록 더욱 유망한 프로그래밍 언어가 될 것이라는 점입니다. \'파이썬 노트\' 강의는 처음 파이썬을 접하거나, 파이썬 공부를 시작했다가…\\n\\n수정: 2023년 6월 7일 3:41 오후\\n\\n한 권으로 끝내는 &lt;머신러닝 노트&gt;\\n\\n저자: 테디노트\\n\\n머신러닝은 최근 가장 주목받고 있는 인공지능 분야 가운데 하나입니다. 머신러닝은 데이터를 기반으로 다양한 통계적 알고리즘을 활용하여 컴퓨터가 스스로 학습할 수 있도록 프로그래밍 하는 것을 의미합니다. 머신러닝 노트는 이러한 머신러닝에 대한 학습을 어디서부터 시작할지 막막해 하는 분들을…\\n\\n수정: 2024년 2월 2일 2:45 오전\\n\\n테디노트의 RAG 비법노트 : RAG 시작하기\\n\\n저자: 패스트캠퍼스, 테디노트\\n\\n## 들어가기 전에 이 책은 유튜브 \'테디노트\'의 2만 구독자의 설문을 기반으로, 랭체인 개념부터 실무를 위한 Advanced RAG가 궁금한 분들을 대상으로 만들었습니다. 특히 RAG를 처음 공부하는 분들을 위해 기본 요소 및 원리와 간단한 실습 프로젝트를 함께 담고자 하였습니다. …\\n\\n수정: 2025년 3월 18일 1:20 오후\\n\\nMCP 가이드: LangChain 기반 구축과 Cursor AI 연동 by. 테디노트\\n\\n저자: 패스트캠퍼스, 테디노트 [...] 저자: 패스트캠퍼스, 테디노트\\n\\n## 들어가기 전에 이 도서는 \\\\\\\\MCP(Model Context Protocol)\\\\\\\\를 활용해 Cursor AI와 같은 나만의 AI 에이전트를 구축하는 방법을 자세히 다룹니다. 핵심은 호스트, 클라이언트, 서버의 역할을 이해하는 것이며, 특히 클라이언트 구현을 통해 다양한 외부 도구…\\n\\n수정: 2025년 7월 7일 3:07 오후&lt;/content&gt;&lt;raw&gt;### 테디노트\n\n---\n\n한줄 소개\n:   블로그와 유튜브 "테디노트"를 운영하고 있으며, "파이썬 딥러닝 텐서플로"를 집필하였습니다. 데이터분석과 AI를 사랑하고 지식공유에 활발히 참여하고 있습니다.\n\n첫번째 컴퓨터\n:   기억이 안나요.\n\n블로그\n:   [테디노트](/blog/@teddynote/)\n\n나의 URL\n:   &lt;https://teddylee777.github.io&gt;\n\n* [저서](#)\n* [최근댓글](/profile/info/comment/10226)\n* [최근수정](/profile/info/page/10226)\n* [최근블로그](/profile/info/blog/10226)\n\n---\n\n[&lt;랭체인LangChain 노트&gt; - LangChain 한국어 튜토리얼🇰🇷](/book/14314)\n\n저자: 테디노트\n\n\\*\\*추천\\*\\*은 공유할 수 있는 무료 전자책을 집필하는데 정말 큰 힘이 됩니다. \\*\\*"추천"\\*\\* 한 번씩만 부탁 드리겠습니다🙏🙏 ✅ \\*\\*랭체인 한국어 튜토리얼 강의\\*\\* [패스트캠퍼스 - RAG ✅ \\*\\*랭체인 한국어 튜토리얼 코드저장소(GitHub)\\*\\* 📘🖥️ ✅ \\*\\*유튜브 "테디노트"\\*…\n\n수정: 2025년 4월 30일 8:06 오후\n\n[한 권으로 끝내는 &lt;판다스 노트&gt;](/book/4639)\n\n저자: 테디노트, Min\n\n판다스는 파이썬에서 가장 널리 쓰이는 라이브러리 가운데 하나입니다. 데이터 분석 전문가가 파이썬으로 데이터 분석을 한다면, 아마 대부분은 가장 먼저 판다스 라이브러리를 임포트할 것입니다. 데이터 분석을 위한 필수 요소로 널리 자리잡은 판다스, 여러분이 파이썬의 기초를 충분히 학습했다면…\n\n수정: 2024년 6월 24일 1:45 오후\n\n[한 권으로 끝내는 &lt;파이썬 노트&gt;](/book/6708)\n\n저자: 테디노트, Min\n\n파이썬은 배우기 쉬우면서도 확장성이 뛰어난 프로그래밍 언어입니다. 때문에 파이썬은 초보자와 숙련자 모두에게 매우 유용한 언어이며, 중요한 것은 시간이 지날수록 더욱 유망한 프로그래밍 언어가 될 것이라는 점입니다. \'파이썬 노트\' 강의는 처음 파이썬을 접하거나, 파이썬 공부를 시작했다가…\n\n수정: 2023년 6월 7일 3:41 오후\n\n[한 권으로 끝내는 &lt;머신러닝 노트&gt;](/book/7002)\n\n저자: 테디노트\n\n머신러닝은 최근 가장 주목받고 있는 인공지능 분야 가운데 하나입니다. 머신러닝은 데이터를 기반으로 다양한 통계적 알고리즘을 활용하여 컴퓨터가 스스로 학습할 수 있도록 프로그래밍 하는 것을 의미합니다. 머신러닝 노트는 이러한 머신러닝에 대한 학습을 어디서부터 시작할지 막막해 하는 분들을…\n\n수정: 2024년 2월 2일 2:45 오전\n\n[테디노트의 RAG 비법노트 : RAG 시작하기](/book/16865)\n\n저자: 패스트캠퍼스, 테디노트\n\n## 들어가기 전에 이 책은 유튜브 \'테디노트\'의 2만 구독자의 설문을 기반으로, 랭체인 개념부터 실무를 위한 Advanced RAG가 궁금한 분들을 대상으로 만들었습니다. 특히 RAG를 처음 공부하는 분들을 위해 기본 요소 및 원리와 간단한 실습 프로젝트를 함께 담고자 하였습니다. …\n\n수정: 2025년 3월 18일 1:20 오후\n\n[MCP 가이드: LangChain 기반 구축과 Cursor AI 연동 by. 테디노트](/book/17801)\n\n저자: 패스트캠퍼스, 테디노트\n\n## 들어가기 전에 이 도서는 \\*\\*MCP(Model Context Protocol)\\*\\*를 활용해 Cursor AI와 같은 나만의 AI 에이전트를 구축하는 방법을 자세히 다룹니다. 핵심은 호스트, 클라이언트, 서버의 역할을 이해하는 것이며, 특히 클라이언트 구현을 통해 다양한 외부 도구…\n\n수정: 2025년 7월 7일 3:07 오후&lt;/raw&gt;&lt;/document&gt;',
 '&lt;document&gt;&lt;title&gt;linktr.ee/teddynote | Linktree&lt;/title&gt;&lt;url&gt;https://linktr.ee/teddynote&lt;/url&gt;&lt;content&gt;## AI Contents Creator. #LLM #RAG #LangChain\\n\\nYouTubeLinkedInGitHubEmail\\n\\n9/24 래블업 컨퍼런스: Agentic 개발팁팁\\n\\n[[FastCampus] 테디노트의 RAG 비법노트🙌](\\n\\n7/1 바이브코딩 컨퍼런스 발표자료\\n\\n2025-랭체인밋업-Q2 발표자료\\n\\n2025 도큐먼트 파서(PDF)\\n\\n3/20 Anthropic Korea Builder Summit 내용\\n\\n03/04 랭체인밋업2025 - LangGraph 기반 Agentic AI 시스템 구축\\n\\n03/04 LangGraph Hands On 튜토리얼 (2시간 분량)\\n\\n[🔥[100% 무료] 테디노트 YouTube 콘텐츠 학습 순서🔥](\\n\\n📘 랭체인 한국어 튜토리얼🇰🇷\\n\\n유튜브\\n\\n블로그\\n\\n12/15 모두콘2024 - AI 시대의 생존 전략: 대체되지 않는 인재로 성장하기\\n\\n11/9 파이콘한국 2024 \\"에이전트 튜토리얼\\"\\n\\nGithub\\n\\n9/21 테디노트-Gencon2024-ModularRAG-20240921.pdf\\n\\n링크드인\\n\\n•Report•Privacy•\\n\\n## Explore other Linktrees [...] 링크드인\\n\\n•Report•Privacy•\\n\\n## Explore other Linktrees\\n\\n@limitlessaxes@ofi\\\\_australia@Willtherealdeal@ginger\\\\_renee@GatewayEspanol@etherealevie@yourfavoritepunkhippie@tyra.blackmon@wildhoovesopenhearts@rafaelaquintinauthor@msbellanicole@RadnorHouseTW@Diamondcappriella @Lisaunterhuber@tornthemovie@j4ink@cammiedan@valeriotecursoseconsultoria@iron2athletics@goashem@culture247@Glams.care@Polycliniqueiaso@baboolfveci@caleparks@histerio@oficialdaron@newbyginnings@eric13lugo@mylittlehorrors@bofg@alainagrealtor@lo.mmunication@NOJShop@nxtzen@gaerard@realtampabaygay@CPDIAfrica@RealeJusticeNetwork@thewatchgang@Somers\\\\_Wealth@AsmodeusDaFox@TAO\\\\_Producoes@maricarmensaneufrasio1984@iwamotoryo&lt;/content&gt;&lt;raw&gt;## AI Contents Creator. #LLM #RAG #LangChain\n\n[YouTube](https://www.youtube.com/c/@teddynote "YouTube")[LinkedIn](https://www.linkedin.com/in/teddy-lee/ "LinkedIn")[GitHub](https://github.com/teddylee777 "GitHub")[Email](mailto:teddylee777@gmail.com "Email")\n\n[9/24 래블업 컨퍼런스: Agentic 개발팁팁](https://docs.google.com/presentation/d/15j2dquEApZQh43Mx4ZljcUNbiB_j6Rtw/edit?usp=sharing&amp;ouid=102894857281845898333&amp;rtpof=true&amp;sd=true)\n\n[[FastCampus] 테디노트의 RAG 비법노트🙌](https://fastcampus.co.kr/data_online_teddy)\n\n[7/1 바이브코딩 컨퍼런스 발표자료](https://docs.google.com/presentation/d/1KnrKmae9oiM2RGvA4hytYhuoizhESf9Lt_5VtOt4xT0/edit?usp=sharing)\n\n[2025-랭체인밋업-Q2 발표자료](https://docs.google.com/presentation/d/1h9PeWpsQSMMAtcwGnuM9Pt65Srtcpg28moBSiNgWoWg/edit?usp=sharing)\n\n[2025 도큐먼트 파서(PDF)](https://www.dropbox.com/scl/fi/6zns0cbl1iu1gucxtzwd3/2025-Parser.pdf?rlkey=u3sf7mahjl7uk493w9oz1s9te&amp;st=aivpidmx&amp;dl=1)\n\n[3/20 Anthropic Korea Builder Summit 내용](https://share.note.sx/yzt86ez1#zRy5ER79y8hL28TW1xjR3DAZe6CXc3j5W66rOC1GPe8)\n\n[03/04 랭체인밋업2025 - LangGraph 기반 Agentic AI 시스템 구축](https://drive.google.com/file/d/1MDAbmH2cDG-X4MBVvLFRbbfCjDUP1yNE/view?usp=sharing)\n\n[03/04 LangGraph Hands On 튜토리얼 (2시간 분량)](https://github.com/teddylee777/LangGraph-HandsOn)\n\n[🔥[100% 무료] 테디노트 YouTube 콘텐츠 학습 순서🔥](https://teddylee777.notion.site/YouTube-RAG-10a24f35d12980dc8478c750faa752a2)\n\n[📘 랭체인 한국어 튜토리얼🇰🇷](https://wikidocs.net/book/14314)\n\n[유튜브](https://m.youtube.com/c/teddynote?sub_confirmation=1)\n\n[블로그](https://teddylee777.github.io/)\n\n[12/15 모두콘2024 - AI 시대의 생존 전략: 대체되지 않는 인재로 성장하기](https://drive.google.com/file/d/1g1FsFOT2i-q2ZTc-sNkrAjjyWaFzo5wj/view?usp=sharing)\n\n[11/9 파이콘한국 2024 "에이전트 튜토리얼"](https://share.note.sx/17l7syil#Vei4HfxlE2WMSVTiYieRHoQFzBGF9GIi6K2lv8Fn0e0)\n\n[Github](https://github.com/teddylee777)\n\n[9/21 테디노트-Gencon2024-ModularRAG-20240921.pdf](https://link.teddynote.com/Gencon2024)\n\n[링크드인](https://www.linkedin.com/in/teddy-lee/)\n\n•[Report](https://linktr.ee/s/about/trust-center/report/?field86145911=https%3A%2F%2Flinktr.ee%2Fteddynote)•[Privacy](https://linktr.ee/privacy)•\n\n## Explore other Linktrees\n\n[@limitlessaxes](https://linktr.ee/limitlessaxes "Visit limitlessaxes\'s Linktree profile")[@ofi\\_australia](https://linktr.ee/ofi_australia "Visit ofi_australia\'s Linktree profile")[@Willtherealdeal](https://linktr.ee/Willtherealdeal "Visit Willtherealdeal\'s Linktree profile")[@ginger\\_renee](https://linktr.ee/ginger_renee "Visit ginger_renee\'s Linktree profile")[@GatewayEspanol](https://linktr.ee/GatewayEspanol "Visit GatewayEspanol\'s Linktree profile")[@etherealevie](https://linktr.ee/etherealevie "Visit etherealevie\'s Linktree profile")[@yourfavoritepunkhippie](https://linktr.ee/yourfavoritepunkhippie "Visit yourfavoritepunkhippie\'s Linktree profile")[@tyra.blackmon](https://linktr.ee/tyra.blackmon "Visit tyra.blackmon\'s Linktree profile")[@wildhoovesopenhearts](https://linktr.ee/wildhoovesopenhearts "Visit wildhoovesopenhearts\'s Linktree profile")[@rafaelaquintinauthor](https://linktr.ee/rafaelaquintinauthor "Visit rafaelaquintinauthor\'s Linktree profile")[@msbellanicole](https://linktr.ee/msbellanicole "Visit msbellanicole\'s Linktree profile")[@RadnorHouseTW](https://linktr.ee/RadnorHouseTW "Visit RadnorHouseTW\'s Linktree profile")[@Diamondcappriella](https://linktr.ee/Diamondcappriella  "Visit Diamondcappriella \'s Linktree profile") [@Lisaunterhuber](https://linktr.ee/Lisaunterhuber "Visit Lisaunterhuber\'s Linktree profile")[@tornthemovie](https://linktr.ee/tornthemovie "Visit tornthemovie\'s Linktree profile")[@j4ink](https://linktr.ee/j4ink "Visit j4ink\'s Linktree profile")[@cammiedan](https://linktr.ee/cammiedan "Visit cammiedan\'s Linktree profile")[@valeriotecursoseconsultoria](https://linktr.ee/valeriotecursoseconsultoria "Visit valeriotecursoseconsultoria\'s Linktree profile")[@iron2athletics](https://linktr.ee/iron2athletics "Visit iron2athletics\'s Linktree profile")[@goashem](https://linktr.ee/goashem "Visit goashem\'s Linktree profile")[@culture247](https://linktr.ee/culture247 "Visit culture247\'s Linktree profile")[@Glams.care](https://linktr.ee/Glams.care "Visit Glams.care\'s Linktree profile")[@Polycliniqueiaso](https://linktr.ee/Polycliniqueiaso "Visit Polycliniqueiaso\'s Linktree profile")[@baboolfveci](https://linktr.ee/baboolfveci "Visit baboolfveci\'s Linktree profile")[@caleparks](https://linktr.ee/caleparks "Visit caleparks\'s Linktree profile")[@histerio](https://linktr.ee/histerio "Visit histerio\'s Linktree profile")[@oficialdaron](https://linktr.ee/oficialdaron "Visit oficialdaron\'s Linktree profile")[@newbyginnings](https://linktr.ee/newbyginnings "Visit newbyginnings\'s Linktree profile")[@eric13lugo](https://linktr.ee/eric13lugo "Visit eric13lugo\'s Linktree profile")[@mylittlehorrors](https://linktr.ee/mylittlehorrors "Visit mylittlehorrors\'s Linktree profile")[@bofg](https://linktr.ee/bofg "Visit bofg\'s Linktree profile")[@alainagrealtor](https://linktr.ee/alainagrealtor "Visit alainagrealtor\'s Linktree profile")[@lo.mmunication](https://linktr.ee/lo.mmunication "Visit lo.mmunication\'s Linktree profile")[@NOJShop](https://linktr.ee/NOJShop "Visit NOJShop\'s Linktree profile")[@nxtzen](https://linktr.ee/nxtzen "Visit nxtzen\'s Linktree profile")[@gaerard](https://linktr.ee/gaerard "Visit gaerard\'s Linktree profile")[@realtampabaygay](https://linktr.ee/realtampabaygay "Visit realtampabaygay\'s Linktree profile")[@CPDIAfrica](https://linktr.ee/CPDIAfrica "Visit CPDIAfrica\'s Linktree profile")[@RealeJusticeNetwork](https://linktr.ee/RealeJusticeNetwork "Visit RealeJusticeNetwork\'s Linktree profile")[@thewatchgang](https://linktr.ee/thewatchgang "Visit thewatchgang\'s Linktree profile")[@Somers\\_Wealth](https://linktr.ee/Somers_Wealth "Visit Somers_Wealth\'s Linktree profile")[@AsmodeusDaFox](https://linktr.ee/AsmodeusDaFox "Visit AsmodeusDaFox\'s Linktree profile")[@TAO\\_Producoes](https://linktr.ee/TAO_Producoes "Visit TAO_Producoes\'s Linktree profile")[@maricarmensaneufrasio1984](https://linktr.ee/maricarmensaneufrasio1984 "Visit maricarmensaneufrasio1984\'s Linktree profile")[@iwamotoryo](https://linktr.ee/iwamotoryo "Visit iwamotoryo\'s Linktree profile")&lt;/raw&gt;&lt;/document&gt;',
 '&lt;document&gt;&lt;title&gt;[AI 개발자가 되고 싶으세요? 저자 X 테디노트] 여섯 명의 ... - YouTube&lt;/title&gt;&lt;url&gt;https://www.youtube.com/watch?v=wDUl7KjV7KI&lt;/url&gt;&lt;content&gt;# [AI 개발자가 되고 싶으세요? 저자 X 테디노트] 여섯 명의 개발자가 기록한 AI 시대의 생존 전략\\n## 테디노트 TeddyNote\\n50200 subscribers\\n92 likes\\n\\n### Description\\n3324 views\\nPosted: 27 Nov 2025\\nAI 개발자가 되고 싶지만 어디서부터 시작해야 할지 막막했던 분들을 위해, 여섯 명의 현업 개발자들이 직접 경험한 시행착오와 깨달음이 담긴 AI 시대의 생존 전략을 공유합니다.\\n\\n✅ 라이브에서 다룰 내용\\n이 책이 AI 개발자만을 위한 책이 아니라, AI 시대를 살아가는 모든 개발자를 위한 책이 된 이유를 풀어냅니다\\nAI 시대에 개발자로 살아간다는 것: 커리어 확장 전략 3가지\\n- AI를 도구이자 동료처럼 활용하기: \'바이브 코딩\'을 통해 LLM을 활용한 업무 효율화와 자동화 테스트 워크플로우를 제시합니다.\\n- 커리어 전환/성장의 기회 포착: 기존 백엔드/풀스택 개발자가 AI 시스템 아키텍처와 운영 안정성을 담당하며 커리어를 확장한 사례.\\n- AI 기술의 본질을 이해하는 시각: 단순 튜토리얼을 넘어 연구자의 관점에서 AI 기술의 큰 그림을 파악하는 법.\\n\\n누군가 걸어본 길: 독자들이 당장 적용할 수 있는 실무 로드맵\\n- AI에 관심은 있지만 막막한 입문자 와 AI 분야로 커리어 전환을 고민하는 현업 엔지니어 를 위한 실용적인 가이드.\\n- 기술 변화 속에서 길을 찾는 모든 독자에게 작은 나침반이 될 경험 공유\\n- 특징: AI와의 협업하는 시대의 상징으로 책의 모든 삽화가 챗GPT-5를 통해 생성되었습니다. [...] 않을까 싶습니다. 그래서 저도 오랜만에 또 이렇게 또 여기 다 선배님들이 와 계시는데 저도 많이 배울 수 있는 큰 계기가 되어서 너무 반가웠고요. 앞으로도 또 종종 인사드리면서 또 많이 배울 수 있었으면 좋겠습니다. 정말 마지막으로 제가 항상 끝 인사를 하기 전에 그 오늘 라이브 어떠셨는지 이거는 그냥 책이랑 상관없습니다. 이게 짧게 소감을 어 남규 님부터 먼저 하겠습니다. 예. 오늘 라이브 어떠셨어요? 어, 일단은 저도 아까 말씀하신 것처럼 어, 되게 뭐 이렇게 할 말이 없거나 어떻게 해야 될지 잘 모르겠다는 약간 두려움이 있었거든요. 근데 또 태님이 또 워낙 진행을 잘 해 주시고 우리 성님하고 그 저 뭐야 &gt;&gt; 그네 &gt;&gt; 그 뭐야 갑자기 아 [웃음] 서형님 홍석형님 &gt;&gt; 많이 서운해 하시겠는데요 &gt;&gt; 예습니다 &gt;&gt; 몇 개월 동안 이름을 계속 봤는데 까먹었어 [웃음] 그래서 다 같이 말씀을 너무 잘 해 주셔 가지고 굉장히 풍성한 오늘 또 어 시간이었던 거 같습니다. 알겠습니다. 감사합니다. 어, 소경님 오늘 어떠셨습니까? &gt;&gt; 네. 아까 테드 님 소개신해 주신 것처럼 진짜 나한 30분밖에 못 말할 것 같다고 [웃음] 생각했는데 벌써 두시간 10분이 넘어왔고 아 진짜 시간이 빨리 가는구나 [웃음] 생각을 했고요. 네. 아까 말씀드리지 못했 부분이 하나 있는데 이제 저는 채용 공고를 홍보 [웃음] 목적도 있기 때문에 &gt;&gt; 아 그러시군요. 루니 아 예 &gt;&gt; 제가 시간 드려야죠. 예. &gt;&gt; 아, 네. 감사합니다. 네. 네. 저 제가 일하고 있는 의료 AI 어, 기업, 글로벌 의료 AI를 비즈니스를 하고 있는 [...] ✨라이브 홍보 ✨\\n신간 소개 | AI 개발자가 되고 싶으세요?\\n여섯 명의 개발자가 기록한 AI 시대의 생존 전략\\nAI 서비스 관련 개발자, AI를 적극 어플리케이션 개발에 활용해온 개발자의 커리어 전환과 생존 전략에 관한 이야기.\\n- 교보문고 👉 \\n- 예스24 👉 \\n- 알라딘 👉 \\n\\n#테디노트라이브 \\n\\n📍 \\"테디노트의 RAG 비법노트\\" 랭체인 강의: \\n📘 랭체인 한국어 튜토리얼(무료 전자책): \\n📝 테디노트(깃헙 블로그) : \\n💻 GitHub 소스코드 저장소:&lt;/content&gt;&lt;raw&gt;# [AI 개발자가 되고 싶으세요? 저자 X 테디노트] 여섯 명의 개발자가 기록한 AI 시대의 생존 전략\n## 테디노트 TeddyNote\n50200 subscribers\n92 likes\n\n### Description\n3324 views\nPosted: 27 Nov 2025\nAI 개발자가 되고 싶지만 어디서부터 시작해야 할지 막막했던 분들을 위해, 여섯 명의 현업 개발자들이 직접 경험한 시행착오와 깨달음이 담긴 AI 시대의 생존 전략을 공유합니다.\n\n✅ 라이브에서 다룰 내용\n이 책이 AI 개발자만을 위한 책이 아니라, AI 시대를 살아가는 모든 개발자를 위한 책이 된 이유를 풀어냅니다\nAI 시대에 개발자로 살아간다는 것: 커리어 확장 전략 3가지\n- AI를 도구이자 동료처럼 활용하기: \'바이브 코딩\'을 통해 LLM을 활용한 업무 효율화와 자동화 테스트 워크플로우를 제시합니다.\n- 커리어 전환/성장의 기회 포착: 기존 백엔드/풀스택 개발자가 AI 시스템 아키텍처와 운영 안정성을 담당하며 커리어를 확장한 사례.\n- AI 기술의 본질을 이해하는 시각: 단순 튜토리얼을 넘어 연구자의 관점에서 AI 기술의 큰 그림을 파악하는 법.\n\n누군가 걸어본 길: 독자들이 당장 적용할 수 있는 실무 로드맵\n- AI에 관심은 있지만 막막한 입문자 와 AI 분야로 커리어 전환을 고민하는 현업 엔지니어 를 위한 실용적인 가이드.\n- 기술 변화 속에서 길을 찾는 모든 독자에게 작은 나침반이 될 경험 공유\n- 특징: AI와의 협업하는 시대의 상징으로 책의 모든 삽화가 챗GPT-5를 통해 생성되었습니다.\n\n🙇\u200d♂️ 연사님을 소개합니다. \n최남규\n- 25년 경력의 베테랑 개발자로, 금융/공공 시스템 구축 경험을 바탕으로 AI 백엔드 시스템 아키텍트로 커리어 확장\n- LLM+RAG 기반 Q&amp;A봇 및 챗봇/콜봇 대화 엔진 설계 전문가\n- RAG 한계 극복 연구로 학술대회 우수 논문상 수상 및 특허 출원\n- LLM RAG 커뮤니티 운영 및 부트캠프 멘토링, 지식 나눔 세미나 진행\n\n홍석용\n- 카카오에서 AI 플랫폼 리더로서 AI 플랫폼(KAP) 설계·개발\n- 현재 루닛(Lunit)에서 AI Platform 실장, 의료 AI 플랫폼 설계·운영\n- 『쿠버네티스 입문』, 『AI 개발자가 되고 싶으세요?』 공동 저자\n- If kakao, KubeCon NA 등 여러 국내외 컨퍼런스 발표\n- 데이터 파이프라인부터 학습·서빙·모니터링까지 AI 전 주기 플랫폼 및 개발 문화·조직 구조 연구\nLinkedIn: https://www.linkedin.com/in/dennis-hong-06b776160/\nEmail: dennis2dev@gmail.com\n\n김성완\n- 한국 게임 개발 1세대로 초창기 3D 게임 기술 개척, 물리학 전공 및 지구과학 박사과정 수료\n- 1990년대부터 퍼지 인공지능, 신경망 퍼셉트론 직접 구현, 펄어비스에서 생성모델 및 실시간 초해상도 연구 수행\n- 현재 그루핀 AI부 이사, 부산 인디커넥트 페스티벌 집행위원장, 인디게임 커뮤니티 \'인디라\' 운영\n\n✨라이브 홍보 ✨\n신간 소개 | AI 개발자가 되고 싶으세요?\n여섯 명의 개발자가 기록한 AI 시대의 생존 전략\nAI 서비스 관련 개발자, AI를 적극 어플리케이션 개발에 활용해온 개발자의 커리어 전환과 생존 전략에 관한 이야기.\n- 교보문고 👉 https://product.kyobobook.co.kr/detail/S000218317288\n- 예스24 👉 https://www.yes24.com/product/goods/162211876\n- 알라딘 👉 https://www.aladin.co.kr/shop/wproduct.aspx?ItemId=375650025\n\n#테디노트라이브 \n---\n📍 "테디노트의 RAG 비법노트" 랭체인 강의: https://fastcampus.co.kr/data_online_teddy\n📘 랭체인 한국어 튜토리얼(무료 전자책): https://wikidocs.net/book/14314\n📝 테디노트(깃헙 블로그) : https://teddylee777.github.io\n💻 GitHub 소스코드 저장소: https://github.com/teddylee777\n\n8 comments\n### Transcript:\n안녕하세요. 예, 좀 어색하시죠? 예. [웃음] &gt;&gt; 네. &gt;&gt; 총 여섯 분의 어 저자님께서 어 작성하신 오늘 AI 시대의 생존 전략에서 AI 책 이름이 AI 개발자가 되고 싶으세요? &gt;&gt; 요거인 거죠? &gt;&gt; 예. &gt;&gt; 알겠습니다. &gt;&gt; 네. 아, 요거 책 안 그래도 보내 주셔 가지고 아직다는 못 읽었는데. 어, 열심히 읽겠습니다. 제 도크감이라도 써야 될 것 같아요. [웃음] 네. 아, 감사합니다. &gt;&gt; 네. 오늘 되게 훌륭하신 분들께서 이제 놔 주셔서 이렇게 책 소개도 해 주시고 오늘 이렇게 저자분들이 워낙 또 경력이 화려하시잖아요. 세 분 다 너무 화려하시고 또 다른 저자님들도 너무 화려하신데 오늘이 AI 개발자가 되고 싶어 하는 잠재적인 미래의 개발자 어 분들도 되게 많거든요. 그래서 미리 한번 경험해 본 사람의 입장으로서 솔직한 조언 많이 해 주시면은 큰 도움 될 거 같습니다. 감사합니다. 아, 예. 오셨네요. 안녕하십니까. 선님, 성미 님, 필캉 님 안녕하십니까? 안피곤 님도 오셨고요. 예. 레타 님 반갑습니다.이나 님, 네, 안녕하십니까? 아, 반갑습니다. 슬슬히 들어와 주시고 계시네요. 어, 저희가 이제 9시가 돼서 이제 슬슬 한번 시작해 보려고 합니다. 먼저 앞서서 간단하게 세 분 차례대로 자기 소개해 주시면 될 거 같은데 남규 님부터 먼저 부탁드릴게요. &gt;&gt; 네, 안녕하세요. 저도 세미나 같은 거를 최근에 11월에 많이 하게 됐는데요. LLM RH 커뮤니티를 운영을 하고 있고요. AI 백핸드 개발자로 이제 12월 1일 부로 이직을 앞두고 있습니다. 반갑습니다.네 &gt;&gt; 반갑습니다.네 다음 홍석 님께서 예 부탁드리겠습니다.네 &gt;&gt; 안녕하세요. AI 플랫폼을 개발하고 있는 홍석용이라고 합니다.네 예, 저는 클라우드 개발자로 커리어를 시작해서 어, 카카오에서 10년 정도 근무를 하면서 이제 중간에 AI 플랫폼 개발자로 커리어를 전향하게 돼서 한 3년 정도 더 AI 플랫폼을 개발을 하다가 현재는 의료 AI 어, 회사인 룬이 돼서 AI 플랫폼을 개발하고 있습니다. &gt;&gt; 아, &gt;&gt; 감사합니다. 네. 저 성원님 한번 부탁드리겠습니다. &gt;&gt; 네. 저는 이제 퍼비스에서 생성 AI 연구를 쭉 하다가 지금 현재는 핀테크 회사에서 AI 쪽 일을 하고 있습니다. 예. 반갑습니다. &gt;&gt; 반갑습니다. 아, 오늘 마침 세 분을 모셔서 아까 그 저희가 사전 인터뷰 때 간단하게 커리어를 여쭤봤는데 또 커리어가 이렇게 겹치는 부분이 하나도 없으시더라고요. 그래서 오늘 다양하게 얘기를 많이 들어 볼 수 있을 것 같습니다. 어, 저 그냥 캐주얼하게 하나 오프닝 질문을 한번 드려 보고 싶은데요. 어, 먼저 성환님께 한번 전 들어보고 싶은데 개발 경력이 엄청 오래되시고 오랫동안 한마디로 이제 저희가이 바닥에서 이제 생존에 오시면서 열심히 어, 또 트렌드에 맞춰서 해 오신 거 같습니다. 요즘이 AI 시대 이후에 그니까 체지T 이후에 이런 트렌드는 어떠 어떠세요? 지금 되게 오랫동안 개발하셨는데 그이 생성형 AI 출연 이후에 어떤이 바뀌는 어떤 개발의 어떤 양상이랄까요? 이런 것들을 포함해서 느낌이 어떠신지 궁금합니다. 그 어떻게 보면 저는 이제 쭉 AI 쪽들 특히 이제 생성 AI 쪽 연구를 쭉 해 오다 보니까 어 정하 2018년부터 했는데음 채비 같은 경우는 사실 나왔을 때는 그냥 연관 입장에서는 늘 봤던 거라서 그냥 뭐 그냥 또 조금 더 개선돼서 나오나 보다 이렇게 생각했는데 사실은 이제 이렇게 대중들의 반응이 없 엄청나게 폭발적일 거라고는 미쳐 예상을 못 했어요. 뭐 저만 그런게 아니고 오픈 AI도 그랬다 그러더라고요. 이제 그리고 사실은 이제 적어도 한 2 20년 정도부터 이제 남들 영 최신 논문들을 지켜보면서 느낌이 어땠냐면이 속도가 너무 빠르다는 걸 이렇게 느끼고 항상 이렇게 뭐라고 해야 되나? 뒤통수가 근질근질하고 막 지금 뭘 내가 하고 있는데 뭐 그 뭘 연구하는게 시간 걸리잖아요. 그런데 어느날 그냥 더 좋은게 나와 버리면 그 연구하던게 물고품이 되니까 항상 뒤가 불안하고 뒤통수 맞을까 봐. 그리고 이제 알다시피 이제 이게 채지T가 등장해서 대중들의 폭발적인 반응이 있고 나서는 그 속도가 더 가속이 돼서 무서울 정도로 빨라 빨라지고 해서 뭐 그렇게 오래 산 건 아니지만 평생 이렇게 기술이 빠르게 발전한 걸 처음 겪었어요. 그래서 그런 면에서 정신 없이 달려오고 막 그래서 너무 모든게 빠르게 변하고 해서 어 그냥 하루하루가 그러니까 또 신나는 것도 있어요. 그 SFS나 가능하던게 막 실제 현실이 되는 모습은 신긴 하는데 그 속도가 너무 빠르니까이 따라가기 벅차고 막 그냥 좀 무섭기도 하고 &gt;&gt; 재밌기도 하고 막 양가인 감정입니다. 아, 지금 댓글창에도 질문이 올라온 거를 하나 읽어 드리고 싶은데 이번에 업데이트된 재미나이와 클로드의 성능이 뛰어나다고 들었는데 &gt;&gt; 발전되는이 바이브 코딩에 대한 생각 저이 파이브 코딩은 사실 여기 계신 세 분께 다 각자의 생각을 한번 여쭤 보고 싶긴 하거든요. 그러면은 제가 요거는 어 홍성현님께 먼저 여쭤보고 싶습니다. 그 파이코딩 요즘에 보면은 저도 깜짝깜짝 놀랄 때가 있는 거 같아요. 이게이 많은 개발자들 우려하는게 이게 이제 내 직업을 대체하지 않을까부터 시작해서 어 그러면 만약에 만약에 저희가 가정을 해 봤을 때이 정도 발전 속도라면 언젠가는 뭐 사람의 역할 개발자의 역할 저는 충분히 대체할 수도 있다라고 생각이 드는데 그러면 지금 우리가 개발자들은 어떤 방향성을 가지고 저희 커리어를 어 쌓아 나가야 되는 건지 우리는 그럼 지금 당장 해야 되는 건 뭐 어 모여 모여야 된다고 생각이 어, 드시는지 그런 것들 한번 여쭤보고 싶어요. 아, 그 뮤 뮤트가 되어 있으신 거 같습니다. &gt;&gt; 네. &gt;&gt; 네. 어, 일단 질문이 굉장히 사실은 복합적으로 돼 있어 갖고 어렵긴 한데요. 네. 하나하나씩 한번 답변을 들어 보자고 하면 일단 저는 바이브 코딩이라는 자체 그 키워드가 어 자극적이어서 많이 흥행하긴 했지만 사실 바이브 코딩이라는 AI를 활용한 코딩을 바이브 코딩이라고 어 표현하는 걸 별로 좋아하진 않아요. 왜냐하면은 그거는 진짜로 어 코드를 하나도 안 보고 느낌 가는 대로 프롬포트만 쳐 갖고 진행을 하겠다라는 거잖아요. 그런데 이제 사실은 어 뭐 심지어 그 프로덕션이 굳이 아니더라도 토이 프로젝트를 만들더라도 코드를 아예 안 보고 개발자로서는 그렇더라고요. 아예 안 보고 가기는네 문제가 항상 생겨서 결국에는 코드를 보면서 가게 되어 있어 갖고 바이브 코딩보다는 어 이전에 이것도 또한 워낙 트렌드가 빠르기 때문에이 키워드도 또한 조금 흘러간 거 같은데 스펙 주도 기반 아 그 스펙 주도 개발네 그런 말 키워드를 더 좋아했었었고요. 어 어쨌든 바이브 코딩을 하더라도 실무에서는 품질을 준수하면서 생산성을 최대화시키는 방향으로 가고 있고 그것이 제 단순히 프롬프트로 해서 자연어 지시문으로 입력이 돼서 코딩이 되는게 아니라 습 문서의 형태로 의도를 좀 자세히 적고 스펙의 형태로 해서 문서를 전달해서 결과물이 구현되고 테스트 코드가 작성되고 자동으로 테스트가 돼서 품질을 보장할 기계적으로 보장할 수 있는 형태의 개발 &gt;&gt; 음 어를 통틀어도 요즘에 다 그것도 바이브 코딩이라고 하는 거 같더라고요. 그래갖고 저는 바이브 코딩을 그렇게 받아들이고 있고 그럼 그것이 개발자를 대체할 것이냐에 대한 어 의견은 어 제 의견은 그렇습니다. 어 제가 어디서 좀 인상 깊은 아티클을 읽었어요. 다 누구나 바이브 코딩을 하게 돼서 개발자가 아닌 사람도 다 프로그램을 어 소프트웨어를 작성할 수 있게 되었다. 저도 그건 동의를 하고요. 그런데 이제 그거에 어 나온 아티클에 나온 교훈은 뭐였냐면 어떤 이제 의대생분이 본인이 생각하는 어떤 세포 어떤 세포에 대한 발견을 어 소프트웨어로 시뮬레이션 할 수 있나를 바이브 코딩을 통해서 구현을 하신 거예요. 그래갖고 와 이게 너무 좋다. 그래 갖고이 시뮬레이터 시뮬레이션 하는이 프로그램을 가지고서 사업을 하고 싶다라고 결심을 하셨는데 그걸 가지고 사업을 할 수는 없잖나요? 왜냐면은 이제 결국에 사업의 영역이 비즈니스의 영역이라고 하는 거는 경쟁이기 때문에 결국 품질 경쟁이거든요. 비슷한 기능을 제공해도 최고의 품질이 결국엔 지부 이사를 불러낸 거기 때문에 그걸 들고 결국에 개발자한테 갔다. 그럼 개발자가 그거를 잡아서 이제 그걸 받아서 프로덕션으로 만들고 비즈니스를 온할 수 있게 해줬다. 그거의 관점 하나랑 그다음에 소프트웨어에 대한 책임을 끝까지지고 품질과 어떤 방향성에 대한 책임을 끝까지지고 이끌어 나갈 수 있는 힘은 여전히 개발자가 리스폰시빌리티를 갖고 있다고 생각을 하기 때문에 저는 개발자가 대체되지 않고 오히려 더 활성화가 된다라는 생각을 갖게 됐어요. 예를 들어서 골프 같은 경우를 예를 들면 &gt;&gt; 골프도 누구나 칠 수 있는 대중 스포츠처럼 다 누구나 칠 수 있잖아요. 하지만 골프를 접하고 좀 더 잘 치게 되, 잘 치고 싶어 하는 사람들은 골프한테 코칭을 받아요. 그래 갖고 골프로를 찾아가 갖고 내 자세를 교정받고 어 게임을 어떻게 더 잘할 수 있는지 배우고 어 저는 소프트웨어도 누구나 소프트웨어를 작성할 수 있는 시대가 될 거 같지만 결국엔 이제 소프트웨어를 작성한 일반인분 비전공자분들이 소프트웨어를 작성을 더 잘하고 싶거나 아니면 내 제품을 더 완성도 있게 만들고 싶으면 결국엔 개발자를 찾기 때문에 예전까지는 개발자를 찾는 수요가 직접 소프트웨어를 갖고 싶은 사람만 개발자를 찾았다면 이제는 누구나 개발자 자를 찾는 시대가 되기 때문에 그런 수요 쪽으로 좀 더 올라오지 않을까라는 생각을 갖고 있습니다. &gt;&gt; 어 답변 감사합니다. 그 그러면은 제가 넘어가기 전에 하나만 더 여쭤보고 싶은데 인프라 쪽에 되게 오랫동안 경력 싸워시면서 아마 진짜 업계 최고의 전문가라고 자신있게 말씀하실 수 있을 것 같은데 그 본인이 하시는 그 업무에 대해서 한번 바이브 코딩에서 얘가 얼마나 잘하나 보자 해서 결과를 보시 실험해 보신 적 있으세요? 어 저는 지금도 항상 플랫폼 개발할 때 바이브 코딩 해 가지고 어 &gt;&gt; 생사성 올리고 &gt;&gt; 그렇다고 코드를 안 보는 건 아니지만요. &gt;&gt; 예. 바이브 코딩을 활용해서 어 작성을 하고 있고요. 신규 프로덕션도 다 바이브 코딩을 해서 작성을 하고 있기 때문에 &gt;&gt; 너무 편하고 이제는 거의 없이는 개발을 못 할 정도의 수준에 어 들어갔다고 저는 생각을 합니다. &gt;&gt; 그 말은 일단 내가 지시를 잘하고 내가 검증할 수 있는 능력이 충분히 있다면 지금 얘가 하는 수준 자체는 상당히 올라와 있다. 이렇게 이해해 볼 수 있겠네요. &gt;&gt; 아네 맞습니다. 제가 네. 그래서 어느 정도 어 개발자 경험치가 쌓인 이후에는 프롬포트로 지시하고 내 의도대로 구현이 됐는가를 확인하는 과정에 반복 &gt;&gt; 음. &gt;&gt; 예. 되는 거 같고요. 근데 그 구현하는 과정이 뭐 보일러 플레이트라든지 뻔한 CRUD 코드 같은 거를 다 일일이 다 옛날에 다 짰다면 &gt;&gt; 그런 것들은 다 예상이 되는 것들이잖아요. 그런 것들은 이제 다 예시켜서 &gt;&gt; 생성해 내고 그다음에 의도대로 동작하는지 어떻게 테스트 내 제 테스트와 조건을 제시해서 기계적으로 테스트하고 그래서 사실은 구현보다는 테스트와 품질 검증이 더 시간이 이잖아요, 요즘에는. &gt;&gt; 예. 그러면 아 이게 자꾸 질문이 생 생각이 나는데 하나 더 여쭤보고 싶은게 그러면 이미 경력을 쌓고 내가이 코드에 대해서 충분히 해왔던 저도 감사하게도 AI 이전에 개발을 시작해서 그걸 이미 축척할 수 있는 시간이 충분했는데 지금 주니어들은 사실 그럴 시간이 많지 않잖아요. 왜냐면 회사들은 야, 바이브 코딩해서 지금 프로덕션을 내야지. 그니까 생산성을 올려야지. 지금 너 공부하려고 해서 왔어. 이런 챌린지를 받을 수 있을 것 같아요. 근데 결국에는 그 주니어 친구들이 성장을 해야 그런 능력들이 생기는 건데 그러면은 그 주니어 이제 완전 사회 촌용생들은 어떤 식으로 점점 접근할 하는게 좋다라고 보세요. &gt;&gt; 네. 굉장히 어려운 질문이신데요. 저도 굉장히 다행히도 이미 AI 이전에 개발을 배워서네. 지금 굉장히 생성이 항상 좋다 생각하는데이 과정이 성숙할 수 있는 과정이 필요하다고 생각하는데 저도 이런 질문들을 굉장히 많이 받았고 회사에서도 뭐 그 동료들끼리 굉장히 많이 토론을 했었어요. 근데 그중에서 제가 가장 어 가슴에 와닿왔던 대답은 어 그러면 신입은 누가 키우나 손은 누가 키워요. 그런데 그 신입사원 분들은 학생 때부터 AI랑 코딩을 해야 된다.라고 어 그 말씀하신 분이 있는데 그게 저는 가장 와닿왔습니다. 그래서 학생 때부터 AI랑 코딩을 하면서 AI한테 끊임없이 질문을 하고 다른 방법이 없는지 어 이게 최선의 방법인지 이거의 장점은 뭐고 단점은 뭔지를 옛날에는 그거를 다 어깨 넘어로 배워야 됐어요. 아무리 책이 잘 돼 있고 구글링을 했었어도 내가 지금 하고 있는 프로젝트에 대한 패턴이나 구현에 대해서 어떤 지의 응답을 할 수 있는 기회는 많지 않았거든요. 선배 개발자분한테 직접 했었어야 되는데 이제는 혼자 할 수 있잖아요. &gt;&gt; 예. 학생 시절에 그 AI랑 같이 프로젝트를 많이 해보면서 그런 지의 응답을 통한 학습과 성장을 많이 해야 된다고 생각을 하고요. 회사에 와서는 물론 생산성을 퍼포먼스를내는 것도 중요하지만 어 좋은 문화를 가진 회사에서는 여전히 주니어들의 성장을 중요하게 생각하고 당장 퍼포먼스를 내서 생산성을 내라고 어 한 회사는 어 업지 않을까라고 생각을 하고 있습니다. [웃음] &gt;&gt; 알겠습니다. 일단 여기까지만 마무리를 하고 또 이따가 추가 질리를 한번 해 보도록 하겠습니다. 이번에는 남규님께 한번 여쭤보고 싶어요. 바이브 코딩 어 시대가 왔는데 요거에 대한 생각과 &gt;&gt; 어 생각에 대해서 먼저 여쭤보고 싶습니다. 아, 일단은 그 바이브 코딩의 시대가 지금 현재는 사실 어, 뭔가 재미나이한테 어, 창으로 이렇게 물어봐서 소스를 카피해서 붙여 넣기 하는 요런 형태부터 진짜 어시스트 같은 거를 설치하는 형태로 이제 조금 더 더 구체적인 것들을 하거나 아니면 시스템 적용까지 하는 다양한 레벨로 로 다양한 방식으로 이제 적용이 되지만 아 향후에 가면 가면 갈수록 약간 자율주행 자동차처럼 처음에는 약간의 사람들이 보조적인 역할을 하하다가 나중에는 완전히 완전한 자율주행하는 것처럼 어 그런 바이브 코딩도 그렇게 되지 않을까 생각을 하고 있습니다. &gt;&gt; 그러면이 그런 관점은 어떻게 보세요? 뭐이 바이코딩이 나중에 개발자 대체할 수도 있지 않느냐? 이 대체 가능성 여부랑 만약에 대체를 일부할 수 있도록 본다면 개발자들은 어떤 방향성을 가지고 뭔가 커리어를 쌓아 나가야 되는지 그런 생각도 한번 궁금합니다. &gt;&gt; 일단은 제가 생각하기에는 어 개발자들이 기획 능력하고 커뮤니케이션 능력이 어 굉장히 중요하다고 생각합니다. 왜냐면 AI 어시스트나 뭐 이런 재미나이한테 물어보더라도 결국 사람과 어 사람끼리 소통하는 것들은 또 커뮤니케이션을 해야 되고 그리고 어떤 그 비즈니스 환경에서 내가 어떻게 해야 될지 그거에 대해서 또 어 주니어 개발자도 판단해야 되고 또 약간 임원들하고도 커뮤니케이션 그 요구를 받아들여지는 요거 하나하고요. 그다음에 또 아직까지는 그 어시스트가 완벽하게 할 수 없는 부분이이 소스를 어떤 시스템에 어떻게 적용할지 어 그다음에 어떻게 구성을 뭐 프런트에 할지 백에 할지 아니면 리누스 어디에 할지 뭐 이런 시스템 구성에 대한 부분은 아직까지는 당분간은 어 좀 어 약할 거라고 생각을 하고요. 그래서 지금 현재 이쪽을 공부한다면음 이런 기획 능력 그러니까 어떤 요구 사항이 왔을 때 빠르게 프로젝트를 구상을 하는 능력과 그다음에 어떤 식으로 시스템을 구성하고 아키텍처를 구성할지 요런 것들을 좀 길러야 앞으로 이제 일 구하는데도 좋지 않을까 생각이었습니다. &gt;&gt; 음. 그러면 제가 좀 더 직구준 질문을 한번 드려 볼게요. 컨텍스트에 대한 안묵지가 소실이 돼서 어 그런 아까 커뮤니케이션 그걸 말씀해 주셨고 그거의 한계점 저도 충분히 공감하고 있습니다. 그리고 아직은 어시스턴트가 잘하지 못하는 아키텍처 영역 요렇게 두 가지를 짚어 주신 거 같아요. 근데 만약에 컨텍스트는 뭐 사람들이 마이크를 찬다든가 해서 해결을 하고 어시스턴트는 성능에 올라와서 해결이 된다면 그 정도 상황에 간다면 그럼 대체될 수 있다라고 보시는 건가요? &gt;&gt; 네. 일단은 그 우리 공산 과학 영화에서 그런 것들을 봤잖아요. 실제 그 뭐 비전이나 이런게 실제 사람 형체처럼 나와서 동작을 하는 것처럼 이제 그런 시대까지 완벽하게 불편함 없이 가려면 적어도 몇십년은 일단은 뭐 있어 있으니까 그 정도 시간은 좀 있다고 봅니다. 음결은중에 공산과학영처럼 되겠지만 그 전까지는 좀 어느 정도는 그 아까이 말씀드렸던 커뮤니케이션하고이 시스템 아키텍처 쪽은 다음분과는 계속 &gt;&gt; 유지할 수 있지 않을까 생각이음 &gt;&gt; 그렇군요. 제가 이런 질문을 드렸던 이유가 사실 사람이 제 제가 그렇고 아마 여기 계신 개발자분들도 일부 공감할 텐데 저희가 AI가 대체될까 봐 두려운 이유는 지금 AI 수준이 100% 올라와서가 아니라 0에서 80까지 오는 시간이 불과 몇 년 안 걸렸기 때문에 그게 두려움을 자극하는 거라고 저는 생각이 들거든요. 그래서 저 지금 사람들이 뭐 예를 들어서 그냥 정량화된 지표로 80점 정도인데 인간이 할 수 있는게 100점 정도라면 80점 정도라서 대체 못해 이게 아니라 야 80점까지 지금 3년밖에 안 걸렸어 그러면은 3년 뒤면은 인간 뛰어넘는 거 아니야 이게 두려움으로 다가오는 거 같다라는 생각이 들어요. 그래서 그래 그래서 사람들이 특히나 요즘에 좀 어 이런 거에 대해서 많은 얘기를 하는 거 같은데 남규 님께서는 그럼에도 불구하고 정말 개발자가 지금 현재 하는 수준까지는 아직은 조금 멀었다라고 보시는 건지네 &gt;&gt; 그 뭐 컨택 포인트 부분에 대해서 어 멀었다고 생각하고요. 소스나 이런 알고리즘 알고리즘적인 부분은 어 사람을 어느 정도는 뛰어넘은 부분이 상당히 많다. 저도 그거에 대해서 상당히 공감하고요. &gt;&gt; 아, 예. 알겠습니다. 제가 제가 왜 그러냐면은 지금 아마 여기 계신 분들도 다 공감하실 텐데 제가 처음에 마이크로소프트 빌드 2020인가 2020년도에 마이크로소프트가 함수 하나 짜는 생성형 AI를 가지고 와서 그때 빌드 2020에서 데모를 했었어요. 그것도 함수 한 줄 한 세네 줄짜리인데 &gt;&gt; 어 신기한데 제가 드 생각은 뭐 그거 함수 짜는 건 해도 이걸 개발 줄 어떻게 대체 그 5년 5년 전 3년 전 아 그때 그걸 느꼈거든요. 그 말이 안 된다. 개발자 어떻게 아 진짜 말도 안 근데 요즘에 코딩 어한테 보면은 아 함부로 장담하면 안 되겠다라는 생각이 정말 많이 들 정도로 많이 올라온 거 같더라고요. 그리고 컨텍스트를 해결하려는 시도가 코딩 어시스턴트에서는 정말 어 많이 시도가 되고 있고 더 제가 더 놀라웠던 점은 이거였던 거 같아요. 원래 우리가 개발자들이 어차피 사람이 하는 일이라서 저희가 회의를 하면은 저희가 대화를 통해서 지금 막 준미팅이든 뭘 통해서 했었단 말이에요. 근데 이제 어 AI가 코딩 짤 건데 우리가 말로 하지 말고 LRM이 잘 이해할 수 있는 마크다운 형식의 개발 문서 남기자 이런 형태로 바뀌게 된다면 컨텍스트도 빠르게 그렇게 인지시켜 줄 수 있는 걸로 좀 전환이 될 수도 있지 않을까 싶은 생각이 있었어요. 그러니까 지금 현재 상태에서는 당연히 안 바뀌겠지만 어차피 AI가 갈 거면 저희가 일하는 방식도 AI에 맞춰져서 바뀌게 될 거라는 생각이 요즘에는 좀 많이 들더라고요. 그래서 저는 약간 더 가속화되지 않을까 이런 생각들도 많이 들어서 참 고민이 많아진 거 같아서 한번 여쭤봤었습니다. 알겠습니다. &gt;&gt; 아, 네. 저도 그렇게 생각합니다. &gt;&gt; 예. 알겠습니다. 마지막으로 오래 기다리셨는데 성원님께 또 한번 여쭤보고 싶습니다. 그 바이브 코딩에 대한 생각 그리고 개발자를 개발자에 대한 대체 가능성 혹은 어 만약에 대체를 한다라고 하면은 어 우리 개발자는 어떤 식으로 이제 일하는 방식을 좀 바꿔야 되는지 뭐 그런 부분들 한번 여쭤보고 싶어요. 일단 제 경험을 좀 돌아보면 어 저는 이제 초창기 한 90년대 같은 경우에는 이제 신 한 중반까지도 어셈블리로만 게임을 만들게 됐거든요. &gt;&gt; 오케이. &gt;&gt; 예. 그러다가 이제 뭐 시원으로 넘어오고 뭐 이제 AI 쪽 하면서 주로 파이썬 하게 되고 그리고 어떻게 보면 이제 그런 쭉 좀 더 좀 더 이제 추상화되고 다루기 쉬운 언으로 옮겨오면서 개발하게 됐고 사실 이제 AI 연구를 하면서는 코딩량이 확 줄어버렸죠. 다시 이제 그걸 안드레이 카파시가 소프트웨어 2.0이라고 했잖아요. 다 맞다 사람이 다 코드 작성하는게 아니고 그냥 그 사실은 AI 쪽에 코드 얼마 되지도 않잖아요. 그 코드가 중요한게 아니고 그 코드를 구동해서 웨이트 그 신경만의 가중치 값을 얻는게 그게 진짜잖아요. 그죠? 그래서 그렇게 되다 보니까 저도 뭐 코드야 이제 그냥 기터브에서 적당한 비슷한 그 오픈소 가져와서 필요한 거 조금만 수정하면 돼서 코딩할 일이 없어지고 어 저도 지금 이제 그냥 거의 직접 코딩하는 경우는 거의 없다시피해요. 그냥 바이브 코딩 하고 있는 셈인데이 바이브 코딩이란 말 자체도 지금 나온지도 안 됐잖아요. 월초에 그냥 불쑥 아드레 카시가 요즘 뭐 바이브 느낌으로 한다 이렇게 한 마디 한게 그냥 용어를 굳어 버렸는데 어 제가 볼 때 이제 일단 지금 우리가 현재 알고 있는 그 개발자는 없어질 거라고 저는 예상을 해요. 뭐 얼마나 빨리 없어질지는 좀 생각들이 다 수 있지만 통상적으로 우리가 예상하는 거보다 더 빨리 올 거라고 저는 그 예상을 하고요. 뭐라고 해야 되나? 그 이거 약간 좀 다른 얘기긴 한데 게임 쪽에서는 개발자를 좀 다르게 정의를 해요. 보통 일반적으로 일반 IT 분야는 이제 프로그램만 한 장에서 이제 개발자라 그러는데 게임 같은 경우에는 게임을 만드는데 어떤 일이든 뭐 프로그래밍을 하든 그래픽을 하든 음악을 하든 다 개발자로 이제 통증해서 부르는 용어거든요. 게임을 만드는 일을 하는 사람. 그래서 제가 볼 때는 아마 개발자라는 용어가 그대로 존속한다면 그 의미는 완전히 달라질 거라 봐요. 그래서 어떤 프로덕트를 만드는 일을 하는 어떤 형태로든 꼭 코딩을 하지 않더라도 그런 일을 하는 사람으로서의 개발자는 넘겠지만 지금 우리가 현재 알고 있는 한땀마텀 코딩하는 그 개발자는 아마 빠르게 없어지지 않을까? &gt;&gt; 음. 그리고 한 가지 또 이제 우리가이 프로그램이나 앱에 대한 생각도 좀 바꿔야 되지 않을까? 앱 자체도 지금 우리가 이제 기존에는 개발자들이 힘들게 막 코딩하고 그다음에 힘들게 테스트해서 만들다 보니까 변경하는 거 이런 거 쉽지 않고 하니까 막 가능하면 오랫동안 유지보스 잘하면 쓸 수 있도록 그렇게 만들고 이랬었잖아요. 그 설계부터 이제 후반에 이제 유지 보습까지 그러다 보니까 그런데 우리가 너무 익숙해 있는데 솔직히 말해서 이제 AI가 그냥 몇 마디 말만 잘 던져 주면 코드를 척착 주니까이 &gt;&gt; 앱이란 것도 이제 이미 이제 저쪽에서 용어가 나오는데 디스포즈블 앱 그까 1회용 앱 그냥 그때 필요할 때 그냥 잠깐 시켜서 만들어 쓰고 뭐 두 번 돌아보지 않는 예 우리 꽃 같은 경우도 중국산 갑사 같은 경우에는 굳이 뭐 몇 번 세탁에서 있는게 아니고 한 번 있고 그냥 예 세탁하 버리는 그런 것처럼 앱도 아마 그런 형식가 되지 않을까 이제 코딩하는 비용이 굉장히 작아 &gt;&gt; 거의 없다시피해지니까 예 그래서 물론 이제 &gt;&gt; 그 오랫동안 정성스럽게 만든 그런 제품도 필요한 곳이 있겠지만 소소한 많은 것들은 그냥 그렇게 한 번만 해서 쉽게 만들어 쓰고 버리고 그리고 이게 가장 빨리 올게 프란트엔드 쪽일 것 같아요. 그래서 오늘 이미 이제 제니리티브 UI란 말이 나오기 시작했거든요. 그때그때 UI를 생성해 버리는 &gt;&gt; 음. &gt;&gt; 예. 그래서 저는 어 어떻게든 바이브 코딩이 일상화되고 해서 그렇게 되면 이게 전통적인 CS를 공부한 이렇게 개발자보다는 자기 해당 분야의 도메인 지식을 제대로 알면서 어느 정도 개발에 대한 이해가 있는 이런 사람들이 훨씬 일을 잘하는 그런 시대가 되지 않을까? 그러면 그러면 제가 또 그 궁금한 점이 하나 있습니다. 그러면 지금 그 말을들은 지금 CS에 공부를 하고 있는 학생들이 굉장히 억울해 하면서 이제 좀 동시에 이제 불안함을 느낄 수도 있고 한데 그것과는 별개로 그러면 저희가 사실이 컴퓨터 사이언스라는 어떤 어 저희의이 코딩의 어떤 기본기라고 할 수 있는 것들을 사실 학교에서 많이 배우게 되는데요. 지금 그러면은 바이브 코딩을 하게 되면은 사실이 능력이 너무 탁월해지면 우리가 컴퓨터 사이언스의 기본기를 사실 몰라도 할 수 있지 않나라는 것도 나이브하게 한번 생각해 볼 수 있을 것 같은데 그러면 어 지금 성원 님께서는 혹시 그 부분에 대해서 어떻게 생각하시는지도 궁금합니다. 그 아마 세월이 많이 흘러도 아주 이렇게 하드웨어 근접한 저수준 부분을 하는 누군가는 극소수는 있을 거예요. 근데 이제 그 수 많 많이 필요하지 않을 때 대우분은 그냥 &gt;&gt; 저 수술 몰라도 되고 그러니까 실제로 이렇게 쭉 지나온 역사를 돌아보면 예 &gt;&gt; 점점 더 추상화되고 그냥 저수는 몰라는 쪽으로 왔잖아요. 저같이 이제 막 이제 어셈블리로 이제 코딩하던 입장에서 보면 뭐라 좀 업설 그냥 시체말로 업을할 수도 있거든요. 그때는 정말 &gt;&gt; 명을 하나하나 클럭 스피드 재면서 는데 &gt;&gt; 그거 가지고 뭐 그 시간도 오래 걸리고 막 그런데 저도 이제 거래도 또 학생들 가르치기도 했기 때문에 제가 어셈블리 코딩을 더 이상 안 가르치게 된게 언제부터냐면 비주얼 스튜디오 6점이 나오고부터 안 가르쳤어요. &gt;&gt; 음. 음. &gt;&gt; 왜냐면 그전까지는 그래도 약간의 어셈블리 코딩을 조금 해도 그 그냥 &gt;&gt; 시 언어 같은 이렇게 고급 언어를 한 것보다 훨씬 좋은 퍼포먼스를 낼 수 있었거든요. 그런데 &gt;&gt; 한빨 성능이 점점 좋아지고 번역을 더 잘하게 되니까 비준스 6.0인 정 딱 돌리니까 제가 굉장히 오랫동안 어블리 코대한 사람이 막 굉장히 막 정성스럽게 하면 조금 좋게 만들 수는 있겠는데 &gt;&gt; 아 &gt;&gt; 그게 들어간 시간과 병이 너무 큰 거예. 그래서 학생들한테는 이걸 그 스킬을 &gt;&gt; 공부할 필요가 없겠다. 그냥 컴파트 맡기자. 어, 그 그러면은 제가 받은 느낌은 지금 말씀하신 거를 비텨서 설명을 드려 보면 약간이 바이브 코딩의 트렌드가 그 처음에 어셈블리어에서 시언너로 넘어갔을 때 그 느낌과 비슷하다. 이것도 어떻게 보면은 어떤 코딩의 어떤 새로운 패러다임이기 때문에 &gt;&gt; 어, 그렇게 받아들여야지 되지 않을까라고 생각을 하시는 건지 &gt;&gt; 네, 그렇습니다. 저는 이제 제가 배운 것보다 더 과거로 돌아와 보면 컴퓨터 프로그래밍이라게 배선하는 거였거든요. &gt;&gt; 아, 네. &gt;&gt; 예. 회로들을 막 직접 직접 연결하는게 그게 코딩이었어요. &gt;&gt; 그래서 그 당시에는 그걸 주로 여성들이 했어요. &gt;&gt; 어, &gt;&gt; 퍼스널 컴퓨터가 등장한 이후에 남자들이 코딩을 하기 시작했어요. &gt;&gt; 쉬워져서. 선을 다 그게 코딩이에 &gt;&gt; 그거 이제 주로 좀 커드 일을 옛날에 이제 여성들이 힘들고 어려운 잘했기 때문에 &gt;&gt; 예 그 사실은 컴퓨터란 말 자체가 원래는 여성 계산하는 계산원들을 가르치는 용어기도 했었어요. &gt;&gt; 음 &gt;&gt; 예 &gt;&gt; 아 그렇군요. 그럼 과거로 돌아본다면 당연히 바이브 코딩이 그냥 이상화 되고 그냥 그 굳이 코드 한 줄 읽을 줄 몰라도 그냥 예, 말로 잘해서 &gt;&gt; 예, &gt;&gt; 그렇군요. 아, &gt;&gt; 코닥터를 만드는 그런 거 같아. 아 일단 세분의 생각에 대해서 되게 공통적인 부분도 있고 그 안에서 약간 약간의 또 차이도 보였던 거 같습니다. 또 이렇게 말씀해 주셔서 너무 감사드리고요. 또 댓글 한번 중간에 한번 읽어 볼게요. 오늘 되게 되게 재밌는데 아 아까 질문 주셨던 거의 연장선상이네요. 답변 감사합니다. 하면서 현재 AI 엔지니어 쪽으로 가고 싶어서 공부하고 있는 학생이라고 말씀해 주셨고요. AI를 어디서부터 공부해야 할지 감히 잡히지 않습니다. 바이브 코딩을 이용해서 여러 개발을 하고 있지만 심화 과정의 파이썬까지 공부를 해야 할지 아니면 오히려 수학적인 공부를 더 해야 할지 사이에서 감을 못 잡겠어서 질문드립니다. 어 요거 남규님께 한번 질문을 먼저 드려 볼까요? 네. 일단은 저는 그 두 가지 자기 진로 진로를 먼저 정한 필요가 있다고 생각합니다. 그러니까 내가 AI 응용 쪽으로 갈 거냐 아니면 약간 데이터 사이언스 &gt;&gt; 디스트나 아니면은 모델 쪽으로 갈 거냐에 따라서 좀 달라진다고 좀 생각을 하고요. 저는 이제 어 AI 응용 쪽에 관심이 많다 보니까 저는 이제 누가 어 상담 요청을 하면 대부분은 어 프로젝트를 처음에 API에서부터 화면까지 이런 것들을 한 프로젝트를 좀 만들어서 포트폴리오화하면 취업에도 더 도움이 될 거라. 특히 이제 우리나라 요즘에 부트 캠프 많이 하지 않습니까? 거기서 어차피 이제 부트 캠프나 이런 데서는 또 팀업도 되게 중요하지만 사실 어차피 개인이 어느 정도까지 했느냐 그런 역량을 볼 때는 개인이 처음부터 끝까지 요런 것들을 다 할 수 있느냐 없느냐 &gt;&gt; 이런 것들을 저는 중요하게 생각음 &gt;&gt; 그럼 정리하자면 만약에 연구 쪽이면은 좀 수학 공부를 더 투자를 하고 그다음에 개발자 쪽이면은 응용 쪽이면은 이제 코딩 영량에 대한 더 투사를 해야 된다라고 말씀 말씀해주셨고요. 또 응용적으로 하고 계시니까 포트폴리오 좀 만들어다 두시면 도움이 될 거 같다라고 말씀해 주셨어요. 그 하나만 또 추가 제가 질문을 드리고 싶은게 그 만약에 예를 들어서 그냥 면접을 보는 상황을 한번 가정해 보겠습니다. 요즘에 &gt;&gt; 저희도 저희 회사도 면접을 보고 있는데 아 포트폴리오가 장난이 아닙니다.이 바이브 코딩을 써서 그런지 아 수준이 장난이 아니에요. 그러면 제가 질문드리고 싶은 거는 요겁니다. 그 혹시 이렇게 포트폴리오만 봐서는 사실 요즘 AI의 어 활용을 정말 잘하는 친구들은 좋은 포트폴리오를 충분히 낼 수 있거든요. 그러면 그것을 검증하는 것, 그러니까 포트폴리오를 통해서 좋은 결과물을 만들어 냈다는 것로 충분한 것인지 아니면은 그 외적으로 만약에 질문을 하거나 더 궁금한 점이 있다면은 보통 어떤 것들을 좀 더 보시는지 그런 것들이 궁금합니다. &gt;&gt; 아, 일단 제가 답변할까? &gt;&gt; 네. &gt;&gt; 네. 일단은 저는 일단 아까도 말씀드렸던 것처럼 이제 최근에 뭐 그 컨닝 그 이슈 있었었잖아요. 어 그런 것처럼 어떤 응용을 해서 뭔가를 만들었다는 거 자체에 저는 큰 의미를 두고 주고 있고요. 근데 이제 어 이거를 내가 컨트롤할 수 없는 수준으로 바이 코딩을 했다. 그러고서 뒷감당을 못 한다. 이런 거 정도 수준이면은 안 될 거 같고요. 일단은 일단 만드는 거가 가장 중요하고 &gt;&gt; 그다음에 그거를 만든 거를 내가 관리할 수 있는 수준이라는 거는 결국은 컴퓨터 사이언스에 대한 기본 원리 뭐 DV를 설계를 한다든지 아니면 리스나 이런 곳에 어떤 소스를 배포를 한다든지 아니면은 기본 그 디렉토리 구조 이런 것들을 어느 정도 도메인 기반으로 이렇게 어 설계를 한다든지 어 최소한의 어떤 요런 것들이 바탕이 되면서 포트폴리오를 많이 자기 스스로 했다면 어 굉장히 긍정적으로 보고 있습니다. &gt;&gt; 음. 답변 감사합니다. 아, 다음은 이제 홍석현님께 하나 여쭤보고 싶은데 뭐 비슷한 질문인데 완전 똑같은 질문을 드린 거는 좀 재미가 없을 것 같아서 그 방금 드렸던 질문 비슷하게 만약에 후배 개발자를 뽑는다 그러면 지금 여기에서도 이제 아마 취업 준비를 하고 계신 분들이 계실 것 같은데 어떤 부분을 좀 중요하게 보실 것 같으세요? 어떤 역량이라고 해야 될까요? &gt;&gt; 네. 어, 저는 일단 개발해서 결과물이 있으니까 일단이 결과물을 만들기 전에 정의했던 문제 의식이 뭐냐? &gt;&gt; 문제를 어떻게 추상화에서 정의했느냐. 그리고 그걸 해결하기 위해서 나온 프로덕이 뭐냐를 먼저 볼 거 같고요. 그다음에 프로덕이 나온 이후에 어 컴퓨터 사이언스에 대한 기본적인 이해나 펀더멘탈이 있는지를 보기 위해서 어이 제품을 운영을 할 때에 다양한 운영 상황을 주고 &gt;&gt; 그런 식으로이 제품을 변형해 가면서 운영 상황에 대처할 것이냐를 볼 거 같아요. &gt;&gt; 네. 사실 개발을 하기는 쉽거든요. 제가 첫 직장은 LGCNS여서 SI 회사에서 시작을 했는데 물론 뭐 어느게 더 쉽고 어렵다 뭐 이런 걸 따진다기보다 개발을 해서 결과물을 내기는 비교적 쉬워요. 근데 그거를 프로덕션에서 운영하는게 진짜 운영의 묘와 어떤 진정한 노하우가 들어가는 거거든요. 실제 트래픽과 데이터가 쏟아져야지 그제서야 어이 설계가 빛이 나기 효과가 있는지 없는지 알고 &gt;&gt; 그다음에 이것들을 견뎌내기 위한 어떤 운영의 묘를 발휘하는 과정에서이 제품에 대한 제대로 된 이해가 있고 앞으로이 제품의 방향성에 대해서 어떻게 설계해 나갈 건지에 대한 것들을 보면은 어 영향이 있는 친구구나 &gt;&gt; 음 &gt;&gt; 거 같아요. &gt;&gt; 네. 그래 갖고 그런 쪽으로 볼 여쭤볼 것 같고 마지막 하나는 그래서이 제품을 만들면서 배웠던 점이 무엇인가에 대한 할 것 같아요. 왜냐면 &gt;&gt; 결국에는 주니어분들을 뽑 채용하는 이유는 이분들을 당장 영 그 어떤 필드에 활용해 가지고 활용한다기보다 어떤 성장 가능성을 보고 투자하는게 기업의 관점이라고 생각을 하거든요. 스타트업 같은 경우에는 어 그렇지 않은 경우도 있겠지만 근데 어쨌든 이제 바이브 코딩을 하더라도 제품을 만드는 과정에서 지속적으로 어 배움이 있어야 앞으로도이 러닝 휠을 타고 가면서 성장을 할 수 있겠구나라는 생각이 어 들 거 같아서 그 세 가지 질문을 물어볼 것 같습니다. &gt;&gt; 음. 그러면은 제가 추가 질문 하나 드리고 싶은데요. 그 저희 주니어 친구들 같은 경우에는 아무래도 뭐 상상은 할 수 있겠지만 운영 경험이 없이다 보니까 어 그거에 대해서 충분히 고려하고 막 상황까지 만들어서 답변하는 능력들이 대부분 좀 없을 것 같아요. 만약에 그러면이 친구들이 그런 것들을 좀 내가 모의 테스트라고 해야 될까요? 하기 위해서 어떤 어 공부 방법이나 뭐 어떤 그런 팁 같은 것들이 있을까요?이 이 친구들이 어떻게 하면 좀 그런 상황들을 시뮬레이션 해 보고 좀 그런 것들 할 수 있는지 &gt;&gt; 네. 어, 그 상황을 제안해 봐라라고 질문드릴 건 아니었고 상황은 제가 드리고 &gt;&gt; 아, 예. 예. &gt;&gt; 그다음에이 상황이 어떻게 할 것이냐를 지금 &gt;&gt; 아, 예. 근데 어쨌든 이제 그런 거에 대해 대응하는 경험이나 그런 것들이 없으시다 보니까 어 답변하기 쉽지 않을 거는 같아요. 근데이 제품을 만들면서이 제품을 만들면서 기대했던 어떤 결과가 있을 거고 그 결과를내는 과정에서 어 이렇게 하면 어떻게 해야지? 이렇게 되면 어떻게 해야지라는 생각을 상상을 많이 해 보시는 거. 그다음에 그럴 땐 어떻게 해야지라고 AI와의 대화를 통해서 또 많이 배울 수 있을 것 같아요. 답이 어 답 정답을 거의 주거든요. 셀렉션이 많아도이 문제를 극복하는 데는 당 다양한 방법들이 있을 거예요. 셀렉션을 정답은 AI가 줄 건데 어떤 정답을 선택하느냐에 따라서이 사람에 대한 어떤 문제에 대한 접근 방식 그다음에 이것들에 대한 제대로 된 이해가 있는지 이런 것들이 나올 거 같아서 뭐 예를 들면은 지금은 뭐 &gt;&gt; 뭐 도서관 책 관리 소프트웨어를 만들었다. 근데 지금은 책이 어 책 책이 텍스트로만 검색을 할 수가 있는데 어 이거를 이미지로 검색을 하게 만들려면 어떤 저장소를 더 추가해야 되며 데이터베이스에는 어떤 것들이 변화가 있어야 되겠느냐 그 어떤 거 변화가 있어야겠느냐를 어 물어보면 개발자로서 답변할 수 있는 부분은 분명 일반인이 답변하는 부분이랑 다르다고 생각을 하거든요. &gt;&gt; 맞습니다. 고맙습니다. 아, 너무 좋은 말씀입니다. 제가 좀 직구준 질문도 드리자면 요즘 저는 실제로 많이 당해 봤습니다만 왜 이렇게 했어? 했을 때가 그러던데요. 이런 것들 [웃음] 요즘에 있거든요. 왜? 아까 AI 대화를 말씀을 해 주셨으니까. 어, 만약에 그런 친구들에게 한마디 해 준다면 어떻게 말씀해 주시겠어요? [웃음] 네. 일단은 채가 아직은 기술적으로 할루시네이션이 다 있는 상태고 그 사람의 말을 전적으로 신뢰할 수 없는 AI의 말을 전적으로 신뢰할 수 없는 상태고 그다음에 걔가 그렇게 했어. 그 이면에 본인이 그렇게 판단한 근거가 항상 붙어야 된다고 저는 생각을 해요. 네. T지T가 DB의 로우 추가하라던 뭐 DB의 로우 추가하라던데요. [웃음] 로우가 추가되면은 어떻게 되는 뭐가 달라지는 건데 뭐 이런 식으로 본인의 생각을 더 여쭤보고 싶습니다. &gt;&gt; 어 알겠습니다. 아 직구준 질문은 많이 드리고 싶은데 예 재밌 [웃음] 그러면 진짜 마지막으로 하나만 더 드리고 넘어가겠습니다. 넘어갈 건데 어 개발 영 역 영 역량은 좀 부족하지만 AI 활용을 정말 잘하는 친구데 개발 영량은 좀 뛰어난데 어 AI 활용도는 좀 떨어지는 친구 중에서는 어떤 친구를 더 픽할 것 같으십니까? 후로는 개발 영량 안에 AI 활용 영량이 포함될 거기 때문에 &gt;&gt; 아 [웃음] &gt;&gt; AI 활용을 잘해서 개발을 잘하는 개발 영 역량이 훌륭한 친구. 네. &gt;&gt; 어 역시 사회 경력이 많이 있으셔서 예. 잘 피해 가신 거 같습니다. 예. 어. 예. 성원님께 똑같은 질문 드려 보겠습니다. 예. 개발 역량이 뛰어난데 AI 활용도가 좀 낮은 사람인데 개발 영 역량은 좀 부족하지만 AI 활용량이 높은 친구 어떻게 보십니까? 그 나 이제 AI 활용이 좋은 사람을 고를 것 같고요. 아 아직까지도 우리 이제 AI를 그냥 도그라고 생각하는데 사실 이제 우리가 AI 사용해 보면 단순한 도구하고 기전과 달리 이제 그거 인격적으로 우리가 대하게 되잖아요. 그래서 이제 어떻게 보면 어떤 AI를 하나의 가치 일한 동료 내지는 뭐 이렇게 부하 직원으로서 잘 관리를 해서 좋은 프로덕트를 만들어 낼 수 있는 그런 역량. 그러니까 앞으로 필요한 거는 프로덕터 매니저 &gt;&gt; 그 안에 이제 AI들이 &gt;&gt; 일꾼들로 있는 거죠. 음. 그니까 어떻게 보면 AI를 잘 다루는 사람이 어떤 사람이냐면 그냥 인간관계에서도 사람을 잘 다루는 사람이 아닌가 싶기도 해요. &gt;&gt; 음. 음. &gt;&gt; 네. 근데 아 맞습니다. 근데 AI 활용을 잘한다는 건 저는 요즘에 그 영량 중에 또 중요한 역량 중에 하나가 또 프럼프트 엔지니어링이 또 하나에 되게 크게 차지하고 있는 거 같아요. 근데 저는 여기 계신 분들은 어떠실지 잘 모르겠습니다만 저 개인적으로는 약간 프럼트 엔지니어링의 역량에 대해서 되게 어렵더라고요. 그러니까 뭐가 어렵냐면 코딩은 이게 정해진 경로가 있고 어 잘못되면 에러가 나고 에러를 고치고 이게 문제 해결을 해 나가는 건데 물론 프럼프트 엔지니어링도 문제 해결의 어떤 일부라고 볼 수 있겠지만 뭔가 이렇게 막연한 어떤 곳에서 다양한 실험을 통해서 결과를 내야 되는데 심지어 그 방법론도 뭔가 이렇게 코딩처럼 정해진 루트가 아 물론 뭐 그 더 깊게 들어면 구조화된 프랑프트 뭐 이런게 있겠지만요. 다시 돌아와서 그 어떠십니까?이이 이이 프럼트 엔지니어링 역량을 다들 어려워하신 거고 계신 거 같아요. 이게 개발자든 비개발자든 상당히 어려워하고 있는 거 같은데 이런 역량이 앞으로는 더욱 더 중요하기 때문에 저희가 여기에 더 투자를 하는게 맞을지 아니면 AI 개발자니까 그래도 어떤 코드적인 부분 이쪽으로 접근하는게 맞지. 물론 뭐 양자태이 아니라 둘 다 잘해야겠죠. 네. 요런 거에 대한 좀 의견이 궁금합니다. 그 일단 프롬포트 엔지니어링은 요즘 어떻게 보면 이제 단지 프롬포트를 어떻게 잘 작성하냐는 차원을 넘어서이 AI한테 컨텍스트를 어떻게 잘 제공하냐까지 뻗었기 때문에 사실 요즘 이제 컨텍스트 엔지니어링이라 말까지 나오잖아요. 그래서 이제 &gt;&gt; 그럼 사실은 이거는 뭐 사람하고 일해도 마찬가지 같아요. 그냥 사람한테 뭐 너 이거 만들어 이렇게 하는 거하고 이거 만들 때 필요한 거 있으니까 이거 참고하고 그다음에 혹시 요런 부분들 궁금한게 질문하고 요렇게 해서 일을 주는 거하고 그냥 &gt;&gt; 아무런 것도 없이 이거 만들어 이렇게 하는 거하고 자기가 있듯이 AI를 활용할 때도 &gt;&gt; 똑같은 원리가 적용된다고 생각해요. 그래서 저가 이렇게 주변에 이렇게 막 AI하고 코딩하고 실험하시는 분들을 쭉 보면 대체로 인간관계에서도 좀 그런 거 잘하시는 분들이 잘하는게 아닌가? 좀 친절하신 분들. &gt;&gt; 예. 친절하고 막 이렇게 좀 요뭐 조뭐 저뭐 이렇게 하고 &gt;&gt; 어 근데 이제 실제 우리가 이제 뭐 이렇게 인간관계도 보면 그 아무 배경 설명도 안 하고 그냥 툭 던져주고 막 당황스럽게 만드는 분들이 가끔 있잖아요. 그죠? 예. 그래서 이제음 AI도 마찬가지고 근데 물론 이제이 아주 어떻게 보면 한이 1년 전 2년 전만 돌아가도 프럼프트 구체적 어떻게 작성하는지 되게 막 그게 중요하게 생각하고 그랬는데 사실 지금 시점에서 보면 가장 최신으로 나온 뭐 제미나이 3라든지 그다음에 이번에 또 뭐 그 클러드 4.5 오프스 나왔잖아요. &gt;&gt; 예.이 이 친구들한테는 이제 맨발하면 그렇게 막 꼼꼼하게 프로포터 안 해도 &gt;&gt; 다 잘하니까. &gt;&gt; 잘하니까. 예. &gt;&gt; 음. 그러면 &gt;&gt; 그래서 &gt;&gt; 결과가 좋지 못하면 제 평소 성격을 좀 의심해 봐야겠네요. &gt;&gt; 그렇다고 말 심리가 [웃음] 더 중요한 거 같아요. &gt;&gt; 예. 알겠습니다. 아이 결론을 내주셔서 감사합니다. 예. [웃음] 알겠습니다. 아, 저희 댓글이 오늘 약간 예, 고민 상담소처럼 가고 있는데요. 저희가 이따가 한 10 몇 분 뒤에는 이제 책도 한번 소개를 해 주셔야 됩니다. 저희 댓글 몇 개만 더 읽어 보고 이제 넘어가려고 하는데 어 아, 코딩보다는 아, 프롬트 엔지니어링 예 능력이 사실 코딩보다 프롬트 엔지니어링 능력 키운다. 모모다 모모가 아니라 이게 이제 개발자 역량 안에 다 코딩과 이제 프라 엔지니어링 다 포함되는 거 아닐까요? 어떠세요? &gt;&gt; 프럼프트 엔진 그냥 커뮤니케이션 능력 같아요. 그냥 그게 AI를 잘 사용한다기보다는 사람하고 일해도 똑같이 필요한 능력인 거 같아요. &gt;&gt; 어 남남규 님께서 프럼프트 엔지어 어떻게 &gt;&gt; 일단은 저 같은 경우는 기본적으로 &gt;&gt; 그 설계 능력하고 커뮤니케이션 능력을 갖고 있으면 프롬프트 엔지니어링에 대한 것들은 거의 다 해결이 되는 거 같고요. 그 거기서 이제 어 최적의 프롬프트 엔지어링을 내가 못 만들었으면 다시 채치피트한테 만들어 달라고 하면 또 [웃음] 잘 만들어지더라고요. 그러니까 어떻게 보면은 약간 입문학적으로 가는 어떤 그런 쪽으로 접근을 하는 경우는 입문학적으로 접근을 하는 부류 분야도 있겠지만 일반적으로 이제 어떤 솔루션을 만드는 입장 뭐 어떤 그런 쪽 입장에서는 어떤 그 커뮤니케이션하고 설계 능력이 있으면 거의 대부분 커버가 될 거 같습니다. &gt;&gt; 음. 음. &gt;&gt; 홍수 님께서 어떠세요? 평소에 이제 AI فيه툴도 많이 쓰고 그러신데. 어, 저도 컴프트 엔지니어링이 필요는 한데 이게 어떤 별도의 전문 여역이나 어떤 별도의 포지션으로 어, 형성되기에는 좀 부족하지 않나라는 생각이 있긴 있어요. 저는 이제 가장 어떤 솔직한 단면이 어떤 경제 시장이라고 보는데 고용 시장에 또 봐도 처음에 포트 엔지니어링이라는 어떤 키워드다 등장했을 때는 엄청 이게 전문 영역이 될 것 같은 느낌이었지만 프로트 엔지니어 뽑는다 뭐 글로벌하게 몇 개 정도 포지션 정도 나왔다가 지금은 또 싹 죽었잖아요. 그리고 현재 기업의 어떤 채용 현황을 봐도 어 프롬프트 엔지니어를 채용해 갖고 육성해야겠다 또는 프로포트치 엔지니어가 당장 필요하다라는 그것만 하는 전문 영역이 당장 필요하다라는 수요는 그렇게 크게 보이지 않아서 저도 또 어 개발자가 갖춰야 될 역향은 맞지만 그게 어 그것만 깊게 파야 되는 어떤 전문 영역은 아니지 않나라는 생각을 현재는 갖고 있고요. 아까 다른 분들 말씀하신 것처럼 어 사람한테 일 잘시키는 사람이 AI한테도 일 잘시키고 똑같고 그다음에 좀 프롬포트가 부족해도 &gt;&gt; 모델의 능력으로 요즘에는 이제 그 띵킹 모델들 나오면서 스스로 추어내고 부족한 컨텍스트를 자기가 채워 갖고 앞단에 정렬을 하고서 뒷단에 결과를 내니까 &gt;&gt; 어 그런 부분들로 인해서 기술로 인해서 보완될 수 있을 것 같아요. &gt;&gt; 음. 음. 아, 감사합니다. 저도 저도 사실 어느 정도 다 공감하는데 저 저는 약간 어, 요렇게 될 수도 있겠다는 생각이 들어요. 그러니까이 대규모 서비스를 할 때는 프럼프트를 어떻게 깎아내느냐에 따라서 비용과 직결이 되다 보니까 &gt;&gt; 약간 예. 예. 예. 예. 그래서 저는 이렇게 생각을 해 봤어요. &gt;&gt; 기업 내에서 한 포지션으로 자리 잡는게 아니라 이제 대한민국 왜 기술사 장인들 있잖아요. 그런 것처럼 프롬트 장인이 있고. 어 우리 이거 프롬프트 비용 절감 똑같이 아웃풋이 나오는데 절감을 하는 기술사를 모셔서 약간 착체 최적화하고 어 빠지고 요런 어떻게 보면 장인의 포지션으로 가면 어 갈 수 있지 않을까 그런 측면에서 약간 기업 내에 상주하는 프람프트 엔지니어의 직군으로서는 저도 최형 포지션이 약간 조금 어떨지 모르겠어요. 왜냐면 기업에서 이게 한번 세팅해 놓고 그걸 자주자주 바꾸는 건 아닐 수 있으니까. 하지만 내가 프롬트를 깊게 파서 그렇게 여러 기업의 어떤 최적화의 전문성을 가지고 가겠다. 그거는 조금 또 유효할 수 있을 것 같다라는 또 생각이 들기도 했습니다. &gt;&gt; 아, 그렇습니다. 근데 또 조금 저는 다르기도 한게 저희가 처음에 아 뭐 더 오 올해부터 AR 시작하시면 되지만 처음에는 컨텍스트 사이즈가 막 2,000 토큰 이러니까 그 안에서 어떻게 해보려고 최적하 어요맞 &gt;&gt; 그러다가 만 토큰 말 되니까 막 순통 좀 틀 거 같고 이제야 좀 돌아갈 거 같고 &gt;&gt; 근데 지금 100만 토큰까지 오는데 진짜 시간이었거든요. 예. 예. 예. &gt;&gt; 1년 전만에 &gt;&gt; 예. 어은 배로 발전하고 있고 모델도 컨택 사이즈가 너무 커지고 있어 갖고 진짜 대규모 서비스고 모델이 작아서 최적화된 소형 모델로 승부하는 그런 쪽에서는 확실히 효과가 있을 것 같긴 한데 제너럴 퍼포즈고 컨택 사이즈가 엄청 커지면 커질수록 텍스트는 미약해서 맞아요. 맞아요. 맞아요. 맞습니다. 맞습니다. 아, 그래서 제 저도 어떤 관점에서 말씀드렸냐면 왜 그 저희가 그 토큰 그 제너럴 퍼포스 그 상용 모델들이 결국에는 토큰 출력당 비용 과금이 되잖아요. 근데 이게 인풋 사이즈를 그러면 시스템 프롬프트를 저희가 최적화를 해서 줄이면 그만큼 한 번 채팅당 비용이 세이브가 돼서 요거를 잘하려면은 확실히 좀 그런 기법들이 좀 있는 거 같더라고요. 왜 저희가 줄로 쓰는게 아니라 한 토큰이라도 줄여서 해야 어 기업의 어떤 이유가도 직결되는 거니까. 아마 제가 알기론 그래서 리튼 같은 데서는 프라 엔지니어들이 내제한게 그게 &gt;&gt; 대규모로 하다 보니까 &gt;&gt; 진짜 막 몇백만이 쓰니까 그 한 토큰 최적화가 실제로 비용의 영향을 끼치는 거 같더라고요. 그래서 아마 리튼 같은 기업들은 프라 엔지니어를 또 보유하고 있는 거 같다라는 생각이 들고요. 그래서 어찌 될지 모르겠습니다. 예. 저도 모르겠는데 어 요즘에 이제 아 근데 어쨌든 제가 드리고 싶은 말씀은 그거였습니다. 그렇게 개발자로서 처음에는 그런 생각이 들었어요. 아이 원래 우리가 코딩을 잘하면 인정받고 했는데 이제는 줄구를 잘 써서 내가 뭐 코딩보다 이게 한다 약간 자존심이 상한다고 해야 될까요? 좀 어떻게든 프람트 엔지니 푸는 것보다 코드 아키텍처로 풀어야 진짜 푼 거 같고 좀 그랬던 거 있는 거 같은데 돌아와서 생각해 보니까 lm의 영향이 좋아지면서 프럼프트로 푸는게 어 더 나은 것도 있겠다 생각이 많이 들면서 아 참 어려워지는 세상 같습니다. 어 예 또 댓글을 몇 개만 더 읽어 볼게요. 어. 아, 아까 어셈블리 아, 이게 댓글이 나온지 꽤 됐군요. 요즘에 포트폴리오 검증하는 것도 상당히 힘든 거 같고요. 어, 앞으로는 문제 해결 능력 있고 기본적인 개발 능력 있으면 대부분 1인 개발이나 자기 사업 시도할 것 같은데 실제로 그런 것들 많이 얘기하고 있는 거 같아요. 이제 혼자 개발자에서 유닛공기업 나올 거다. 이렇게 전망하고 있는 것도 꽤 되는 거 같고요. 저도 이제 예전 같았으면 진짜 말도 안 되는 얘기죠. 마케팅 어떻게 할 거야 했는데 요즘엔 진짜 에이전트들이 너무 잘해 주는 거 같고요. 어. 아, 프람프트 엔지니어 비전에 대해서도 말씀해 주셨고 아, 프람프트가 최적으로 만들어졌는지 이것도 또 정량 평가하는 방식이 있습니다. 예. 그렇게 하면 될 거 같고 어 정성적인 부분이라 여러 예, 맞습니다. 여러 이터레이션 하면서 노력이 필요한 거 같고 제한돼 있고 어, 네. 아, 다양한 뭐 프럼트 엔지니어링 관련해서 많은 의견들 주신 거 같아요. 예. 어, 맞습니다. 예. 다들 공감하시는 분이 예전에 GPT 3.5 때는 진짜 프롬프트 엔지니어링 중요하다 더 그때 했던 거 같아요. 왜냐면 그때는 모델 카시티가 떨어지니까 프랑프트 어떻게 작성하냐에 따라서 그 편차가 진짜 좌지가 크게 됐었거든요. 근데 요즘에 모델이 오히려 좋아지면서 좀 그런 분들이 많이 해소가 되고 있는 것도 같고요. 그렇습니다. 네. 어 일단 질문도 받아봤고 저희 오늘 중요한 목적이 있죠. 아, 남규 님께서 혹시 책 소개를 한번 먼저 해 주셔야죠. 예. 화면 공유 한번 해 줄 수 있어요? 아, 네. 예. 알겠습니다. 저희가 이렇게 오늘 모신 분들이 어,네 명의 저자분들이십니다. 예. 그래서 책이 AI 개발자가 되고 싶으세요.이 제목은 혹시 누가 지으셨나요? 어, 편집자님이 아마 지신 거 같습니다. &gt;&gt; 아, 그러시군요. 아, 편집자님께서 &gt;&gt; 되게 오늘 편집자님을 모시고 싶었는데 극 아이시라고 하셔서 이렇게 화면에서 뭔가 얘기하기가 힘드시대요. &gt;&gt; 그래서 어차피 제가 얘기를 꺼내 김에 제가 한번 이걸 준비를 해 봤습니다. 아, 저자분들 여섯 분의 저자분들 다 화려한 경력들을 또 가지고 계시는 여섯 분이서 어떻게이 책을 그러니까이 책을 어떻게 쓰시게 됐는지 그 배경이 좀 궁금한데요. &gt;&gt; 어, 일단은 그 처음에 배경은 편집자님께서 시작은 어, AI 모델이나 이런 쪽 연구하는 개발 위주로 처음에 생각을 하셨대요. 아니, 그리고 그다음에 AI를 활용, 그러니까 AI 서비스나 이런 것들을 만드는 거를 생각하셨다가 이제 그 바이브 코딩하는 그 요즘에 &gt;&gt; 휘동님, &gt;&gt; 베위동님 유명하시잖아요. 그 베이 베이동님처럼 이런 바이브 코딩을 통해서 생산성을 어 극대화하는 이런 것들도 정말 어 우리가 AI 시대에 정말 필요한 능력이겠다 생각을 하셔 가지고 어 일단 AI 기반 서비스 개발뿐만 아니라 AI를 활용한 그런 영역까지 이제 좀 어 넓히셨다고 하십니다. &gt;&gt; 아 그러셨군요. 그러면은 혹시 어 저 돌아가면서 각자 쓰신 파트에 대한 내용을 짧게 한번 요약해서 말씀해 주실 수 있어요. 요거는 성환님께 먼저 한번 부탁드려 보고 싶습니다. &gt;&gt; 어떤 내용을 좀 작성을 하셨는지. &gt;&gt; 네. 어, 저는 이제 아마 여기서 대부분 다른 분들은 이제 AI를 개발하거나 아니면 이제 AI 활용해서 뭐 다른 걸 개발하는 그런 분들이고 뭐 아마 저기 저랑 좀 비슷한 분 같은 경우에 이제 정금모님 같은 경우가 AR을 활용해서 생성 AR를 활용해서 게임을 개발했던 분이고 그래서 여기 저자로 초대가 되는데 이제 저는 이제 좀 연구를 어려했기 때문에 사실은 연구사 연구자에서 정체성이 더 강하다고 보시면 되고요. 어 지금은 이제 연구는 이제 거의 안 하고 있고 뭐 새로 논문이라 살 필요 있긴 하지만 그래서 저는 그래도 이제 연구자로서 쭉 어떤 이력으로 지내왔는지 그 위주로 했고 이제 그리고 이제 제가 어차피 또 원래 클리어가 게임 쪽이다 보니까 그 관련해서 게임에 대한 커리어도 많이 좀 얘기를 담았어요. 그러니까 뭐 좀 오래된 얘기도 좀 재밌어 할 것 같아요. 그래서 어 나름대로 이제 지금은 이제 다 알다시피 딥러닝 인공지능이 이제 대세가 완전히 돼 버려서 모두 이걸 하고 있지만 뭐 저 이제 오이되다 보니까 초창제에 이제 뭐 퍼즐 인공지능도 조금 하고 막 그런 적이 있었거든요. 그래서 이제 그런 얘기도 좀 됐고 그 저는 이제 주로 이제 어 퍼비스에서 연구했던 내용 이제 가능하면 이제 공개할 수 있는 범위 내에서 했고 그다음에 이제 그 보통 그 AI 같은 경우에도 이제 일반 지금 일반적인 경우는 그냥 이미 다 만들어서 나온 걸 이렇게 접해 보는게 텐데 그 뒤에서 그게 만들어지는 과정에 대해서도 좀 알면 재밌을 것 같아 가지고 특히 이제 좀 지저분한 데이터 전처리하고 막 데이터 이렇게 막 다듬고 하는 그런 부분까지 이제 그런게 담았고요. &gt;&gt; 그리고 아마 제 얘기가 좀 맨 뒤로 간 이유 중에 하나는 그러면서도 또 한편 이제 앞으로 AI로 인해서 세상이 어떻게 바뀌게 될지 AI 미래에 대한 얘기를 좀 &gt;&gt; 마무리하는 내용이 있어서 그렇게 됐고 제가 이제 작년에 단독 저소로 AI 미래라는 또 책을 내기도 했었거든요. &gt;&gt; 예. 대충 그렇고 그리고 제가 좀 축간에 이제 물리학 전공자 부심이 있어서 물리학 얘기를 했는데 요즘처럼 너무 세상이 빠르게 이렇게 A팀이 빠르게 변할 때는 좀 변하지 않는 걸 갖다가 또 탄탄하게 알고 있는 것도 중요한 거 같고 그런 면에서 일런머스크도 이렇게 왜 제일 원리라는 얘기를 종종 강조하잖아요. 그죠? 그런 차원에서 거기 제일 원리라고 얘기하는 거에는 이제 물리학이 빠질 수가 없죠. 뭐 보통 좀 넓게 보면 물리 과학을 보는데 자인을 다루는 과학은 이제 자연의 법칙은 일단 우리가 전혀 다른 우주로 가지 않는 변하지 않잖아요. 이 세상에 너무 막 인간이 만든 것도 너무 빨리 변하니까 그래서 뭔가 변하지 않는 단토가 필요하기 때문에 그런 면에서 연구나 이런 쪽을 하기 위해서는 &gt;&gt; 음 &gt;&gt; 그런 물리학적 베이스가 필요하고 특히 요즘 와서 그걸 더 강하게 느끼는게 뭐냐면 저는 생성 AI가 이제 디퓨저 모델 같은 경우 특정했을 때 되게 반가웠거든요. 제가 물리에서 배웠던게 바로 직접적으로 응용돼서 나오니까요. 예. 보통 이제 그 CS 쪽을 하신 분들은 이제 좀 어 이게 뭐지하고 좀 이렇게 의하셨는데 저는 제가 원래 하던 거서 되게 반거없고 그런 면에서 조금 AI 연구하면서 조금 유리하지도 않았나 싶기도 하고요. 네. 그 그 그러면 책에서 그 설명해 주신 것들 중에서 AI의 미래에 대해서도 좀 &gt;&gt; 네 &gt;&gt; 그 작성해주 집필해 주셨다고 말씀해 주셨는데 그거에 대한 내용을 조금만 더 간단히 소개해 주실 수 있으세요? 아, 그냥 뭐 좀 추상적인 얘기를 주로 적긴 했어요. 왜냐면 이제 미래가 어떻게 될지 제가 예측을 할 수 없기 때문에 &gt;&gt; 아, 예측하면 제가 이제 미래로 가서 한번 &gt;&gt; 예. [웃음] 예. &gt;&gt; 이분의 예측이 맞았나 안 맞았나 이게 그 아 오히려 조금 책에는 이렇게 막 제대로 쉽지를 않았는데 어 이건 좀 책이는 없지만 어차피 연장성에서 얘기할 수 있는게 제가 보는 관점에서 지금 현재이 AI의 상황이 어떤 상황이냐면 요즘 뭐 데이터 센터를 짓는데 전력이 부족하다. 그래서 뭐 이렇게 소유 원자료가 필요하다 그런 얘기 나오고 이제 특히 뭐 어 최신 GPU들이 막 전력 소모도 심하고 반열 때문에 뭐 심하면 냉각까지 한다 그러고 하잖아요. 근데 이제 이걸 보면 꼭 예전에 지운관 시대가 떠올라요. 음, &gt;&gt; 지금으로 이렇게 모든 전자기나 뭐 컴퓨터 만들고 갈 때는 뭐 덩치도 크고 그다음에 이제 열도 많이 나고 막 시끄럽고 막 그래서 이제 고등도 중간에 잘 나고 그래서 이걸 대체할 걸 찾다가 이제 찾아낸게 트랜지스트죠. 그래서 우리가 트랜지스트가 발전한 시대에 살고 있는데 어떻게 보면 지금이 트랜지스트의 끝에 와 있는 거 같아요. &gt;&gt; 아, &gt;&gt; 지금 우리가 사용하는 트랜지는 정말 뭐 나노단이에 정말 뭐 전자연으로 봐요. 겨우 보이는 수준의 그런 사이즈까지 줄었는데 근데 이제는 물리적 한계 때문에 더 이상 줄이고 싶어도 이제 줄이기가 너무 어려운 뭐 억지로 줄일 수는 있지만 줄이는 비용이 너무 많이 들어요. 저희는 그냥 무어의 법칙이 쉽게 쉽게 작동했었는데 그래서 이걸 대체할 새로운 하드웨어가 필요한 상황이 됐고 실제 그런 후보들이 있어요. 어 &gt;&gt; 그래서 저는 이제 최근에 이제 관심 있게 모니터링 하고 있는 것 중에 하나가 연력학 컴퓨터라고 허 혹은 연력학 컴퓨팅이라 하는데 연력학적인 원리를 활용해서 전력 효율을 했기적으로 이렇게 높이는 그래서 기존보다 전력을 한분 정도만 쓰면 되는 뭐 그런 것 쪽으로 &gt;&gt; 근데 올해 그게 시제품들이 나오기 시작했어요. 우리는 그게 이제 실제 대량 쓸 수 있도록 스케일합이 될지는 이제 좀 더 두고 봐야 되긴 하는데 그래서 그런게 저는 재밌어요. 그래서 이게 만약에 활용되면 모든게 지금 사실 좀 특이한게 뭐냐면 원래 전통적인 우리가 IT 개발은 이렇게 논리로 해서 돌아가기 때문에 정확한 0 1해서 트로폴스로 해 가지고 이렇게 정확한 논리로 모든게 구성이 되잖아요. 근데 사실 우리가 지금 그 위에서 구동하고 있는이 인공지능의 경우에는 그냥 다 확률이잖아요. 확률로 돌아가다 보니까 어떻게 보면 정확하게 돌아가는 하드웨어 위해서 애매하게 돌아가는 걸 어뮬레이션하고 있는 상황이거든요. 오히려 어떻게 보면 그래서 더 전기를 더 많이 먹고 있다고 볼 수도 있거든요. 그런데이 연력학은 그냥 확률을 확률 자체를 그냥 그대로 그냥 자연에 존재하는 무작기는 확률을 그대로 계산에 활용하는 뭐 그런 거라서 좀 기대를 하고 있고 그러면 이제 코딩하거나 뭐 만드는 방법도 완전히 달라지는 &gt;&gt; 음. &gt;&gt; 예. 그렇군요. 아, 이렇게 또 물리 쪽에 나오시니까 더 눈이 반짝반짝하시면서 [웃음] &gt;&gt; 너무 재밌게 말씀해 주신 거 같습니다. 뭐 요즘에 양자 컴퓨팅 뭐 이런 것들도 되게 많이 화두가 되고 있는 거 같고요. &gt;&gt; 그렇습니다. 아, &gt;&gt; 대부분 양자 컴퓨팅까지는 많이 들어봤어도 연력한 컴퓨팅 처음 들어보실 거예요. &gt;&gt; 맞아요. 예. 처음 들어봤습니다. &gt;&gt; 이거 오래 정도에 본격적으로 나오셔 핫서 &gt;&gt; 아, &gt;&gt; 예. 혹시 관련주 좀 추천해 줄 수 있나요? 아 농담 상장에서 [웃음] 전 세계 그 관련 스타트이 한 두 세 개밖에 없어요. &gt;&gt; 아 &gt;&gt; 예 &gt;&gt; 알겠습니다. 아 &gt;&gt; 제가 나중에 따라 알려 드 [웃음] 내용을 너무 잘 설명해 주셔 가지고 책을 안 읽어도 되겠는데요. 다 읽은 거 같은 느낌이 [웃음] 농담입니다. 너무 재밌게 제가 바로 있으니까 더 잘 한번 읽어 보도록 하겠습니다. 그러면 다음으로 석용 님께서 혹시 예 소개와 함께 어떤 내용을 좀 집필해 주셨는지 어떤 내용을 담아 주셨는지 좀 궁금합니다. 아, 네. 저는 어 일단 AI 개발자가 무엇을 어떤 일을 실질적으로 하하고 사는지에 대해서 궁금하실 것 같아 갖고 처음에 이제 AI 개발자는 무엇을 할까 해서 AI 개발자의 하루 그래서 출근해서 뭐를 하고 &gt;&gt; 어 &gt;&gt; 플랫폼을 만들 때 누구랑 협업하고 이런 내용들을 어 다루 다뤘고요. 그다음에 제가 특이하게 이제 저희 커리어를 겪으면서 어떻게 AI 개발자가 됐는지에 대한 내용을 어 썼는데 여기 계신 그 선배님들 앞에서 커리어 얘기를 하니까 굉장히 부끄럽네 [웃음] 굉장히 짧은 네 &gt;&gt; 아 그래도 커리어 커리어도 엄청 화려하신데요 &gt;&gt; 네 &gt;&gt; 그래서 어쨌든 그 제가 또 특이한 점이 이제 저도 비전공자거든요. &gt;&gt; 아 원래 전공은 어떤 전공하시? 전공은 경영학과입니다. &gt;&gt; 아, 근데 이제는 경영학과를 안 하신지 너무 오래돼서 비전공자라고 말씀하시기가 좀 &gt;&gt; 어렵지 않으세요? [웃음] 경영학 경공한 거보다 세배 이상의 시간을 개발자로 지냈기 때문에 &gt;&gt; 맞습니다. &gt;&gt; 그래서 이제 어떻게 개발자를 하기로 마음을 먹어서 어떻게 개발자로 자리를 잡았는지 그다음에 클라우드 개발자로 시작을 해서 어 그 첫 직장은 저는 LGCNS에서 이제 클라우드 플랫폼 개발자로 시작을 했거든요. 했고 그 어떻게 클라우드 개발자에서 이제 카카오로 이직을 하게 됐는지 그다음에 카카오에서 지내면서에 한 10년 정도 중에 7년은 클라우드 플랫폼은 AI 플랫폼을 했었어요. 그래갖고이 과정에서 어 클라우드 플랫폼 개발자를 하다가 어떻게 AI 플랫폼 개발자로 어 전향하게 됐는지 그다음에 그 과정 속에서 그 카카오의 동료들과 있었던 일들 뭐 이런 일들을 다고 &gt;&gt; 어 너무 재밌겠는데요. [웃음] 네. 어 그 부분이 이제 그 현실을 직시하라 AI 서비스 개발의 진짜 얼굴. 네. 그렇다고 뭐 이제 카카오 산내 정보를 뭐 거기다 지필 놓지 않았고 &gt;&gt; 예. 네. &gt;&gt; 이제 AI 서비스를 런칭을 하려면은 그 일반적으로 어 AI 개발자라고 하면은 다 대부분의 분들이 이제 AI 모델을 개발하는 사람만 생각을 하고 계시는데 AI 서비스 개발을 런칭 하려면은 어떤 다양한 개발자들이 AI 개발자라고 불리면서 어 참여를 하고 어떤 역할들을 하는지 그것들이 왜 중요한지에 대한 내용들을 담았고요. 그럼 그 과정을 통해서 아 AI 개발자라고 불리는 어 관련자들 중에서 어떤 포지션들이 있고 어떤 것들이 나한테 맞을 수 있겠구나 그런 상상을 하실 수 있게 어 구성을 했고요. 그다음에 이제 어 AI 저는 AI 플랫폼 개발자니까 AI 플랫폼 개발자로서 어떤 일을 하고 어떻게 성장할 수 있는지 &gt;&gt; 음 &gt;&gt; 그다음에 마지막으로 이제 지속 가능한 커리어 관점에서이 어차피 이제 개발자라는 직업을 택하신 이상 앞으로는 더 빠를 거라고 생각을 하는데 기술은 계속 변할 거예요. 그래서 지금은 AI 개발자라는게 가장 반짝반짝한 간판이지만 지금 여러 다른 참여해 주신 다른 저자분들도 마찬가지로 저분들이 사실 커리어가 기시기 때문에 뭐 AI로 쪽으로 전향하신게 특별한 일은 아니고 그 이전에도 아마 여러 번 저녁하셨을 거라고 생각을 합니다. 지금 시작하는 학생분들도 아마도 다양하게 전환을 할 거거든요. 그중에서 이제 그런 변화 속에서 성장하고 즐기고 살아남는 법에 대해서 어 서술을 했습니다. &gt;&gt; 음. 어 너무 기대가 됐는데 제가 여쭤보고 싶은 거는 원래 경영학 하셨는데 어떻게 하시다가 개발자로 도전하시게 되셨어요? 원래 개발자 되고 싶으셨어요? &gt;&gt; 네. 아 원래는 이제 처음에 인터넷을 할 때 그루폰이라고 하는 소셜 커머스에서 인터널 했었는데 &gt;&gt; 거기 경영 이제 bi 부서에서 경영학과로서 일을 하다가 엑셀 노가다를 너무 많이 했어요. [웃음] &gt;&gt; 네. &gt;&gt; 퇴근을 못 할 정도로. 아, &gt;&gt; 아침에 출구해서 DV에서 데이터 갖고 와서 로우에 붙여서 피벗 테이블 돌려 가지고 리포트 뽑아낼 때까지가 너무 오래 걸렸기 때문에 내가 이런 거를 하려고 경영학과 전공한게 아닌데. &gt;&gt; 네. 그래서 이제 학교 도서관에 가서 엑셀 책을 빌려서 함수라는 걸 배워서 적용을 하니까 엄청 빨라졌고 &gt;&gt; 거기에 이제 VBA를 배워서 적용을 하니까 &gt;&gt; 야 &gt;&gt; 하루 쟁게 출근해서 클릭 한번 하면 끝나는 거예요. 그 당시 이제 거의 구서에서 신급 존재가 하면 되고 [웃음] 그 리포트를 뽑할 때까지의 자동화해야 되는 각각의 과정들이 있는데 그것들이 딱 제가 상상한 대로 딱딱 맞물려 가지고 자동으로 딱 PDF가 떨어서 메일이 쫙 쏴지는 그 쾌감음 &gt;&gt; 개발자를 해야겠다. [웃음] &gt;&gt; 거기서 적성을 찾으셨군요. &gt;&gt; 네네. 네가 성을 고 &gt;&gt; 그럼 &gt;&gt; 또 근데 LGCNS에 &gt;&gt; 비전공자들을 많이 뽑았어요. 삼성도 S 직권들이라고 비전공자 많이 뽑아 소프트웨어를 가르쳐 주는데 저는 분명히 ERP B 직권으로 지원을 했는데 너는 스타트업 출신이니까 신기술을 해 봐서 전혀 다른 클라우드에 가서 &gt;&gt; 아 됐기 때문에 또 커리어가 약간 운과 관련이 있다. &gt;&gt; 아 그렇게 가신 거군요. 그러면은 지금에 어떻게 보면은이 AI 플랫폼 개발자는 어 정말 여러의 운이 딱 종합이 돼서 그게 이어져서 이제 또 지금까지 오게 된 거네요. &gt;&gt; 네. 네. 아, 되게 신겼습니다. 왜냐면 보통 비전공자가 요즘에 요즘에는 비전공자 부트 캠프도 되게 많고 해서 개발자 전향하는 사례들이 많이 있는데 보통 어 많이 하시는게 뭐 프런트엔드 개발자, 백엔드 개발자 이렇게 접근을 많이 하시는데 또 플랫폼 개발자 뭐 인프라도 하시고 그러신 거 봐서 제가 어떠한 사유로 그렇게 되셨을 가게 되셨는지 궁금해서 여쭤보게 됐습니다. 어 재밌겠습니다. 그 제가 요즘에 저는 원래 기술을 보는 거를 되게 좋아하는데 기술을 보다 보면은 보통 내가 필요한 것만 이렇게 꼽아 꼽아서 보고 덮어 놓고 하는데 왠지이 스토리를 들었으니까 좀 끝까지 읽어보고 싶은 생각이 더 듭니다. 소개해 주셔서 너무 감사드리고요. 마지막으로 남규 님 한번 소개 한번 부탁드려도 될까요? &gt;&gt; 일단은 제 소개만 할까요? 아니면 여기신 저자네 &gt;&gt; 내용이랑 내용이랑 같이 한번 소개해 주시면은 감사드리겠습니다. 작성하 &gt;&gt; 여자분들 &gt;&gt; 아 예 먼저 남교 님이 뭐 한 파트 먼저 해 주시면 되겠습니다. &gt;&gt; 아네 일단 제가 작성을 했기 때문에 제 내용을 제일 많이 적었습니다. 어, 일단은 어, 저 같은 경우는 어, 원래는 대형 그 은행, 금융 시스템, 은행이나 증권사, 보험사 이런 쪽 그 시스템의 이제 SI라고 하죠. 시스템 구축 프로젝트에 이제 참여해서 개발을 하다가 최근에 이제 5년 정도는 이제 AI로 전향을 했습니다. 그 중간에도 뭐 블록체인이라든지 아니면 클라우드 쪽에 좀 관심이 있어서 그런 쪽으로 하다가 어 예전에 이제 그 김성원 대표님 홍콩 가기대 어 계셨을 때 모델 딥러닝 거기에서 이제 그거하고 그다음에 뭐죠? 그 알파고 그 사건을 계기로 아 이제 AI 시대에 AI를 해야 되겠다. 어라는 생각을 좀 했고요. 원래는 제가 수학에 자신이 없어서 어 AI를 망설렸었어요. 근데 그 김성훈 대표님이 계속 하시는 말씀이 수학을 못 해도 AI를 할 수 있다. 용기를 가져 가지시라. 어, 요렇게 했던 거에 저도 이제 용기를 갖고 이제 했던게 이제 그때 시작을 하고 그다음에 이제 어, 제가 첫 프로젝트를 어, AI 프로젝트 이제 와이지너에 이제 그 검색 엔진을 구축하고 그다음에 그 분석하는 프로젝트였거든요. 국방부 프로젝트였었는데 한 800억 정도 되는 큰 사업이었어요. 네. 거기에 웹 개발로 원래는 참여를 했어요. 근데 그 전에 한 1년 정도는 독학으로 뭐 뭐죠? 밑바닥부터 하는 뭐 뭐 이렇게 딥러닝이나 아니면은 파이썬으로 뭐 간단하게 열줄로 코딩하기 요런 것들은 이제 조금 그 독학을 한 상태였고요. 그런 상태에서 웹 개발 어 포지션으로 갔는데 거기 프로젝트에서 의외로 그 현장에 있는 개발자들이 AI에 대해서는 그렇게 많이 알지는 못하더라고요. 그러니까 연구서 쪽은 많이 아시는데 그래서 거기에 이제 시니어로 웹 개발하러 1년 했다가 이제 정규직 제한을 받은 거죠. 1년은 프리랜서로 하고 2년 차에는 정규직이 되면서 PM을 한 거예요. 이제 PM을 하다가 보니까 거기에 이제 연구소에서 만든 프로그램이 그때 당시에 뭐 뭐더라? 개체명 인식 뭐 요런 기술 어을 다루는게 있었는데 이게 이제 어 딥러닝만으로는 해결이 안 되는 거예요. 그래서 뭐 단어를 넣는다든지 이런 것들을 해야 되는데 연구소에서 그거를 수정할 여력이 안 된다고 해서 현장에서 제가 바로 그 파이썬 코딩을 해서 그거를 어 가이드를 받으면서 직접 고쳤죠. 그렇게 해서 처음 웹 개발로 갔다가 파이썬 개발을 실전으로 한 거죠. 800억 규모 프로젝트에서. 그래서 그걸 통해서 자신감을 얻었어요. 아 그러면 내가 어 여기서 응용 개발할게 아니고 차라리 연구소에 가서 솔루션을 만드는게 더 낫겠다. 어 원래는 이제 연구소를 가고 싶었죠. Y는 연구서를. 근데 이제 어 뭐 일반 회사들이 그 부서 이동이 쉽지 않잖아요. 그래서 그렇게 하면서 제가 연구소를 어 들어가고 그다음에 이제 지금 현재 그 체포을 어 만들고 그다음에 AI 에이전트까지 하면서 요렇게 이제 갔고요. 그다음에 그런 내용을 이제 제가 이제 어떻게 AI 개발자가 됐는지 그런 얘기하고 그다음에 그다음에 이제 제가 75년생이거든요. 그래서 어 저보다 지금 나이 나이가 많으신 분은 이제 김성 선생님이신데 [웃음] 그외는 이제 그래서 제가 이제 50을 막 넘었는데 얘 최근에 이제 딱 느끼는게 고용 절벽인 거예요. 그니까 왜 그러냐면 일단은 30대에서 40대의 이제 AI 전공자들이 나오면서 그 분들이 한 4년 5년 하면서 팀장 자리를 다 차지를 하는 거예요. 아주 그렇게 하니까 그러니까 저도 이제 6년 차거든요. AI를 그러니까 어 근데 이미 이제 팀장 포지션이 30대 후반에서 40대에서 어느 정도 되니까 요즘에는 심지어 대기업 본부장 분들도 40대인 경우가 있으시더라고요. 그 엊그적게 제가 어 뭐야 커피 챗을 했었는데 거기서도 이제 글로벌 1조 규모의 그 프로젝트 아니 그 사업을 하시는 분인데도 40대예요. 그 본부장님이 그래서 그럴 정도로 이미 40대로 어 그게 내려왔기 때문에 &gt;&gt; 그 샘 알트마는 30대 아닌가요? &gt;&gt; 네. &gt;&gt; 샘 알트마는 30대 아닌가요? &gt;&gt; 아 그렇죠. 예 맞아요. 아 맞아요. 일단 요즘에 스타트업들 중에서는 갑자기 성장한 스타트업들은 20대 30대 또 부서장 본부장 분들이 있더라고요. 네. 그래서 그런 그 고용 절벽에서 어떻게 하면 그 어 이거를 해결을 할까? 뭐 그다음에 노후 준비나 이런 것들을 어떻게 할까? 요런 것들하고 그다음에 이제 국내 어 AI 개발자나 일반 개발자들이 왜 고용 절벽이 오는가? 이제 제가 또 여기에도 이제 있지만은 제가 어 지금 LLM R도 운영하지만 그 북미테크라는 어 미국 캐나다 지역의 한인 엔지니어분들 또 커뮤니티가 있어요. 거기에 또 부방장이거든요. 그러니까 해외에 이제 계신 분들하고도 소통하면서 그다음에 이제 어 그동안 어학연수도 갔다 왔고 외국 그런 거에 관심이 저도 많았어요. 그렇게 하면서 느낀 거는 이제 주변에 이제 그런 것들을 통해서 알게 된 거는 이제 미국이나 이런 데는 이제 그 기술 테크하고 관리 테크가 있어서 늦은 나이에서도 계속 채용을 할 수 있고 그다음에 이제 고용이 되게 자유로우니까 잘리기도 잘 잘리지만 일자리도 잘 구할 수 있는 이런 것들이 있는데 이제 우리나라는 이제 고용이 조금 경직돼 있데다가 이런 나이 문화가 있다 보니까 어 50대가 되면은 정말 어 취업이 어려워진 그런 상황이 되는데 그럼에도 불구하고 &gt;&gt; 우리는 그 상황을 탓탈 것이 아니고 그곳에서 또 내가 어떻게 하면 살아남을 수 있지 가족들을 먹여 살려야 되잖아요. 이제 막 그 저희 아들도 이제 중학교 고등학교인데 이제 그런 것들에 대해서 이제 좀 적었습니다. 그러니까 사회 초년생 분들이나 주니어분들 그다음에 시니어 분들이 어떻게 하면 AI로 전형할 것인가 이제 요런 것들을 좀 다뤘습니다. &gt;&gt; 음. &gt;&gt; 다른 저자분들도 한번 설명을 &gt;&gt; 아 예. 아, 뭐 그것도 좋은데 제가 여기서 여쭤보고 싶은 거는 그러면은 어, 요거는 어떻게 보면 진짜 생업에 대한 고민도 같이 어, 현실적인 고민 그런 것들을 같이 녹여해서 집필를 하신 거예요. &gt;&gt; 네, 맞습니다. 생업적인 측면하고 커뮤니티를 하면서 커뮤니티를 하면 또 우리나라 많은 기업들이 또 좋은 소식, 나쁜 시선으로 보는 경우도 있어서 이제 그런 것들에 대해서 어떻게 하는지 그런 고민도 약간 좀 닮았고요. &gt;&gt; 음. 그러면은 이제 50대이시거나 아니면 이제 정말 시니어 분들 시니어 개발자인데 어 아직까지 AI 개발을 하시지는 않지만 이분들이 좀 봤으면 하는 어떤 메시지들을 담고 있다. 요렇게 이해하면 될까요? 네, 맞습니다. &gt;&gt; 그 그러면은 남규 님께서는 혹시 AI 개발 어, 그러니까이 AI 개발이라는게 AI2를 사용한 개발을 말씀하시는 건지 아니면 직접적인 AI 어플리케이션이나 이런 것들을 만들어내는 개발을 해야 된다라는 관점이 있신지 곧 둘 중에는 어떤 취지세요? 일단은 저는 좀 약간은 완전한 스타트업처럼 모험하는 그까 이미 제가 사업을 두 번 망해 봤기 때문에 어떤 모험적인 측면보다는 좀 안정적인 비즈니스를 조금 추구를 하거든요. 그 뭐냐면 기존에 어 이미 잘 돌아가는 비즈니스하고 서비스가 있을 때 어떻게 하면 AI를 활용을 했을 때 이거를 더 극대화해서 더 수익과 더 고객들한테 좋은 서비스를 하는지 이런 관점에서 어 접근을 하면 시니어분들한테 굉장히 매력적인 포지션이라고 생각합니다. AI 응용 개발자는 이미 시니어분들은 커뮤니케이션이나 고객 상계를 많이 했기 때문에 여기서 AI한테 우리가 영어에 울렁증만 없으면 영어를 배울 수 있잖아요. 그러니까 마찬가지로 AI도 AI 울렁증만 없으면 오히려 그런 어떤 대형 시스템 경험이나 이런 것들을 살려서 AI를 조금 더 매력적으로 붙이면 어 시니어 개발자분들한테 자바개발자들 특히 이제 자바 개발과 활성 개발을 하면 축구로 치면 양발 잡비를 손흥민 선수처럼 양발을 쓰는 거기 때문에 굉장히 기업들한테도 최정 시장에서도 되게 매력적 적이라고 생각을 합니다. 세 사람 쓸 거를 저는 항상 아 최근에 이제 제가 인터뷰에서 합격한 거기서도 제가 그렇게 말씀드렸어요. 세 사람 그니까 저는 이제 웹 개발도 되니까 자바 응용하고 자바 웹하고 파이썬 되니까 세 사람을 쓸 거를 저 한 명을 써 써 주세요. 써 주십시오. 음. 대신 이제 동시에 세 사람 몫은 하지 않지만 그 순차적으로 시리얼하게 어 세 사람이 할 수 있는 그런 어떤 시도들 시도들이나 이거 이런 것들을 세 명이 들어왔다고 실패하면 리스크가 크잖아요. 어 그것보다는 차라리 이런 풀스택으로 시니어를 썼을 때 어떤 그런 효과가 있지 않을까? &gt;&gt; 음. 근데 제가 드리고 싶은 말씀은 이게 사실은 그 시니어 개발자분들이 AI 울렁증이 있어서 못 한다기보다는 그게 고객과 상담할 때 내가 지금까지 해왔던 거와 AI 판도가 너무 다르기 때문에 거기에서 어려움을 많이 느낀다고 저는 생각을 하고 있는데 어떻게 보세요? 그니까 커뮤니케이션 스킬이 좋은 거는 저도 이해합니다. 근데 &gt;&gt; AI가 내가 20년 동안 개발을 해 왔던 영역이랑 완전 다르잖아요. 근데 그 갭을 메꾸려면 또 리스킬을 해야 되는데 리스킬를 할 시간과 시간적 여유가 사실 그걸 기술을 따라 잡기에 좀 어려워하시는 부분들도 있는 거 같고요. 어떻게 보세요? 어, 일단은 이게 우리나라 또 시장까지 우리나라 이제 그 소프트웨어 이제 시장까지 이제 짚어야지 되는 이야기인 거 같아요. 그러니까 우리나라 시니어 개발자들이나 이런 엔지니어들은 중소 기업과 중경 기업과 대기업에 있는데 어, 일단은 그나마 이제 중소 기업에 있는 분들은 어느 정도 풀스택에 가까운 개발자분들이 어느 정도 있을 거예요. 이제 그런 분들은 사실 접근을 하려면 그냥 LM이나 이런 서비스를 이용해서 접목만 하면은 사실 거의 한 80%는 와 온 거예요. AI 응용 개발자. 이제 여기에서 내가 조금 더 어 AI 리터러시나 아니면 기획적인 것들만 내가 조금 더 어 받아들이면 어느 정도 완성이 된다고 보고 있고요. 그다음에 이제 어 대기업이나 이런 쪽 분들을 보면 우리나라가 이제 대기업 그런 어 뭐 카카오나 아니면 서비스 기반의 대기업 빼놓고는 외주화가 많이 돼 있기 때문에 어 일단 이런 거에 대한 구현이나 이런 것들의 경험이나 한계가 있기 때문에 그렇기 때문에 그런 상황에서 AI까지 뭔가 접하는 것들은 실제 AI의 그런 어떤 실제 원리를 파악하는데 약간 어려움이 좀 있다고 보거든요. 일단 코딩 자체를 놓은 경우나 아니면은 연습 정도 수준으로 하는 경우가 많다고 저는 보고 있기 때문에 그렇게 해서 일단은 어떤 내가 속하에 있는 기업에 따라 약간 접근 방식은 조금 다를 거라고 생각니다. &gt;&gt; 음. 알겠습니다. 감사합니다. 또 재밌게 읽어 보도록 하겠습니다. 다른 분들이 쓰신 것도 공유가 가능하세요? &gt;&gt; 네. 네. &gt;&gt; 어, 원래는 제가 편집자님께 그 한번 편집자님께서도 여기 출연하셔서 쭉 설명을 해 주시면 좋겠다라고 말씀드렸는데 극 아이씨라고 하셔 가지고 어차피 제가 말을 꺼낸 김에 누군가는 총대를 매서 한번 설명을 해야겠다 생각을 해서 제가 한번 어 정리를 했고요. 음. 일단은 책 제목은 AI 개발자가 되고 싶으세요인데 어이 책의 장점은 어 이미 이제 저희 지금 오늘 출연한 세 명도 각각 다른 영역에 있으세요. 그러니까 어떤 새로운 AI를 하고 싶은 분들이 접점이 우리 세 명 중에 아니면 여섯 명 중에는 어느 정도 근접한 분들이 있을 거라고 저는 보거든요. 그런 측면에서 저희 어 책은 되게 가치 있는 책이고 어느 정도는 맞다고 보고 있고 요번에 최근에 제가 이제 석평 이벤트를 했었거든요. 그랬었는데이 개발자뿐만 아니라 기획자나 아니면 그냥 현업에 계신 분들도이 책을 읽고 싶다고 하시는 거예요. 그러니까 어떻게 보면은이 책은 개발자만을 위한 책이라기보다는 어떻게 하면 기획자가 어떻게 하면 현업이 개발자들을 이해할 수 있는가? 어떻게 하면 AI 산업을 이해할 수 있느냐 이런 또 접근이라고 좀 생각을 해하고요. 그래서 오늘 안 오신 분들 위주로 이제 제가 좀 설명을 드리면 아까 제가 초반에 이제 말씀드렸던 것처럼 그 바이브 코딩 개발자 요즘에 이제 여러 가지 블로그로 유명하신 베이동 님이 계시고요. 그다음에 좀 전에 그 홍석경 님은 한번 설명하셨고 오연우 님이라고 일본에서 어 그 강화 학습을 어 공부하고 솔루션 엔지니어 그러니까 글로벌 AI 솔루션 엔지니어로 일본 베이스로 이제 그 하시는 개발자 분이 계시고 그다음에 독일 스타트업에서 이전에는 게임으로 하다가 이제 의료 또 하시는 어 분이 계시더라고요. 마침 또 어우 님처럼 일본 쪽 베이스를 잘하시는 분하고 그다음에 독일 유럽 쪽을 커버하고 또 이제 저 같은 경우도 이제 그 북미 쪽 커뮤니티 쪽 활동을 하면서 하기 때문에 이제 북미쪽에 대한 그런 교류도 많이 있어서 어 어떻게 보면 굉장히 범위나 이런 그 뭐죠 교집합적인 부분이 많지 않을까 생각을 합니다.네 네. 그래서 요렇게 이제 책을 총 공동 저자는 여섯 분이고요. 그래서 저희 소개 안 했던 세 분 빼고 이제 설명을 한번 드리면 예. 배위동 님이라고 바이브 코딩하는 개발자 그러니까 AI를 통해서 어떻게 하면 효율 높일까? 네. 이런 것들. 그런 다음에 이제 좀 전에 저희도 얘기를 한번 나눴었는데 효율만 높인다고 이런 어떤 품질을 또 고민을 안 하면 안 된다. 요런 것들도 한번 얘기를 하셨고요. 결국은 이제 어 그런 어떤 앱에 대한 운영까지 운영의 안정성을 높이는 부분. 그다음에 이분도 이제 블러 블러서 10만 조에 넘는 그런 글 같은 것들을 하셨거든요. 그러니까 어떻게 보면은 이런 활동이 결국은 저희가 어떤 직장인이 아니고 어 업 AI라는 거를 업으로 해서 계속 이어가는 거죠. 직장이 변하더라도 가급적이면 저는 항상 직장은 근속 연수가 중요하다고 저는 강조를 하는데 제가 그렇게 못했기 때문에 어 그럼에도 불구하고 어쨌든 블로그나 이런 걸 통해서 꾸준한 어떤 커뮤니티를 통해서 어떤 더 기술 발전이나 이런 것들이 중요하다고 생각을 합니다. 그래서 어 베이동 님 같은 경우도 강산나 코치 컨설턴트라는 여러 가지 어 정체성을 갖고 계신 분이 어이 책을 쓰셨고요. 그다음에 이제 좀 전에 그 홍석님 이제 설명하셨는데 어 플랫폼 그다음에 비전공자 그리고 클라우드 어 그리고 이런 어떤 변화 속에서 성장하고 즐기고 사람는 이런 꾸준히 공부하시는 부분 또 비전공자분들도 또이 책을 또 아마 관심이 있으실 것 같아요. 그래서 홍성님 같은 경우는 어쨌든 첫 시작이 중요한 거 같아요. 비전공자라도 내가 어떤 소프트웨어에 대한 경력을 확실히 키울 수 있는 그런 곳에 이미 오면 그다음부터는 비전공자라는 의미가 어 의미가 없는 거 같아요. 그러니까 항상 첫 시작이 중요하다. 네. 이렇게 보시면 되고 오연우 님 같은 경우도 이제 지금 이제 글로벌 AI 플랫폼 이제 기업에 근무하시는데 어 강화 학습이나 이런 쪽으로 하시다가 어 책 같은 것도 추천하셨어요. 그 밑바닥부터 시작하는 딥러닝, 강화 학습에 도움이 되는 케라스로 배우는 강화 학습 이런 어떤 식으로 스터디할지와 그다음에 그런 어떤 어 연구가로 시작을 해서 솔루션 엔지니어로 이제 하는 그런 과정에 대해서 좀 소개를 하셨고요. 그다음에 그 정금모님 같은 경우는 어 오늘 그 같이 참여하신 김성환 님하고도 약간 어 영역이 공통 분모가 있는데요. 그러니까 독이 그러니까 그 게임 쪽으로 해서 시작을 하셨는데 아까 이제 저 김성환 님께서도 아마 어떤 시대의 변화에 따라서 어떻게 공통점으로 어떤 인사이트를 얻을 수 있느냐 이런 말씀을 하셨잖아요. 마찬가지로 정금호 님도 보시면 어떤 모바일 시대가 왔을 때 그런 모바일 중심의 게임을 만들면서 내가 한번 도퇴되지 않고 적응했다. 요런 것들을 좀 말씀을 하셨고요. 그다음에 이분도 생성형 AI를 통해서 50개 게임을 만드셨대요. 근데 사실 어 뭐 바이브 코딩만 하셨겠어요? 아마 50개를 만드시느라 아마 잠을 엄청 못 주무셨을 거예요. 남들 남들 8시간 잘 때 하루에 아마 한시간도 아마 못 주무셨지 않았을까? 그러니까 결국은 극단적인 생산성을 만들기 위해서는 AI만 활용한게 아니고 본인이 정말 피를 토하는 그런 노력을 하지 않았을까? 하셨고 이분께서도 첫 스타트가 좋으시더라고요. 게임 개발 했는데 SKT 공모전에 어 대상을 하시면서 취미해서 직업이 되었대요. 저 같은 경우도 웹 개발자로 들어갔다가 PM을 하면서 파이썬 그거를 연구소에서 안 만들어 준다고 해서 제가 만들었더니 그게 실전 경험이 된 거예요. 그니까 운도 좀 따라야 되고 그다음에 이제 개인의 의지도 중요한 거죠. 이제 저도 사실 그 제 위에 책임자는 파이썬 그거 연구소 건드리지 말라고 했어요. 왜냐면 그걸 건드리는 순간 사업팀에서 책임져야 된다는 거예요. 근데 그때 상황이 그거를 어 보완하지 않으면 그 어떤 프로젝트 그 통합 테스트나 단위 테스트 통과하기 어려운 상황이었어요. 그래서 이제 제가 PM으로서 아 이거는 무조건 해야 된다라고 설득하고 연구소에 협조를 얻어서 했거든요. 결국은 어떤 어 내가 뭔가를 전환을 하려면 대충해서는 안 될 것 같습니다. 그냥 목숨을 걸어야 됩니다. 네. 그래서 정말 뭐 어 실력이 있거나 아니면은 정말 뛰어나신 분들 취미로 해서 뭐 당첨될 수 있는 운도 따르겠지만 대부분은 어 정말 노력을 해야 우리가이 지극 직무 전환을 할 수가 있는 거 같습니다. 예. 그래서 아까 이제 좀 전에 제 얘기 했었고요. 예. 김성환 님 같은 경우도 이제 어 한번 말씀으로 좀 하시기 어려운 이제 부끄럽잖아요. 자기 자랑하기. 그거를 이제 제가 대신 설명드리면 그 물리학을 전공하시고 지구학 박사까지 하셨습니다. 그러니까 뭐냐면 게임을 만드실 때 어 어떤 그 게임의 캐릭터나 이런 것들이 움직일 때 아니면 주변 환경에 대한 이런 역학 관계 이런 것들이 물리학을 전공을 하셨기 때문에 그런 것들이 굉장히 큰 어 베이스가 됐다고 하십니다. 그리고 또 많이 놀랐던 것 중에 이미 그 AI의 그 윈터라고 할 수 있는 그 93년도쯤에 퍼지 인공지 어 지능 이론이나 그 퍼셉트론 요런 것들을 시프플루도 만드시고 당시에는 이제 게임 업계뿐만 아니라 모든 소프트웨어 업계가 완전 윈터였죠. 이제 이런 측면에서 어떻게 보면 인공지능 초창기서부터 이런 이론이나 이런 것들을 경험하셨고 그 우리 김성환 님께서도 정말 좋은 어어 평소에 노력하셨지만 또 운이 또 따르셨죠. 준비가 되셨으니까. 그래서 그 펄어비스라는 곳에 어 뭐야 원래는 잠깐 도와주러 갔다가 나중에 퍼비스에서 불러서 진짜 정식 연구원으로 하셨다고 합니다. 그래서 그런 얘기도 재미가 있었고요. 그다음에 3D 게임 프로그래밍이나 통계 물리학 요런 것들이 인공지능에 어 또 도움이 되셨고 또한 수학 어차피 인공지능 연구까지 가면 또 수학을 또 해야 되잖아요. 그 그런 부분이 되게 도움이 됐다고 하십니다. 그래서 네. 요렇게 저자하고 기본적인 제가 이해한 내용을 좀 관심 있는 부분 위주로 정리를 했습니다. &gt;&gt; 아, 네. 정리해 주셔서 너무 감사합니다. 네. 여섯 명의 저자분들은 이제 다시 한번 또 어 말씀해 주셨는데요. 그 이제 정리하자면은 이제 다 여섯 분에 완전히 AI와 관련이 있지만 약간 어떻게 보면 영역이 또 다양한 부분인데 어 제가 뭐 제가이 책을 읽는다면은 여섯 분의 스토리가 다 너무 재밌을 것 같아요. 제가 비단 게임 개발을 당장 하진 않겠지만 저는 그런 거가 너무 재밌더라고요. 그분이 어떤 철학을 가지고 지금의 위치까지 걸어가셨는지 그런 것들을 엿보는게 너무 재밌는 거 같습니다. 그래서 제가 즐겨 있는게 기술서 말고 유일하게 자서전 보는 걸 되게 좋아하거든요. 자서전 보면은 하나같이 다 왜 예전에 그 MBC에서 했었던 성공 시대 이런 거 있잖아요. 그런 거 보면은 성공한 사람들이 꼭 중간에 그 난관이 한 번씩 찾아오더라고요. 근데 제가 그걸 보는게 너무 재밌는게 그 성공한 사람들이 그 난관을 극복하는 그 자세 마음가짐 그게 다 다른데 거기서 배울 점들이 되게 많다 많은 거 같더라고요. 다 처음부터 잘해서 지금까지 성공해 왔습니다. 이러면 사실 재미가 없잖아요. 아, 저 사람은 원래 잘났나 보다 했는데 제가 이걸 읽으면서 아마 되게 여기 계신 여섯 분들도 되게 많은 고민과 커리어 전환과 분명 분명히 있을 거라고 생각이 드는데 그런 것들을 염두해 두고 읽을 생각하니까 너무 재밌을 것 같다는 생각이 많이 듭니다. 어, 네. 이렇게 소개해 주셨는데 성환님께 한번 여쭤보고 싶은 거는 이게 이번에 책을 쓰시기로 마음 먹으신 어떤 계기라고 해야 될까요? 계기가 있으셨어요? 원래 그전에도 좀 집필를 하셨긴 했는데 &gt;&gt; 아니 이제 공조로는 뭐 여러 번 내기 했고 작년에 이제 아 단독 조소는 이제 AI에 대한 책도 내게 됐고 그래서 뭐 그냥 계기라기보다는 그냥 안 그래도 이런데 대한 책은 뭐 기회가 있으면 쓰고 싶은데 어 그냥 출판사에서 이렇게 써 보지 않겠냐고 컨택이 왔기 때문에 뭐고 두 번 고민하 예 그리고 사실은 단독 조소는 정말 힘들어요. 거는 어쨌든 불량이 아니라 혼자 써야 되는데 이렇게 그 공적인 경우에는 다른 분들하고 힘을 합쳐 제가 딱 맡은 부분만 열심히 하면 돼서 훨씬 부담을 덜 가지고 재밌을 수 있었어. &gt;&gt; 음. 음. &gt;&gt; 예. 예. 그런데 이제 다 엮어지면 이또 이렇게 굉장히 풍부해지고 더 다양한 시점들을 접할 수 있으면서도 독자분들한테 큰 도움이 되는 책이 나와서 그 개인으로 보면 좀 쉽게 쓰면서도 전체로 보면 큰 도움이 되는 &gt;&gt; 음. &gt;&gt; 그 &gt;&gt; 어 혹시 책에는 그럼 못 담았지만 아 요거 얘기하고 싶다 했던 메시지나 하고 싶으신 말 있으세요? &gt;&gt; 네. 네. 저기 안 그래도 이제 실은 여기 이제 저자 중에 저도 그렇고 이제 정금모님 같은 경우도 오늘 참석 못 하셨지만 이제 게임 쪽의 커리어가 굉장히 컸고 어 정고모님 같은 경우도 바로요 이전에 같은 나온 책이 그 생성애를 활용해서 게임 개발하는데 대한 책이에요. 진짜 본인이 이제 경험했던 예, 그런 걸 담고 있고 하는데 예, 저는 이제 보면 많은 분들이 이제 게임하고 AI하고는 좀 상관이 없을 거라고 이렇게 좀 지혜짐작하는 경우가 있는데 사실 지금 우리가 이제 쓰고 있는이 AI 이제 특히 신경에 기반을 둔 이제 딥러닝 AI 같은 경우에는 어 사실 AI는 떼놓을 수 없는게 대표적으로 적으로 이제 안 그래도 얼마 전에 구글 딥마인드에서 열심히 만든 재미나 3가 나왔잖아요. 그래서 이제 다 알다시피 딥마인드 CEO와 데미스 하사비스가 개인 개발자 출신이거든요. &gt;&gt; 음. 음. &gt;&gt; 그래서 책에도 잠깐 언급이 되지만 개인적으로 2001년에 이제 한번 직접 볼 기회가 있었어요. 이제 게임 쪽에는 이제 실리콘 밸리에서 계속 GDC라고 해서 1년 한 번씩 &gt;&gt; 게임 디로버스 컨퍼런스가 걸리는데 &gt;&gt; 그때 그 무리반에 제가 이제 거의 몇 년 가던 때라서 그 2001년이 좀 특별한 해였어요. 그 알다시피 이제 그 스타디 큐브릭 감독에 2001 스페이스 오디세이라는 영화가 있잖아요. 그게 1967년인가 8년에 나온 영화인데 SF 역사상 굉장히 기념비적인 영화이기도 하고 그게 보면 이제 하이라는 이름의 이제 인공지능 컴퓨터가 나와요. 이제 그게 이제 그 당시 보면 이제 승무원들이랑 그냥 자연으로 대화도 하고 뭐 채수도 두고 뭐 전체 이제 우주선의 시스템 관리한 역할을 맡고 있고 뭐 물론 이제 소울적 재미에 따라서 이제 뭐 승무화 갈등이 생기고 뭐 이렇게 사건들이 생기긴 하지만 이제 그때 2001년도에 이제 GDC가 택한 주제가음 왜 우리가 2001년이 됐는데 아직까지도 그 2001년 스페이스 오디세이라는 영화에 에서 그랬던 그 2001년인데 &gt;&gt; 아직 할처럼 자연으로 대화할 수 있는 그런 인공이 아직 없냐? &gt;&gt; 음. 음. &gt;&gt; 그게 이제 큰 화도 있고 이제 그 당시에 이제 어 인공지능의 대부로 불린 MIT의 마비 민스키 교수가 이제 그 키노트 강연을 했어요. 제가 이제 그분 강연도 듣고 그다음에 이제 두 번째로 들었던 강연이 이제 바로 그 데미스 하사비스의 강연 주제가 굉장히 흥미로 끄는 거라서 그때 강연 주제가 어디 오브 AI라 그래 가지고 그 게임에서는 이제 복자 물체를 있는 그대로 다 이렇게 화면을 그리려면 너무 이제 부하가 많이 걸리니까 멀리 있으면 이렇게 대충 그리고 가까이 있으면 세미나 그리고 이렇게 하는 걸 레벨 오브 디테일라 서 이제 LOD라고 쓰거든요. 근데 그 LOD는 시각제인 거 그래픽을 표현할 때 쓰는 건데 LOD 오브 AI라고 주제가 다니더 AI도 LOD를 하나? 음. &gt;&gt; 그래서 재밌는 주제에 대해서 이제 드러났는데 웬 새파랗게 젊은 친구가 가연자라고 나오더라고요. 그 당시에 데미 사사비가 24살밖에 안 크거든요. 근데 이제 저는 이제 딱 보는 순간 어떤 느낌이었냐면 이마에 나는 천재라고 서없이가 [웃음] 진짜 그 천재 아우라가 참 빛나는데 그 이렇게 강연하는 것도 굉장히 그 그 똑소리 나게 하면서 그 당시 그 주제가 뭐였냐면 그 원래 이제 그 그 당시에 블랙앤 화이트라는 게임이 출시되기 직전이었거든요. 본인이 이제 참여해서 만들었던 그 당시 2001년에 나온 게임으로 굉장히 중요한 게임 AI 역사상 굉장히 뛰어난 그런 AI를 담고 있는 그런 게임이었어요. &gt;&gt; 음. &gt;&gt; 거기에는 그 당시도 신경망이 조금 쓰이기도 했고요. &gt;&gt; 음. &gt;&gt; 그 크리처라는 걸 갖다가 사람이 이제 막 그 학습을 시켜서 막 이렇게 부리는 뭐 그런 내용이 있는 거거든요. 인공지능 캐릭터인데. 근데 이제 거기를 출시되기 전에 이제 자기가 나와서 차갑한 회사의 게임이었어요. 그 그 당시 그 게임의 제목이 리퍼블릭이었는데 어떤 거냐면 한나라의 국가 시스템을 시뮬레이션하는 게임이었어요. &gt;&gt; 음. &gt;&gt; 예. 정치적인 어떤 국가 시스템 &gt;&gt; 그러니까 이제 엄청난 대을 해야 되니까 이제 그런 Lood가 필요했던 거죠. 이제 &gt;&gt; 아 &gt;&gt; 멀리 있는 거는 대충하고 가까이 있는 거는 상세하게 하는 식으로. 그래서 저는 이제 솔직히 이제 그때 강연자로 뒤에서 들으면서 아 저 친구가 되게 똑똑하고 그다음에 차는 걸 알겠는데 아 세상에 쓴 맛을 좀 더 봐야 될 것 같다 [웃음] 그러니까 이제 그 게임이 그렇게 출신을 했는데 원래 이제 목표만큼도 완성을 못한 상태 출신했고 했지만 시장에서는 반응이 별로였어요. 예. 그리고 두 번째 게임은 조금 그래도 좀 대중적인 좀 소구력 있는 좀 이렇게 좀 테주한 풍을 해서 나오긴 했는데 그것도 시장에서 별로 이렇게 반응이 안 안 좋았거든요. 그래도 어떻든 자기는 이제 그 게임을 통해서 좋은 AI를 구현하고 싶은 욕심이 있어서 이제 투자를 계속 이렇게 찾아내는데 투자를 못 받아 가지고 그때 이제 좀 은퇴원을 하고 깨기를 떠났는데 그 떠나면서 이제 박사 과정에 들어간 거죠. 음. &gt;&gt; 그래서 그때 내과학 박사관 들어가서 &gt;&gt; 그 박사 논문도 굉장히 좀 기념비적인 논문을 썼고요. 내에서 기억 작용에 대한 중요한 좀 돌파를 찾아낸 그런 논문이었고 그리고 이제 박사 따고 딥마인드를 차업했죠. 그 저는 이제 사실은 딥러닝이라게 나왔다는 걸 그 딥인드에서 아타리 게임을 &gt;&gt; 강화 학습을 혼자서 학습을 깨는 걸 막 했다. 그거 보고 &gt;&gt; 어 되게 반가웠어요. 그 보니까 어이 사람 보니까 옛날에 &gt;&gt; 반 그 친구였네. &gt;&gt; 그걸 정확하게 기억하고 계실 정도면 되게 그때 인상이 되게 깊으셨어. 경생 살면서 직접 이렇게 눈으로 본 사람 중에 천재 아우라가 그렇게 하는 사람을 처음 봤어요. 그 지금 돌이켜 보니까 그게 이제 노벨상 받을 아라였던 거죠. &gt;&gt; 예. 그 저는 그래서 이제 막 되게 반갑 반갑게 됐고 이제 뭐 특히 그래서 약간 그래서 제가 어떻게 보면 2016년에 알파고하고 우리 이세돌 9단하고 대전했을 때 대부분 다 사람들이 이세 9단이 뭐 쉽게 이길을 거라고 예측했는데 저는 알파구가 5대 0으로 이길 거라고 예측을 했었어요. 물론 이제 제가 이제 신경방 쪽을 좀 했기 때문에 좀 그런 감도 있었지만 좀 그렇게 이겨져서 한 발행도 있었고 제가 이제 사실은 &gt;&gt; 그 인공지능 지금은 이제 신경마 인공지능이 완전히 대세가 돼 버려서 뭐 그런 일 없지만 제가 1999년에 막 신경막 이렇게 간단한 거 이렇게 막 구현하고 하던 시마하더라도 제가 있던 곳에도 그렇지만 학교에서도 신경만 연구한다 그러면 완전히 그냥 미운이 새끼 직업을 받았거든요. &gt;&gt; 음. &gt;&gt; 뭐 이렇게 논문에 신경망이란 단어만 들어가도 실어 주지도 않고 학술대에 뭐 제출해도 뭐 시 올해 신경방 하나 발표하겠으니까 당신도 안 돼. 이게 &gt;&gt; 음. 그래서 그 노벨 작년에 노벨 물리학받은 제프리 흰 교수 그 팀자의 대부 그분이 낸 논문도 발표할 기회를 못 찾아 가지고 &gt;&gt; 어 &gt;&gt; 학회장 옆에 따로 텐트 치고 &gt;&gt; 그렇게 하고 그 그런 진짜 그런 분들이거든요. &gt;&gt; 그래서 그래서 저는 이제 오히려 좀 이렇게 좀 알려져야 된다. 이게 그래서 그랬고 그 저는 개인적으로 이제 어떻게 보면 제가 이제 물리학 전공한 입장에서 좀 위했던게 뭐냐면이 사실은 이제 그동안 전통적인 소위 말해서 그 규칙 기반 논리 기반의 AI는 주로 CS 전공하신 분들이 주로 주도를 했었어요. 그런데이 신경망 쪽은 재미나게도 주로 물리학 하셨던 분들이 끝까지 이걸 좀 버티고 했었어요. &gt;&gt; 음. &gt;&gt; 그래서 이제 뭐 알다시피 저기 스탠포드 대학에 그 페이리 교수님 아시죠? 그 &gt;&gt; 네. 예. &gt;&gt; 이미지하신 그분도 &gt;&gt; 물리학자 출신이고 뭐 &gt;&gt; 그 사실은 좀 재미난게 이제 재프리던 교수님 같은 경우에는 이제 필슨 대학에서 물리학 과목을 하는 바람에 오늘 저 전공을 심리 좀 바꾸셨는데 재밌잖아요. 물리학 낙재생이 &gt;&gt; 너무 물리학생을 받으 [웃음] &gt;&gt; 그러네요. 그리고 이제 그분하고 절친 이제 그 세즈노브스키 같은 경우는 물리학자 출신이에요. 그러니까 이제 그 그분하고 같이 쓴 논문도 있고 뭐 이렇게 음성 합성에 최초로 신경망을 활용해서 굉장히 자연스러운 음성이 나오게 하는 그런 걸 하신 분이기도 하고 근데 흥미로운게 뭐냐면 우리가 보통 일반적으로 딥러닝 그러면 2012년에 그 재든 교수님이 그 제자 두 사람 같이 한 알렉스넷이 이비진 그 대회에서 압도적인 성적을 우승하면서 이제 딥더닝 시대가 열렸다고 보통 알고 있는데 사실은 이 신경만 기반으로 한 딥러닝이 굉장히 재뛰어 잘 된다는 걸 가장 먼저 한 거는 마이크로소프트였어요. &gt;&gt; 음. &gt;&gt; 마이크로소프트 내부에서 음성 인식을 딥러닝으로 했더니만 굉장히 잘 되는 걸 먼저 알았어요. 근데 문제는 뭐냐면 그냥 어쩌다가 좀 특이하게 잘 된 거겠지. &gt;&gt; 어. 그렇게 생각했대요. &gt;&gt; 아, &gt;&gt; 그게 보편적인 방법이 될 거라고 생각 안 했대요. &gt;&gt; 그래서 아무튼 뭐 지금 우리가 쓰고 있는 이제 GPU만 하더라도 사실은 다 알다시피 게임을 위해서 게임 때문에 발전한 하드웨어잖아요. 사실은 게이머들이 더 화려한 그래픽의 게임을 잘하기 위해서 기꺼이 돈을 으라고 M비D한테 돈을 집으라고 그 했기 때문에 GPU가 발전했고 그 발전된 걸 갖다가 쓸 수 있긴 한데 &gt;&gt; 그 보통 이제 그 한 9년 뭐 7년 정도에 이제 AI 연구자들이 이제 어 이거 GPU가 병렬 연상 잘하니까 이걸 AI 쪽에 쓰면 좋겠다고 한 걸로 보통 알려져 있는데 흥미롭게도이 GPU를 신경 경망에다가 처음으로 활용하기 시작한 첫 논문은 2003년인가 4년 한국 송실대에서 논물이 최초예요. &gt;&gt; 아. &gt;&gt; 아. &gt;&gt; 예. 잘 모르는데. 그래서 그런 것도 있고 제가 이제 전에 이제 주로 생성해야죠. 연구를 했으니까 특히 많이 연구했던게 음성 생성 쪽으로 많이 왜냐면 게임 쪽에서 &gt;&gt; 이게 다양한 캐릭터들 음성을 막 많이 하면 좋은데 그게 쉽지 않은게 성우들 녹음해야 되고 그러면 이제 쉽지 그게 성 녹음하는 것도 쉽지 않지만 변경상이 생겼으면 더 골치 아픈 거야. 변경이 생기면 다시 또 스튜디오 시간 잡고 또 서우 초대해서 또 이렇게 녹음하고 해야 되니까. 그래서 이제 어떻게 하면 물론 이제 그 메인 캐릭터까지 아니더라도 마인드한 MPC들이라도 좀 이렇게 AI 음성으로 이렇게 대체가 안택카에서 이제 그렇게 그걸 연구했는데 이제 그거 하면서 이제 잠깐 파일럿을 했던게 그 신혜철님 목소리 제연하는 걸 했었어요. 사실은 책에도 적혀 있지만 그래서 그거 하면서 좀 제대로 고생을 했죠. 데이터 전리자가 한 10개월 걸렸으니까요. 근데 이제 문제는 뭐냐면 물론 이제 그 실제 전처리 작업하시는 분이 따로 있긴 해서도 세용주님 검수를 제가 혼자 다해야 되니까 그걸 내 하루에 한 한두 시간씩 계속 이제 핸드폰 끼고 다 들어봐야 되. 그것도 이제 배속도 안 되고 원래 속도로 그대로 다 들어가야 되는 무슨 &gt;&gt; 예 &gt;&gt; 그래서 그거는 &gt;&gt; 그 그래서 사운드 쪽이 제일 힘든 힘들었어요 사실은. 근데이 발전하니까 그것도 그때는 이제 막 굉장히 잘 정제된 품질이 좋은 사운드를 다 가지고 학습을 시켜야 되는데 &gt;&gt; 지금 이제 상관없어요. 양만하면 그냥 잘되는 쪽으로 돼 가지고 &gt;&gt; 아무튼 뭐 아 이렇게 좀 약간 중구 난방이 됐는데 그래서 게임이 지금 현재 우리가 쓰고 있는 이런 AI의 지대한 기여이었고 영향을 미쳤고 특히 이제 뭐 그런 하드웨어 분야도 그렇고 뭐 데미스 하사 하사 같은 인물도 그렇고 그다음에 뭐 물리학도 그랬고 그래서 그럼 왜 물리학자들이 이렇게 지금 딥러닝의 그런 겨울 때 어떻게 그렇게 버티면서 할 수 보면 저는 이제 책에 그 적은게 뭐냐면 이게 좀 자인에 대한 겸손함 물리학자들은 어떻게 보면 우리가 모든 걸 다 완벽하게 알 수 없다는 걸 먼저 알았어요. 20세기 넘어오면서 상대성이 이런 등장하고 특히 대표적으로 양자하게 등장하면서 우리가 세상을 완벽하게 알 수 없다. 확률적으로밖에 파악할 수 없다는게 세상의 원리라는 걸 이제 먼저 알았기 때문에 그래서 우리가 모든 거 하나하나 다 논리적으로 따져서 알 수 없다는 걸 이미 알고 있었기 때문에 그런 모하고 애매한 것도 다룰 수 있는 그런 신경망이라는 걸 갖다가 할 수 있지 않았나? &gt;&gt; 음. 음, 그렇습니다. &gt;&gt; 아, 너무 재밌게 말씀도 너무 잘해 주시고 지금 이런 역사 짚어 주시니까 너무 흥미롭게 시간 가는 줄 모르고 잘 들었습니다. 아, 너무 감사합니다. 물리학 저는 페이일리 교수님도 물리학에지 몰랐는데 오늘 &gt;&gt; 또 많은 걸 알게 되네요. 아, 감사합니다. 제가 꼭 어, 오늘 당장 자기 전에 읽으면서 자도록 하겠습니다. [웃음] 감사합니다. 아, 홍성 님께서도 혹시 뭐 책에 담지는 못했지만 뭐 메시지 하시고 싶은 말씀 있으세요? &gt;&gt; 아, 저는 책에 충분히 다 [웃음] &gt;&gt; 다 담아 주셨어요. &gt;&gt; 네. 아, 알겠습니다. AI 개발자 그러면 제가 하나만 질문을 드려보도록 하겠습니다. AI 개발자가 어, 되고 싶은 분들 그 대상이 취업 준비생도 있겠지만 그 리스키를 하시는 분들이 각상 고민하는게 어렵고 내가 잘할 수 있을까? 이런 거라고 생각이 듭니다. 조금 현실적으로 어, 조언 하나만 해 주실 수 있으세요? 이런 분들께. 뭐 어떤 용기를 드리는 것도 되고 아니면 현실은 다르다면 뭐든 다 좋습니다. &gt;&gt; 아, 네. 저는 다 가능하다고 생각을 해서 용기를 드릴 수 있을 것 같은데요. 일단은 AI 개발자가이 측에서 다루는 AI 개발자의 종류가 모델 개발하는 리서처뿐만 아니라 이제 플랫폼이나 아니면 AI를 이용해서 서비스 개발하는 백엔드 개발자 프론트도 다하기 때문에 현재 어떤 포지션에서 일하시더라도 AI와 다 맞다 있는 부분들이 있을 거고 예. 본인이 어 관심이 있으시고 기술적으로 흥미 있으시고 동기 부여되시는 방향으로 가면은 다 성공할 수 있다고 저는 생각을 하거든요. 어차피 개발자라는 직업을 택한 이상 평생 공부해야 되고네 자기가 갖고 있는 어떤 기술 백그라운드 플러스 거기에 이제 AI와의 접점이 될 수 있는 기술 한 가지씩을 통해서 어 확장을 할 수 있다고 생각을 해요. 예를 들면 백엔드 개발자 같은 경우에는 뭐 AI 플랫폼으로 예를 들어서 도전을 해 보고 싶으시다 &gt;&gt; 그러면은 &gt;&gt; AI에 대한 백그라운드가 없어도 가장 먼저 접할 수 있는 어떤 제품군들이 있거든요. 예를 들면은 뭐 데이터 저장소, 모델 저장소 이런 것들은 이제 AI 백그라운드가 없어도 백엔드 개발자로서 어느 정도 쉽게 접할 수 있는 부분이라고 생각이 들고요. 그다음에 플랫폼이 아니고 나는 AI 서비스에 관심이 있으시다. 그러면 일단 테디 님의 레그를 좀 구분하시고 네. AI 에이전트 쪽으로 먼저 프로치를 해 보실 수가 있으실 거라고 생각이 들고요. 네. 그다음에 AI 모델 쪽에 관심이 있으시다 하면은 어 당장 모델을 개발하시는 거는 좀 어느 정도 공부가 필요하시니까 처음 어프로치는 데이터에서부터 시작해 보시는게 어떨까 싶기는 해요. 사실 모델러분들도 어 AI를 구성하는 3대 요소를 보통 이제 인프라 데이터 알고리즘이라고 얘기를 하는데 알고리즘은 공개되어 있잖아요. 대부분 뭐 실제로 그 알고리즘을 적용해서 모델을 만들어서 어떤 퀄리티 이상을 뽑아내는 거는 공개되어 있지 않은 어떤 것들에 대한 노하우들이 있겠지만 어쨌든 트랜스포 아키텍처 기반으로 한 알고리즘 공개되어 있기 때문에 그럼 접근해 볼 수 있는 건 인프라랑 데이터인데 어 인프라는 이제 플랫폼에 가까운 형태인데 플랫폼에서 좀 더 밑단 뭐 GPU라든지 어 플랫폼도 포함해서 인프라스트럭처라고 보통 하 하고 있고 &gt;&gt; 음 &gt;&gt; 그런데 이제 데이터 쪽은 어 모델 아주 모델은 아니지만 모델러 가시기에 아주 적절한 어 패스라고 생각이 들어요. 모델 성능은 결국에는 알고리즘 공개 어 인프라스트럭처는 기술적인 면이 있지만 인프라스트럭처의 목적은 결국 성능과 돈이거든요. 비용. 네. 그렇기 때문에 데이터 쪽으로 가시면은 모델 성능에 가까우시면서 가장 기어를 처음에 쉽게 어프로치 하실 수 있는 부분이라고 생각이 들어요. 네. 그 실제 연구자분들도 데이터 스크래핑하고 데이터 전 처리하고 처리하고이 모델의 성능을 올릴 수 있는 데이터의 종류를 탐색하고 리서치하고 이런데 시간을 굉장히 많이 들으시거든요. 네. 그렇기 때문에 그쪽을 추천을 드립니다. &gt;&gt; 감사합니다. 완전히 그 교과서 같은 답변을 말씀해주셔 가지고 아 저도 거의 100% 공감했던 거 같아요. 그 어 이런 질문이 맞을지 모르겠는데 솔직히 저희가 그니까 어떤 분들 같은 경우에는 인프라 그다음에 모델러 레그 개발자 어 이걸 다 경험해 보지 않으면 어 어떤게 나한테 적성에 맞는지 좀 알기가 어렵잖아요. 그래서 조금 더 현실적으로 어떤 직업부터 먼저 접근해 보는게 조금 시작에서는 좋다. 뭐 요런 것들도 좀 있을까요? 왜냐면 그 그게 다 경험해 보고 이제 판단되기가 워낙 어렵다 보니까 좀 결정을 어 결정에 도움을 줄 수 있는 방법 그런 것들이 있을까요? 음. &gt;&gt; 일단 학생분들이라고 가정하거나 현업분들이라고 가정을 하면 &gt;&gt; 일단 백엔드 개발이 가장 익숙하실 거 같기는 해요. 왜냐면은 어 플랫폼 쪽은 어느 정도 들어가면 이제 인프라 OS와 네트워크와 인프라에 접점이 있거든요. 근데 그런 부분들은 어 좀 처음에 낯선 단어들이 많기 때문에 접근하기가 어려우신 분들이 많고 시스템 엔지어를 목표로 하시는 분들이 오히려 어 접근하기 쉬운 영역이어서 저는 태지 님의 영상을 보고서 어 메디오를 [웃음] 펑션 같은 거 요즘에 MCP도 같다고 하니까 이제 그런 거를 통해 가지고 에이전틱한 동작을 구현하는 데에 먼저 백핸드 개발자로서 어프로치를 해 보시는 거를 를 추천을 드려요. 그래갖고 그쪽에 먼저 만나를 탐색을 해 보시고 그다음에 데이터 그다음에 플랫폼이 맞지 않나? 근데 아 처음부터 인프라에 관심이 있다 하면 처음부터 인프라를 하시는데 일반적으로 그냥 개발자라고 하시는 분들은 그 정도 순으로 탐방을 해 보시는게 저는 좋다고 생각하고 그리고 백핸드 개발자로서 에이전트 기술에 대해서 경험을 해 보는게 중요하다고 생각하는게 지금은 에이전트라고 하는게 뭐 어떤 특정 AI 신규 기술의 영역으로 나와 있지만 저는 사실은 이제 이거는 그냥 커먼한 기술이 될 거라고 보거든요. 누구나 다 에이전틱한 처리를 할 수 있는 백엔드 개발자가 돼야 된다고 저는 생각을 해요. &gt;&gt; 이전에는 어 영 알고리즘에 의해서 코드로 처리하는 거는 명확한 것들 인풋이 명확하고 아웃풋이 명확한 것들은 코드로 처리하는데 비정형이라든지 인풋과 아웃풋이 명확하지 않은 것들은 모델로 처리하게 될 거거든요. 그럼 그럴 때의 모델을 똑똑하 모델을 이용해서 똑똑하게 처리하는 방법이 저는 이제 에이전틱이라고 어 생각이 들고 그렇기 때문에 결국에 궁극적으로 모든 개발자들이 양쪽 다 코드로 처리해서 알고리즘으로 처리하는 부분 코드나 알고리즘으로 처리가 안 되는 건 에이전틱한 방법으로 처리하는 것들을 다 알고 있는게 이제 기본 소양이 되지 않을까라는 생각입니다. &gt;&gt; 아 너무 또 공감이 됩니다. 예. 저도 100% 공감이 되는 부분이에요. 요즘에 뭐 예전에 그런 말들까지 있는 거 같아요. 예전에 웹 시대 API였다면 요즘에는 어 에이전트 시대는 MCP다 뭐 이런 말이 있을 정도로 뭐 MCP MCP A2A 뭐 이런 것들 나오는 것들이 다 통신하는 방식이 바뀌게 되고 또 저희가 인프라 설계할 때도 사실 저희가 웹사이트에서도 뭐 로그인 버튼 눌렀다 그럼 리스판스 바로 와야지 정상인데 LRM은 답변까지 뭐 30초 이렇게 잡고 있으니까 &gt;&gt; 아 진짜 완전히 패러다임도 바뀌게 되는 거 같고 그렇습니다. 그래서 말씀해 주신 내용 너무 공감이 되고 좋 너무 주옥 같은 어 조언 해 주셔서 감사합니다. 마지막으로 남규님께 또 여쭤보고 싶은 거는 책에 뭐 담았든 담았지 않든 어 뭐 하시고 싶은 말씀 있으세요? 여기 책에 담지 못했다 하는 내용들이 혹시 있으실까요?네 네. 일단은 최근에 제가 그 11월 그 29일까지 현재 직장 아ICN이라는 이제 뭐죠? 콜 인프라하고 그다음에 AI 컨택 센터 중심의 모든 라이 라인업을 개발을 하는 회사예요. 그래서 여기에서 이제 제가 책보드 엔진하고 콜보드 엔진하고 R를 만들었고 어 이렇게 하면서 이제 회사가 정말에 컨택 센터로서는 모든 라인업을 그러니까 이렇게 작은 회사가 이렇게 모든 라인업을 갖추기가 쉽지 않거든요. 그래서 이곳에서 저와 회사가 이제 모두 또 성장을 하는 것들을 경험을 했고 그러면서 이제 제 저 또한 조금 더 더 성장이나 큰 곳에서 이제 경험을 하고 싶은 어 생각이 들었어요. 그래서 지금 6년 차거든요. 전체로는 25년 차고 이제 그렇게 하면서 이제 요번에 일을 구하는데 어 50대 확실히 40대 중반 후반 때보다 50대가 훨씬 어렵더라고요. 게다가 요즘에 이제음 경기가 좋지 않잖아요. 경기가 좋지 않고 그다음에 AI만으로 하는 포지션이 그렇게 생각보다 많지 않거든요. 그래서 일 구하기가 어 쉽지 않지만 어쨌든 이제 어 새로운 그 이제 제조 중심의 쪽으로 일을 시작을 하게 됐어요. 네. 그래서 어 이걸 구하면서 어 일단은 그런 것들은 노력을 하고 그다음에 아까도 잠깐 얘기했을지 모르겠지만은 시니어들이나 이런 분들 아니면 AI를 하려고 하는 분들이 그러니까 비전공자면 저는 부트 캠프를 좀 추천을 드리고요. 왜 코딩이나 이런 것들을 정말 숙달를 해야 비전공자들은 이제 완전 리서처나 이런 쪽으로 갈게 아니면 코딩은 정말 숙달를 해야 된다고 저는 생각을 하고요. 그래서 비전공자들은 부트 캠프를 무조건 가는게 좋다라는 주의고 요즘에 제직자이면서 야간해 하는 것도 있습니다. 그래서 제가 코딩 뭐야 그런 이제 멘토링 같은 것도 하고 있거든요. 그래서 이제 그런 것들이 좋고 전공자 이미 이제 자바 개발이나 이런 것들을 하셨던 분들이라면 어 그냥 간단하게 lm API 호출해서 내가 만든 서비스가 AI를 붙여서 조금 더 풍성해지고 뭔가 매력적인 서비스로 된다면 뭐 그것만으로도 충분히 좋은 시작이라고 저는 생각을 합니다. 그래서 어렵게 접근할 것이 아니고 내가 이제 처한 상황에 맞게 어 가급적이면 어 석사 전공을 할수록 AI 업계에서는 당연히 좋고 이제 그게 여건이 안 된다면 뭐 LM이나 이런 것들을 호출을 해서 내 서비스를 더 어 풍성하게 하는 요런 것들을 하시면 어 좀음 그 이직이나 아니면 새로운 AI 쪽으로 오는 도움이 될 거라고 생각을 하고요. 무엇보다도 일단은 지금 이제 눈높이가 많이 높아졌기 때문에 어 신입이 정말 회사에서 뭔가 경험을 프로젝트 경험을 하는 것이 아니고 이미 프로젝트를 어 경험을 한 사람을 뽑는 그런 눈높이로 옮겨져 왔습니다. 그래서 그런 것들이 혼자 하기가 어렵다면 그런 부트캠프나 이런 것들 정말 활용을 하면 충분히 좋다고 생각하고 부트캠프의 그런 대신 프로젝트에만 의존하지 말고 자기만의 포트폴리오를 어 미리 이제 따로 준비를 해서 내가 처음부터 끝까지 돌아가는 이런 것들을 이해를 하면 어 나름대로 어떤 경쟁력이 있지 않을까 그렇게 생각을 합니다. &gt;&gt; 감사합니다. 아, 이게 또 조언까지 이렇게 말씀해 주셨고 또 실제로 이게 좋은 또 지금 현 앞으로 이직하신다고 하셨지만 그 이루셨던 것들이 또 많았고 저는 저희도 회사 규모가 작지만 여기 작은 데서 근무하는 거에 또 가장 큰 장점 중에 하나가 내가 혼자서 처음부터 끝까지 다 한다. 다해보면서 확실히 나 개인으로 봤을 때는 또 성장할 수 있는 기회가 있는 거 같고요. 그런 것들을 몸소 느끼고 그런 점들을 말씀해 주신 거 같습니다. 아, 제가 여기서 하나 자랑 비슷하게 한다면 &gt;&gt; 어떻게 보면은 저는 항상 이직을 할 때 제가 나가면 아, 우리 회사가 잘 굴러갈까? 이런 걱정을 하는데 항상 제가 나가면 회사가 상장을 한다든지 제 나가고서 두 기업이 상장을 한 경우 있거든요. 앵크리어 글로벌, YG. &gt;&gt; 게이트 안 좋. &gt;&gt; 그럼 그럼 남교님이 빨리 나가 줘야 된다고 회사가 생각하지 않을까? 아 대신 아 대신 저가 나가면서 어 제 빈자리를 위해 세 명을 뽑았 뽑뽑았습니다. 그래서 일자리 창출도 제가 세 명이나 어 저희 회사가 한 40명 50명 규모거든요. 거기서 AI 개발자 세 명을 뽑는다는 거는 &gt;&gt; 네, &gt;&gt; 엄청난 제가 저의 빈자리가 그만큼 크면서 회사에서도 그걸 커버하고 또 더 확장해서 더 많은 일을 &gt;&gt; 하려고 하는 그런 것들이 있기 때문에 &gt;&gt; 저도 민이고 회사도 &gt;&gt; 앞으로 잘 될 거라고 생각을 하고 있습니다. &gt;&gt; 음. 또 더 쿵 꿈을 펼치시기 위해서 어 또 이직을 하시는군요. 그 나가고 나서 상장 또 하면 어떡하죠? 네. [웃음] &gt;&gt; 어 이제 마침 제가 가는 곳이 상장을 또 준비를 좀 하고 싶어 하는 준경 기업입니다. &gt;&gt; 아 예. HN라고 이제 현대 중공업이나 한라 그룹의을 이제 주고액사라는 약간 제조 중심 쪽 회사거든요. 그래서 제가 거기서 AI 기술 리딩이나 이런 것들을 좀 주로 할 것 같습니다. 그래서 거기서 나름대로 어떤 직원들의 역량들을 함께 키우고 그다음에 또 회사에서 꿈꾸는 그런 상장에도 또 기여하면 저도 어 또 회사를 또 성장하는 거를 또 같이 경험할 수 있지 않을까 기대하고 있습니다. &gt;&gt; 아 너무 좋습니다. 어 지금 가셔 가지고 또 새로운 곳에서 또 잘 어 프로젝트 리딩 해 주셔 가지고 좋은 결과로 이어졌으면 좋겠습니다. 예네 &gt;&gt; 알겠습니다. 오늘 요렇게 얘기하다 보니까 벌써 2두시간이 넘었는데요. 어, 어떠셨어요? 오늘 시간 빨리 가시죠? 생각보다 두시간. [웃음] &gt;&gt; 네. 아, 네. &gt;&gt; 네. 이게 이게 원래 연사님들이 처음에 나오셔서 아 나는 할 얘기가 없어서 30분에서 한시간밖에 못 할 것 같다라고 말씀을 하시는데 또 막상 이게 긴장도 풀리고 그동안 못 해 왔던 얘기들 이렇게 딱 풀리면은 어 이렇게 말씀드 너무 잘해 주시더라고요. 그러다 보니까 이제 두 시간이 또 넘어갔는데 오늘 어 이렇게 또 바쁘신 분들이신데 이렇게 어 여기 나와 주셔 가지고 진심으로 저 개인적으로 감사하다 말씀드리고요. 또 이게 또 영상으로 남는데 이걸 보신 분들이 꽤 많으세요. 그래서 그 분들이 그분들은 또 미리 갔던 선배님들의 어떤 조언이니까 그런 어 진짜 현실적인 조언들 바탕으로 아마 성장하는데 큰 도움이 되지 않을까 싶습니다. 그래서 저도 오랜만에 또 이렇게 또 여기 다 선배님들이 와 계시는데 저도 많이 배울 수 있는 큰 계기가 되어서 너무 반가웠고요. 앞으로도 또 종종 인사드리면서 또 많이 배울 수 있었으면 좋겠습니다. 정말 마지막으로 제가 항상 끝 인사를 하기 전에 그 오늘 라이브 어떠셨는지 이거는 그냥 책이랑 상관없습니다. 이게 짧게 소감을 어 남규 님부터 먼저 하겠습니다. 예. 오늘 라이브 어떠셨어요? 어, 일단은 저도 아까 말씀하신 것처럼 어, 되게 뭐 이렇게 할 말이 없거나 어떻게 해야 될지 잘 모르겠다는 약간 두려움이 있었거든요. 근데 또 태님이 또 워낙 진행을 잘 해 주시고 우리 성님하고 그 저 뭐야 &gt;&gt; 그네 &gt;&gt; 그 뭐야 갑자기 아 [웃음] 서형님 홍석형님 &gt;&gt; 많이 서운해 하시겠는데요 &gt;&gt; 예습니다 &gt;&gt; 몇 개월 동안 이름을 계속 봤는데 까먹었어 [웃음] 그래서 다 같이 말씀을 너무 잘 해 주셔 가지고 굉장히 풍성한 오늘 또 어 시간이었던 거 같습니다. 알겠습니다. 감사합니다. 어, 소경님 오늘 어떠셨습니까? &gt;&gt; 네. 아까 테드 님 소개신해 주신 것처럼 진짜 나한 30분밖에 못 말할 것 같다고 [웃음] 생각했는데 벌써 두시간 10분이 넘어왔고 아 진짜 시간이 빨리 가는구나 [웃음] 생각을 했고요. 네. 아까 말씀드리지 못했 부분이 하나 있는데 이제 저는 채용 공고를 홍보 [웃음] 목적도 있기 때문에 &gt;&gt; 아 그러시군요. 루니 아 예 &gt;&gt; 제가 시간 드려야죠. 예. &gt;&gt; 아, 네. 감사합니다. 네. 네. 저 제가 일하고 있는 의료 AI 어, 기업, 글로벌 의료 AI를 비즈니스를 하고 있는 기업인 루닛이라는 회사고요. 어, 국내에서 AI 회사로서 1세대 첫 번째 AI로 창업한 회사고요. 어, 저희 회사에서 데보스 엔지니어랑 어, 풀스택 그 플랫폼 엔지니어를 채용을 하고 있습니다. &gt;&gt; 관심이 있으시면. [웃음] &gt;&gt; 네. 그 연사 소개란에 있는 연락처로 연락을 주시거나 아니면 저희 회사 홈페이지에 다음 주쯤에 어 방문 해 보시면 체험 공고가 올라와 있을 것입니다. 지원을 하셔서 함께이 버티컬 AI를 국내에서 어 글로벌 시장에 도전할 수 있는 기회이기 때문에 어 함께 하실 분들 계시면 관심 있으시면 한번 지원해 주시면 감사하겠습니다. &gt;&gt; 아 그럼 석영님과 같이 일할 수 있는 기회가 생기는 건가요? 아, 네. 네, 맞습니다. &gt;&gt; 아, 예. 원들의 한 20% 정도는 외국인 분들이 있으셔서 &gt;&gt; 어 외국인 분들과 함께 자연스럽게 영어를 사용하면서 일할 수 있는 업무환경 &gt;&gt; 해서 영어를 수 있습니다. &gt;&gt; 아 여기 풀스택 신입도 뽑나고 어 질문이 왔는데 신입도 뽑으세요. 아, 이번에는 신입 채용은 또 아니긴 해서 [웃음] 하지만 영어가 아주 익숙하시고 영량과 어떤 의지가 있으시면은 &gt;&gt; 예. &gt;&gt; 가능하십니다. &gt;&gt; 예. 아, 좋습니다. 아, [웃음] 감사합니다. 어, 성원 님 마지막으로 예, 오늘 라이브 어떠셨는지 서만디 부탁드리겠습니다. 예, 딴 거보다도 사실 이제 같은 책을 쓴 공동자분들인데 두 분은 그나마 이제 좀 개인적으로 조금 안면이 있는데 나머지 분들은 그런게 없었는데 그래도 이제 이중에 나머지 두 분을 나이지만 이렇게 만날 수 있어서 너무 좋았고 어 그러니까 사실 이런게 하면 너무 좋은게 제가 잘 모르는 분야에 또 하시는 분들을 만나면 굉장히 많이 배우게 돼요. 그 조금 이거 이렇게 재밌게 하고 나서 보니까 아쉬운게 여섯 명이 다 나왔으면 얼마나 재밌을까? 아, &gt;&gt; 그러니까요. &gt;&gt; 아이, 참. &gt;&gt; 예. 그 아, 저는 사실 이제 뭐 이렇게 편집된 거는 나가 본 적에서도 이렇게 완전히 생 라이브는 처음이라서 어, 조금 긴장하긴 했는데 어, 라이브에 묘미가 있네. 그래서 앞으로 &gt;&gt; 긴장이 전혀 느껴지지 않았습니다. [웃음] &gt;&gt; 겉보기랑 다르게. &gt;&gt; 네. &gt;&gt; 예. 아, 저 사실 이제 뭐 하고 싶은 얘기나 풀 풀고 싶은 얘기는 되게 많긴 한데 또 이제 어, 요런 비슷한 또 기회가 있으면 또 이제 적극적으로도 놨으면 좋지 않을까 싶. &gt;&gt; 아, 예. 알겠습니다. 제가 또 다음에 또 다른 저자분들이랑 해 가지고 한번 또 자리 한번 마련하도록 하겠습니다. &gt;&gt; 네네. 아무튼 좋은 기회 해 주셔서 감사드립니다. &gt;&gt; 아유, 저야말로 이렇게 나와 주셔서 너무 감사드리죠. 예. 아, 알겠습니다. 아, 오늘 이렇게 세 분 늦은 시간까지 고생해 주셔서 너무 감사드리고요. 오늘 함께 해 주신 구독자분들도 어, 감사합니다. 오늘, 오늘 그 누리오 누리오 발사가 있었나 봐요. 예. &gt;&gt; 어허. &gt;&gt; 저희 라이브 도중에 있었나 봐요. [웃음] 어쨌든지 좀 그렇게 됐는데 아무튼 어, 함께 해주신 분들 너무 감사드리고요. 그 오늘 라이브는 여기까지 하도록 하겠습니다. &gt;&gt; 아, 저도 하나하예. 아까 그 LLM R시는 분이 계셨는데요. 일단은 그 뭐야 카카오톡 단톡방에서 LRM RA를 검색하면 제일 인원 많은 단톡방 찾으면 되고요. 그다음에 유튜브에서도 LLM RAG DV라고 영어로 치시면 나옵니다. &gt;&gt; 아 그렇군요. 예 그래서 카톡방에 그렇게 검색을 해 주시면 되겠습니다. 아 0시 55분 예정이라고 하네요. 예 알겠습니다. 감사합니다. 오늘 그러면 라이브 여기까지 하도록 하겠고요. 다들 좋은 밤 되시고 오늘 감사했습니다. 감사합니다. 라이브 여기까지 하도록 하겠습니다. 감사합니다.네 감사합니다. 네 &gt;&gt; 감사합니다. 감사합니다.&lt;/raw&gt;&lt;/document&gt;',
 '&lt;document&gt;&lt;title&gt;#LangGraph 개념 완전 정복 몰아보기(3시간) - YouTube&lt;/title&gt;&lt;url&gt;https://www.youtube.com/watch?v=W_uwR_yx4-c&lt;/url&gt;&lt;content&gt;# 🔥 #LangGraph 개념 완전 정복 몰아보기(3시간) 🔥\\n## 테디노트 TeddyNote\\n50200 subscribers\\n976 likes\\n\\n### Description\\n113091 views\\nPosted: 30 Apr 2025\\n패스트캠퍼스에서 테디노트 구독자 분들을 위하여 선물을 준비해 주셨습니다!\\n무려 3시간에 육박하는 편집을 해주셔서 \\"LangGraph 개념 완전 정복\\" 몰아보기 강의를 편집해 주셨습니다.\\n편집을 지원해 주시고, 강의 영상 공개도 허락해 주신 패스트캠퍼스 관계자 분들께 정말 감사드립니다.\\n\\n이 영상이 LangGraph 를 시작하시려는 분들께 좋은 시작점이 되었으면 좋겠습니다!\\n\\n✅ 소스코드 링크: \\n\\n전체 강의를 수강하고 싶으신 분들은 아래 할인코드로 할인 받아 결재하세요!\\n✅ 20% 할인 쿠폰 코드\\n- 할인코드: 테디노트RAG\\n- 강의링크: \\n- 쿠폰코드 사용방법: 강의 수강신청 → 쿠폰 선택 창에 쿠폰코드 입력 → 쿠폰 등록 [...] ✅ 타임라인\\n00:00 LangGraph 개요\\n21:29 LangGraph 세부 기능(State, Node, Edge, Conditional Edge, Compile)\\n46:56 LangGraph 로 자유롭게 그래프 로직 구성(흐름 엔지니어링)\\n1:10:30 Naive RAG(전통적인 방식의 RAG) 를 LangGraph 로 구현\\n1:31:43 답변의 할루시네이션 관련성 평가 모듈 추가\\n1:43:28 웹 검색 노드 추가\\n1:51:37 쿼리 재작성 모듈 추가\\n2:00:55  [프로젝트] Agentic RAG - 에이전트를 활용한 RAG\\n2:24:50  [프로젝트] Adaptive RAG\\n\\n#agent #rag \\n\\n📍 \\"테디노트의 RAG 비법노트\\" 랭체인 강의: \\n📘 랭체인 한국어 튜토리얼(무료 전자책): \\n📝 테디노트(깃헙 블로그) : \\n💻 GitHub 소스코드 저장소: [...] 리라이트하고 에이전트하고 리라이트하고 에이전트하고 이걸 뺑글뺑글 도는데 우리가 우리가이 관련성 체크 로직이 계속 녹았니까 얘도 이제 재기에 빠지는 것을 볼 수가 있고 최종적으로 그래프 리콜션 에러에서 10 리미트에 도달한 것을 볼 수가 있죠. 그러니까 이게 재기에 빠지는 거는 뭐냐면요. 우리가 아까 그래프 흐름에서 자 보세요. 에이전트의 대한민국의 수도는 어디야? 그건 바로 답변했죠. 그다음에 PDF 리트버 도구를 써서 답변 찾을 수 있는 거는 요기죠. 요렇게 요렇게 지금 여기에서도 조건문이 하나 더 추가가 된 건데요. 요렇게 요렇게 요렇게 해서 최종 답변을 받는 거죠. 리칠브 하고 관련성 체크를 해서 통과를 했으니까 바로 제너레이트 해서 결과를 얻는 것을 볼 수가 있습니다. 자, 그래서 여기까지 했는데 했는데 마지막으로 나온게 지금 요거였었죠. 테디노트의 영체인 튜토리얼. 자, 얘는요. 우리가 이런 상황에 도달한 거죠. 어 얘는이 내용을 모르기 때문에 일단이이 경로로는 갈 수가 없어요. 그다음에 툴을 써야 된다라고 판단 내려서 툴를 썼습니다. 근데 문서 검색 결과에 당연히 트노트 관련된게 없으니까 페일이 났을 거거든요. 페일이 나면 얘 어때요? 리라이트를 하죠. 리라이트를 해서 다시 에이전트로 보낸단 말이에요. 그럼 에이전 다시 판단을 내해서 또 2를 써야 될지 말지를 계속 판단을 내려요. 근데 얘 같은 경우에는 어이 레버스가 노가 떴어요. 그러면은 에이전트로 다시 돌아왔잖아요. 그러면은 에이전트는요. 이게 관련성 체크 노가 됐으니까 다시금 어떻게 툴를 써야 될지 다 지금 프로세스로 들어가게 되는 거예요.&lt;/content&gt;&lt;raw&gt;# 🔥 #LangGraph 개념 완전 정복 몰아보기(3시간) 🔥\n## 테디노트 TeddyNote\n50200 subscribers\n976 likes\n\n### Description\n113091 views\nPosted: 30 Apr 2025\n패스트캠퍼스에서 테디노트 구독자 분들을 위하여 선물을 준비해 주셨습니다!\n무려 3시간에 육박하는 편집을 해주셔서 "LangGraph 개념 완전 정복" 몰아보기 강의를 편집해 주셨습니다.\n편집을 지원해 주시고, 강의 영상 공개도 허락해 주신 패스트캠퍼스 관계자 분들께 정말 감사드립니다.\n\n이 영상이 LangGraph 를 시작하시려는 분들께 좋은 시작점이 되었으면 좋겠습니다!\n\n✅ 소스코드 링크: \nhttps://github.com/teddylee777/langchain-kr/tree/main/17-LangGraph/02-Structures\n\n전체 강의를 수강하고 싶으신 분들은 아래 할인코드로 할인 받아 결재하세요!\n✅ 20% 할인 쿠폰 코드\n- 할인코드: 테디노트RAG\n- 강의링크: https://buly.kr/Gvmu8DQ\n- 쿠폰코드 사용방법: 강의 수강신청 → 쿠폰 선택 창에 쿠폰코드 입력 → 쿠폰 등록\n\n✅ 타임라인\n00:00 LangGraph 개요\n21:29 LangGraph 세부 기능(State, Node, Edge, Conditional Edge, Compile)\n46:56 LangGraph 로 자유롭게 그래프 로직 구성(흐름 엔지니어링)\n1:10:30 Naive RAG(전통적인 방식의 RAG) 를 LangGraph 로 구현\n1:31:43 답변의 할루시네이션 관련성 평가 모듈 추가\n1:43:28 웹 검색 노드 추가\n1:51:37 쿼리 재작성 모듈 추가\n2:00:55  [프로젝트] Agentic RAG - 에이전트를 활용한 RAG\n2:24:50  [프로젝트] Adaptive RAG\n\n#agent #rag \n---\n📍 "테디노트의 RAG 비법노트" 랭체인 강의: https://fastcampus.co.kr/data_online_teddy\n📘 랭체인 한국어 튜토리얼(무료 전자책): https://wikidocs.net/book/14314\n📝 테디노트(깃헙 블로그) : https://teddylee777.github.io\n💻 GitHub 소스코드 저장소: https://github.com/teddylee777\n\n43 comments\n### Transcript:\n네, 여러분 안녕하세요. 드디어 랭그래프 시간입니다. 아, 여기까지 오늘 정말 고생 많으셨고요. 아마이 랭그래프 영상을 처음 보시는 분들도 계시겠죠? 어,이 랭그래프 영상을 사실 제가 유튜브에 먼저 올렸고요.이 랭그래프에 대한 설명 영상인데 그때와 조금 자료를 보충해서 이제 설명드리려고 합니다. 어, 랭그래프라는 거는 저희가 왜 필요한가 요거는 차차 말씀드리기로 할 건데요. 먼저 여러분들이 래그를 하면서 가지고 계신 많은 고민들이 있을 거예요. 그 고민들을 어느 정도 해결해 줄 수 있는게 바로이 랭그래프이기 때문에 제가 최근에는이 랭그래프에 대한 중요성을 많이 강조드리고 있어요. 실제로 커뮤니티에 보면은 해외 커뮤니티에서이 랭그래프에 대한 인기를 실감할 수가 있는데요.이 랭체인에 대해서는 사실 호불로가 조금 있습니다. 아무래도 우리가 쉽게 쓸 수 있지만 커스터마이제이션이 좀 완전하진 않아서 그 부분 때문에 약간의 호브로가 있었다면요.이 랭그래프라는 거는 꼭 랭체인을 쓰지 않아도 그래프 형식으로 흐름을 잡아주는 굉장히 유용한 프레임키이기 때문에 인기가 굉장히 많은 편이라고 보시면 돼요. 그래서 여러분들이 만약에 이전 영상을 꼼꼼히 보지 않으셨더라도이 랭그래프 영상만큼은 꼭 꼼꼼히 보셨으면 좋겠습니다. 그래서 제가 이번에 자료도 정말 열심히 준비를 했거든요. 게다가 요즘에 제가 대회 활동할 때이 모듈딜러 레그에 대한 강조를 강조를 또 하고 있습니다. 그런데이 모듈러 레그를 가는 그 도구가 필요할 텐데 그 도구가 바로이 랭그래프라고 보시면 돼요. 자, 그러면 바로 한번 들어가 보도록 하겠는데요.이 이 랭그래프의 탄생 배경부터 먼저 살펴보도록 하겠습니다. 제가 항상 강의 때 강조드리는게 뭐냐면 Y라는 측면이에요.이 Y이 랭그래프라는게 도대체 왜 나왔는가 거기에 우리가 어 다시 한번 좀 빠져들어서 살펴볼 필요가 있는데요. 어 사실 기술의 발전이라는 거는 어떤 갈증으로부터 시작이 됩니다. 내가 이런 것들을 하고 싶은데 뭔가 불편하네. 그러면 이걸 또 타파할 수 있는 새로운 기술이 나오게 되는 거죠. 그래서이 랭그래프가 탄생을 했다라고 보시면 되겠는데요.이 배경에는이 레그라는 강력한 기능을 갖게 된 우리는 한 번쯤 다음과 같은 갈등을 마주하게 되는 거예요. 그래서 LM이 생성한 답변이 혹시 할루시네이션이 있지는 않을까 이런 불안함이 있으실 수도 있고요. 혹은 레그를 잘 적용했다라고는 하지만이 답변이 문서에는 없는 자기가 알고 있는 지식 속에서 답변을 하면 어쩌지?이 사전 지식으로 답변한 것 아닐까? 이런 것들이 궁금할 수도 있고요. 혹은 문서 검색에서 원하는 내용이 없을 경우에 인터넷 혹은 논문 부족한 검색을 보강을 해 가지고 지식 보강을 할 수 없을까? 이런 갈증이 있다라는 거죠. 자, 그래서 레그 개발 단계의 고민 사례를 보시면요. 일반 레그를 수행했을 때 우리는 다음과 같은 문제점을 어 봉착하게 됩니다. 어,이 생성 AI 가우스를 만든 회사의 2023년도 매출액을 알려줘라고 하는 건데요. 여기에 질문에 보시면은이 생성용 AI 가오스를 만든 회사는이 문서 내에 정보가 있었다라고 가정을 해 볼게요. 그래서 문서에 찾아봤더니 생성령 AI 가오스를 만든 회사는 삼성전자입니다라는 정보를 얘가 잘 찾아와서 어 답변을 하려고 했는데요. 그런데이 회사에 2023년도 매출액을 알려 줘라는 질문을 했기 때문에 결국에는 삼성전자의 2023년도 매출액을 알려 달라는 그런 질문이 되는 건데이 정보가 없다라는 거예요. 그래서 이런 고민이 많으시겠죠? 어 그래서 우리는 어떻게 변경을 할 수가 있냐면이 부족한 정보를 웹에서 검색을 해 가지고 문서에 추가하는 로직을 구현할 수가 있습니다. 그래서 요거를 이제 체인을 하나 더 만드는 거예요. 만들어서 생성 AI를 만든 회사는 삼성전자입니다. 하지만 매출액 정보는 문서에 나와 있지 않으니 여기에다가 체인을 덧대는 거죠. 그래서 인터넷 검색하는 체인을 덧해서 생성 AI 가우스를 만든 회사인 삼성전자의 2023년도 매출액을 검색해 줘라는 커리를 날리게 되는 거죠. 그렇게 날려 보니까 인터넷에서 검색을 해서 보니까 2023년도 매출액은 250조였다고 합니다. 결국에는이 답변이 완성이 되는 거예요. 생성령 AI 가우스를 만든 회사는 삼성전자이고이 삼성전자의 2023년도 매출액은 250도였습니다라고 답변을 주게 되는 거죠. 자, 그런데 만약에 검색 결과에 잘못된 정보가 포함되어 있을 수도 있잖아요. 그런 경우에는 어떨까요?이 생성령 AI 가우스를 만든 회사는 삼성전자인데 매출액 정보는 문서에 나와 있지 않아서 검색을 했어요. 검색을 했는데 얘가 인터넷 검색을 하다 보니까 부정확한 정보를 가지고 올 수도 있는 거죠. 그러다 보니까 갑자기 답변이 삼성 SDS의 매출액은 20조였습니다. 이렇게 생뚱맞은 답변으로 이어질 수도 있다라는 거예요. 그래서 결국에는 잘못된 검색 결과가 할루스네이션으로 이어질 수도 있고요. 그러다 보면은 굉장히 머릿속에 복잡해져요. 우리가 이거를 뭐 할루스네이션 체커를 둬 가지고 또 검증한 다음에 다시 검색을 하려고 하는데 체인이 막 덕지덕지 붙는다는 거죠. 그래서 결국에는 뭐냐면 우리가 못 하는 건 아니죠. 할 수는 있습니다. 할 수 있습니다만 구조 자체가 굉장히 덕지덕지 구조로 갈 수밖에 없는 거예요. 이게 안 되면 또 이걸 덧대고 이거 안 되면 또 덧대고 더고 이렇게 주렁주렁 가는 방식이 될 수밖에 없다라는 거예요. 그래서 결국에는 이렇게 보시면은 만들었습니다. 없습니다. 가면은 여기에 붓구 붙구 붙구 붙구 하다 보면은이 체인이 정말 끝없이 늘어날 수밖에 없고요. 더군다나 이렇게 늘어난다고 해서 답변이 잘 나오면 그나마 다행이라고 보여져요. 하지만 하지만 우리가 언제까지 이렇게 체인들을 막 덕지덕지 만들어 놓고 어 이게 잘 수행이 되겠지 그냥 마냥 기다릴 수는 없는 거죠. 그래서 우리가 중간중간에 여기에서 이미 답변이 잘 나왔으면 굳이 아래쪽까지 갈 필요 없이 여기서 끝내 주는 그런 로직도 필요할 수도 있고요. 그래서 이런 로직들이 계속 들어가다 보면은 우리 레그 파이프라인의 복잡도 자체가 굉장히 올라갈 수밖에 없는 겁니다. 자, 그래서 우리가이 컨벤셔널 레그, 전통적인 레그 혹은 나이브 레그라고 하죠. 이 나이브 레그의 가장 큰 문제점은 뭐냐면요.이 사전에 정의된 데이터 로더. 그다음에 고정된 청크의 사이즈 그다음에 퀄리 방법. 우리가 중간에 막 실행 단계에 바꿀 수가 없죠. 미리 한 번에 딱 셋업을 해 놓고 끝내 줘야 되는 거예요. 그다음에 신뢰하기 어려운 LLM. 그다음에 고정된 프럼프트. 문서와의 관련성 혹은 신뢰성. 요런 것들이 한 번에 잘해야지 좋은 답변이 나올까 말까 하는 거예요. 그래서 한마디로 우리가 이거를 뭐라고 얘기하냐면 단방향. 단방향의 파이프라인이다. 이렇게 얘기를 하거든요. 그래서 얘 다음에 얘, 얘 다음에 얘, 얘 다음에 얘이 단방향의 구조가 한 번에 우리는 잘해 내야 된다. 그래야지 우리가 좋은 답변 얻을 수 있다. 이런 어 문제점 아닌 문제점에 봉착할 수밖에 없는 거예요. 그래서 궁극적으로이 컨벤셔널 레그 어 나이브 레그 혹은 이전까지 보셨던 어벤스 레그의 구조는 어 단방향 구조이기 때문에 그러니까 뒤로 빠꾸가 안 된다는 거예요. 갔다가 어 이거 별로였네. 다시 돌아와서 수정해서 가는 거. 이런 것들이 전혀 안 되기 때문에 우리가 모든 단계를 한 번에 잘할 수밖에 없는 거죠. 근데 이게 한 번에 잘 되면 다행인데 보통은 잘 안 된다라는 거예요. 그래서 여러분들이 혹시 회사 생활을 하실 때도 어 보고서 작성을 할 때 우리가 팀장님께 보고서를 가지고 갔어요. 그래서 피드백을 받고 수정을 하고 다시 가고 피드백 받고 다시 가고 이렇게 왔다 갔다 하다 보면은 보고서가 결국에는 원하는 방향성대로 나오잖아요. 근데 우리는 지금 처한 상황이 어떤 상황이냐면 한 번에 제출을 잘해서 한 번에 통과를 해야 되는 그런 상황이라고 볼 수가 있습니다. 자, 그래서 여기서 제한된 아이디어가 바로 랭그래프라는 거예요. 각각의 세부 과정들을 우리는 이제 노드라고 부르기로 했어요. 그래서 여기에 있는 로더 노드, 스플릿 노드, 인베딩을 도와주는 노드, 그다음에 저장을 해 주는 노드, 그다음에 질문이 들어오면 검색을 해 주는 노드, 프롬프트 노드도 있고요. 뭐 LM 엔서 이런 것들을 다 노드로 세분화시킬 수가 있는 거예요. 그래서 각각의 역할 하나하나마다 노드라고 정의를 하고요. 그다음에 어떤 노드에서 어떤 노드로 갈지 그 연결짓는이 부분을 우리가 뭐라고 하냐면 바로 엣지라고 부르는 거예요. 그래서 이전 노드에서 다음 노드로 연결하는 거를 우리는 엣지라는 걸 통해서 연결을 해 줄 거고요. 그다음에 중간에 보면은 조건부 엣지를 넣을 수가 있어요. 아, 이건 정말 좋죠. 우리에게 꼭 필요한 거였어요. 그래서 우리가 중간에 파이프라인을 하다가 분기를 태우고 싶을 경우가 있어요. 우리가 대체적으로 많이 제가 말씀드렸던 예시 중에 하나가 추상화된 답변이 있고 답변을 요청할 때가 있고 좀 구체적인 답변을 요청할 때가 있어요. 이러면 우리가 체인을 나누어서 처리하는 방법이 있을 수 있거든요. 이때 우리가 라우팅이라는 기법을 쓰는데 라우팅도 구현하기가 너무 어렵죠. 이럴 때에는 우리가 조건부 엣지를 둬 가지고 어 이게 추상화된 답변을 요구하는 거야. 그럼 추상화된 노드로 보내고 어 이거 구체적인 답변을 원하는 거야. 그러면 구체화된 답변을 생성해내는 노드로 보내 줄 수가 있어요. 이렇게 조건부 엣지를 둘 수가 있는데 조건부 엣지 같은 경우에는 두 갈래뿐만 아니라 세 갈래,네 갈래 이렇게도 분기 처리를 할 수가 있습니다. 자, 그래서 랭그래프를 쓰면은 우리 구조가 어떻게 바뀌는지 좀 더 소개를 해 드릴게요. 원래 질문이 들어오고 우리는 문서 검색을 한 다음에 검색된 문서를 LRM에 줘서 답변 생성을 하고요. 최종 답변까지 연결을 짓게 되는데요. 우리가 이거 하나하나를 전부 다 노드로 만들기로 했었죠. 그리고 노드와 노드는 이렇게 엣지로 연결을 짓는 거고요. 그런데 엣지로 이제 우리가 흐름이라는 걸 만들 거예요. 흐름을 만들 건데 여러분들께서 플로우 엔지니어링이라는 거를 하실 겁니다. 그래서이 플로우 엔지니어링이라는 건 뭐냐면 우리가 기존에 딱 정해진 단방향의 구조가 아니라 노드들을 이렇게 펼쳐 놓고요.요 단계 다음에는 여기로 가.요 단계 다음에는 여기나 여기로 가. 요런 것들을 여러분들 여러분들이 굉장히 쉽게 흐름을 짜실 수가 있어요.이 엣지 구성을 통해서요. 그래서이 첫 번째 제한된 예시를 보시면은 질문이 들어오죠. 그다음에 문서 검색을 합니다. 검색을 하면 바로 답변 생성을 하러 가는게 아니라 평가자한테 검색된 문서의 내용과 질문의 내용을 같이 주는 거예요. 그래서 평가자로 하여금이 내용에 대해서 관련성 평가를 수행하게끔 요청을 하는 거죠. 평가자가 봤더니 질문과 문서, 검색된 문서가 어, 관련성이 있어요. 그럼 패스했으니까 바로 답변 생성하러 갑니다. 그러면 아무래도 할루스네이션이 나올 가능성이 많이 줄어들겠죠? 자, 그런데 질문과 문 검색된 문서가 있어요.이 같이 이제 넣으려고 평가자한테 저어봤더니 평가자가 보니까 어,이 질문에 답변하기 위한 내용이 검색된 문서에 없어요. 그러면이 패스를 안 주고 페일을 준 다음에요. 그다음에 쿼리 제작성을 요청을 하는 거예요. 왜냐면은 이제 쿼리가 동일하면 결국에는 검색된 문서도 동일할 거잖아요. 그래서 쿼리를 한번 바꿔 보는 거예요. 그래서 제작성을 한 다음에 다시 질문을 하는 거예요. 질문을 하고 문서 검색으로 하면 우리가 문서 검색할 때 들어가는 퀄리가 달라졌으니까 검색된 문서도 달라지게 되겠죠. 그다음에 이제 원래 있던 질문이랑 관련성 평가를 하고 여기에다가 이제 뺑글뺑글뺑글 돌릴 수가 있는 거예요. 이런 흐름을 만들 수가 있고요. 자, 그다음에 추가 검색기를 통해서 우리가 문맥을 보강을 할 수가 있는데요. 어, 질문이 들어오죠. 그다음에 문서 검색을 합니다. 그다음에 답변 생성까지 했어요. 답변 생성까지 한 다음에 이번에는이 생성된 답변과 질문간에 어떤 할루스네이션 체크를 하는 거예요. 혹은 검색된 문서와의 체크를 할 수가 있고요. 릴러스 체크를 할 수가 있고요. 그래서 관련성 평가를 요청을 합니다. 요청을 했더니 평가자가 딱 봤더니 어 이거 보니까 검색된 문서 안에 정보가 없네.이 삼성전자의 매출액 정보가 문서 안에 없잖아. 그러면 외 검색으로 가세요. 그래서 외 검색을 수행한 다음에 어이 삼성전자 매출에 대한 내용을 검색을 한 다음에 그 내용을 보강을 해 주는 거예요. 보강을 해서 보강된 문서 검색 문서를 가지고 답변 생성을 할 수가 있고요. 또는 이럴 수도 있죠. 평가자가 봤더니 아 이거는 질문이 너무 성의가 없다. 너무 단초하네. 이러면은 쿼리 제작성을 요청해서 다시 질문해서 다시 문서 검색을 유도할 수가 있는 거예요. 혹은 내가 살펴봤더니 어 이거는 명쾌하네 하면은 패스를 주고 바로 답변 생성하러 갈 수도 있고요. 요런 식의 흐름도 구성이 가능하고요. 또 좀 더 복잡하게 가자면 이런 것들도 가능하죠. 질문이 들어와요. 그다음에 문서 검색을 했습니다. 그다음에 평가자한테 줘요. 그래서 평가자가 아, 이거는 외 검색을 통해서 문서를 좀 보강해야겠습니다. 요런 것들도 가능하고 아, 이거는 쿼리를 재작성을 해야겠어요. 다시 돌아가세요. 이렇게도 가능하고요. 혹은 평가자가 이번에는 패스를 줬어요. 그래서 다음 단계로 넘어갔는데 답변 생성을 했는데 답변이 마음에 들지 않아 그러면은 왜 마음에 들지 않을까? 이걸 다시 본 다음에 웹 검색으로 보낼 수도 있고 쿼리 제작성을 보내던가 만약에 통과를 했다면 이제 패스를 했으면 최종 답변으로 하러 가게끔 이렇게 평가자를 두 개 이상 노드로 구성을 해서 만드는 것도 가능하죠. 지금 여기에서 제가 랭그래프의 몇 가지 예시를 보여 드렸는데요. 지금 위에 방식이랑 아래 방식이랑 보시면 어떤가요? 굉장히 다이나믹하다는 것을 알 수가 있어요. 여기에서는 얘가 얘로 갔으면 얘 역할 끝나거든요. 다시 돌아올 일이 없어요. 그래서 우리가 한 번에 잘했어야 됐죠. 하지만요 밑에처럼 구성을 하면요. 꼭 한 번에 잘하지 않더라도 얘가 뺑글뺑글 돌면서 좀 정보들을 보강을 하거나 다 좋은 답변을 만들어 내기 위한 과정을 좀 더 어 사이클리컬하게 돌아가면서 구성을 할 수가 있다라는 거예요. 그래서이 랭그래프의 어떤 다이나믹한 특성 때문에 우리가 플로우 엔지니어링을 통해서이 레그의 파이프라인을 좀 더 정교하게 만들어 낼 수가 있다. 이렇게 말씀드릴 수가 있습니다. 자, 그래서 랭그래프로 구현한 예시를 보시면요. 우리가 이렇게 흐름을 만들 수가 있어요. 아까와 같은 예제인데 생성형 AI 가우스를 만든 회사에 2023년도 매출액을 알려줘. 이거를 전달을 하죠. 그래서 문서 검색을 합니다. 어 그런데 생성용 AI 가우스는 삼성전자가 만들었다는 정보는 알겠어요. 그런데 매출액 정보가 없네. 그러면 추가 정보가 필요합니까?요 분기 노드를 태우는 거예요. 그래서 필요하면은 예쓰면은요 왼쪽으로 가는 거죠. 이걸 검색 쿼리를 작성을 합니다. 그래서 인터넷에 검색에 용이한 쿼리 작성을 한 다음에 검색을 실행을 하고 검색된 문서를 여기다 추가를 해 주는 거예요. 그러면요 파 파 파 파 파이프라인을 동일하게 타는 거죠. 근데 그다음에 왔을 때는 어떨까요?이 정보가 지금 문서에 보강이 되어 있는 상태죠. 그러면 생성 AI 가우스를 만든 회사는 삼성전자라는 정보도 알고 있고 그리고 우리가 이전 단계에서 인터넷에서 검색을 해서이 삼성전차의 매출액 정보도 가지고 있으니 결국에는 최종 답변을 만들 수가 있다라는 거죠. 그래서 우리가이 아래쪽으로 쭉 길게 느려뜨리면서 아 이거 다음에 이거 이게 안 되면 이거 이런 식으로 막 복잡하게 구성할 필요 없이 중간에 분기 노드 그다음에 뭐 검색 노드 요런 것들을 추가해서 흐름만 잘 짜 주면 된다는 거예요. 그래서 여러분들이 앞으로 남은 과정에서 결국에는 배우실 거는 뭐냐면이 노드을 만드는 방법 그다음에 엣지들을 연결하는 방법 그리고 분기 엣지를 만드는 방법 그래서 이렇게 흐름을 만들어서 세우는 방법만 아시면 결국에 얘가 알아서 이제 돈다라는 거죠. 자, 그래서이 랭그래프를 사용해서 저희가 앞으로 이런 흐름을 만들어 볼 거고요. 이걸 잘 만들기 위해서는 여러분들이 몇 가지 용어들을 알고 계셔야 됩니다. 일단 첫 번째로 제가 말씀드린 건 노드인데요.이 노드는이 후반부에 말씀드리겠지만 함수로 이루어져 있어요. 결국에는이 파이썬 함수거든요. 그래서 디파인 해 가지고 함수명 들어가고 입력은 이제 스테이트 그것도 이따가 말씀드릴게요. 우리 상태가 입력으로 들어올 거고 그다음에 출력도 상태가 아웃으로 할 거예요. 어쨌든 입력과 출력은 동일한 형태를 가질 거고요. 결국에는 얘는 파이썬 함수로 구현이 될 겁니다. 그러니까 우리가 파이썬 함수로 구현을 한다는 것은이 노드 내부를 여러분들이 자유자재로 구성할 수가 있다는 거예요. 꼭 여러분들이 랭체인 문법을 쓰지 않아도 된다. 어 나는 회사 내부에서 쓰는 DB를 조회하는 API가 있어요. 그게 파이썬으로 구현이 되어 있어요. 그러면 그거를 안 노드 안에 구성해도 얘는 잘 동작한다는 거예요. 그래서 이제는 랭체인에 대한 디펜던을 많이 덜어낼 수가 있다. 이렇게 보시면 되겠고요. 결론은 뭐냐면 노드는 파이썬 함수로 이루어져 있고 그 노드의 로직은 여러분들이 정의를 하시는 거고요. 그래서 요런 질문 노드, 문서 검색 노드, 답변 노드 요런 것들을 쭉 만드신 다음에 그다음에 여러분들이 해 주셔야 되는게 바로 엣지 구성이죠. 여기 다음엔 여길로 가. 여기 다음엔 여길로 가. 여기 다음에는 분기 노드야. 분기에서는 요런 상황에 따라서 예스일지 노일지에 따라서 요렇게 분기를 해 줘. 요런 엣지들을 만드실 거고요. 그다음에 상태 관리입니다. 아,이 상태 관리가 랭그래프에서는 굉장히 굉장히 중요해요. 굉장히 중요한데요. 여기에서 미리 말씀을 드리고 후반부에 한 번 더 말씀을 드릴게요. 자, 여기에서 여러분들이요. 노드라는 거를 만들어서 결국에는 다 독립적이게 만들어 줄 거예요. 쉽게 비율을 들자면 뭐냐면 얘네들 하나하나가 각각의 회사라고 보시면 돼요. 서로가 서로를 몰라요. 그냥 전혀 남인 회사인 거예요. 그런데 협력 관계에 있는 회사입니다. 그래서 A 회사에서 B 회사로 이렇게 연결이 되어 있는데요. B 회사는 A 회사에서 어떤 일이 일어나는지 전혀 알 수가 없어요. 그래서 A로부터 물건을 전달받긴 해야 되는데 A 회사에서 어떻게 처리를 해서 전달을 해 준다는 건지는 자기는 몰라요. 그렇기 때문에이 노드와 노드 간에는 우리가 어떤 걸로 통신을 하냐면요. 바로 스테이트라는 거를 통해서 통신을 하게 돼요. 요거는 이제 메시지 전달자의 역할을 한다라고 보시면 돼요. 그래서 이전에 A 회사에서 이런 거예요. 어, 내가 이번에는 질문이라는 걸 처리를 했어요. 이거를 스테이트라는데 택배처럼 담아다가 B회사한테 전달을 해 주는 거예요. 그럼 비회사가 이거를 택배 상자를 받아서 열어 봅니다. 열어봤더니 아, 이전 회사에서는 요거 질문을 처리를 해 줬구나. 그러면 자기네들이 또 해야 할 일을 해요. 그런 다음에 다시 택배 상자에 담은 거예요. 그래서 B회사에서는 요로 요러한 처리를 했습니다. 담아서 또 C 회사한테 주는 거죠. 이렇게 어 각각의 노드들은 다 독립적인 관계이기 때문에 어 여기에서 어떤 일이 일어난지 모르기 때문에 우리가 스테이트 즉 상태라는 데에다가 각각의 노드에서 일어났던 그 결과물을 담아서 다음 노드로 전송을 해 준다. 이렇게 이해를 하시면 되겠고요. 그리고 lm을 활용한 워크플로우의 순환 연산 기능을 추가를 했어요. 그래서 순환 기능이라는 건 뭐냐면 말 그대로 순환하는 기능이에요. 이렇게 순환을 할 수가 있다라는 거고요. 그다음에 순차적인 흐름에 따라서 진행이 됩니다. 물론 나중에 병렬 처리도 가능하긴 해요. 가능한데 기본적인 구조는 요거 다음에 요거, 요거 다음에 요거 이게 갑자기 막 1번, 2번, 3번, 4번 이거는 안 된다라는 거예요. 그래서 어, 이렇게 흐름이 순차적으로 일어나고요. 그다음에 컨디셔널 엣지는 아까 말씀드렸던 분기 엣지가 있어요. 그래서 어, 얘가 처리를 했잖아요. 그럼 처리된 결과물에 따라서 얘쓰일지 놀지 판단해 주고 그다음에 그 판단된 결과를이 컨디션 컨디션에 따라서 다음로드 어디로 가야 돼? 어, 이거 끝내야 돼? 아니면 검색해야 돼. 요걸로 연결해 주는 녀석이 바로 컨디셔널 엣지라고 보시면 되겠고요. 그다음에 휴먼더 루 기능도 있어요. 그래서이 노드에 도착을 하면 휴먼더 사람이 개입할 수 있도록 이렇게 허락을 해 주는 그런 기능이 있습니다. 뭐 대단하게 어려운 기능은 아니고요. 여기다가 이제 인풋 값을 줘 가지고 요거에 대해서 딱 노드에 도착하면은 사람이 그 노드에 관여을 할 수가 있어요. 그래서 여기에 입력값을 조정을 하거나 아니면은 계속 진행할지 말지 여부를 사람이 판단할 수가 있어요. 가령 분기 노드에 휴먼인더을 넣잖아요. 그러면 추가 정보가 필요합니까를 사람한테 물어보게끔 구성할 수도 있는 거예요. 그래서 사람이 보고 판단해서 어 그래 이거는 원래 없었지 하고 예스로 보낼 수도 있어요. 이렇게 사람이 개입할 수 있는 기능들도 마련이 되어 있고요. 그다음에 체크포인트. 아, 이게 정말 좋습니다.이 메모리와 체크포인터가 바로 과거의 실행 과정에 일어났던 그 내용들을 저장해 주는 역할을 하는데요.이 체크포인터 덕분에 우리는이 과거에 했던 대화 내용들을 기억을 하고 이걸 기반으로 멀티턴 대화 우리 대화가 싱글 턴이 아니라 그다음 대화를 했을 때 이어지는 거 우리가 멀티턴이라고 하죠. 요런 것들도 체크포인터 때문에 굉장히 굉장히 쉽게 구현이 가능하고요. 그리고 이전에 있었던 결과물에 대해서 수정을 해 주는 기능도 가능하고 리플레이 기능도 있어요. 아, 이거 너무 좋아요. 여기까지 왔는데이 2번 단계에서 일어났던 결과물이 마음에 안 들어. 그러면은 2번 단계로 리플레이를 할 수가 있어요. 그래서 여기서부터 다시 실행이 되도록 그런 기능들도 어이 랭그래프에서 제공을 하고 있습니다. 자, 그래서이 주요 용어에 대해서는 말씀을 드렸고요. 그러면 차례 차례 하나씩 하나씩 면m밀히 살펴보도록 하겠습니다. 자, 이번에는이어서 상태에 대해서 알아보도록 하겠습니다. 자, 첫 번째 상태죠. 상태 매우 중요한데요. 어,이 상태는 이전 영상에서 제가 언급해 드린 것처럼이 노드와 노드 간의 정보를 전달을 할 적에 바로이 상태라는 객체에 담아 가지고 전달을 합니다. 그래서 정확히 말씀드리면은이 타입트라는 것을 상속받은 그래프 스테이트라는 곳에다가 우리가 필요한 정보들을 이렇게 담게 되는 거예요. 담게 되는데 여기서 중요한게 우리가 그냥 일반 딕셔너리를 써도 되고이 타입딕트를 써도 되거든요. 근데이 타입트라는 거에 대해서 많이들 생소하실 거예요. 저도 사실이 랭그래프 쓰기 전에 파이썬 문법에 있지만 어 사실 자주 들여다보는 그런 문법은 아니었었습니다. 그래서이 타입트라는 거는 일반 파이썬 딕트의 타이팅 기능을 추가를 한 개념이거든요. 그래서 쉽게 얘기해서 그냥 딕셔너리라고 생각하셔도 되는데 그냥 딕셔너리에 우리가 키랑 밸류 쌍으로 이렇게 넣을 수가 있거든요. 그래서 question에다가 지금 여기 보시면 리스트를 지정을 해 주고 그다음에 컨텍스트에다가는 문자열 뭐 엔서는 문자열 메시지는 리스트로 들어가야 되니까 리스트 이런 식으로 그냥 지정해도 되는데 앞에 보시면은 어노테이티드라는게 있어요. 요거는 타이핑으로부터 임포팅을 해 주는 건데요. 어노테이티드라는 뜻은 말 그대로 이제 주석이거든요. 그래서 원래이 str을 주고이 str이 뭘 넣어 줘야 돼? 그니까 정보들을 추가로 알려 주는 거예요. 어노테이션을 통해서. 그래서 컨텍스트라는 데에는 str이라는 문자 타입을 넣어 줘야 되고 그다음에 여기에서는 그냥 어떤 컨텍스트를 넣어 주면 돼. 그다음에 엔서를 넣어 주면 돼. 이렇게 지정하셔도 되는데 예외적으로 여기에 보시면 뭐가 있냐면 랭그래프의 그래프의 메시지에 애드 메시지스라는 리서라는 개념이 있어요. 리서. 리서도 되게 생소하시죠?이 이 리서는 뭐냐면 어이 리서라는 역할은요. 조금요 다음 장에 한 번 더 자세히 설명드릴 건데 지금 리스트잖아요. 근데 리스트면은 보통 우리가 메시지를 추가를 한다고요. 뭐 가령 메시지스를 한번 볼게요. 그러면 우리가 휴먼이 질문을 하고 AI가 답변을 하고요. 그다음에 휴먼이 또 질문을 하고 AI가 답변을 해서 리스트 안에다가 메시지를 이렇게 쭉 쌓아 나갑니다. 근데 여기에다가 어펜드라는 문법을 쓰는게 아니라이 하나의 리스트가 있고 덧셈으로 하나의 리스트를 이렇게 주기만 하면 그 반환값에 리스트를 주기만 하면이 어노테이션의 애드 메시지가 붙어 있으면 자동으로 기존 리스트에 추가가 되는 개념이에요. 그래서 이거를 랭그래프에서 리서라는 걸 만들어 놓은 이유는 왜 그러냐면 어 이걸 편하게 하기 위해서요. 어 퀘션 어 너 앞으로 애드 메시지 할 거지? 추가 메시지 그냥 리스트 만들었으면 너 추가하는 기능금만 할 거잖아. 그러면은 여기에다가 애드 메시지라고 지정을 해 놔. 그럼 내가 알아찰게. 그러면 네가 question션이라는 값을 반환을 해 주면 나는 그걸 덮어 씌우는게 아니라 리스트에다가 애드를 해 줄게. 이렇게 되는 거예요. 그래서 정리해 볼게요. 어, 우리 메시지로 예를 들면 만약에 여기에 1번 메시지가 들어가 있고 2번 메시지가 들어가 있어요. 두 개 들어가 있죠. 요렇게 들어가 있는데 여기에다가 어떤 노드에서 반환값이 3번 메시지를 반환을 해 줘요. 만약에 애드 메시지가 없고이 리스트를 대입을 하면 어떻게 돼요? 앞에 메시지가 날아가고 3번 메시지만 덩그런이 있죠. 그럼 1, 2번 메시지가 날아가게 돼요. 근데이 리서가 이렇게 붙어 있으면 는이라는 걸 선언을 해서 넣어 주더라도 3번을 대입을 하더라도 메시지스에다가 이게 데입을 하더라도이 기존에 있던 메시지에다가 추가하는 기능으로 메시지를 추가를 해 줘요. 그게 바로 리서의 역할이라고 보시면 됩니다. 그래서요 다음 장에 한 번 더 설명 드릴 거고요. 그다음에 또 하나 어 모든 값을 다 채우지 않아도 돼요. 지금이 스테이트라는 것은 뭐냐면 노드와 노드 사이에 정보 전달을 할 건데 거기서 사용되는 키들은 이러 이러한 것들을 쓸 겁니다라는 사전에 정의를 하는 거예요. 그런데 내가 처음에 질문을 했는데 당연히 컨텍스트 엔서 메시지 러스 없겠죠? 없을 거예요. 근데 이걸 꼭 채우지 않아도 된다는 거예요. 이거 그냥 내비 두고 퀘션만 채워도 돼요. 요거 두 개만 채워도 되고. 그래서 모든 값 채우지 않아도 된다. 그다음에 새로운 노드에서 값을 덮어 쓰기 방식으로 채워요. 아, 이게 참 좋은게 뭐냐면요. 만약에 컨텍스트를 가져왔어요. 문서 검색을 했어. 근데이 검색된 문서가 마음에 안 들어. 그러면 다시 재검색을 할 거거든요. 그러면은이 재검색을 해서 여기다 넣어 주게 되면은 나중에 검색된 녀석이 기존값을 기본적으로 덮어 씌우기 하는 방식이 되는 거예요. 여기에 있었던 애 애드 메시지스라는 리서는 덮어 씌우기가 아니라 자동으로 얘가 추가를 해 준다라고 했죠. 근데 이렇게 리서가 붙어 있지 않는 일반적인 녀석 같은 경우에는 대입하는 방식으로 하면은 나중에 온값이 기존값을 덮어 씌우게 되는 거예요. 그래서 요런 기능들이 있고 요거는 조금 있다가 제가 상태값의 이동 부분을 좀 더 자세히 설명을 드릴게요. 어 리서 리서 많이 나오는데 많이 헷갈려서 다시 한번 짓고 넘어가면요.이 애드 메시지스 혹은 오퍼레이터 애드라고도 담겨 있거든요. 예전에는 오퍼레이터 애드가 담겨 있었고 요즘에는 랭그래프에서 아예 출시를 해 버렸어요. 그래서 애드 메시지라는 걸로 통영이 되는데 어테이티드에 타임 명시해 주고 오른쪽에다가 애드 메시지 하면 리스트에다가 메시지를 추가해 주는 개념이고요. 기존 메시지에다가 병합할 메시지를 추가를 해 주는 개념이에요. 그래서 어 여기에 예시를 하나 가지고 왔는데요. 메시지 1번에요 휴먼 메시지가 들어가 있고 메시지 2번에 요렇게 들어가 있어요. 그래서 애드 메시지 해 주면 어노테이트를 달아주면 요거를 달아주면 얘가 자동으로 어떤 기능을 수행하냐면요 다음 장에 나오는요 역할을 수행을 해 주는 거예요. 그래서 원래 있던 휴먼 메시지에다가 나중에 온 AI 메시지를 추가해 준다. 이걸 덮어 씌우는게 아니죠. 메시지스 2가 기존에 있던 거를 대체를 하고 얘만 덩그런이 남는 그 개념이 아니라 기존에 있었던 메시지에다가 추가를 했기 때문에 이렇게 합쳐져서 보인다. 요게 바로 리서예요. 앞으로 리서 많이 나오니까 여러분들이 꼭 기억해 주셨으면 좋겠고요. 그리고 다음으로는 이제 상태 이동인데 우리가 상태를 가지고 노드 노드 간의 통신을 한다라고 말씀을 드렸어요. 그래서 노드 1번과 2번과 3번과 4번에서 각각의 작업이 일어날 겁니다. 이렇게 일어나는데요. 자, 그런데 여기 보시면 노드 1번에 타임에다가 1을 대입을 했어요. 그리고 LM에다가는 GPT를 넣었어요. 자, 여기에서 이제 작업이 다 끝났어요. 작업이 다 끝나고 마지막으로 타임에다가 1 기입하고 LM에 GPT 기입하고 끝났어요. 그러면 노드 2번 전달했죠? 2번은 아까도 말씀드렸지만 어떤 식으로 되냐면 노드 1에서 어떤 일들이 일어났는지 노드 2는 전혀 알지 못해요. 그래서이 상태값에 담아서 전달을 해 주는 거거든요. 전달 받았어요. 노드 2에서 뭐 참고할 정보 참고해 가지고 작업을 했어요. 그리고 작업이 다 끝났으면 상태에다가 내가 작업을 어떻게 끝냈는지 적어 줘야 돼요. 그래서 타임은 2. 네임에다가는 테디. LM에다가는 GPT를 아 LM은 지금 기비를 안죠. 빨간 것만 기입을 해 줬습니다. 자, 그러면 어떻게 된 거예요? 지금 노드 2에서 타임에다가 2라는 값을 새롭게 덮었었죠. 근데 이전에 노드에서 1이 있었잖아요. 원래 있었던 값은 날아가고 새로운 값이 덮어신 거예요. 어, 그런데 네임이라는 값은 원래 없었죠. 그래서 새로운 값 넣었으면 어떻게 되는 거예요? 얘는 그냥 새롭게 들어온 값이죠. 그러면 노드 2에서 보시면은 새로운 값이 이렇게 들어갔어요. 그럼 기존값을 덮어 씌우는 애도 있고 새롭게 들어온 녀석도 있어요. 그러면 노드 3번에 보자고요. 3번에 보시면은 기존에 마지막으로 덮었었던 값이 어때요? 그대로 남아 있어요. 유지되면서 3번에서는 타임을 3만 업데이트를 해 주는 거예요. 그리고 4에서 마지막으로 네임까지 바꿨네요. 그러면 최종적으로 노드 4가 끝나고 난 다음에 상태값을 열어 보면 어떻게 돼 있다? 여기에 있는 상태값이 그대로 남아 있는 거예요. 그래서이 상태 전달이라는 거는 굉장히 유용해요. 왜냐면 노드와 노드 간의 어떤 프로세스를 거침에 따라서 우리가 상태를 업데이트해야 될 일이 있고 추가해야 될 일이 있는데 그게 계속 유지가 되면서 그대로 전달이 된다라는 점이 굉장히 유용한 부분 중에 하나예요. 자, 그래서 노드별 상태값의 변화를 보시면요. 우리가 실제 레그 사례를 보시면 question이 들어왔죠. 그래서 캐천에 질문 1이 들어왔어요. 그다음에이 질문 1을 가지고 문서 검색을 합니다. 근데 노드 2에서 얘가 검색하는 노드거든요. 그 검색을 하려면은 question이 필요하잖아요. 근데이 question 정보를 어떻게 가져왔어요? 상태값을 열어 보니까 질문 1이 담겨 있죠. 왜? 유지가 되는 거니까. 그래서 1에서 질문을 넣어주고 상태값에 질문을 넣어 줬잖아요. 전달했어요. 그러면 어 1번 노드에서 질문 기입해 줬네. 요거를 꺼내서 질문 1을 가지고 검색을 수행하는 거예요. 검색해서 검색된 문서 이번에 기입해야겠죠? 컨텍스트에다가 기입해 주는 거예요. 그러면 우리가 지금 두 개가 업데이트 돼 있네요. 문서 1이랑 질문 1. 그다음에 엔서 노드로 전달을 합니다. 그러면 엔서 노드에서 문서 1이랑 질문 1이 그대로 담겨 있죠. 지우지 않았으면 요대로 담겨 있어요. 그다음에 엔서 노노드에서 문서와 검색된 문서와 질문을 가지고 이제 답변을 받는 거예요. 답변을 받았으면 답변을 엔서에다 적어요. 그다음에 이밸류에이트 평가하는 노드에서이 문서 질문 답변을 가지고 평가를 해 보는 거예요. 근데 평가가 아쉽게도 스코어가 배드가 나왔네요. 베드가 나왔을 경우에 그러면 우리가 뭘 할 수 있어요? 여기에서 이제 세 가지 방식을 선택할 수가 있는 거예요. 어떤 식으로 갈 수가 있냐면이 스코어가 베드니까 이걸 그냥 내보낼 수 없잖아요. 우리 고객한테. 그래서 베드가 나왔으면 우리가 4번이 판단하는 거예요. 아, 이거 베드 나왔으면 내가 봤을 때 질문이 잘못됐다 하면은 1번 노드로 보내는 거예요. 혹은 아, 이거 내가 봤을 때 문서 검색이 잘못됐다. 2번 노드로 보내는 거예요. 혹은 아, 이거는 엔서가 잘못 출력이 됐다.요 두 개는 문제가 없다. 이러면은 3번 노대로 보내는 거예요. 그래서 이렇게 선택해서 뒤로 빠꾸시킬 수가 있는 거예요. 그래서요 다음에 보면은 만약에 질문을 제작성 요청을 했을 때에는이 아까 여기에선 배드가 나왔잖아요. 그러면은 질문 자체가 잘못돼서 지금 그런 거니까 얘를 1번 노드로 다시 보내는 거예요. 그래서 오면은 질문은 제작성을 하죠. 그럼 원래 기존에 어떤 값들이 들어가 있었을까요? 문서 1, 질문 1, 답변 1이 있었는데 질문 제작성 했으니까 질문만 갱신이 되는 거죠. 자,이 질문이 갱신이 되면 우리가 왼쪽에서 오른쪽 순서대로 가잖아요. 그럼 순차적으로 질문이 바뀌었으니까 리트리브 노드에서 문서 검색도 바뀌게 되죠. 왜냐면 질문이 검색이 들어가는 거니까. 그럼 문서도 갱신이 됐죠. 그다음에 질문과 문서가 갱신이 됐으니까 엔서도 자연스럽게 갱신이 돼요. 그러면 엔서의 품질이 좋아졌겠죠. 다시 평가를 해 보니까 굿이 나오는 거예요. 만약에 이게 또 배드를 맞으면 또 이걸 반복할 수가 있는 거고요. 그다음에 노드 2번을가 보면 문서 검색을 제욕청하는 것도 있어요. 만약에 얘가 판단을 내렸는데 질문 자체에는 문제가 없어요. 근데 검색된 문서가 별로야. 그래서 다른 리트리버 알고리즘을 쓰든 해서 다시 검색을 합니다. 그러면 질문은 그대로 남아 있잖아요. 그렇죠? 요걸 거치지 않았으니까. 그래서 문서만 지금 갱신이 일어났고요. 그다음에 갱신된 문서를 가지고 지금 문서 바뀌었고 그다음에 퀘션은 질문 그대로 있 문서가 바뀌었으니까 답변도 바뀌겠죠? 그럼 답변이 업데이트가 됐어요. 그러면은 요거를 가지고 최종 평가를 하는 거예요. 개선된 답변을 가지고요. 평가를 했더니 이번에는 9시 나왔다. 이런 거죠. 자, 그다음에 3번 노드를 보시면은 얘가 평가를 해 보니까 질문도 문제가 없어. 검색된 문서도 괜찮아. 근데 LM이 좀 답변을 잘못한 거 같아요. 그래서 어 얘 같은 경우에는 다시 돌아가서 다시 답변을 만들도록 하는 거죠. 그래서 답변이 갱신이 일어났고요. 답변이 2가 됐죠. 새로운 답변을 받았어요. 근데 여기 보시면 스코어가 그대로 남아 있죠. 왜? 6번 다음에 5번으로 왔으니까 빠꾸한다고 스코어 개입한게 삭제되는게 아니에요. 사실 엄밀히 따지면 1 여기가 이렇게 되는 거죠. 1번, 2번, 3번, 4번 노드까지 오고 그다음에 5번, 6번이니까 4번 상태에서 스코어를 기입을 했잖아요. 베드로. 그러니까 여기로 왔겠죠. 그래서 배드 스코어는 이번에는 남아 있는 거예요. 그리고 답변은 갱신이 일어났고 그다음에 갱신된 답변 가지고 다시 평가를 하니까 붓이 나왔다. 이런 겁니다. 그죠? 그래서 이런 식으로 랭그래프를 쓰면요. 내가 원하는 방식에 따라서 이렇게 유동적으로 흐름을 바꿀 수가 있는 거예요. 자, 그다음에 노드와 H 보겠습니다. 노드와 H엣는 정말 간단한데요. 노드는 우리가 앞으로 많이 만들어 볼 거예요. 왜냐면 여러분들이 이제 랭그래프를 쓰다 보면 아직 생소해서 그렇지 사실 랭그래프라는 문법은 어려운게 아니에요. 굉장히 쉬워요. 다만 뭐가 어렵냐면 여러분들의 결국의 핵심 로직에 어 해당하는이 함수를 만드는게 어렵다. 이게 어렵다라는 표현보다는 사실 어 많이 좋은 품질의 노드를 만드는게 중요하게 되는 거죠. 어 그래서 여러분들이 함수들을 많이 만드실 거예요. 그래서이 노드가 지금 보시면 이전에도 보면요.요 단계가 세부 단계로 나뉘어질수록 그러니까 더 작은 단위로 갈수록 더 유리해요. 내가 더 정교한 튜닝이 가능하고 더 정교한 흐름을 만들 수가 있어요. 그래서 여러분들이 앞으로 집중하셔야 될 거는 내가 좋은 노드들을 만드는 것. 결국에는 노드는 뭐냐면 파이썬 함수를 이루어졌기 때문에이 함수 안에 내용을 채우는게 중요한 거죠. 그래서 여러분들이 여러분들만의 노드를 많이 가지고 계셔야 돼요. 자, 그러면이 노드를 어떻게 만드느냐? 노드는 함수로 만든다라고 했죠? 근데 노드 생각해 보세요. 이전 단계에서도 보면 상태를 입력으로 봤잖아요. 우리 노드 2번의 입장에서 볼까요? 이전에 작성된 상태값을 전달받죠. 전달받는 게예요. 그다음에 얘가 작업이 다 끝나면 상태에 적어서 상태를 주거든요. 그러니까 결국에는 스테이트라고 하는 상태를 입력으로 받아서 상태를 내보내는 거. 입력이 상태, 출력도 상태. 요게 되는 거예요. 요게 기본 구조예요. 간단하죠? 그래서 여기 보면은 입력이 상태. 상태를 입력으로 받아서 필요한 정보들을 상태로부터 꺼내서 쓰는 거예요. 얘 어차피 딕셔너리니까 그냥 킥업 가지고 꺼내면 되는 거예요. 그래서 내가 필요한게 question션이다. 이런 식으로 킥합 가지고 조회해서 꺼내면 되는 거예요. 그럼 question이 꺼내지는 거예요. 그다음에 내가이 question션 키를 꺼내서 리트리로버로부터 검색을 했어요. 그럼 검색대 문서가 나오죠. 이것도 상태에 담아서 보내는 거야. 어, 그냥 검색했다 하고 끝나는게 아니라 상태에 담아서 보냅니다. 이것도 그래프 스테이트에 내가 담아 줄 키에다가 대입해서 이렇게 보내면 되는 거예요. 그래서 여기 보면은이 문법이 뭐예요? 입력도 상태, 출력도 상태라는 말이에요. 그래서 상태를 입력으로 받아서 이걸 가지고 처리해서 결국에는 반환값도 상태가 돼야 되는 거죠. 그래서 요것만 잘 기억해 주시면 되겠고요. 그다음에 어 노드를 추가하는 방법은 이런 식으로 추가를 합니다. 우리가 애드 노드 애드 노드라는 걸 통해서 왼쪽에 들어오는 건 일반적으로 문자열인데 한글로 적지 마시고 영어로 적는게 좋아요. 물론 한글도 인식을 하긴 합니다. 근데 오류가 발생할 수 있으니 그냥 쉬운 영어로 적어 주시는게 좋아요. 일반적이고요. 그다음에 오른쪽에다가는 함수명을 적어 주시면 돼요. 그래서 이전 단계에서 내가 요런 리트리브 도큐먼트라는 노드를 만들었잖아요. 그러면이 리트리브 도큐먼트라는 노드를 여기다가 이렇게 넣어 주시기만 하면 돼요. 그럼 노드 바로 추가된 겁니다. 자, 그래서 여기 리트리브 도큐먼트 있고 LM 엔서 노드가 있었죠? 그러면 리트리브라는 어 노드의 이름을 지어 주는 거고요. 오른쪽에다가는 함수를 넣어 주고 LM엔라는 이름에 LM엔 M 함수명을 넣어 주시면 됩니다. 자, 다음으로는 엣지예요. 우리 노드를 만들었어요.요 리트리브 문서 검색을 하는 노드도 만들고 LRM 엔서 노드도 만들고 관련성 체크를 하는 릴러스 체크라는 노드로 만들었어. 이렇게 노드만 덩그런이 있으면 동작하지 않겠죠? 그다음에 더 재미난 거 여러분들이 흐름을 만드셔야 돼요. 그래서 노드 어떤 노드에서 어떤 노드로 갈 것인가, 어떤 노드에서 어떤 노드로 갈 것인가를 여러분들이 만드는 거예요. 이걸 정의해 주는 겁니다. 그래서 애드 엣지라고 해서 엣지는 항상 두 군데 왼쪽에서 오른쪽으로 적는데 얘가 프롬이고 얘가투예요. 그래서 리트리브에서 LM 엔서로 간다. 그다음에 llm 엔서에서 렐러스 체크로 간다. 이렇게 흐름 정의만 잘해 주시면 되고 어 렐러스 체크한 다음에 나는 무조건 이거 말이 안 되겠지만 이러면 순환 로즈가 걸리겠죠? 그렇지만 그냥 예를 들어 볼게요. 만약에 렐러스 체크해서 나는 리트리브로 보내고 싶다 그러면 여기에다가 애드 엣지 한 다음에 렐러스 체크 렐러스 체크로부터 쉼표하고 리트리브 문자열 적어 주시면 돼요.이 문자를 어디서 적용했다고요? 이전에 노드 여기에서 적용을 해 준 거죠. 애드 노드에서 요런 식으로요. 적용을 해 줬습니다. 그래서요 노드 명을 가지고 애드엣를 통해서 프롬투로 연결해 주시면 돼요. 자, 그다음에 정말 많이 쓰는이 조건부 엣지예요.이 조건부 엣지가 너무 좋은 기능이에요. 우리가 가끔 가다가 레그 파이프라인을 만들면 여기에서 어 조건에 따라서 분기문 뭐 라우팅을 라우팅을 줄 수도 있고요. 그런 것들을 수행할 때가 있어요. 그래서 우리가 조건부 엣지를 많이 쓰는 경우가 언제냐면 llms 저지를 가지고 답변에 대한 평가를 수행한 다음에 평가가 원래 우리가 기준으로 세워 놓은 점수에 못 미치면 못 미친다면 만약에 뭐뭐 한다 면이 붙으면 그럴 때 조건부 엣지를 쓸 수가 있는 거예요. 그래서 평가를 측정을 하고 만약에 못 미친다면 이제 다른 데로 보내면 되는데 지금 여기에 보시면이 렐러스 체크에서 나온 결과죠. 요게 프롬이에요. 프롬인데요 나온 결과를 그다음 인자인 함수한테 전달을 해 줘요. 그래서 만약에 릴러스 체크를 하고요. 하고 그다음에요 노드의 결과물을 이러트한테 전달을 해요. 얘도 함수거든요. 그래서 예보로 판단을 해요. 그러면은 얘가 판단을 내렸는데 그라운디드라는 애를이 함수가 만약에 반환을 해줬어요. 그러면 그라운디드라는 거는 관련성이 있다라고 나온 거니까 끝내 주면 돼요.요 D 노드 D 노드는 끝내 주는 노드입니다. 끝 끝 끝이라는 뜻이에요. 그다음에 notounded나 아니면 not라는 결과값이 나오면 다시 어디로 보내는 거예요? llm엔서라는 것으로 보내는 거죠. 그러면 얘가 다시 빠꾸를 해 가지고 거기서부터 다시 돌기 시작하는 거예요. 그래서 이런 식으로 우리가 맵이라고 하는데요. 패스맵. 그래서 우리가 나온 노드 그다음에 전달을 해서 패스맵을 통해서 얘가 어디로 가야 할지 방향성이 달라지게 되는 거예요. 그래서 요런 식으로 어 정해져 있고요. 여기 노드 이름과 조건부 판단 함수가 들어가고 다음 단계로 결정하는 거 요거를 꼭 기억해 주시면 되겠습니다. 저희가 실습할 때 분기문 정말 많이 쓸 거예요. 자, 그다음에 우리가 시작점을 지정을 해야 돼요. 만약에 여러분들이 이렇게 노드 설계를 했는데 시작점을 이걸로 설정을 했다. 그러면은 에러가 발생을 해요. 여기는 도달할 수가 없다. 요런 에러가 발생을 합니다. 그래서 시작점을 잘 설정을 해 주셔야 되고요. 요거를 셋 엔트리 포인트로 지정할 수가 있어요. 그래서 리트리브 노드로 시작점을 설정하면 우리가 질문이 들어가면 여기서부터 시작을 하게 되는 거예요. 그래서 시작점은 셋 엔트리 포인트 요걸 기억해 주시고요. 자, 그다음에 이제 거의 다 왔습니다. 그래프 생성하는 쪽이고요. 어, 우리가 생성을 할 적에는 여기에 컴파일만 사실 주시면 되거든요. 이거 없어도 돼요. 요거 없어도 되고 워크플로우에 컴파일을 주면 생성이 돼요. 생성이 되는데 우리가 앞으로 메모리라는 걸 많이 쓸 거예요. 메모리를 왜 쓰느냐? 메모리는 기억 저장 용도예요. 그래서이 체크포인트라는 걸 써야 뒤로 빠꾸를 시키던가이 스냅샷이라는 걸 활용해서 뒤로 되돌리기가 가능해져요. 그래서 우리는 앞으로이 메모리라는 기억 기능을 쓸 거다. 그다음에 나중에 멀티턴 대화를 할 때도이 메모리라는 기능이 유용해요. 그래서 앞으로 거의 대부분의 그래프를 만들 때에는 바로 메모리 메모리라는 거를 써 가지고 체크포인터에다가 메모리를 넣어 줘서 수행을 하게끔 만들어 주도록 하겠습니다. 자, 그다음에 그래프 시각화인데요. 사실 요거는 제가 나중에 따로 보여 드릴 거예요. 더 간단하게 시각화할 수 있는 로직을 넣어 놨고요. 우리가 개크래프해 가지고 디스플레이를 실행을 한 결과를 보시면은 드로움 멀이드 편지를 통해서요 API 방식이거든요. 그래서 실제로 통신이 이루어져야 돼요. 그래서 인터넷이 끊긴 상황에서는 동작을 안 하더라고요. 물론 로컬로 할 수 있는 방법도 어 제공을 해 주긴 합니다. 근데 요거는 이제 돈이 안 드는 거니까 인터넷만 연결되어 있으면 되고요. 요거를 호출해서 결과를 받으면 요런 식으로 그래프를 그려 줘요. 그래서이 시각하는 저도 무조건 해 보는데 우리가 이전에 보셨던 것처럼 막 노드 만들고 이런 식으로 노드 만들고 노드 연결치잖아요. 근데 이게 코드로 이렇게 들어가 있으면 되게 헷갈려요. 어디서 어디 흐름으로 가는지 헷갈려요. 그래서 거의 대부분의 케이스에서는 꼭 시각화를 해서 확인을 해 보고 간다. 시각화해 보면 되게 잘 나와 있어요. 스타트 해서 리트리브 가고서 가고 관련성 체크해서 확인 불가능 관련성 없으면 빠꾸 하고 있으면은 엔드하고 이런 로직을 우리가 한 눈에 볼 수 있어서 굉장히 유용하다고 볼 수가 있습니다. 자, 그다음에 이제 그래프 실행하는 부분인데 실행해서 결과 볼 때 사실 인보크 하는 것도 있고 그다음에 나중에 스트리밍 토큰 출력하는 것도 있거든요. 근데 우리가이 랭그래프에서는요. 중간중간에 LM이 또 여러 개 관여할 수가 있어요. 그리고 LM은 스트리밍 토크 출력을 허용하잖아요. 그래서 중간중간마다 스트리밍 하는 방법도 있어요. 그것도 차차 알려 드릴 건데. 근데 여기에서 먼저 쉽게 말씀드린 거는 이제 인보크 상태부터 먼저 말씀을 드릴게요. 우리가 체인에 인보크를 해서 결과를 받을 수 있듯이 그래프도 마찬가지로 인보크를 날려 가지고 결과를 받을 수가 있는데 여기에 지금 넣어 주시는 걸 보면은 인풋트의 그래프 스테이트를 넣어요. 그래서 우리가 상태값에다가 초기에 전달할 내용을 담아서 애초에 담아서 왜냐면은 첫 번째 만난 애도 노드예요. 그러니까 노드는 입력을 상태로 받아야 돼요. 스테이트로 받아야 되기 때문에 상태에 담아서 전달을 해 주는 거예요. 전달을 하고요. 그다음에 여기에 보면은 컨피그에 러너블 컨피그라고 나와 있죠. 이거는 이제이 그래프를 실행함에 있어서 어떤 컨피그 값을 넣어 주는 건데 우리가 크게 리컬션 리미트랑 쓰레드 아이디 요거 두 가지를 설정을 해 줄 겁니다. 리컬션 리미트라는 건 뭐냐면 얘가 순환 로직에 걸릴 수가 있어요.이 순환 로직이라는 건 뭐냐면요. 이전으로 돌아가면 만약에 우리가 이런 흐름을 만들었잖아요. 요거보다 좀 더 단순한 걸 한번 볼게요. 이런 흐름을 만들었어요. 근데이 문서 검색된 결과가 계속 별로일 수 있잖아요. 그럼 이거 뺑글뺑글 돌아요. 계속해서 시간 지연되고 토큰이 관여하면은 토큰도 계속해서 비용 발생할 수 있겠죠. 거지 될 수 있습니다. 그래서 이런 순환직에 빠지지 않기 위해서 우리가 일반적으로 리컬션 리미트라는 걸 걸어요. 그래서 몇 회 정도까지만 얘가 실행할 수 있다라는 그 리미트를 주는 거예요. 그래서 13인 경우에는 총 13개의 노드까지 실행하는 겁니다. 그러니까 한 번 그 순해를 하는 거를 1로 카운트하는게 아니라 1번 노드 갔으면 1, 1번에서 2번 갔으면 2, 두 번 세 번 이렇게 해서 총 13개의 노드까지 방문을 할 수 있다라는 뜻이에요.이 리커션 리미트를 여러분들이 뭐 더 늘릴 수도 있죠. 뭐 100개, 200개 이렇게 늘리셔도 됩니다. 그렇게도 가능하고 그다음에 컨피어러블에 보시면 쓰레드 아이디라는 걸 주는데요. 쓰레드 아이디가 또 중요해요. 이게 왜 중요하냐면 나중에 멀티턴 대화를 할 적에이 쓰레드 아이디별로 대화 내용을 따로 구분해서 저장을 해요. 예를 들어서 제가 처음에 왔을 때 대화 내용을 저장을 해요. 그 쓰레드 아이디를 만약에 1번이라는 아이디에다가 저장을 했어요. 근데 내가 새롭게 대화창을 만들었어요. 그 그 대화창은 쓰레드를 2번으로 했어요. 그러면 1번까지 했던 대화 내용은 1번 안에만 저장이 되고 새롭게 만든 쓰레드 2번의 대화는 처음부터 시작을 하는 거예요. 이렇게 하다가 어 나 다시 1번으로 돌아가야 되는데 하면은 쓰레드 아이디를 다시 1번으로 주면은 이전에 저장했던 1번의 어 최근 메시지부터이어서 진행을 할 수가 있어요. 그래서이 쓰레드라는 개념이 굉장히 편해요. 그냥 우리가 카톡으로 따지면은 카톡의 어떤 그 단톡방의 개념이라고 보시면 돼요. 그래서 각각의 개별 방이 있고 그 쓰레드 아이디를 활용해서 왔다 갔다 할 수가 있어요. 굉장히 편리한 기능이고요. 자, 그다음에 이제 결과 확인인데 결과 확인은 나중에 겟스테이트라는 걸 통해서 결국에는 마지막 노드가 출력해내는 것도 스테이트예요. 처음부터 끝까지 다 스테이트예요. 그래서 출력된 스테이트를 받아서이 상태를 받아서요. 어,이 상태 값의 question션과 엔서와 릴러스를 찍어 보면 마지막으로 저장된 상태를 확인해 볼 수가 있어요. 결국엔 이런 거예요. 여기 또 돌아가서 보면은 우리가 이런 식으로 이제 진행이 되잖아요. 만약에 1 2 3 4번까지 왔어요. 그러면 마지막에 나왔던 여기서 4번하고 끝났다라고 가정해 볼게요. 그러면 상태값에요 내용이 그대로 저장이 되 있는 거예요. 그럼 마지막에 있는 엔서를 꺼내면 거기에 최종 답변이 담겨 있는 거예요. 그런 컨셉이라고 보시면 되겠습니다. 자, 그래서 여기까지 이제 어 전부 다 봤어요. 그래서이 이후의 내용부터는요. 저희가 실습 파일을 가지고 직접 확인해 보고 그다음에 각각의 스테이트나 노드나 엣지 만드는 거 요런 것들도 좀 더 면밀히 보면서 실습하면서가 보도록 하겠습니다. 네. 안녕하세요, 여러분. 이번 시간부터는 우리 랭그래프의 스트럭처스 폴더에서 진행을 해 볼 거예요. 여기 보시면은 지금 1번부터 7번까지 들어가 있거든요. 그런데 1번은 저희가 이제 기본 그래프를 생성하는 내용들을 먼저 보실 거예요. 그래서이 기본 그래프를 생성하는 과정에서 먼저 스테이트 정의를 하고 노드 정의를 하고 그래프 정의를 하고 컴파일하고 시각화하는요 과정들 있죠?요 요 과정들에 대해서 쭉 한번 톱아보는 그런 과정이에요. 그리고 2번부터 시작해서 5번까지는 사실 하나의 파일로 보셔도 되는데 제가 일부러 단계별로 좀 쪼개 놨습니다. 그래서 이렇게 쪼개서 보시면 되고 6번은 에이전트 레그에 대한 부분 그리고 마지막으로 아댑티브 레그까지 이렇게 쭉 보는게 2번 스트럭처스 폴더예요.이 이 이번 스트럭처스 폴더는 저희가 기존에 알고 있던 어떤 라이브 레그서부터 어드벤스트 레그까지의 과정을 이제 그전에는 랭체인의 LCL 문법으로 진행을 했다면요. 지금은 랭그래프를 사용해서 이걸 구현해 볼 거다. 이렇게 이해를 하시면 되겠습니다. 그래서 사실 1번 파일에 대한 이해만 잘 되시면 2번부터는 자연스럽게 물 흐르듯이 아마 진행이 될 거예요. 그래서 한번 같이 보실 건데요. 먼저이 기본 그래프 생성 파트입니다. 01번 파일을 열어 주시면 되고요.이 파일을 보시면서 여러분들이 같이 열어 두셨으면 하는 부분이 뭐냐면 바로이 PDF 파일입니다. 제가이 PDF 파일을 같이 드렸는데요.이 PDF 파일 쪽에 보시면은 이제 상태 부분이죠. 상태 부분에 대한 설명과 그다음에요 뒤에 나오는 내용들 요런 내용들을 같이 보시면은 도움이 되실 것 같아요. 그리고 혹시나 어 내가 이거 PDF 파일 처음 보고이 강의 내용 안들은 거 같은데 하시면은 이전 챕터로 돌아가셔서요 처음에 보시면은이 PDF 자료를 가지고 개요 설명드리는 부분이 있거든요. 그거를 꼭 이해를 하시고 오시는 것이 좋습니다. 자, 그러면 바로 한번 들어가 보도록 할게요. 먼저 기본 그래프 생성입니다. 이번 튜토리얼에서는 랭 그래프를 사용해서 그래프를 생성하는 방법을 배우실 거고요.이 그래프를 정의하기 위해서는 크게 1번부터 5번까지요 내용을 꼭 기억하셨으면 좋겠습니다. 먼저 스테이트 정의가 들어가고요. 그다음에 노드 정의, 그래프 정의하고 컴파일 한다면 시각요 과정만 쭉 진행하시면 되는 거예요. 자, 그래서 우리가 밑에 보시는 거와 같이 요것처럼 다소 복잡해 보이는 이런 구조를 만들어 줄 거예요.이 구조에 대한 설명을 간략히 드리면 먼저 문서로부터 리트리브를 합니다. 디트리브를 해서 GPT로도 요청을 하고 클로드도 요청을 할 수가 있죠. 이렇게 병렬로 요청을 해서 각각의 답변을 받은 다음에이 결과를 한대 묶어 주는 거예요. 그래서 두 개의 답변 형식이 다를 건데 두 개의 어떤 이점들을 뽑아낼 수도 있고요. 아니면 두 개를 각각 나중에 평가를 해서 더 좋은 답변을 선택해서 가져가는 것도 가능하겠습니다. 그리고 결과 종합을 했는데 만약에 답변이 별로다 하면은 리라이트 커리를 해서 다시 리트리브를 해서이 과정을 이렇게 순해 두는 거 요런 것들도 물론 가능하겠죠. 자, 그래서 요거를 만들어 볼 건데요. 저희가 이번 파일은 안에 들어가 있는 내용이 없어요. 그 말은 뭐냐면요 밑에 내용이 보시면 함수의 내용들이 전부 다 비어져 있죠. 이렇게 간단하게만 나와 있습니다. 이유는 우리가 안에 있는 복잡한 코드들이 들어가 있으면 큰 그림을 잡기가 좀 어렵더라고요. 그래서 소위 말하는 저희가 수도 코드라고 하죠. 그러니까 여기에서 나중에 검색된 문서를 구현을 할 거야. 혹은 검색을 구현할 거야. llm 실행 구현할 거야. 이렇게 가정을 해 보는 겁니다. 안에 내용은 비어져 있고요. 하지만 여러분들이이 큰 그림을 얻어 가신 다음에 이제 그래프 설계하고 실행까지 하셨으면 나중에는이 뼈대 코드를 토대로 안에 있는 내용들만 채워 주면 되는 거죠. 그래서 이번 시간에는 저희가 큰 그림을 먼저 보실 건데요. 그중 첫 번째가 바로 스테이트 정의입니다.이 스테이트 정의는 타입드디디트를 상속받아서 구현을 하는데 어 이전에 제가 개요 시간에도 말씀드렸던 거 같은데이 타입디트라는 말이 나와서 이게 생소해 가지고 어 나 괜히 어려운 거 같다 이렇게 생각하시는 분들 꽤 많거든요. 근데 그러실 필요 없다. 딕셔너리에요. 딕셔너리고 여기 왼쪽에 들어가는게 키고 오른쪽 들어가는게 밸류죠. 그런데이 밸류에서 타입을 명시해 주는게 바로 타입 딕트입니다. 그래서 여기에 컨텍스트에다가 내가 파이썬 같은 경우에는 아무런 데이터 타입이나 다 허용을 하니까 여기에 문자율도 들어갈 수가 있고 뭐 리스트 도큐먼트가 들어갈 수도 있고 여러 가지 형태가 들어올 수 있는데 이걸 타임 명시를 안 해 버리면은 얘가 알 수가 없어요. 아 여기에 문자율이 들어올 건가? 여기에 리스트 도큐먼트가 들어올 건가? 알 수가 없는 거죠. 근데 우리가 이거를 타이핀을 통해서 이렇게 미리 정의를 내려 주게 되는 거예요. 여기 보시면은 걸 가져와서요. 이건 명시해 주는 걸 의미합니다. 그래서 어테이티드 한 다음에 대가로를 쓰고 그다음에 왼쪽과 오른쪽으로 이렇게 구분해서 보시면 되는데 왼쪽에다가는 이렇게 타입을 적고요. 요렇게 그다음에 오른쪽에다가는 이제 문자율로 적을 수가 있어요. 여기 부분도 지금 뭐가 조금 다른데요. 컨텍스트 부분에 오퍼레이터 애드로 이렇게 다 들어가는게 아니라 문자율로 적어 줄 수 있습니다. 그러니까 설명구를 달아 줄 수 있다는 뜻이에요. 우리가 어노테이션 하면은 주석이잖아요. 그래서 주석을 달 수도 있고 이런 리서라는 함수도 달아 줄 수가 있습니다. 우리가 리서 함수도 이전 챕터에서 보셨죠? 그래서 그 내용을 한번 보고 오시면 좋을 것 같아요. 만약에 내가 바이너리 스코어에다가이 리스 함수를 맵핑하지 않고 그냥 요거는 바이너리 스코어다 이렇게 넣어도 되고요. 스코어예 or노 뭐 이런 식으로 커멘트를다는 것도 가능하다라는 거죠. 여기에 예를 들면 answer to the question 이렇게 넣는 것도 가능하고요. 그다음에 여기도 reteved docum먼트 이런 식으로 적어 주는 것도 가능하죠. 그리고이 오퍼레이터 애드라는 부분은요. 리스트에다가 엄밀리 따지면 적어 줘야 돼요. 그래서 우리가 굳이 이거를 쓴다라고 하면은 오퍼레이터. 리스트니까 얘도 오퍼레이터점 애드를 쓸 수가 있는데 문자열에는 안 돼요. 문자열에는 안 되기 때문에 여기에서는 엄밀히 따지만 이게 쓸 수가 없어요. 그래서 이게 잘못 나온 거죠. 여기에다가는 SQL 쿼리. 그리고 얘도 뭐 퀘션 이런 식으로 유저 퀘션 이런 식으로 한번 적어 볼게요. 자, 좋습니다. 이렇게 쌓 봤고요. 저희가이 타입드를 상속받은 그래프 스테이트라는 거를 정의를 해 줬고 여기에 있는 키들만 저희가 활용을 할 건데 나중에 키가 추가가 될 거면 어떡하냐? 그러면은 나중에 그래프 스테이트에다가 여기다가 더 추가해 주시면 되는 거예요. 그런 것들도 물론 가능합니다. 자, 이걸 실행해 보고요. 그다음에 노드 정의하는 부분 올게요. 자, 우리가 노드를 정의할 때는 기본적으로 함수 구조를 가진다. 우리 장표에서도 한번 볼까요? 노드를 어떻게 정의했는지. 자, 노드 정의할 때 저희가 함수로 정의한다라고 했었어요. 나중에 물론 우리가 더 나아가서 클래스를 상속받는 구조로 만드는 것도 가능합니다. 하지만 우리는 아직 입문 단계이기 때문에 먼저 함수로 구현하는 방법을 보시면 되고요. 내가 함수로 잘 구현을 한다 하면은 그다음 단계로 넘어가는 거는 너무나도 쉬워요. 그래서 먼저 여러분들 함수를 보시면 되는데이 함수의 이름도 잘 적어 주시는게 이왕이면 좋고요. 그다음에 입력으로 들어오는 것도 스테이트, 출력으로 나가는 것도 스테이트예요. 그런데 제가 여기에서 말씀드릴게 뭐가 있냐면 자 얘가 입력으로 들어오는 거 스테이트죠. 나가는 거 스테이트잖아요. 그런데 우리가 랭그래프 튜토리얼 같은데 보면은 이게 그래프 스테이트가 안 돼 있고 이런 식으로 돼 있는 경우가 있어요. 리턴한 다음에 컨텍스트의 도큐먼츠 자 얘는 딕셔너리죠. 얘는 타입 디텍트를 상속받은 그래프 스테이트예요. 얘랑 얘랑 결국에는 사실 같다. 어, 같아요. 그러니까 우리가 어, 이거는 어떻게 보면은 좀 취향의 문제일 수도 있을 것 같아요. 뭐 내가 나는 명시적으로 이건 그래프 스테이트를 반환할 거고 그 안에 있는 키에다가 요거를 넣어서 반환할 거야.라고 하면은 이게 낫죠. 자, 그런데 이렇게 하면은 여기에 어 딕셔너리고요. 얘도 딕셔너리인데요. 이렇게 해도 되지만 사실은 저는 좀 더 클린한 코드를 쓰려면 이게 더 맞다라고는 생각이 들어요. 왜냐면 얘 같은 경우에는 우리가 안에 정의되는 키값들을 다 정의를 해 줬잖아요. 그러니까이 안에 클래스에 보면은 하나, 둘, 셋, 넷, 다섯 개가 올 수 있어요가 되는 거잖아요. 그래서 여기다가 다른 키를 넣으면은 이제 타이핀에서 오류가 날 거고요. 만약에 컨텍스트라고 넣으면은 지금 여기에서 이렇게 밑줄 안져 있지만 나중에 이게 타이핀 걸러 주는 데서 어 에러를 내보낼 수도 있어요. 그래서 이게 더 명시적으로는 전 좋다라고 보여지고 하지만 많은 튜토리얼에서는 이렇게 딕셔너리로 반환하는 경우도 있습니다. 그래서 어 저도 여러분들의 혼란을 막기 위해 어떤 튜토리얼은 이렇게도 적어 봤고요. 어떤 튜토리얼은 이렇게도 적어봤어요. 그래서 질문 주신 분도 계셨었는데 어 이거 강사님 이게 아니라 요걸로 적으면은 틀리지 않나요? 무조건 이렇게 적어야 되지 않나요라고 주신데요. 결국에는 두 개가 같다. 여러분들이 이렇게 적으셔도 되고 이렇게 적으셔도 된다. 그런데 희한하기도 생각보다 튜토리얼에서는 요렇게 반환하는 것도 꽤나 많아요. 자, 그래서 정리를 한번 해 볼게요. 입력으로 들어오는 것도 딕셔너리. 그다음에 반환하는 것도 딕셔너리고요.이 구조를 따르면 지금 노드 하나, 두 개, 세 개,네 개, 다섯 개 이렇게 쭉쭉쭉 만들어 낼 수가 있는 거죠. 이렇게 입력과 출력만 약속된 형식이면 돼요. 그 안에 구현은 이제 여러분들이 자유롭게 하시는 겁니다. 자, 이번에는 저희가 수도 코드로 이렇게 어, 작성해 둔다고 했죠. 그래서 노드들을 이렇게 쭉 정의를 해 봤어요. 안에 이렇게 쭉 정의를 했고 노드들을 좀 많이 생성을 해 놨죠. 자, 이걸 한번 실행해 볼게요. 자, 다음으로는 우리가 그래프 정의 부분입니다. 자,이 부분인데요. 이것도 너무 쉬워요. 사실은 너무 쉬운데 어, 우리가 스테이트 그래프 해 가지고 그래프 스테이트를 넣었습니다.이 스테이트 그래프는 뭐냐면 우리 상태 그래프를 만드는 거 랭그래그래프 그래프의 스테이트 그래프에서 가져왔어요. 여기 안에다가 뭘 넣어 주는 거냐면 우리의 상태값을 넣어 줘야 돼요. 그래서 우리가 상태값을 여기에서 그래프 스테이트로 정의를 했거든요. 그래서이 그래프 스테이트를 여기에다가 넣어 주시면 됩니다. 그래서 워크플로우를 하나 생성을 해 주고요. 뭐요 워크플로우라고 하는데도 있고 앱이라고 하는데도 있고 그래프라고 하는데도 있어요. 뭐 이거는 변수니까 여러분들이 자유롭게 정하시면 되겠습니다. 자, 그런데 우리가 상태 정의를 하고 먼저 노드 추가를 해 줘야 돼요. 노드 추가하는 방법 왼쪽에다가는 노드 추가 이름을 적어 주시면 되는데 한글도 넣어도 상관없어요. 근데 대부분은 이제 영어로 적기 때문에 이왕이면 영어로 적어 주시는게 좋을 것 같아요. 그리고 오른쪽에다가는 함수의 이름을 적어 주시면 되는데요.이 리트리브라는 함수는 우리가 위에서 요런 식으로 이제 정의를 했었죠. 여기에 있는 노드들이 다 정의가 되면이 노드의 이름을 여기 노드에다가 추가만 해 주시면 되는 거예요. 자, 그래서 우리가 첫 번째로 만들어 볼 거는이 컨벤셔널 레그라는 건데 컨벤셔널 레그는 뭐냐면 우리가 가장 기본적인 레그 있죠? 그냥 리트리브 해서 엔서 제너레이션 하는 거 가장 간단한 구조를 한번 만들어 볼 거예요. 자, 그래서 우리가 워크플로우를 생성을 하고요. 스테이트 그래프를 만들고 여기에다 우리 상태 정의한 걸 넣어 주고요. 노드 추가를 할 때 리트리브라는 이름으로 이건 왼쪽에 있는 건 별충입니다. 리트리브라는 노드를 넣어 주고요. 그다음에 우리가 GPT한테 답변 요청을 해 줄 거예요. 답변을 만들어 낼 거고 그다음에 답변을 만들어 냈으면 렐러스 체크를 할 겁니다. 관련성 체크를 할 거고요. 관련성 체크를 통과를 하게 되면은 마지막으로 결과 종합을 할 겁니다. 자, 이렇게 노드가네 개를 정리를 해 줬고 얘를 이제 우리가 순차적으로 연결할 거예요. 자, 우리가 연결을 할 때는요. 처음에 있는 노드부터 우리 머릿속에 그려 놓은 노드들을 순서대로 연결만 지으면 됩니다. 나는 만약에 리트리브 노드에서 GPT 요청으로 가겠다. 그러면요 왼쪽게 프롬이고요. 오른쪽에요. 그러니까 리트리브에서 GPT 요청으로 보내겠다라는 거죠. 그다음에 GPT 요청은 GPT 릴러스 체크로 보낼 거고 GPT 릴러스 체크는 결과 종합으로 보내겠다. 마지막으로 결과 종합에서 엔드로 보내겠다. 이렇게 연결만 해 주시면 됩니다. 나머지 주석은 일부러 남겨 놓은 거예요. 자, 이렇게 되고 엔트리 포인트 지정을 해 줘야 되는데 우리가 원래 이제 스타트라는 걸 가져올 수도 있습니다. 여기다가 이걸 가져와서 주면은 엔트리 포인트 굳이 연결 안 해도 되지만 우리가 스타트를 별도의 노드로 만들어 주지 않았잖아요. 그렇기 때문에 엔트리 포인트를 지정해 주면 돼요. 여기서 시작점이 리트리브거든요. 그래서이 리트리브라고 넣어 주고 메모리 세이브 생성해서 어 메모리 하나 만들어 주고요. 그다음에 메모리를 체크포인터에다 넣어 주고 그래프를 생성해 주시면 됩니다. 자, 요거 한번 실행해 볼게요. 실행해 보면은 우리가 머릿속에 그렸던게 그대로 비주얼라이제이션이 되면서 우리가 만들어 놓은 흐름이 만들어지게 되는 거예요. 그래서이 흐름을 보시게 되면은 처음에 유저가 질문이 오겠죠? 그러면이 질문이브 문서 검색을 수행하게 될 거고요.이 검색된 문서와 질문을 가지고 GPT한테 요청을 하게 됩니다. 자, 여기서 중요한게 뭐냐면 우리 상태값들을 전달을 하잖아요. 우리가 질문이 들어오면 그 질문을 퀘션에다 담아 줄 거고 그 질문을 가지고 꺼내서 검색을 하겠죠. 리치브 노드에서이 리치브 노드에서 검색할 건데 여기에서이 질문 상태를 꺼내서 그걸 가지고 리트리브해서 리치브 되는 결과를 컨텍스트한테 넣어 줄 거예요. 그러면 우리가 지금 뭐가 채워졌냐면 컨텍스트랑 패션이 채워진 상태거든요. 자, 이게 채워졌으면 그다음에는 그다음에는요 단계 있죠? GPT 요청할 때 우리가 컨텍스트라는 키와 그다음에 퀘션이라는 키가 지금 채워져 있는 상태니까요 두 개를 가지고 GPT한테 답변 요청을 수행을 하는 거예요. 우리가 알고 있는 일반적인 매그 프로세스를 따르게 되는 거죠. 그래서 이제 답변이 나오면은 엔서 부분이 이제 채워지게 됩니다. 답변이 나왔으니깐요. 이게 새롭게 채워지게 되면 얘를 가지고 이제서 to the question 체크를 할 수가 있죠.이 이 엔서가 패션에 대한 답이 맞느냐 이거와 혹은이 엔서가 컨텍스트를 기반으로 만들어진 거냐 요거에 대한 렐러스 체크를 할 수가 있습니다. 관련성 체크를 한다라는 얘기죠. 그래서 관련성 체크를 통과를 하고 그다음에 최종적으로 결과 종합을 하게 되면은 이제 최종 엔서로 나오게 되는 구조예요. 이게 어떻게 보면은 우리가 일반적으로 알고 있었던 우리가 랭체인에서도 구현을 했었던 가장 기본적인 구조라고 보시면 됩니다. 저희가 그거를 이제 랭그래프로 옮겨 놓은 거예요. 그렇죠? 자, 그런데이 랭그래프의 장점은 사실이 정도 수준을 구현하기에는 물론 우리가 그냥 랭체인으로 구현해도 좋습니다. 우리가 굳이 노드를 만들지 않아도 된다라는 소리죠. 자, 그런데 우리가 랭그래프를 쓴다라는 거는 우리가 원하는 흐름대로 자유자로 변할 수 있다는 거예요. 그래서 우리가 이럴 수도 있잖아요. 만약에 재검색하는 노드를 추가를 해서 재검색하는 로직을 추가해 보고 싶어요. 자, 그러면 저는 어떻게 할 거냐면 여기에 있는 2번의 주석만 생각하시면 돼요. 그래서 요거를 일단 오프를 하고요. 주석을 딱 쳐 주시고 그다음에 여기서부터 여기까지를 주석을 해제를 해 줄게요. 자, 주석은 참고로 컨트롤 슬래시 아니면 맥북 쓰신 분들은 커맨드 슬래시를 해 주시면 됩니다. 자, 그래서 주석 해제를 해 주고요. 그다음에 위에는 나머지 건들게 없죠? 네, 없습니다.요 상태에서 다시 한번 실행을 해 볼게요. 자, 그러면 지금 우리가 순식간에 재검색하는이 흐름이 만들어진 걸 볼 수가 있어요. 그러니까 우리가 랭체인에서는 이런 흐름들을 바꾸려면 처음부터 다시 코딩을 해 줘야 되거든요. 굉장히 어려워요. 그런데이 랭그래프라는 거는요. 내가 이런 식으로 원하는 흐름들을 우리가 불과 1분도 안 걸렸죠. 바로바로 만들어서 테스트할 수 있다라는 거예요. 자, 그러면 우리가 재검생 노드가 없었을 때는 어떤 흐름이었냐면이 렐러스 체크의 결과가 좋든 싫든간에 무조건 받아들여야 돼요. 무조건 엔서로 나오는 그런 구조였거든요. 이게 없기 때문에 그냥 이게 패스를 하든 페일을 하든 그냥 유저는 그냥 답변을 받을 수밖에 없는 상태인 거예요. 근데 우리가 재검색이라는 노드를 추가하면서이 패스를 만들어 냄으로써 우리가 뭘 할 수가 있냐면이 관련성 체크를 한 다음에 관련성에서 만약에 페일이났다 하면은 다시 리트리브로 보낼 수가 있는 그런 흐름을 만들어 준 거예요. 굉장히 순식간에 만들어 준 거죠. 그래서 여기 흐름에 보면은 애드 컨디셔너 엣지라고 해서 조건부 엣지라는 거를 추가를 해 줬습니다. 그래서이 조건부 엣지를 쓰는 방법을 한번 보시면은요. 자, 먼저이 조건부 엣지의 시작점을 볼게요. 시작점은 결과 종합 노드거든요. 그럼 여기 조건부 엣지의 시작점은 결과 종합 노드죠. 자, 여기 잘 보세요.이 결과 종합 노드에서 지금 두 갈래로 갈라집니다. 이게 바로 조건부거든요. 어떤 조건에 따라서 일로 갈지 절로 갈지 이게 결정지는 거죠. 이거의 시작점이 결과 종합 노드이기 때문에 우리가 첫 번째로 넣어 주는 거는 결과 종합 노드라고 넣어 줬어요. 여기 위에서 정리한요 노드죠. 자, 그다음에 두 번째로 와야 되는 거는 디시전입니다. 이거는 한마디로 어 ifl스로 구성이 된 하나의 함수 하나의 함수를 넣는다라고 보시면 돼요. 이게 정확한 그 목적 그 형태는 뭐냐면 여기에 지금 보시면은 콜러블이라고 나와 있을 겁니다. 여기에 한번 들어가서 볼게요. 보시면은 콜러블이라고 나와 있죠. 그래서 콜러볼이라는 거는 우리가 이제 함수라고 이해하셔도 좋습니다. 호출 가능한 이런 의미를 가지고 있죠. 그러면은 디시션이라는 함수로 한번가 볼게요.가 보면 자, 여기에 이제 결정이라고 나와 있는데 여기에 사실은 이제이 헬스 조건문이 들어가야 되는데 지금 수도 코드이다 보니까 이런 식으로 나왔어요. 자, 그런데 우리가 지금 여기에 재검색과 종료가 나와 있잖아요. 그러면 이거에 반환되는 형태는 어떻게 돼야 되냐면 여기에 여러분들의 어떤 로직이 로직을 추가 할 수가 있고요. 그다음에 여기에 if 어쩌고저쩌고으면 리턴 한 다음에 여기에다가 만약에 관련성 체크를 통과를 했으면 어 종료라고 해 볼게요. 종료 종료. 그다음에 통과를 못 했으면은 우리가 어떻게 해 줄 거냐면 재색이라고 해 줄 거예요. 재색. 자, 이렇게 넣어 줬습니다. 이거 지어 볼게요. 자, 그러면 이렇게 되는 거죠. 우리가 스테이트에서 바이너리 스코어 안에 렐러스 체크의 결과가 담길 거예요. 이걸 통과를 했으면 예라고 담길 거고 통과를 못 했으면 노라고 담겨 있을 거예요. 자, 그런데 이걸 통과를 했으면 리턴 종료 종료라는 문자를 해 주고 이걸 통과를 못 했으면 재검색이란 걸 반환을 해 줍니다. 자, 그러면이 재검색과 종료를 반환을 받잖아요. 이게 왼쪽에 있는 키로 들어가는 거예요. 키로 들어가서이 함수의 실행 결과가 만약에 제 검색이라면 리치브 노드로 보내 주세요라는 거예요. 그다음에이 실험의 결과가 종료라면 and이 모든 그래프를 종료를 해 주세요. 이런 흐름이 만들어지게 되는 거죠. 자, 그래서이 결과 종합을 하고 이게 별로오면은 제 검색 들어가고요. 그다음에 좋으면은 이제 종료로 들어간다. 이런 흐름까지 이제 만들어 본 거죠. 자, 여기까지 해서 이제 2번 재 검색을 만들어 보는 것까지 저희가 해 본 거예요. 해봤는데 어, 여기서 이제 좀 더 나아가 볼게요. 다음으로는 우리가 멀티 LLM 멀티 LM 한번 보도록 하겠습니다.이 멀티 LLM은 우리가 LM을 하나만 쓰는게 아니라 LM을 하나 더 추가해 보겠다는 거예요. 우리가 만약에 지금 GPT를 쓰고 있는데 여기에다가 클로드에다가도 요청을 해서 답변을 받아서 두 개를 나중에 비교를 하거나 아니면 두 개의 답변을 합치거나 이렇게 응용할 수가 있거든요. 자, 그러면은 멀티르 한번 추가해 보죠. 자, 여기 오른쪽에 3번으로 나와 있는 곳에 주석을 먼저 해제를 해 주실게요. 그래서 클로드 요청하는 노도를 하나 추가를 해 주시고 클로드에 대한 관련성 체크하는 부분들도 하나 추가해 보도록 하겠습니다. 자, 다음으로는 어, 우리가 3번으로 나오는게 리치브의 클로드 요청이라고 나와 있는데요. 이거는 뭐냐면 우리가 클로드 요청 노드를 추가했기 때문에 리트리브에서 지금 하나는 GPT로 가고요. 다른 하나는 클로드로 가게 되죠. 그러면 이렇게 병렬 분기가 실행이 되게 되는 거예요. 그래서 여기에 보시면은 이제 리트리브 노드가 있고요. 있고 여기에 이제 나눠져서 근데 이게 이거는 조건부가 아니에요. 그러니까 우리가 컨디셔널 엣지라는 거는 둘 중에 하나만 실행되는 건데 얘 같은 경우에 둘 다 실행을 하는 거예요. 병렬적으로. 그래서 하나는 GPT로 신호를 보내고 다른 하나는 클로드로 신호를 보내는 이런 구조를 만들게 되는 거죠. 자, 다음으로는 우리가 클로드 요청에서 클로드 러스 체크로 보낼 거고요. 클로드도 답변을 했으면 이거에 대한 관련성 체크를 해야 되고 그다음에 결과 종합까지 해야 되죠. 그러면 이게 최종적으로 GPT의 렐러스 체크 결과도 결과 종합에 모이게 되고요. 클로드의 렐러스 체크도 결과 종합에 모이게 되는 거죠. 자, 이런 식으로 해서 결과 종합이 모여서 이제 끝내 주는 그런 흐름을 만들어 줬습니다. 자, 이거를 실행해서 보면은요. 이제 이런 식으로 만들어지는 거예요. 우리가 이렇게 새로운 흐름을 만들었는데 굉장히 간단하게 그냥 만들어져 버리잖아요.이 리트레브에서 원래 단일 답변, 단일 GPT 하나의 모델에 대한 답변 요청을 해서 받았는데 거기에다가 이제 모델 하나를 병렬적으로 이렇게 추가를 한 구조가 순식간에 완성이 됐습니다. 자, 마지막으로 하나 더 해 볼 거는 이제 쿼리 제작성 노드를 한번 추가를 해 볼 거예요. 그러면 여기에 4번에 있는 거 주석 해제해 주시면 되고요. 리라이트 쿼리라는 노드의 이름으로 리라이트 쿼리라는 노드를 추가를 해 봤어요. 결국엔 함수를 추가를 해 주는 거죠. 그리고 이거를 추가를 해 줬으니까 리라이트 qu리의 리트리브 부분으로 연결하는 거를 하나 연결을 해 주시고요. 그리고 얘는 다시 주석을 해 주시고 마지막에 나와 있는 4번만 요렇게 풀어 주시면 되겠습니다. 자, 그래서 이거를 왜 바꿔 줬냐면 우리가 결과 종합을 했을 때 재검색을 할 때 제검색이 나오면은 리트리브를 보내는게 아니라 리라이트를 해서 리라이트를 한 다음에 그다음에 제 검색이 들어갈도록 그런 식으로 쿼리를 제작성하도록 그래야지 검색되는 결과가 바뀔 거잖아요. 그런 식으로 흐름을 바꿔 준 거예요. 그래서 여기 보면은 이제 흐름이 어떻게 달라졌냐면 우리가 이전까지는 동일했거든요. 리트브를 하고 병렬적으로 하나는 GPT에 요청, 하나는 클로드에 요청해서 각각을 릴러스 해서 결과 종합을 합니다. 그런데이 결과 종합의 결과가 별로였어요. 그러면은 재검색이 떴는데 이때 그냥 재검색을 하는게 아니라 쿼리를 제작성하는 거죠. 원래 있는 질문을 제작성을 해서이 제작성된 결과를 다시 리치브로 넣어서이 과정들을 이제 수행하게끔 이런 식으로 만들어 주게 되는 겁니다. 자, 그래서 요렇게 만들어 봤고요. 우리가 수도 코드로 해 봤지만 여러분들이 여기에서 노드를 추가해 보고 뺐다 꼈다 해 보면서이 그래프들을 다양하게 설계해 보는 연습을이 수도 코드를 통해서 해 보시는게 좋아요. 그래서 이렇게 한번 다양하게 흐름 잡는 거 한번 해 보시고요. 밑에는 또 SQL 레그의 어떤 그 수도 코드를 사용한 흐름 잡는 거를 제가 샘플 코드로 넣어 놨어요. 그래서 요거를 실행해 보고 그래프를 시각화해 보면 SQL 우리가 쿼리 밸리데이션 하는 것도 꽤 복잡해요. 나중에 질문 들어오고 이걸 가지고 이제 테이블에 자연어를 가지고 SQL 커리문을 만들어서이 결과를 조회를 하는 거니까 먼저 조회를 하려면 테이블 정보 있어야죠. 그다음에 SQL 커림은 만들고 엑스큐트 해야죠. 엑스큐트 실행 결과 밸리데이트 한지 봐야죠. 검증해야죠. 그다음에 별로 오면은 리라이트 question션에서 어 넣거나 아니면 리라이트 쿼리를 바로 해야죠. 그래서 요런 식으로 뺑글뺑글 도는 구조. 그다음에 만약에 패스를 했다. 검증 쿼리가 올바르게 쓰여졌다라고 검증이 끝나면 이걸 GPT에 요청을 해서 그니까 검색된 결과가 있겠죠. 그래서 결과를 GPT한테 요청을 해서 릴레버스 체크해서 끝내주는 요런 식의 이제 구조를 짜면 얘가 알아서 쿼리 밸리데이션까지 이렇게 쭉 순해를 하면서 돈단 말이에요. 그래서 이런 복잡한 흐름들도 우리가 랭그래프로 어렵지 않게 만들 수가 있다라는 내용을 보여 드리기 위해서 이렇게 예제로 만들어 놨습니다. 자 여러분들이 이제 그 안에 들어가 있는 함수의 구현체는 없거든요. 그래서 여러분들만의 어떤 다양한 흐름들을 만들어 보시는 걸 연습을 하시고요. 우리가 아직 구동하는 건 아니니까 이게 실제 구동을 했을 때 오류가 날 수는 있겠죠. 하지만 처음에는 이런 흐름들을 좀 만들어 보는 연습을 먼저 손해 있게 하시면 그 이후 문제는 더 쉽게 풀릴 수가 있습니다. 네. 이번 시간에는 저희가 처음이죠. 처음으로 어 프롬 스크래치부터이 랭그래프를 활용한 빌딩 그래프 하는 방법에 대해서 알아봤습니다. 네. 안녕하세요. 이번 시간에는 나이브 레그. 나이브래그를 랭그래프로 구현해 볼 건데 이전에 했던 방식과 다른 점은 이전에는 수도 코드로 진행을 했었어요. 그런데 이번에는 실제로 동작하는 그래프를 만들어서 한번 돌려보도록 하겠습니다. 어 저희가 이번 튜토리얼 2번부터 5번까지는요. 여기 나와 있는 2번부터 5번까지는 사실은 쭉 이어지는 내용이에요. 그래서 여러분들이 2번부터 5번까지는 뭐 전혀 다른 파일이 아니라 하나로 이어지는 흐름을 가진다라는 거를 염두해 두고 보시면 좋은데 2번부터 3번 4번 5번 뭐가 더 추가가 되냐면 2번에는 기본적인 라이브 래그에 3번에서는이 라이브 레그에다가 플러스로 렐러스 체크를 하는이 컨디셔널 엣지를 추가하는 방법에 대해서 알아볼 거고요. 다음으로는 웹서치를 하는 실시간으로 웹에서 검색을 해서 그 정보들을 바탕으로 답변 생성을 하는 그러한 로직을 추가해 볼 거고 마지막으로 쿼리 리라이트를 해서 우리 질문을 좀 더 잘 예쁘게 만들어서 리라이트 해서 추가를 해 주는 그 로직을 한번 추가를 해 볼 거예요. 그래서 추가되는 로직마다 제가 이렇게 빨간색으로 어 표시를 해 놨습니다. 그래서 여러분들이 요거를 보시면서 한번 진행해 보시면 좋을 것 같아요. 그래서 우리가 처음에는 어 2번 2번 파일을 열어 주시면 되겠습니다. 자 우리가 어이 나이브레그 나이브레그라고 하는 거는 쉽게 얘기해서 question이 들어오면 사용자의 질문이 들어오면 우리가 일반적으로 알고 있는 그 여덟 단계의 래그를 수행하는 것과 동일하다라고 보시면 돼요. 그런데 우리가 바로 노드 생성할 때 여기에 1번 노드, 2번 노드 노드 두 개만 생성을 할 거거든요. 그런데이 리트브 하기 위해서이 중간 단계들은 저희가 다 생략을 해 놨습니다. 그래서 제가 만들어 놓은이 PDF 리트리버 체인을 사용해서 우리가 리트리버 가져오고 체인을 가져와서 활용할 거고요. 요거에 대한 내용을 저희가 이전 강의에서 다뤘기 때문에 별도의 설명 없이 넘어가도록 하겠습니다. 자, 그래서 굉장히 심플해요. 질문이 들어오면 리트리버 사용해서 검색을 하고 그다음에 검색된 문서를 제네레이트한테 노드한테 넣어 줘서 요거를 가지고 이제 답변 생성을 해 볼 건데요. 먼저 요걸 진행하기 위해서 환경 설정해 주시고 그다음에 랭스미스 추적도 한번 진행해 보도록 하겠습니다. 자, 다음으로는 우리가 기본 PDF 기반 리치버 체인을 생성을 할 건데 요거는 우리가 이전에 봤던 내용이라 동일해요. 그래서 요거 곧장 생성해 주시면 되겠고요. 우리가 사용할 PDF 문서는 여기에 들어가 있습니다. 자, 그러면 PDF 언더바 리트리버에는 검색기를 담아 줬고요. 그다음에 체인은 PDF 체인에다가 넣어 줬어요. 자,요 상태로 리트리버에 인보크를 해서 제대로 동작하는지 한번 볼게요. 엔스로픽에 투자한 기업과 투자 금액을 알려 주세요. 요렇게 인크를 하게 되면은 제가 기본값으로 설정에 열 개 문서를 가져오게끔 해 놨거든요.이 혹시이 내용이 궁금하신 분들은 레그 밑에 보시면은 PDF 쪽에가 보시면은 PDF 체인에 K가 10으로 설정이 돼 있기 때문에 열 개를 가져오는 거예요. 그런데 나는 열 개가 아니라 나는 이거를 뭐 다섯 개로 바꾸고 싶다. 그러면 다섯 개로 바꿔서 적용해 보시면 되겠습니다. 자, 우리는 일단 열 개로 지정이 되어 있는데요. 자, 그러면 10열 개 문서를 가져왔죠. 위에서부터 관련성 높은 정보부터 쭉 내림차순으로 가져온 거예요. 자, 요거를 우리가 검색된 결과를 설치 리트에다가 담아줬잖아요. 그러면은이 문서들을요. 문서들을 넣고 퀘션에다가 우리 질문들 넣어 주고 채티 스토리 어, 멀티처인인데이 대화 내용은 어, 생략하고 들어갑니다. 그래서 요거를 실행해서 결과를 보시게 되면은 어, 요렇게 나오죠. 구글은 엔스로픽에 최대 20억 달러를 투자하기로 합의했으며이 중 5억 달러를 우선 투자를 했다. 구글은 2023년도에 2월에 이미 5억 5천만 달러를 엔스로픽에 투자한 바 있다. 뭐 이런 식으로 이제 쭉 나오는 거죠. 그래서 솔스까지 이렇게 넣어 놨습니다. 자, 이렇게 잘 나오는 것까진 봤는데 우리가이 과정을 한번 랭그래프로 만들어 볼 거예요. 자, 그래서 먼저 스테이트 정의를 해 주시면 되는데 스테이트 부분에 어, 그래프의 노드와 노드강 공유하는 우리 상태를 의미한다. 그러니까 제가 노드에서 노드는 각각이 다른 회사라고 했죠. 전혀 각각이 무슨 액션을 하는지 전혀 몰라요. 그러면 이전 노드에서 처리된 결과를 다음으로 전달할 때 우리는 스테이트에다가 그 작업된 결과들을 담아서 담아서 마치 택배처럼 전달을 해 주는 거예요. 그러면이 다음 노드가이 스테이트를 전달을 받았잖아요. 그럼 택배 상자를 열어 봅니다. 열어봤더니 아 이전 노드에서 요러 요러한 작업을 했구나를 알 수가 있게 돼요. 그러면이 정보들을 활용해서이 해당 노드에서 해당하는 작업들을 진행하게 되는 거죠. 그래서이 스테이트를 정의가 중요하고이 스테이트는 우리가 전달하는 내용만 여기 안에다가 넣어 주면 돼요. 우리가 굳이 전달 안 해도 되는 내용들까지 스테이트에 담아 줄 필요는 없게 되는 거죠. 자, 그래서 우리가 사용자의 질문이 들어오면은 그 질문을 퀘션에다가 저장을 해 줄 거예요. 그리고 컨텍스트에다가는 검색된 문서를 넣어 줄 거고요.이 문서는 문자율로 들어가 있어요. 자, 그런데 우리가 보면은요. 검색된 문서가 원래 리스트예요. 리스트 도큐먼트 형태예요. 그래서 원래 저거를 어, 다 넣어 주려면 어떤 식으로 들어가야 되냐면 이런 식으로 들어가야죠. 프롬 랭체인의 코어에 도큐먼트에 임포트 도큐먼트를 해서 어 타이핑에도 리스트를 넣어 볼게요. 이렇게 해서 원래 같았으면은 검색되는 문서가 도큐먼트의 리스트 형태니까 여기에다가 그대로 리스트 도큐먼트 이런 식으로 들어가야 돼요. 이걸 그대로 넣어 줄 거면. 근데 여기에서 제가 스트링으로 문자열로 그냥 바꿨다는 건 무슨 의미냐면이 문서들을 나중에 문자열 변환을 해서 하나의 문자열 형태로 내가 가공을 해서 내가 포매팅을 해서 넣어 주겠다라는 의도죠. 그래서 요렇게 넣어 준 거고요. 그다음에 메시지는 우리 리스트 메시지스 들어가는데 애드 메시지스 리서 함수입니다. 혹시 리서 함수 내가 지금 처음 들어봤다 하시는 분들은 요거 리서 함수 강이 있어요. 랭그래프의 초반에 나오거든요. 요거를 한번 보고 오시면 좋을 것 같아요. 그래서이 애드 애드 메시지스라는 리스 함수를 쓰면 우리가 메시지 리스트를 반환을 해 주면 기존의 리스트에다가 신규 메시지를 추가를 해 줘요. 그래서 계속해서 누적이 될 수 있도록 만들어 준다는 거죠. 자, 요걸 실행해 주시고요. 그다음에 노드 정의 한번 해 볼게요. 우리가 노드 쓸 거는 하나, 그다음에 두 개. 나머지는 없죠. 왜냐하면 우리가 위에서 그림을 그릴 때 리트리브 노드 하나랑 제너레이터 노드 두 개만 구성을 했잖아요. 그러니까 우리가 만드는 노드도 함수도 두 개가 되는 거예요. 그러니까이 랭그래프에서는 뭐가 중요하냐면 여러분들이 이런 것들을 만약에 구현한다 하기 전에 메모장에다가 여러분들이 한번 이렇게 그려 보시는 거예요. 어, 나 이런 식으로 설계할 거야. 그린 다음에이 노드의 개수 이퀄함수의 개수가 나와 주면 되는 거죠. 자, 그래서 우리 지금 노드 두 개 그렸으니까 요렇게 하나랑 그다음에 밑에도 보시면은 두 개 이렇게 만들어 놓셨어요. 처음에 리트리브 도큐먼트라는 노드는요. 말 그대로 우리가 질문을 받으면이 질문을 리트리버한테 넣어 가지고 인크를 해서 문서 검색된 결과를 가져올 거예요. 자, 그런데 여기에 포메터스라는 함수가 보여요. 얘가 뭐 해 주는 거냐면 문서를 포매팅해서 하나로 합쳐 주는 역할 합니다. 자, 그런데 여러분들이 이거를 그냥 합쳐 주나 보다 하고 넘어가셔도 상관없죠. 우리가 코드는 어차피 제가 완성용으로 다 드리기 때문에 구동에는 문제가 없을 거예요. 그런데 여러분들이 만약에 어 여기에 이러한 코드가 있는데 내가 어떤 내가 만들지 않았으니까 어떤 결과로 나오는지 모르겠으면 항상 이거를 별도로 찍어 보셨으면 좋겠어요. 그래서 아이 나오는 형태가 어떻게 바뀌는구나 그거를 머릿속에 가지고 계시면 좋거든요. 그래서 제가 그걸 어떻게 하는지 한번 보여 드릴게요.이 함수 안에 있으면이 출력하는게 힘들어요. 그래서 저 같은 경우에는 이걸 따로 빼다가 요것만 따로 빼다가요. 뭐 예를 들면은 요거 두 개가 궁금하다 하면은 여기다가 이제 따로 빼 주는 거죠. 자, 이렇게 따로 빼 주는데 지금 노란색이 켜져 있는 거는 이게 아직 정의가 안 된 거죠. 얘는 요렇게 정의해서 가져올게요. 자, 이건데 그럼요 라스트 question션 레이티스 퀘션은 우리가 변수가 없잖아요. 아직 question이 안 들어왔으니까. 우리가 임의로 하나 넣어 주는 거예요. 뭐 여기다가 삼성전자가 개발한 생성형 AI의 이름은 자, 여기 한번 보세요.이 얘 주석하고 결과 한번 보죠. 그럼 리트리뷰드 도큐먼트에 문서 열 개가 들어가 있을 거예요. 자, 요거를 출력해 보면은 열 개가 이렇게 나온다고요. 나오는데 우리가 에딱스는 이건 제가 만들어 놓은 함수인데 여기에다가 얘를 한번 씌워 보는 거죠. 자, 원래이 코드가 있었잖아요. 씌워 보면 얘가 어떻게 바뀌냐면 이렇게 하나의 문자율로 바뀝니다. 자, 얘는 뭐냐면 우리가 문서들을요. 이렇게 하나로 연결을 해서 XML 형식의 태깅을 씌워서 만들어 주는 변환기예요. 근데 우리가 제가 이거를 왜 포매팅해서 하나의 문자율로 합쳤냐? 항상 Y가 중요하거든요. 사실 이거 안에도 답변이 잘 나올 수 있어요. 그런데 제가 이렇게 포매팅해서 넣어 주는 걸 좋아하는 이유는요. LM이 더 잘 알아들어요. 그러니까 우리가이 문서 도큐먼트 형태 이게 그냥 문자율로 그냥 들어가 버리거든요. 이거보다도 더 좋은 거는 우리가 필요한 정보들만 그 속아내서 도큐먼트라는 걸로 여기서부터 여기까지는 하나에 검색된 결과야라는 걸 알려 주면서 우리가 필요한 메타데이터만 끄집어내는 거예요. 그러니까 우리가 문서에도 보면은요. 메타데이터가 되게 많거든요. 소스도 있고 파일패스도 있고 여기 가면은 되게 많아요. 근데 우리가 어서나 크리에이터나 이런 것들 다 필요가 없잖아요. 괜히 불필요한 토큰 낭비만 한다라는 거죠. 굳이 이거를 매번 토큰 낭비하면서 만들어 줄 이유가 전혀 없습니다. 그래서 우리가 필요한 메타데이터 우리는 뭐가 필요하느냐? 어, 여기에서는 이제 페이지 정보 소스도 여기에 넣어 줬네요. 소스. 소스 하면 이제 파일명과 페이지 정보만 있으면 되거든요. 우리가 출처 밝힐 때. 어, 뭐 어서 정보도 있으면 좋겠죠. 근데 일단 요거 두 개만 넣어 준 거예요. 그래서 메타데이터는 요거 두 개 넣어 주고 그다음에 가져온 콘텐츠는 컨텐트라는 XML의 형식 태깅을 걸어서 여기다 넣어 줘서 여기서부터 여기까지 하나의 검색된 문서입니다. 이렇게 구분자까지 줬어요. 그러니까 이렇게 구분자까지 주게 되면은 우리가 구분자를 안 줬을 때는 여기에 있는 문서 정보의 끝과 여기가 이어지게 되면서 할루스네이션으로 이어져요. 왜냐면이 문장의 끝과요 문장의 처음이 마치 연결되는 것처럼 보일 수가 있거든요. 근데 우리가 이렇게 태깅으로 감싸게 되면은이 두 개 문서는 전혀 다른 문서야라고 알려주는 효과까지 갖게 되는 거예요. 그래서 이렇게 포매팅이라는 함수를 해서 열 개의 문서를 하나의 문자율로 이렇게 예쁘게 포매팅을 해서 어 하나로 만들어 줬어요. 그래서 얘가 하나의 문자율이기 때문에 우리가 컨텍스트에 리스트 도큐먼트로 들어가는게 아니라 그까 보시면은 str로 들어갔다 이렇게 보시면 되겠죠. 자, 좋아요. 자, 요렇게 우리가 확인해 보시라는 겁니다. 확인해 보면 이렇게 나온다는 걸 알 수가 있고요. 자, 이게 이해됐으면 넘어가 보죠. 자, 이렇게 해서 컨텍스트에다 넣어 줍니다. 여기에서도 많이 나오는 질문 중에 하나가 리턴에 우리가 그래프 스테이트의 컨텍스트 이렇게 넣어 주는 것도 되고요. 그다음에 얘 얘처럼 이렇게 넣어 주는 것도 돼요. 그래서 여러분들의 선택이니까 편하신 대로 해 주시면 되겠습니다. 자, 이렇게 컨텍스트 키에다가만 반환을 해 주면 우리가 스테이트에 여기 있는 스테이트에 얘만 얘만 써지는게 아니라 기존에 있던 값은 계속 누적이 되는 거예요. 누적이 되고 해로 반환되는 키값에는 어 요거에 추가가 되는 개념인 거죠. 그래서 퀘션은 이미 들어와 있고 컨텍스트만 반환하면 돼요. 그러니까 정리하자면이 question까지도 반환해 줄 필요는 없다는 거예요. 여기에다가 question은 어 레이트 question션을 넣어 주는 거는 의미가 없다. 큰 의미가 없다. 하지만 우리가 question을 리라이트 하거나 변경 사항이 있었을 때에는 question션에다가 다시 넣어서 반환해 주는 거 의미가 있을 수 있겠죠. 그것만 유념해서 보시면 되겠습니다. 자, 그다음에는 LM 엔서 노드에서는 우리가 제네이션 해 주는 거예요. 자, 이전에 보세요. LM 엔서 노드는 어느 다음에 나오는 거냐면 여기에 보면은 우리가 리트리브 다음에 나온다고요. 그러면 여기서 우리가 유추해 볼 수 있는 거는 뭐냐면 아, 리트리브 단계에서 우리가 문서들을 검색을 완료한 상태구나. 그럼이 완료된 것과 질문이 있네. 그러면 이거 두 개를 사용해서 우리가 제네레이션 할 수가 있겠구나. 이런 것들을 우리가 미리 사전에 여기서 확인을 이미 했잖아요. 여기서 제너레이션을 했단 말이에요. 그래서 우리가 했기 때문에 여기에서는 어 우리 question션 레이티스 퀘션 가져오고 스테이트 값에서 꺼내면 되는 거죠. 꺼내고 그다음에 이전에 우리가 컨텍스트 반환했기 때문에 컨텍스트에 우리 문서들 검색된 문서들이 포매팅돼서 나와 있을 거예요. 그럼요 패션과 컨텍스트를 넣어 줘서 어 생성을 해 주면 되고요. 그다음에 우리가이 채트 스토리가 중요해요. 우리가 멀티턴을 구현하기 위해서는이 스테이트의 메시지스에 지금 메시지가 계속 누적이 됩니다. 그러니까 이런 식으로 된단 말이에요. 어이 메시지는요. 멀티턴 대화를 하니까 Q1이 들어오고 엔서 1이 들어오고 Q2가 들어오고 엔서 2가 들어오면 이게 계속 메시지스에다가 누적이 됩니다. 근데 여기서 중요한 거는 어떻게 누적이 돼요? 어떻게냐면 어떻냐면 우리가 메시지스에다가 지금 애드 메시지로 루적크해 주는 걸 해 주고 있잖아요. 그 얘가 답변 생성을 해서 기존에 있는 메시지 유지된 채로 뒤에다가 계속 쭉쭉쭉쭉쭉쭉쭉쭉쭉 붙게 되는 거예요. 그러니까 알아서 멀티턴 구현을 위한 준비가 랭그래프에서는 굉장히 쉽게 되는 거죠. 알아서 누적이 되는 거니까. 그래서 우리가 예전에는 뭐 채 with 런오브 히스토리 막 이렇게 복잡하게 했었는데 전혀 그럴 필요가 없다라는 거예요. 그러면 메시지스에서는 이미 누적이 됐고요.이 메시지스 히스토리 하면은 이걸 히스토리 하는 애로 바꿔줘요. 이거 함수 들어가서 보면요. 여기에 롤 from롬 메시지스라 해서 롤 롤을 설정해 주고 그다음에 메시지 컨텐트를 이렇게 만들어 줘요. 그래서 메시지 히스토리를 만들어 주고요. 얘가 알아서. 자, 얘는 어디서 가져온 거냐면 얘는 테디노트 패키지에 제가 구현해 놓은 거에서 가져오신다라고 보시면 됩니다. 구현이 궁금하신 분들은 데피니션가 보시면 요렇게 들어가 있어요. 자, 그러고 그이 이전까지 했던 대화들을요. 이전까지 했던 대화들을 예쁘게 포매팅을 해서 이거를 채팅 히스토리에다 넣어 줬어요. 그러면이 PDF인은 뭘 알고 있냐면 이전까지 했던 대화의 내용과 이번에 새로 들어온 question다에 컨텍스트를 해서 요거 세 개를 가지고 이제 답변 생성을 해 주게 되는 거예요. 그래서 엔서에다가 이제 리스폰스를 넣어 주게 되고요. 메시지스에다가는 뭘 누적시킨다고요? 이번에 들어왔던 새로운 질문과 그다음에 답변 AI 어시스턴트의 답변 답변을 넣어 가지고 메시지스에다가 추가를 해 주게 되는 거죠. 이렇게 추가를 해 줬고요. 그다음에 이제 어 그래프 생성하는 부분 아엣 연결하는 부분 생성 및 엣지 연결이죠. 요것도 이렇게 바꿔 줄게요. 그래프 생성 이렇게 바꿔 주겠습니다. 자, h 연결 해 줄 건데 먼저 우리가 스테이트 그래프 해서 여기 그래프 스테이트는 우리가 상태 정의한 거 넣어 주기로 했었죠. 그래서 상태 정의한 거를 여기다가 이렇게 넣어 주시면 됩니다. 여기도 지어주고요. 넣어 줬고 그다음에 우리 노드 두 개 심플하게 정의를 해 줄 거예요. 리트리브 도큐먼트 노드랑 그다음에 LM 엔서 노드 추가해 줬고 엣지 연결 간단하죠. 우리 리트리버에서 LM엔 LM 엔서에서 엔드로 보내주는 이렇게 시퀀셜한 구조로 짜봤어요. 그다음에 시작점 설정해 줘야 됩니다. 그래서 리트리브로 시작점 할 거다. 메모리 설정까지 해 주고요. 체크포인트 설정까지 해서 그래프 컴파이 해 주시면 돼요. 자, 다 됐으면 우리가 비주얼라이즈 그래프를 실행을 해서 비주얼라이이션 해 보면 아, 이제 눈에 환하게 보이는 거죠. 리트리버로 들어와서 문서 검색하고 검색된 문서를 LM 엔서로 넣어서 이제 결과를 낸다라는 것까지 우리가 시각화를 해 볼 수가 있었어요. 이렇게 그냥 가장 나이브한 형태 레그가 완성이 됐고요. 이제는 드디어 우리가 그래프를 실행을 해 볼 차례입니다. 우리가 이전에는요. 그래프를 실행까지 옮기진 않았거든요. 그런데 우리가 이번에는 실행을 해 볼 거예요. 그런데 이번에 실행할 때 여기에서 제가 만들어 놓은 패키지 중에서요. 인보크 그래프라는 것과 스트림 그래프라는게 있어요. 이거는 여러분들이 그냥 인보크를 하시기 위해서는 좀 코드가 복잡해요. 얼마나 복잡한지 보여 드리면 어 뭐 많이 복잡한 건 아닌데 우리가 스트리밍 스텝스에 보면은요. 여기에 보면은 이런 식으로 구현이 들어가거든요. 어렵잖아요 코드가. 그죠? 이런 거 보면은 이런 식으로 어렵다고요. 그래서 여러분들이 어려우실 것 같아서 제가 요번에는 인보크 그래프와 스트림 그래프를 만들어 놨어요. 어 근데 이거는 제가 만들어도 너무 잘 만든 거 같아요. 그래서 왜 잘 만들었는지 이거 어떻게 쓰시는지 알려 드릴게요. 자 여기에서요. 여러분들이 일단 question에다가이 질문을 넣어 가지고 질문을 합니다. 이렇게 만들어도 되고 아니면은 인풋트에다가 이렇게 넣으셔도 돼요. 그냥 퀘션스에다가 이렇게 넣으셔도 됩니다. 딕셔너를 상관없어요. 자, 그런데 어, 우리가 제가 이게요 너무 심플해요. 일단 실행해 볼게요. 인보크 그래프를 하면은 얘는요. 여기 보세요. 이렇게 제가 예쁘게 포인팅도 해 놨어요. 그래서 맨 처음에 노드가 리틀브 노드 우리 여기에 보면은 리틀 노드로 들어갔죠. 들어가서 여기에 초록색으로 나오는 거는이 키값 키값이 업데이트가 되면요. 업데이트가 되면이 초록색으로 표기를 해 줘요. 여기서 업데이트란 뭐냐? 얘가 이렇게 키값을 반환을 해 주잖아요. 그럼이 반환된 값은 신규로 업데이트 되는 값이라고 보는 거예요. 그래서이 값만 출력을 해 줘요. 그러니까 나머지 값들은 다 출력하는게 아니라 반환되는 값만요. 그래서이 반환되는 값에 보시면은 컨텍스트에 이렇게 어 컨텍스트 리트리브 한 결과가 담겨 있고요. 그다음에 lm 엔터 노드로 가잖아요. 그럼 최종적으로 이제 엔서를 반환하게 되는데 엔서이 이렇게 나왔다는 거를 우리가 알 수가 있죠. 그래서 인보크 그래프를 수행하면요. 얘가 따다 스트리밍 출력은 안 되지만 우리가 디버깅하기에 좋아요. 여기서 디버깅이란 무엇이냐? 우리 개발자 관점에서 개발을 할 적에이 노드 하나하나의 반환값들을 우리가 모니터링 해야 될 때가 있거든요. 그럴 때에는 인보크 그래프를 쓰시면 좋아요. 왜냐면이 노드가 다 출력이 되고이 노드의 반환값들을 이렇게 확인해 볼 수가 있는 거죠. 이게 좋은데 근데 나중에 우리가이 노드가 되게 복잡해지잖아요. 그러면이 값들이 계속 출력이 되면 이것도 스트레스예요. 그래서 우리가 어 나는 컨텍스트에서 반환값들 너무 기니까 이거는 그냥 생략해 버리고 싶다 하실 수도 있거든요. 그런 경우에는 어떻게 하시면 되냐면 여기에 이제 노드 이름이 있잖아요. llm 엔터 노드가 있고 그다음에 여기에 리트리브 노드가 있잖아요. 여기에다가 쉼표를 하나 더 주시고 내가 출력하고 싶은 노드에 이름만 넣어 주시면 돼요. LM 엔서 이렇게 넣으시면 자 실행해 볼게요. 자 출력을 하게 되면은 어 요것만 깔끔하게 나옵니다. 그러니까 너무 좋은 거죠. 내가 출력하고 싶은 노드만 리스트로 감싸서 넣어 주면 걔네들만 나오기도 하고요. 아니면은 이거를 아예 빼 버리면은 이제 전체 노드가 다 출력이 되는 그런 형태로 제가 구성을 해 놨습니다. 그래서 여러분들이 이렇게 어 개발을 하실 때 각각의 노드에 어떤 출력값이 나오는지 보고 싶다면이 인보크 그래프를 써 주시면 되고요. 인보크 그래프를 쓰는 방법 앱이랑 인풋. 앱은 뭐냐면 우리 그래프요. 우리 여기서 만들어 놓은 그래프 있죠? 요거. 요거 넣어 주시면 되고 그다음에 인풋 인풋는 여기서 만들어 놓은 인풋트 넣어 주시면 되고 마지막으로이 컨피그 컨피그값 넣어 주시면 됩니다. 그래서 요렇게 만들어 봤고요. 자 그런데 우리가 서비스 단계에서는 이렇게 나오는 것보다 llm이 제너레이션하는 부분 있죠? 그러니까 낮변을 생성하는 부분 이거를 기다렸다가 지금은 한 번에 출력을 하거든요. 여기서부터 여기까지 기다렸다가 한 번에 빵 출력을 해요.데 이게 아니라 우리가 서비스 단계에서는 토큰 출력 단위로 가야 된단 말이에요. 따다다 해 줘야 되면은 그때는 뭘 쓰면 되냐면 스트림 그래프를 쓰시면 돼요. 자, 이거의 인터페이스는 제가 똑같이 만들어 놨어요. 위에 보시면요. 앱이랑 인풋트랑 컨피그가 들어가 있고요. 자, 요게 있고 요거를 스트림 그래프로만 바꿔 주시면 돼요. 어떤 차이가 있는지 한번 보여 주죠. 자, 실행을 하면은 자, 얘는 이렇게 토큰 출력이 돼요. 아, 기가 막기가 잘 만들었죠? 예, 제가 이것도 이제 서비스 단계에서 필요에 따라서 이렇게 만들어 놓은 건데요. 어, 얘 같은 경우에는 LRM이 관여하는 부분에 대해서 LM이 스트리밍 출력이 가능하면 걔를 스트리밍하도록 설계를 만들어 놓은 녀석이에요. 그래서 우리가 나중에는 LRM을 중간 단계에서도 쓸 수가 있는데 그 중간 단계에 있는 녀석들도 전부 다 토큰 스트림이 되더라고요. 그래서 우리가 만약에 퍼플렉스티와 같은 UX를 만든다. 중간에 뭐 검색하거나 확인하는 과정에서도 토큰 스트리밍을 하고 싶다 하면은 그때도 스트림 그래프를 써 주시면 됩니다. 그래서 이렇게 두 가지를 만들어 놨고 보통은 여러분들이 개발 단계에서는 인보크 그래프로요 안에 있는 반환된 내용들을 확인한다. 그다음에 실제 서비스 개발할 때는이 스트리밍 스트림 그래프를 통해서 스트리밍 출력을 해 주시면 되겠습니다. 자, 그래서 이렇게 완료가 됐으면은 마지막에 앱의 겟스테이트에 컨피그를 넣고 밸류스를 가져오면은이 아웃풋의 모든 키값들이 담겨 있어요. 여기 아웃풋을 출력해 보시면은요. 아웃풋트 출력해 보시면 모든 키값의 값들이 이렇게 담겨 있거든요. 여기에서 이제 우리가 원하는 값들을 꺼내서 확인해 주시면 돼요. 최종 값이거든요. 그래서 우리가 최종 값의 패션은 이거였고 엔서를 출력해 보면은 이렇게 나온다라는 것까지 확인해 볼 수가 있죠. 그래서 겟스 스테이트 하면은 이제 최종 스테이트를 꺼내는 거예요. 그러니까 우리가 최종 스테이트를 꺼내면 우리가 노드를 다 돌았으니까 마지막 최종단에 다 모든 정보들이 누적된 상태로 있겠죠. 거기에 밸류스를 꺼내 와서 아웃풋에 담고요. 그 얘는 딕셔너리로 되어 있어요. 우리 스테이트니까. 그래서 딕셔너리에 키값으로 꺼내서 값을 하나하나 확인해 주시면 되겠습니다. 네. 그래서 이번 시간에는 우리 02번 파일에 대해서 보셨고요. 아주 간단한 라이브 레그에 대해서 보셨습니다.이 라이브 레그를 랭그래프로 옮겨서 저희가 구형까지 해 봤고요. 실제로 우리가 이번에는 그래프를 실행을 해서 안에 디버깅 하는 방법도 보셨고 그다음에 스트리밍 출력하는 방법까지도 같이 한번 보셨습니다. 네. 네, 안녕하세요. 어, 이번 시간에는 관련성 체크 축하하는 방법에 대해서 알아보도록 하겠습니다. 저희가 이전에 보셨던 02번 파일이랑 연결되는 파일이라고 보시면 좋을 것 같아요. 그래서 저희가 이번에는 관련성 체크를 이전에 수행했던 나이브 래그에다가 중간에 여기 보신 바와 같이이 렐러스 체크하는 로직을 추가해 보도록 할 거예요. 그래서 우리가이 관련성 체크라고 하는 거는이 답변의 문서에 대한 그러니까 여기서 말이 좀 이상한데 답변의 문서가 아니라 우리가 리트리브한 문서죠. 그니까 검색된 문서라고 제가 수정을 해 놓을게요.게 답변의 문서가 아니라 검색된 문서죠. 검색된 문서에 대한 관련성 체크를 수행을 할 거예요. 그래서이 관련성 체크는 누가 하느냐? 사람이 하는게 아니라 우리는 LMS 저지를 쓸 겁니다. 그래서 오픈 AI 모듈을 써 가지고 여기에다 프랑프팅을 해서 그라운드 니스 체크를 줄 거고요. 그래서이 그라운드스 체커를 통해서 우리가 검색된 문서가 질문과 관련성이 있는지를 먼저 체크를 해 줄 거예요. 이렇게 체크를 해서 만약에 관련성이 없다 노라고 나오면은 다시 리트리브를 하도록 유도를 할 거고요. 관련성 체크해서 통과를 하게 되면은 바로 답변 생성을 하도록 요런 흐름으로 만들어 봤어요. 이번 튜토리얼의 목적은 뭐냐면 물론 우리가 그라운드니스 체커를 추가하는 것도 있겠지만 여기에다가 컨디셔널 엣지이 조건문을 추가를 해 가지고이 조건에 따라서 예 or 노에 따라서이 흐름을 분기할 수 있는 그 내용에 대해서 좀 더 상세히 알아보도록 하겠습니다. 자, 그래서 이전에 보셨던 나이브래그 부분은 저희가 대부분 겹치는 내용이기 때문에 바로바로 넘어갈게요. 환경 설정하는 부분과 그다음에요 랭스미스 추적하는 부분 똑같습니다. 이전에 했던 내용이랑 그래서이어서가 보도록 하겠고요. 요거 가져오는 것도 동일해요. 동일하고 그다음에 스테이트 정의하는 부분도 동일한데 여기에 뭐가 추가가 됐냐면 렐러스 부분만 추가가 됐어요. 그래서 이게 관련성이 있다 없다를 체크해 주는이 렐러스 부분이 새롭게 추가가 됐다. 이렇게 이해를 해 주시면 되겠고요. 그다음에 노드 정의를 해 줄 거예요. 노드 정의도요. 이전에 보셨던 내용이랑 동일해요. 여기 리트브 도큐먼트 부분에 보면은 리트리브 하는 내용 코드 하나 토시 하나 안 틀리고 똑같이 들어가 있고요. 그다음에 LM서 부분도 동일하게 들어가 있어요. 자, 그런데 여기에 이번에 추가되는 노드가 바로 렐러스 체크하는 노드와 여기 밑에 보시면은 is트 요거는 엄밀히 따지면 노드는 아니고 우리가 컨디셔너 엣지에서 활용하기 위한 그런 함수 분기 처리를 위한 함수를 추가해 둔 거예요. 자, 그러면 렐러스 체크는 어떤 식으로 동작하느냐? 우리가 그라운드 닛스 체커를 가져올 건데 요거는 제가 패키지 안에 만들어 놓은 모듈을 가져올 거예요. 그래서이 그라운드니스 체커는요. 여기에다가이 사용법은 우리가 먼저 GPT를 이렇게 설정을 해 줍니다. 뭐 4 5 미니를 넣으셔도 되고 아니면 여러분들이 좀 더 정교하게 하고 싶다면은 좀 더 똑똑한 GPT 4 5를 써 주시면 됩니다. 그래서 넣어 주시고요. 그다음에 타겟에다가는 이제 두 가지가 있는데 question션 엔터를 넣으실 수도 있고 question션 리트리버를 넣으실 수가 있어요. 뭐가 다르냐면 question션리트리벌은이 검색된 문서와 질문을 관련성 평가를 해 주는 거예요. 그래서이 검색된 문서가 질문에 답변하기 위한 내용이 포함이 돼 있는지 관련성이 있는지 그걸 체크하는게 크션 리트리버이에요. 우리가 이번에 활용할 거고요. 그다음에 나중에 최종적으로 답변 생성을 해서이 생성된 답변이 질문과 관련성이 있는지 보고자 할 때는 question션 엔서를 써 주시면 됩니다. 그래서 이렇게 만드실 수가 있는데요. 아 요것도 지금 좀 오타 있네요. 리트리벌로 제가 바꿔 둘게요. 리트리벌 렐로먼트로 맞춰 주고 얘도 바꿔 줄게요. 이런 식으로요. 자, 그다음에 관련성 체크를 수행을 하게 됩니다. 인보크를 날리게 되면은이 결과가 예솔노 노로 나오게 돼요. 그래서 여기에다 넣어 주실 때는 우리가 question션 리트리버이니까 question션과 컨텍스트를 넣어 주면 돼요. 그래서 이전에 우리가 과정에서 지금 여기 보면은 어 question션을 넣으면 검색을 하잖아요.이 검색대 문서를 컨텍스트에다 넣어 줄 거거든요. 그러면 퀘션 채워졌고 컨텍스트가 채워졌어요. 채워졌으니까요 두 개의 문서를 가지고요. 여기에다가 넣어 가지고 관련성 체크를 수행하게 됩니다. 그러면 리스의 스코어를 찍어 보면은 이거에 대한 스코어가 예인지 노인지 나와요. 예면 관련성이 있다. 노면은 관련성이 없다. 이런 식으로 나옵니다. 그러면 이걸 나중에 최종적으로 예솔 노에 따라서 분기 처리를 해 줄 거예요. 요건 조금 있다가 다시 한번 돌아와서 볼게요. 자, 그러면 우리가 노드가 하나가 더 추가가 됐어요. 릴러스 체크하는 노드가. 그럼 밑에 한번 보시죠. 나머지는 동일해요. 나머지는 동일한데 지금 여기에 렐러스 체크하는 노드가 하나가 추가가 됐고요. 그다음에 여기에 애드 컨디셔널 엣지스 부분에 릴러스 체크하는 노드로부터 시작되는 조건부 엣지가 추가가 됩니다. 자, 일단 얘를 실행하고 실행하고 밑에서 한번 볼게요. 자, 이렇게 실행하게 되면은요. 여기 중간에 보이시는이 노드 있죠?이 이 노드를 우리가 방금 추가해 준 거예요. 자, 그런데이 릴스 노드를 추가를 했고 여기에서부터 시작하는이 릴러스 체크로부터 시작하는 조건 분기문을 하나 만들어줬어요. 그래서 이거의 결과에서 not트인 경우와 렐트인 경우 두 가지로 지금 분기로 나눠져 있는 것을 볼 수가 있죠. 자, 그러면 여기에서이 isvent트 우리가 항상 콜러블 함수를 넣어 줘야 되기 때문에 여기에다가이 is버트 함수를 하나 더 만들어 준 거예요. 자, 그러면이 is 러트 함수로 한번가 볼게요. 보면은 이전 스테이트에서 러스에다가 여기에다가 or노를 적게 되잖아요. 만약에 관련성이 있다면 예가 담기 되고 관련성이 없다면 여기에서 노가 담기게 되는 거죠. 그러면 is relevant 함수에서 스테이트에 꺼내 봅니다. 꺼내 봐서 러번스한지 아닌지 체크해 보는 거죠. 체크 봤더니 예다. 어 그러면 릴러트라는 문자를 반환해 줘요. 체크 봤는데 만약에 이게 예가 아니다 그러면은 not트를 반환을 해 줍니다. 자 그러면 렐러트를 아까 반환해 준다라고 했잖아요.이 함수가 렐러트 관련성이 있다라고 반환을 해 주면 얘는 어디로 보내요? 흐름을 관련성이 있으니까 그다음에 바로 답변 생성하러 가면 되겠죠? LM 엔서 쪽으로 보내 주는 거예요. 그런데 얘가 not 렐러트라고 반환을 해 주게 되면은 그러면 얘는 리트브 노드로 보내 주게 되는 거죠. 여기 보면은 다시 리트리브 가서 다시 검색을 해라. 다시 검색을 해라라고 요청을 주게 되는 거예요. 자, 그렇게 해서 이제 만들어 놨고요. 요거를 실행하게 되면은 만약에 관련성이 있으면 답변 생성하러 가고 없으면 이거를 뺑글뺑글 돌게 되는 거죠. 자, 얘를 그래프 실행을 한번 해 볼게요. 우리가 실행하는 거는 이전에 보셨다시피 똑같이 실행하면 되는데 우리가 중간 과정을 다 출력할 필요 없이 이번에 릴러스 체크랑 LRM 엔서 부분만 한번 실행을 해 볼게요. 이번에 우리가 질문을 할 거는요. 엔스로픽에 투자한 기업과 투자 금액을 알려 주세요. 이렇게 실행을 해 볼 거예요. 해보면 렐러스 체크에서 검색된 문서가 질문과 관련성이 있대요. 그래서 릴러스 체크에 예수로 나왔고 그리고 LM 엔서 쪽에 보면은 엔서에 어 바로 답변 생성하는 거를 볼 수가 있다. 왜냐면 관련성 체크를 했으니까. 자, 이렇게 하면은 여러분들의 외그 정확도도 올라갈 수밖에 없어요. 왜냐면 우리가 문서를 평가를 할 때 이미 관련성이 있는지 없는지를 평가를 했기 때문에 만약에 없는 경우가 발생하면 다시 리트리브로 보낼 수가 있게 되는 거죠. 그러니까 우리가 기존에는 이런 관련성 체크를 전혀 하지 않았어요. 그리고 어떤 조건문을 주지도 않았습니다. 그러다 보니까 이게 관련성이 있든 없든간에 답변을 만들어 내죠. 그이 만들어 낸 답변이 관련성이 없는 문서로 만들어 냈으면은 얘는 말짱 꽝인 거죠. 얘는 완전히 할루스네이션이 나올 가능성이 있어요. 근데 우리가 이거를 통해서이 중간에 할루스네이션이 나올 가능성이 있는지 없는지를 중간 버퍼를 통해서 이제 체크를 해 볼 수가 있게 된 거예요. 자, 이렇게 만들었고요. 얘를 스트림 그래프 해도 마찬가지로 잘 나옵니다. 예로 나오고 이렇게 엔서를 해서 우리가 스트리밍 출력까지 잘 나오는 것을 볼 수가 있었어요. 자, 그래서 최종적으로 이렇게 확인해 보면은 어, 잘 나온 것까지 확인해 볼 수가 있고 렐러스도 체크해 보면은 예스라고 나오죠. 자, 그런데 우리가 이다음에 해 볼 거는 일부러 이상한 질문을 던져 볼 거예요. 그래서 관련성 체크를 통과하지 못하도록 한번 만들어 보겠습니다. 그래서 여기 밑에 보시면은 이번에는 질문을요. 데디노트의 랭체인 튜토리얼에 대한 정보를 알려 주세요라는 질문을 던져봤어요. 완전히 문서랑 관련이 없거든요. 이런 내용은 없어요. 그러면 얘는 관련성 체크를 할 때 계속 노가 뜰 거거든요. 한번 보시죠. 자, 얘를 한번 실행해 볼게요. 자, 실행하면은 노가 계속 뜨죠. 왜냐면 이런 내용은 없으니깐요. 그래서 노가 계속 뜨다가 얘가 리컬션 리미트에 걸려 버립니다. 우리가 리컬션 리미트에 10으로 했으니까 10개 노드까지 왔다 갔다 할 수가 있는 거예요. 그러면 왔다 갔다 해서 최종적으로 노를 가다가 얘가 리컬 리미트에 걸려서 중간에 멈추게 됩니다. 지금 API 상태가 좀 느려서 그런지 답변이 조금 늦게 나오네요. 원래이 정도 느리진 않고요. 얘를 껐다가 다시 한번 해 볼게요. 여기다가 중간에 여러분들도 이렇게 행이 걸리는 순간 있거든요. 행이 걸려 버리면은 그러면 저처럼 이렇게 인터프트를 주시면 돼요. 그럼 꺼지죠? 다시 한번 실행해 보십시오. 자, 노 해서 지금 리컬션 에러로 금방 끝났어요. 이렇게 금방 끝나야지 정상입니다. 그러면 리컬션 리미트가 10이 리치드 됐대요. 이게 왜 다섯 개밖에 안 출는데 왜 열 개인가요라고 하실 수 있는데 노드가 왔다 갔다 하나 노드 방문할 때마다 일씩 카운트가 어떻게 되는 거냐면 어 하나 둘 셋 넷 다섯 여섯 일곱 여덟 아홉 열 이런 식으로 가서 이제 실제로 찍히는 거는 다섯 번 밖에 안 찍히게 되는 거지만 실제로 얘가 방문한 노드는 10열 개 도달하게 된 거죠. 근데 개의 도달을 먼저 했기 때문에 and드에 도달하기 전에 열 개의 중간 노드에 도달했기 때문에 얘는 그래프 리컬션 에러를 띄우고 멈춰요. 근데 우리가 트라이셉트 구문을 통해서이 그래프 리컬션 에러로 이렇게 잡아낼 수가 있거든요. 그러면 우리가 서비스가 죽어 버리는 그런 현상을 좀 방지할 수가 있어요. 그래서 어 여러분들이 항상이 원래 같았으면은 이제 어 인크를 할 때도 인보크나 스트링 그래프를 할 때도 이렇게 트라이셉트 구문으로 만약에 사태에 대비를 해서 얘가 이제 중간에 재기에 계속 빠지는 경우를 대비를 해서 이런 식으로 구성하는게 좋아요. 어쨌든 요지는 뭐냐면 이런 내용은 당연히 없기 때문에 얘가 아무리 문서 검색을 해도 관련성이 제대로 잡힐 수가 없어요. 그러다 보니까 얘가 이제 리컬션 리미트에 걸리고 끝나 버렸죠. 자, 근데 여기서 궁금한 건 뭐냐면 우리가 우리가요 여기서 릴러스 체크를 하고 다시 검색하라고 요청을 했잖아요. 근데 이게 왜 못 찾느냐? 원래 이제 문서 안에 당연히 이걸 답변하기 위한 내용이 없었을 수도 있지만 근데 여기서 더 중요한 건 뭐냐면 리트브를 할 적에 똑같은 쿼리문으로 계속 검색을 하거든요. 그러니까 우리가 만약에 만약에 내가 그 방금 우리가 질문한 내용이 있다 하더라도요. 동일한 질문을 넣는 건 사실 의미가 없겠죠. 왜냐면 동일한 질문을 넣으면 동일한 항상 동일한 검색 결과가 나올 거니까 동일한 검색을 가지고 똑같이 리트리버 하는 거는 큰 의미가 없습니다. 그래서 보통 어떻게 되냐면 만약에 여기서 릴레트가 뜨게 되면 퀄리 리라이트를 해 줘요. 퀄리 리라이트를 해서 질문을 제작성을 한 다음에 다시 한번 질문을 하는 구조가 바람직하겠죠. 근데 여기서는 이제 보여 드리려고 이런 식으로 한번 구성을 해 봤습니다. 그래서 저희가 이번 시간에서는요. 이렇게 어 릴스 체크 실패를 하고이 노 들어가는 상황에 대해서 먼저 보셨다라고 보시면 되고요. 여기 아까 제가 말씀드린 것처럼 동일한 쿼리가 다시 리트리브로 들어가게 되면은 동일한 검색 결과를 이어지기 때문에 결국에는 계속 제기된 제기 상태에 빠질 수밖에 없어요. 그래서 리컬션 리미트로 해서 요거를 이제 딱 잡아내는 것까지는 보셨지만 우리가 이게 궁극적으로 해결한 건 아니잖아요. 그래서이 다음 튜토리얼부터는 이걸 어떻게 궁극적으로 좀 해결을 해서 릴러스 체크에 페일이 떴을 때 다른 방식으로 우리가 검색 도출 할 건지 만약에 외 검색이 필요하면 외 검색을 할 거고 만약에 다시 쿼리 리라이트가 필요하면 퀄리 리라이트 할 거고요. 그래서 이런 식으로 여러분들이 자유롭게 흐름이 구성이 가능한데 그런 식으로 좀 확장해서 이렇게 재기 상태에 빠지는 것을 좀 방지하는 방법에 대해서 알아보도록 하겠습니다.네 네, 이번 시간에는 웹 검색 모듈 추가에 대해서 알아보도록 하겠습니다. 저희가 이전까지 봤던 내용은 라이브레그 수행과 그다음에 검색된 문서에 대한 관련성 체크까지 진행을 했었어요. 자, 그런데 이번에는 웹치 모듈을 추가해 볼 건데요. 지금 이전에 보셨던 플로우는 저희가이 웹서치 모듈이 빠져 있었던 상태였거든요. 그러다 보니까이 렐러스 체크가 바로 리트리브 쪽으로 들어가도록 요렇게 구성이 됐었고요. 그다음에 렐러버스 체크를 통과를 했을 경우에는 이제 제너레이션에 들어가도록 이런 식으로 이제 구성이 되어 있었습니다. 자, 그러다 보니까이 렐러스 체크가 녹아 나왔을 때 어 리트리브로 들어가니까 어 계속해서 우리가 재귀에 빠져 가지고 그러니까 어떠한 쿼리 변경 없이 그냥 넣다 보니까 동일한 문서가 검색이 되게 되는 거고요. 그러다 보니까 얘는 해결책을 못 찾게 되는 거죠. 그래서 우리가 이번에는 어 렐러스 체크에서 노가 나왔을 때는 문서에 없는 내용으로인지를 시키고 그다음에이 결과에 따라서 우리가 웹서치로 어 우리가 원하는 결과를 검색하도록 유도를 할 거예요. 그래서 검색을 해서 내용을 보강을 한 다음에이 보강된 내용을 토대로 제너레이션 하는 방법까지 알아보도록 하겠습니다. 자, 이전과 내용이 비슷한 부분들이 많아 가지고요. 앞부분은 빠르게 넘어가도록 할게요. 요것도 내용이 동일하고 그다음에 스테이트 부분도 동일합니다. question션이랑 컨텍스트 엔서 메세지스 레먼스까지 전부 다 동일하고요. 그다음에 노드 정의하는 부분도 동일합니다. 도큐먼트 하는 부분도 이전에 보셨던 영상이랑 동일하고 엔서도 동일하고 렐러스 체크도 동일하고요. 그다음에이 렐러트까지 동일해요. 자, 요것도 실행해 주실게요. 자, 이제 다음으로 우리가 새롭게 추가되는게 바로 인터넷 검색 모듈인 태리 서치 도구이죠. 요거는 랭체인 공식으로 제공해 주는 모듈도 좋은데요. 그런데 제가 만들어 놓은 모듈은 좀 더 커스터마이제이션 가능하도록 이렇게 구현을 해 놨어요. 그래서 태블릿 설치 도구에서는 우리가 퀄리랑 맥스 리트 그다음에 포맷 아웃풋을 툴루로 줘서 이제 포매팅 되는 기능까지 넣어 놨거든요. 그래서 만약에 우리가 2024년도 노벨 문학상 수상자는이라는 내용을 이제 검색을 돌리게 되면은 이제 얘가 검색을 쭉 수행하게 되고요. 최대 세 개의 검색 결과를 가져오게 되는 거죠. 그런데이 가져올 때 제가 포매팅하는 기능까지 넣어 놨거든요. 그래서 이렇게 예쁘게 포매팅이 쭉 되는 것까지 확인해 보실 수가 있습니다. 그래서이 포매팅 되는 결과에 보시면요. 어떤 식으로 포매팅이 되냐면 이전에 제가 알려 드렸던 방식과 동일하게 도큐먼트 태그가 붙어 있고 타이틀에는 이제 왼문서의 타이틀이죠. 타이틀이 들어가 있고요. 그다음에 URL 부분에는 URL이 쭉 들어가 있고 컨텐트 부분에는 컨텐트가 들어가 있는 것을 확인해 볼 수가 있습니다. 자, 이렇게 포매팅을 하실 수도 있고 어, 나는 포매팅이 싫어요. 내가 직접 포매팅을 하고 싶어요. 하시는 분들은 이거를 퍼스로 줘서 실행을 하게 되면은 자, 요것도 한번 결과로 한번 보여 드리죠. 자, 이런 식으로 나옵니다. 자, 여기에 보면 쭉 올려 볼게요. 자, 이렇게 나오는데 요게 어, 딕셔너리 형식으로 이렇게 들어가 있어요. 그래서 타이틀에서 타이틀 가져올 수 있고 URL 그다음에 컨텐트 내용으로 검색된 결과를 보실 수가 있습니다. 저희가 이번에 진행할 때는 툴로 놓고 한번 진행해 볼게요. 자, 그다음에 다음으로는 검색 노드로 패키징해서 추가를 할 거예요.이 이 패키징 한다라는 말은 뭐냐면 우리가 노드로 만들기 위해서는 이런 식으로 구성이 되어 있을 때는 노드로 만들 수가 없어요. 왜냐면 우리가 노드를 만들 때에는 함수 형태로 구현이 되어 있어야 되죠. 그래서 디파인으로 시작하는 키워드로 시작해서 노드명이 들어가고 그다음에 스테이트를 입력으로 받고 그다음에 스테이트를 반환하는 그런 구조 안에서이 과정이 일어나야 됩니다. 자, 그래서 우리가이 노드를 만들어 볼 건데요. 밑에 보시면은 똑같은 내용이에요. 동일한 내용인데 요거를 옮겨줬고 그다음에 맥스 리트는 좀 여섯 개로 좀 늘려 봤어요. 그래서 요거는 여러분들이 알아서 원하시는만큼 조절하셔도 되고 나중에 스테이트의 키값으로 뭐 맥스 리트를 넣어 가지고이 맥스 리트 값을 동적으로 넣는 것도 가능합니다. 저희는 일단 고정으로 여섯 개를 넣어 봤어요. 자, 그래서 태블릿 설치 도구를 써 가지고 이제 쿼리 검색을 하게 되고 퀄리한 결과를 컨텍스트 안에 넣어서 반환하게끔 주는 거죠. 자, 우리가 컨텍스트 부분에요. 이전까지 레그체인에서는 문서에 검색된 결과를 컨텍스트에다 넣어 줬었거든요. 그런데 이번에는 그게 아니라 컨텍스트에다가 웹을 한 결과를 넣어 준다. 이렇게 이해하시면 되겠습니다. 자, 요거 실행해 주시고요. 그다음에 엣지 연결하는 부분도 이제 쉬워요. 우리가 하나씩 누적이 되니까. 자, 이전까지 어, 추가했던 노드들 그대로 들어가 있고요. 그리고 아니라 우리가 이번에 만들어 놨던 웹서치 노드를 웹서치라는 노드 명으로 추가를 해 줬어요. 자, 이렇게 노드 추가를 해 주고요.이 부분이 중요합니다. 우리가 이전에는 날 릴트했을 때 리트리브로 보냈거든요. 그래서 리트ave를 보낸다는 말은 뭐냐면 우리가 관련성이 없다라고 판단이 들면 여기에서 릴러스 체크 노가 나왔을 때 바로 위로이 리트리브로 들어가게끔 이런 식으로 구성을 해 놨던 거죠. 그런데 우리가 이번에는 그게 아니라 얘로 보내지 말고 웹치로 보내서 필요한 내용들을 보강을 해서이 제너레이트 LM 쪽으로 라우팅 할 수 있도록 이렇게 만들어 주자라는 거예요. 그래서 다시 쭉 아래로 내려와서 보시면은 어 여기에서 웹서치 노드가 추가가 됐고 not트라고 판단이 되면 웹서치로 이제 웹색을 수행하도록 하는 거죠. 관련성이 없으면 이제 웹하는 걸로 이거 웹합니다로 이제 바꿔 놨어요. 자, 요런 식으로 이제 수행을 하게 되고 나머지 내용은 동일해요. 자, 거 실행해서 우리 그래프 한번 시각화해 보도록 하겠습니다. 자, 그래프를 시각해 보시면 이제 좀 예쁜 그림이 나오게 되는데 자, 이렇게 되는 거죠. 리트리eve를 하고요. 검색을 하고 관련성 체크를 수행합니다. 그래서 만약에 관련성이 있다라고 하면은 우리가 래그한 그러니까 그 벡터 DB로부터 래그한 PDF 문서죠. PDF 문서 안에서 답을 찾을 수 있다라고 판단했기 때문에 검색된 문서를 LM엔한테 넣어서 이제 답변에 도출하게 되는 거고요. 만약에 우리가 찾아봤는데 어 그 해당 내용이 문서에 없다라고 판단이 들면 웹을 해서 웹 검색한 내용을 토대로 래그를 수행하게 되는 그런 구조로 이제 짜본 거죠. 자, 이제는 그래프 실행을 한번 해 볼 거예요. 실행하는 건 어렵지 않죠? 네. 동일합니다. 자, 이번에는요. 우리가 문서 안에 없는 질문 한번 던져 볼 거예요. 그래서요 내용은 문서 안에 없거든요. 원래가 됐으면 재기처럼 뺑글뺑글 돌았는데 이제는 얘가 없다라고 판단이 되면 외 검색을 수행하게 되는 거죠. 자, 그래서 요거를 한번 실행을 해 볼게요. 실행을 하게 되면은 렐러스 체크에 보면은 얘가 노로 떴잖아요. 노로 떴기 때문에 얘는 그다음으로 외 검색을 수행하게 되는 거예요. 외검 검색 내용은 지금 비워 놨는데 워낙 내용이 길다 보니까 비워놨어요. 외 검색을 토대로 이제 LM 엔서를 주는 걸 볼 수가 있는데요.이 엔서 쪽에 보시면은 2024년도 노벨 문항상 수상자는 한국의 작가 한강입니다. 년의 채식 주지자와 소년이 온다의 저자로 최초로 노벨 문학상을 수상했습니다라는 내용이 들어가 있고 그다음에 솔스 부분에도 이제 출처가 예쁘게 잘 들어가 있는 것을 볼 수가 있습니다. 마지막으로 우리 채 메시지까지 이렇게 잘 들어가 있네요. 자, 그러면 우리가 이번에도 이제 그래프 스트리밍 출력을 할 수가 있어요. 자, 그래서 요것도 동일하게 실행하면은 릴러스 체크가 노가 뜨면은 어, 이렇게 얘가 외검 검색을 수행하게 되겠죠. 외 검색 수행을 해서 요런 식으로 이제 완성을 해 주는 거까지 보실 수가 있습니다. 소스까지 잘 나오는 거 보니까 거의 완벽한 거 같아요. 그래서 최종 출력값을 확인해 보시면은 이제 원래 질문은 이렇게 들어가 있었는데 엔가 인터넷 검색 결과를 토대로 이런 식으로 잘 나온다. 마지막으로 출척까지도 예쁘게 잘 포함해 주는 것까지 볼 수가 있습니다. 자, 이제 여기까지 되시면은요. 여러분들이 어느 정도 감을 잡으셨을 것 같아요. 우리가 처음에 라이브 레그부터 시작해서 이런 식으로 여러분들도 개발을 하실 때요. 내가 처음부터 완벽하게 다 설계를 하고 하겠다 하면은 굉장히 머리가 아파요. 근데 일단 나이브한 레그를 만들어 보고 내가 부족한게 뭔지를 체크를 해 본 다음에 이런 식으로 모듈을 하나씩 하나씩 붙여 나가다 보면은 여러분들이 이제 나중에 봤을 때 굉장히 흐름이 탄탄해지는 것을 볼 수가 있습니다. 그래서 우리가 이전에 러먼스 체크를 했을 때 노가 나왔을 때 not 먼트가 나왔을 때리브로 가서이 제기적인 문제를 이번에는 웹서치라는 노드를 통해서 한번 풀어 봤습니다. 네. 안녕하세요. 이번 시간에는 쿼리 제작성 모듈을 추가해 보는 어 우리가 연속된 튜토리얼의 마지막 시간이라고 보시면 될 거 같습니다. 그래서 우리가 이제 마지막으로 쿼리 리라이트까지 추가를 하면은 이제 대략적으로 기존 나이브 레그에서 우리가 랭그래프를 활용한 것까지 이전을 했고 그다음에 여기다가 이제 외검 검색 모듈과 쿼리 리라이트까지 추가함으로써 이제 얼추 완성이 돼 가는 느낌이에요. 그래서 관련성 체크 모듈도 들어가 검색도 들어가 쿼리 리라이터 하니까 기존에 있었던 아주 순정 모델의 나이브 레그보다는 좀 더 업그레이드된 레그를 우리가 만들 수가 있는 거죠. 자, 그래서 우리가 쿼리 제작선 모듈을 추가를 해 볼 건데요. 전혀 어렵지 않습니다. 우리가 이번까지 왔었으면 이제 위에다가 쿼리 리라이트 모듈을 이제 추가만 해 주면 되는 거거든요. 그래서이 모듈러 레그의 장점 여러분들 이제 좀 와닿으시나요? 이렇게 모듈 구조로 짜서 조립하듯이 하나씩 하나씩 추가하는게 전혀 어렵지 않은 거죠. 그래서 이제 마지막으로 여기에 들어가 있는 쿼리 리라이트 모듈을 한번 추가해 보도록 할게요.이 쿼리 리라이트라는 거는요. 유저가 보통 question을 친절하게 주지 않을 가능성이 높은 거죠. 그러다 보니까 유저가 입력한이 question션을요 다시 한번 리라이트해 주는 그런 모듈이라고 이해해 주시면 되겠습니다. 자, 그래서 위에 한번 볼 건데 어 환경 설정 한번 해 주시고요. 그다음에 임포트하고 추적하고 PDF 기반 요것도 가져오시고요. 스테이트 정의 부분도 바뀐게 없습니다. 다만 여기 퀘션 부분에다가 우리가 누적을 시키기 위해서 리스트 형식으로 바꿔 놨어요. 뭐 우리가 이렇게 리스트로 넣어도 되고요. 아니면은 또 하나 허용되는 방식 중에 하나가 좀 더 깔끔하게 난 하고 싶다 하면은 리스트에 어 str런 식으로 넣어 주셔도 되는 거죠. 자, 그러면 얘가 리스트이기 때문에 우리가 리서 함수인 애드 메시지를 넣었단 말이에요. 그러면 우리가 퀘션을 리스트에 묶어서 반환을 하게 되면은 question션의 누적이 됩니다. 자, 그런데 우리가 이전까지는 question은 str로 가져갔었어요. 리스트가 아니었거든요. 그럴 때에는 우리가 question을 반환하게 되면은 원래 있었던 질문을 얘가 덮어 씌우게 돼요. 자, 그런데 여기 위에 한번 볼게요. 만약에 여러분들이 유저의 질문이 들어오고요. 우리가 리라이트 하면은 우리가 리라이트 하는 결과물이 일반적으로 더 좋거든요. 그렇기 때문에 원래 질문은 그냥 덮어 씌워도 되긴 합니다. 자, 그런데 제가 덮어 씌우지 않고 누적을 시킨다라는 의도는 뭐냐면 원래 있던 질문이 그대로 남아 있고요. 그러니까 여기다 적어 보면은 원본 질문이 그대로 남아 있고 그다음에 여기에다가 리라이트한 질문을 누적을 시킨다라는 개념이거든요. 요런 식으로. 그럼 원본을 왜 살려둘까요?이 이 Y를 생각해 보는게 사실 중요한데 여기에는 제가 직접 개발을 하다 보니까 느끼게 된 점이 이제 유저가 원래 질문을 한 내용이 있잖아요. 근데 리라이트 내용을 우리가 보여 주는 것도 방법이 될 수 있겠지만 유저가 대충 질문을 해도 우리가 알아서 내부적으로 리라이트를 해서 좋은 결과로 이끌어냈다. 즉 유저의 질문은 원본 그대로 보여 주고요. 결국엔 우리가 좋은 답변을 이렇게 보여만 주면 되는 거지. 중간 과정에 있는 리라이트는 굳이 보여 줄 필요도 없을 수도 있는 거예요. 물론 우리가 리라이트 하는 과정을 보여 줘도 되겠지만 그니까 제가 드리고 싶은 말씀 뭐냐면 우리가 원본을 살려두기 위해서는 원본에다가 덮어 씌워 버리면 안 된다는 소리예요. 우리가 만약에 리라이트해서 덮어 씌우게 되면은 유저가 실제로 입력한 질문과 어 나중에 표기되는 question이 약간 괴리감이 있어요. 이게 왜 변하지? 이렇게 느낄 수도 있단 말이죠. 그래서 우리가 원보는 유저가 원래 입력한 질문을 보관하기 위한 용도로만 보관을 하고 실제로 우리가 쿼리을 날릴 때에는 리라이트한 질문으로 넣기 위해서 이런 식으로 리스트의 스트링 애드 메시지 리서로 구현을 한 겁니다. 자, 그래서 그것만 인지해 주시면 되겠고요. 그다음에 밑으로 내려가서 우리가 노드들 나머지 거는 똑같아요. 랜서 맞는 거. 그다음에 렐러스 체크 이러트 확인하는 거. 그다음에 웹서치 모듈까지 전부 다 동일하게 들어가 있습니다. 자, 이번에는 쿼리 리라이트 하는 노드를 추가해 볼 건데요. 간단한 프랑프트 템플릿에 맞춰서 어, 퀄리 리라이트 해 주는이 프롬프트를 제가 한번 작성을 해 봤어요. 그래서 여기다가 쿼리 리라이트 프롬트를 넣어 주고 스텝스에 어떤 방식으로 리라이트 할 건지 넣어 줘 봤고요. 그다음에다가 인풋 아웃풋에 대한 리라이트 내용을 넣어 줬어요. 자, 이렇게 넣어 주고요. 리라이터에다가 GPT 45미니 혹은 나는 좀 더 정교하게 하고 싶다. 그러면 4 5를 가져와서 쓰셔도 되는 거죠. 자, 요런 식으로 써 주고요. 리라이트 프롬트에 어픈 AI 그다음에 마지막으로 STR 아웃풋 파서까지 이렇게 만들어 줬습니다. 체인을 만들어 준 거죠. 그래서 question션 리라이트를 하나 만들어 주고요. 여기에다가 원래 질문을 한번 넣어 볼게요. 엔스로픽에 투자한 미국 기업 상대적으로 조금 단순하게 한번 넣어 봤는데요. 이게 좀 더 풍부한 표현으로 바뀌는지 한번 볼게요. 자, 보시면은 엔스로픽에 투자한 미국 기업은 어떤 곳들이 있나요? 이렇게 좀 더 친절한 오로 잘 바뀐 것을 볼 수가 있죠. 자, 그러면 우리가 퀘션 리라이터를 통해서 이제 원래 있던 질문을 다시 리라이트 해 준 건데 우리가 얘가 노드로 돌아가기 때문에 노드로 패키징을 한번 해 주는 작업이 필요하겠죠. 자, 그래서 우리가 이거를요 함수 형태로 만들어 줄 건데 이제 함수의 이름은 qu리 리라이트로 줬고 입력으로 들어오는게 이제 스테이트이고요.이 스테이트의 question션에 -1번째 한다라는 것은 무슨 의미냐면 question션은 리스트예요. 리스트라는 말은 누적이 되는 개념인데요. q1, q2 이렇게 쭉 누적이 될 거예요. -1이라 거는 가장 최신에 넣어줬던 패션을 의미합니다. 사실 얘가 리라이트를 하는데 어 왜 가장 마지막 걸 가져오냐면 원본 그냥 질문 가져오면 되잖아요. 그게 아니라 최근 짐을 넣는 이유는 우리가 리라이트를 여러 번 수행할 수가 있어요. 그러니까 원래 있었던 question이 있고 question션 리라이트 첫 번째 시도했던게 있고요. 이게 또 결과가 안 좋을 수도 있거든요. 그럼 이걸 토대로 question션 리라이트 2를 또 만들어 내고 3 이렇게 계속 만들어 낼 수가 있어요. 그래서 -1을 주겠다는 거는 가장 최신 질문을 가져온다라는 뜻이니까 가장 마지막 질문을 가져와서 레이티스트 퀘션에다가 넣어 줄 거고요. 이거를 넣어서 개선하는 작업을 한 다음에 개선이 됐으면 요거를 반환해 주는 형식으로 노드 구성을 해 봤습니다. 자, 그래프 스테이트가 티파인드네요. 자, 그러면은 어, 우리 위에서부터 다 나파인드였네요. 자, 여기 그래프 스테이트가 지금 요게 실행이 안 됐죠? 거 다시 한번 실행해 주시고 쭉 실행을 해서 자 이렇게 볼게요. 그러면 노드 정의까지 완료가 됐고요. 그다음에 엣지 정의 한번가 보도록 하겠습니다. 나머지 내용은 동일해요. 우리 웹치까지 추가가 돼 있으니까 여기까지 동일하고요. 그다음에 퀘션 리라이트 하는 거 노드 하나 추가해 주고 그다음에 우리가 맨 처음에 질문이 들어오면은 이제 리트리브를 하고 여기에 아 퀘션 리라이트부터 하겠죠. 퀘션 리라이트를 하고요. 그다음에 요게 리트리브로 가고 요거 순서도 이렇게 바꿔 주면 덜 헷갈릴 것 같아요. 그러니까 흐름이 먼저 질문이 들어와서 question션 리라이트를 하게 되고요. 리라이트 한 다음에 리트리브 그 리라이트된 결과를 가지고 검색을 할 거예요. 검색을 하고 그다음에 관련성 체크까지 넘겨 주게 됩니다. 그럼 관련성 체크된 결과가 있을 거잖아요. 이게 관련성이 있다, 없다가 나올 건데 만약에 관련성이 있으면 lms로 가고 없으면 이전과 동일하게 웹서치를 해서 부족한 내용을 보강을 해서 최종 답변으로 받는 요런 구조를 한번 짜봤습니다. 자, 이렇게 짜봤고요. 우리 그래프 실행 한번 해 보죠. 나머지는 동일해요. 그래서 요거를 그대로 실행시키면 이제 결과를 볼 수가 있는데요. 자, 여기에 보시면은요. 우리가 엔스로픽 투자 금액이라는 어 비교적 좀 간단한 질문 했는데 얘가 예쁜 질문으로 이렇게 바꿔 준 거를 볼 수가 있고요. 바꿔서 리치브 해서 결과를 얻어내고 자, 그다음에 릴러스 체크에서 예스가 나와서 요거에 대한 답변을 이렇게 예쁘게 만드는 것을 볼 수가 있어요. 이거 답변 만들 때도 우리가 리라이트한 쿼리 있죠? 리라이트한 쿼리를 가지고 와서 요걸로 조회를 하거든요. 이거를 내가 한 번 더 체크해 보고 싶다 하면은 리트리브 도큐먼트 쪽에 보면은 question션의 -1번째 그러니까 가장 최근 question을 가져오는 거를 볼 수가 있어요. 원본 질문이 있고 그다음에 이걸 리라이트한게 있었으면이 리라이트한게 가장 최신이니까 가장 최신 질문이 레이티스트 question션에 담기게 되는 그런 구조로 이제 구조 변경을 한 거죠. 자, 그래서 다시 내려가서이 결과에 보면은 이렇게 잘 나오고요. 어, 요거 스트리밍 출력도 가능합니다. 그래서 퀘션 리라이트 하는 부분도 스트리밍이 됐고 그다음에 LNM 엔서 부분까지 이렇게 잘 나오는 것을 볼 수가 있어요. 최정 출력가까지 확인해 보시면 이렇게 잘 나오는 것까지 보실 수가 있습니다. 그래서 우리가 이제 쿼리를 리라이트 하는 경우 되게 많아요. 그래서 리칠별 단계에 우리가 쿼리 리라이트를 해서이 리라이트 좀 더 정성스러운이 질문으로 문서 검색을 해서 그걸로 통해서 얻은 정보를 이제 넣어서 최종적으로는 유저가 입력한 건 이건이 질문이지만 우리의 답변은 이렇게 예쁘게 나올 수 있다를 어필해 줄 수가 있겠죠. 자, 그래서 이번 시간에는 우리가 쿼리 리라이트 모듈을 한번 추가해 봤어요. 그래서 여기까지 보시면은 어, 대략적으로 나이브 레그에서 좀 더 발전된 형태의 그래프를 만들 수가 있게 되는 거고요. 자,이 구조가 아주 기본 구조라고 보시면 돼요. 여기서 여러분들이 응용을 하셔 가지고요. 어, 우리가 질문하기 전에 question션 리라이트를 한 번 더 될 수도 있고 아니면이 부분에 있던 거를 그냥 아예 빼 버리고 질문이 들어왔는데 관련성 체크가 놓일 경우에 그럴 때 리라이트를 해서 웹서치 들어가도록 이렇게도 구성이 또 가능합니다. 그래서 여러 가지 여러분들이 창의성을 최대한 발휘해서요. 가장 좋은 여러분들의 흐름을 한번 만드는 연습을 해 보셨으면 좋겠습니다. 네, 이번 영상에서는 퀄리 리라이트에 대해서 알아봤습니다. 네, 여러분 안녕하세요. 자, 이번 시간부터는 쭉 프로젝트가 이어지게 됩니다. 저희가 무료 프로젝트가 굉장히 많아요. 한 12개, 13개를 연속적으로 다뤄 볼 겁니다. 우리가 이제 프로젝트가 스트림을 주로 보긴 했는데 제가 여기 6번, 7번 파일에서부터 유스케이스에 있는 파일들은 전부 다 이제 프로젝트 단위로 정의를 했어요. 왜냐면 이거 하나하나가 이제 처음부터 끝까지 다 다른 주제를 다루고 있고요. 그리고 하나하나가 그냥 주제가 아니라 하나의 파일을 제가 구성을 하는데도 굉장히 많은 시간을 쏟았습니다. 그마만큼 하나가 이제 프로젝트가 될 정도로 길이도 좀 길고 해서 프로젝트라는 라벨을 달아서 이제 빼게 되었습니다. 자, 그래서 이번 시간부터는 우리가 쭉 프로젝트의 내용을 보게 될 건데요.이 에이전틱 레그입니다. 에이전틱 레그인데 어 여러분들 파일 기준으로 6번 파일이라고 보시면 돼요. 자, 그런데 우리가이 에이전틱 래그에서는 에이전트를 활용한 레그. 그래서 우리가 에이전틱 레그라는 말을 쓰게 되는데 요즘에 뉴스에서도이 에이전틱 레그란 말을 정말 많이 쓰죠. 그래서 기존에 있던 레그가 아니라 에이전트를 활용한 레그인 에이전틱 레그를 써야 된다. 뭐 이런 식으로 해서 뭐가 많이 나옵니다. 자, 그런데 이제 여러분들은 이거를 코드로도 직접 돌려보면서 원래 우리가 짰었던 레그와 어떤 차이가 있는지 그 내용들을 보시게 될 거예요. 자, 여기서 중요한 거는 우리가 이미 이전에 봤었던 에이전트의 역할입니다. 자, 여기에 보시면은요. 우리가 이전에 봤었던 내용에서는 에이전트를 쓰진 않았거든요. 에이전트는 빠져 있고 여기에 노드 하나하나를 잘 조합을 해서 어 꽤나 괜찮은 우리가 레그 파이프라인을 만들어 놨단 말이에요. 자 그런데 우리가 이제 볼 거는 에이전트가 들어가 있죠. 근데 우리가 에이전트를 썼다와 에이전트를 안 썼다가 어디에서 두드러지게 차이가 나냐면 바로 여기에 있는이 에이전트의 역할 부분에서 가장 크게 차이가 나요. 그럼 우리가 다시 우리 16번 폴더에서 에이전트의 튜토리얼 내용에 대해서 많이 보셨는데요. 에이전트와 에이전트가 아닌 경우에 가장 큰 차이점이 뭐였냐면은 바로이 에이전트를 쓰게 되면은 에이전트가 스스로 판단을 내려서 툴를 쓸지 말지 만약에 얘한테 리트리버하는 툴을 지어줬다라고 하면은 문서 검색 도구를 활용해서 래그를 수행을 할지 말지 여부를 에이전트가 스스로 판단을 내릴 수 있다라는 거예요. 가령 더 쉬운 예제를 하나 들어보죠. 만약에 우리가 대한민국의 수도는 어디야?라는 질문을 사용자가 했다라고 가정을 해 볼게요. 그런데 우리가 대한민국의 수도는 레그를 쓰지 않아도 알 수 있는 내용이잖아요. 그런데요. 우리가 이전에 만들어 놨던 프로세스에 따르면 대한민국의 수도는 어디야라는 질문이 들어오면 쿼리 리라이트라 해서 좀 더 예쁘게 바꿔 주긴 하겠죠. 그다음에 무조건 리트리브로 들어가게 돼요. 그러니까 우리가 어 가지고 있던 문서에서 먼저 대한민국 수도는 어딘지 찾는 과정이 고정이 되어 있기 때문에 그게 바로 들어간다라는 거죠. 자, 이런 거는 사실 스마트하다라고 보기가 어려워요. 왜냐면 대한민국의 수도는 어디아와 같은 가장 기본적인 질문들은 그냥 바로 LRM이 알고 있는 지식 속에서 답변을 해 주면 되는 부분이죠. 그래야 지연 속도도 없이 가장 빠르게 답변이 나올 수 있고 불필요한 토큰 비용도 아낄 수가 있는 거예요. 자, 그런데 우리가 아까 말씀드린 것처럼이 구조에서는 고정이 되어 있기 때문에 우리가 무조건 레그를 수행하는 그런 파이프라인으로 지금 짜져 있는 거죠. 근데 우리가 이거를 만약에 에이전틱 레그를 쓰게 되면요. 에이전트가 스스로 먼저 떠이라는 과정을 통해서 판단을 내리게 되는 거예요. 그래서 떠이라는 과정을 통해서 얘가 생각을 합니다. 어 내가 이거 도구를 써야 될까 말아야 될까? 이걸 판단 내리고요. 어 이건 쉬운 지문인네. 내가 바로 답변할 수 있겠다 하면은 도구를 쓰지 않고요.이 툴 컨디션도 바로 건너뛰고 바로 제네레이션을 하게끔 되어 있는 거죠. 그런데 얘가 이번에는 판단 내렸을 때 뭐 삼성전자가 개발한 생성 AI는 어디야? 이런 내용은 잘 모르니까 문서에서 검색을 수행하게 되는 거예요. 그런 질문 같은 경우에는 그래서 툴를 써 가지고 리치브를 써서 문서 검색을 수행하게 되고요. 문서 안에서 내가 답변에 필요한 내용들을 검색을 한 다음에 그걸 가지고 이제 그레이드를 합니다. 그레이드를 해서이 검색된 문서가 관련성이 있는지 판단해 내리고요. 관련성이 없다라고 하면은 쿼리 리라이트를 해서 다시금 수행하도록 하는 거죠. 혹은 관련성이 있다라고 바로 예스라고 뜨게 되면은 바로 생성을 해서 이제 우리가 원하는 결과까지 얻을 수가 있는 거예요. 그러니까 우리가 에이전트를 쓰는 가장 큰 이점은 뭐냐면요. 레그를 쓸지 말지 판단하는 거를 굳이 라우팅 체인을 쓰지 않더라도 얘가 스스로 알아서 결정을 해 준다라는 점이 굉장히 매력 있는 포인트라고 보시면 되겠습니다. 그래서이 에이션트를 이번에는 랭그래프 안에 녹여 가지고이 파이프라인 구성하는 방법을 한번 보실 거예요. 자, 먼저 환경 설정해 주시고요. 그다음에 이전의 내용과 동일하기 때문에 요거는 그대로 실행해서 가져오도록 하겠습니다. 자, 그다음에 우리가 에이전트를 만들 때 항상 따라붙는게 뭐냐면 툴를 만드는 거죠. 그래서 여기서 우리가 어떤 툴을 만들 거냐면 레그 리트리버 할 수 있는 리트리버 툴을 하나 만들 거예요. 그래서이 리트리버 툴은이 에이전트한테 쥐어 줄 건데이 쥐어 주기 전에 몇 가지 설정이 필요합니다. 자, 그래서 여기 부분에 보시면은요. 크리에이트 리틀버 2를 해서 PDF에서 문서 검색을 해 주는 리틀버 넣어 줘요. 그다음에 얘를 뭐라고 부를지 별칭 넣어 줬어요. 그냥 저는 똑같이 넣어 줬습니다. 여러분들이 자 요렇게 바꾸셔도 됩니다. 자, 그런데 우리가 툴를 만들 때 그냥 아무런 관련성 없는 이름 뭐 홍길동이라고지면 안 되겠죠?이 네임도요. LM이 E2를 쓸지 말지 판단할 때 중요하게 고려해야 될 사항 중에 하나가 바로 네임이에요. 그래서 PDF 리트리버를 우리가 이름으로 지정했다라는 뜻은 뭐냐면 간접적으로 LM한테 너 이거 PDF 문서한테 문서에서 검색이 필요할 때는이 도구를 쓰면 돼. 알려주는 효과가 있거든요. 그래서 그냥 막 짓지 마시고 여러분들이 상황에 맞게 적절하게 지어 주시면 되겠습니다. 자, 그다음에 또 중요한게 뭐냐면 다음으로 문자율로 길게 제가 적었잖아요.이 부분이 바로이 툴에 대한 디스크립션 부분이거든요. 그런데이 디스크립션이란 건 뭐냐면 llm이 이툴을 쓸지 말지 판단낼 때 아까 네임도 참고한다라고 했었는데요.이 디스크립션도 같이 참조를 해요. 그래서 어 PDF 리트리버 툴이라는 네임을 가지고 있고 그다음에 이건 언제 쓰는 거냐? search and return information about sprdf이라고 나와 있죠. 그러면 유저가이 파일과 관련된 질문 했을 때에는 이렇게 디스크립션이 나와 있으니까 얘는 자연스럽게 쓰게 되는 거예요. 그래서 좀 더 자세히 적어 주자면 it contains useful information on recent AI trends라고 나와 있고 document is published on December 2023. 자, 그래서 우리가 연도까지 이렇게 지정을 해 줬는데이 스프리 AI 브리프 문서는 이제 월간 발행되는 거기 때문에 만약에 우리 유저가 2024년도 어쩌고 해서 물어보게 된다면 아, 요거는 연도가 2023년도로 나와 있으니까이 토론은 쓰면 안 되겠구나 이런 것들을 알려 주는 효과도 있어요. 그래서 여러분들이요 디스크립션 적을 때 이렇게 자세히 적어 주는게 좋다라는 거고요. 자, 그다음에 여러분들이 아마 처음 보시는 부분이 바로 도큐먼트 프람프트 부분이에요. 자, 이거는 뭐냐면은요. 제가 만약에 이거를 주석을 터 볼게요. 음. 치고 그다음에요 부분을요. 분할을 한 다음에요. 자, 얘를 실행합니다. 그다음에 리트리버툴한테 인보크를 날릴 거예요. 그래서 여기에 삼성전자가 개발한 생성형 AI의 이름은 자, 이런 식으로 한번 날려 볼게요. 자, 날리면 결과가 나오거든요. 결과가 문자율로 나오죠. 자, 프린트를 한번 해 볼게요. 툴이라서 문자율로 나오는데 이렇게 나오거든요. 자, 그런데 여기 보시면은요. 다 좋아요.이 검색된 결과를 얘가 알아서 페이지 콘텐츠 부분만 쫙 반란해 가지고 나오거든요. 네, 여기에 몇 가지 문제점들이 있죠. 아까도 이전에 영상에서도 제가 강조드린 것처럼 어디서부터 어디까지가 끊어지는 부분인지 명확하지는 않아요. 여기 공백이 들어가 있긴 하지만 아주 명확하다라고 보기에는 좀 어렵죠. 그러다 보니까 얘가 여기 끝에서 요렇게 있을 때 이어지는 문장으로 판단 내릴 수도 있어요. 일단 그 첫 번째 문제점이 있고요. 두 번째 우리는요 얘가 답변을 했으면 어떤 문서에 어떤 몇 페이지로부터 나온 답변이다라는 출처를 달게끔 되어 있어요. 그런데 여기에는 지금 메타데이터가 포함이 안 되어 있거든요. 그러다 보니까 얘는 답변을 하더라도 몇 페이지에서 발된 내용입니다라는 것을 우리한테 알려 줄 방법이 없어요. 그러니까 제가 무슨 말을 드리고 싶냐면 그냥 기본값을 이렇게 쓰게 되면은 페이지 컨텐트만 가져오지 메타데이터는 반영을 안 해 준다라는 거예요. 그래서 우리가 메타데이터를 효과적으로 반영해 주기 위해서 도큐먼트 프ரும்트라는 키값에다가 프ரும்트 템플릿을 써서 여기에다가 메타데이터를 이렇게 정의를 해 줍니다. 자, 그래서 이걸 쓰는 방법은요.이 중가를 열고 페이지 컨텐츠는 페이지 컨텐트 넣어 주시면 되고 메타데이터의 키값만 여기에다가 넣어 주시면 돼요. 그래서 우리 메타데이터 안에는 솔스라는 애도 있고 페이지라는 애도 있거든요. 저는 요거 두 개를 넣어 줬어요. 그래서 어떻게 예쁘게 포매팅해서 넣어 줬냐면 도큐먼트 들어가고요. 컨텍스트 부분에다가는 페이지 컨텐트를 넣어 줬고 메타데이터 부분에다가는 솔스 부분에 이제 문서의 파일 명이 들어가게 되는 거고요. 그다음에 어 페이지 부분에다가는 이제 페이지 번호가 들어가게 됩니다. 여러분들도 이런 식으로 이제 수정해서 쓰실 수가 있는 거죠. 자, 그래서 이걸 실행한 다음에 그다음에 제가 한번 실행해 볼게요. 자, 실행하면 이제 우리의 우리가 입력하해 놓은 어떻게 보면 양식이라고 말씀드릴 수가 있을 것 같은데 그 양식에 맞춰서 들어간 걸 볼 수가 있죠. 그래서 도큐먼트 XM의 태깅으로 잘 되어 있고요. 컨텍스트 부분에 우리가 참조해야 될 문서의 부분들이 잘 들어가 있고 페이지 번호 예쁘게 들어가 있고요. 그다음에 솔스도 잘 들어가 있는 걸 볼 수가 있죠. 자, 이런 정보들을 우리가 같이 줘야 얘가 최종적으로 답변에 대한 어떤 참조 레퍼런스를 달 때 페이지 번호와 소스가 있기 때문에 정상 답변을 얻을 수 있게 돼요. 만약에 여러분들이이 과정을 뺐다면 그 참조되는 부분이 반영이 안 되게 되는 거죠. 그래서 리트리버 2를 쓸 때는 웬만하면은 도큐먼트 프롬프트를 이런 식으로 주시는게 좋다라고 볼 수가 있습니다. 자, 그러면 다시 얘를 합쳐서 여기다가 넣고요. 목록 정의까지 해 줄게요. 그러면은 툴에 우리 리트리버 툴 하나만 넣어 줬습니다. 우리가 원래 이전까지 많이 했던 거는 이제 웹 검색 툴도 넣었었죠. 근데 이번에는 리틸버툴만 넣어 줬어요. 자, 다음으로는 우리 에이전트인데요. 에이전트에서 에이전트 스테이트라는 걸 정의를 해 줄 건데 얘는 타입 딕트를 상속받아서 우리가 이전까지는 뭐 그래프 스테이트라는 걸로 정의를 해 줬었는데요. 이번에는 다른 거 필요 없이 메시지스만 담긴 에이전트 스테이트를 한번 정의해 볼 거예요. 그래서 이게 시퀀스 베이스 메시지라는 건 뭐냐면 이건 시퀀스 시퀀셜하게 들어간다는 얘기고 리스트랑 동일하다라고 이해하셔도 좋습니다. 자, 그래서 베이스 메시지 형태가 쭉 들어가게 되고요. 애드 메시지스 리서 함수로 메시지를 추가를 해 줄 거예요. 에이전트에서는 요것만 있으면 돼요. 되게 심플해지죠. 자, 그다음에 이제 노드와 엣지입니다. 노드를 구성을 할 건데요. 모델 네임을 가져올 거예요. 자, 이거는 뭐냐면 제가 여기에서 가져와서 보여 드릴게요. 제가 별도로 만든 패키지 중에 하나가이 모델 네임인데요. 모델 네임이 자꾸 바뀌어요. 그러다 보니까 나중에 제가 일괄적으로 업데이트 해 드리기 위해서 이런 함수를 만들어 놨어요. 그래서 GPT 4를 쓰면은 GPT 4 미니가 이렇게 세팅이 되고요. 45라고 적으면은 45가 자동으로 세팅이 되게끔이 조정을 해 놨고 여러분들이 이런 식으로 이제 변수로 할당하면은 좋은 점은 뭐냐면 처음에는 되게 번거러워 보이거든요. 이거 그냥 문자를 넣는 거 아니야? 넣으면 되는 거 아니야? 이렇게 생각할 수 있는데 나중에이 모델명이 또 업데이트가 될 수가 있겠더라고요. 그래서 업데이트가 되면은 제가 알아서 반영을 해 드릴테니까 여러분들은 이렇게 코드로 넣어 주시면 되는 거죠. 만약에 GT 4OS로 나왔다 하면은 여러분들이 일일이 찾아서 이거를 다 업데이트 할 필요 없다라는 소리예요. 그래서 요런 것들 하나 만들어 놨고요. 모델 네임을 받아 와서 어 여기에 그레이드 먼저 관련성 체크를 합니다. 그레이드 다큐먼트를 해서요.이 스트럭처드 아웃풋으로 정여화된 답변을 받을 거예요. 그래서 어 스트럭처드 아웃풋의 그레이드 부분에 그레이드 클래스를 넣어 주고요. 그다음에 프롬트를 넣어 놨어요. 요거는 이제 그레이딩을 해 주는 그런 프롬프팅이라고 보시면 되겠습니다. 자, 그래서 프롬프트의 lm 위드 툴를 써 가지고요. 체인을 만들어 주고 메시지스의 현재 상태에서 메시지를 가져와요. 메시지 목록들이 쭉 달려 들어옵니다. 리스트 형태로 되어 있을 거예요. 자, 그러면이 중에서 -1번 하면은 가장 최근 질문을 가지고 오는 거예요. 왜냐면 유저가 질문을 하면 그 질문이 가장 최상단에 있기 때문에 요거를 가져왔고요. 그다음에 요거에 question에 원래 있던 퀘션이랑 그다음에 마지막에 있었던 라스트 메시지를 가져와서 요거를 가지고 이제 검색된 문서 아 죄송합니다. 제가 아까 어 혼선이 있었네요. 먼저 유저의 질문이 먼저 쌓이는 거죠. 그래서 0 번째죠. 우리 메시지 리스트 다시 한번 볼게요. 자 이렇게 보면은 유저의 질문이 먼저 쌓이겠죠? 그다음에 우리가 컨텍스트 리트리버 하게 되면은 리트리벌 된 결과가 그다음에 이렇게 쌓이게 됩니다. 자,이 부분에 있는게 바로 라스트 메시지가 되는 거고요.이 라스트 메시지의 컨텐트가 결국에는이 검색된 문서다. 문서가 들어가 있을 거다라고 가정을 해 보는 거죠. 자, 그다음에 원래 질문은 메시지의 가장 최상단에 있는 거고요. 자, 이렇게 해서 컨텍스트 부분에 우리가 검색된 문서 넣어 주고 그다음에 퀘션 부분에 퀘션 넣어서 체인자 인보크 하면은 스쿼드 리트가 나오게 되고요. 요거에 바이너리 스코어를 찍어 보면은 이게 도큐먼트가 릴러먼트하다 아니다를 우리가 알 수가 있죠. 만약에이 도큐먼트가 릴러트 하면은 바로 답변 생성하러 갈 겁니다. 그런데 릴러트 하지 않으면은 리라이트 노드로 보내 주는 거를 볼 수가 있어요. 자, 그다음에이 에이전트라는 노드에서는 이제 스테이트 메시지스 메시지 목록들 입력으로 받아서요.이 바인드 툴수 하면은 리트리버 2을 바인딩을 해 준 거예요. 우리 LM 모델에 리트리버 할 수 있는 도구를 지어주고 여기에다가 메시지를 이제 넣어 가지고 최종적으로 응답을 생성하게 됩니다.이 이 리스 함수를 썼기 때문에이 최종 응답도 자동으로 메시지스에 이렇게 추가가 될 예정인 거죠. 자, 그다음에 리라이트인데요. 만약에 우리가 결과가 안 좋았을 경우에는 이제 리라이트를 할 수도 있어야 됩니다. 그래서 휴먼 메시지에다가 언더라인 스멘트 인택트에 어쩌고 준 다음에 퀘션을 주고요. 그다음에 리라이트 수행을 시켜요. 그래서 채 오픈에 가져와서 모델전 인복해서 메시지를 넣어 주게 되면은 우리가 가장 최근에 질문과 질문과 그다음에이 질문을 바탕으로 리라이트된 결과가 이제 리스에 담기게 되는 거죠. 그러면이 결과를 메시지스에 마찬가지로 넣어 주게 돼요. 자, 다음으로는 제너레이션 파트인데요. 제너레이션 파트에서는 메시지스를 받아다가 원래 있던 질문은 항상 0 번째라고 했죠. 가장 처음에 들어왔으니깐요. 그다음에 가장 마지막 부분에서는 이제 닥스가 있으니까이 검색된 독이죠.이 검색된 독과 원래 있던 질문을 가지고 레그 프럼프트를 사용해서 이제 안에다 넣어 주게 됩니다. 넣어 주게 되고 컨텍스트와 패션을 넣어서 최종적으로 응답을 생성하게 되는 거죠. 자, 다음으로는 우리가 그래프 정의를 한번 보실 건데요. 어, 그래프 정의는 에이전트 노드, 그다음에 툴로드라는 걸 추가를 해 줬어요. 여기에다가는 우리가 툴스라는 도구 목록을 넣어 놨잖아요.이 툴로드로 이렇게 정의하실 수가 있습니다. 간단한 거죠. 요거는 툴로드 내가 만약에 처음 본다 하시는 분들은 우리 챕터 1에서 다뤘던 코어 기능들 있죠? 거기에 한번 보시면은 도움이 되실 것 같아요. 거기에 툴로드 세션이 있거든요. 그래서 툴 노드만 다루니까 그거 한번 보고 오십시오. 자, 그다음에 리트리블 하고 리라이트하고 제너레이터 하는 거 노드 추가했고요. 에이전트를 하고 에이전트가 어툴를 그러니까 툴을 쓸지 말지 와 그다음에 툴을 썼다면은 그거에 대한 결과런 것들이 이제 툴스 컨디션에 담기게 되는 거죠.이 이 툴스 컨디션은요. 랭그래프에 원래 있던 어 요거가 어디에 있냐면 여기에 이제 원래 있던 내용이거든요. 요거 정의된 부분이 우리가 위에서 정의를 했나 봐요. 자, 여기에 보면은 툴스 컨디션 랭그래프의 프리빌트에 들어가 있는 거를 볼 수가 있죠. 자, 그래서 얘가 해주는 역할은 이거 하나예요. 우리가 에이전트 노드로부터 어, 툴스 컨디션 에이전트가 도구를 쓰잖아요. 그러면이 도구 실행 결과가 있을 거예요.이 결과가 툴스 컨디션의 결과로 넘어오게 되고 툴스라고 나오면은 얘는 도구를 쓰겠다라는 판단을 내린 거예요. 그러면 도구를 쓰겠다라는 판단을 내렸으니까 retri리브를 수행하게 되는 거고요. 만약에 얘가 도구를 안 써도 된다라는 판단을 내리게 되면은 그럴 때는 이제 and드 조건에 따라서 and로 끝나는 것을 볼 수가 있습니다. 자, 그래서 여기까지 받고 그다음에 애드 컨디션나 엣를 통해서 리치브 된 결과를 어 그레이드 도큐먼트에 넣어 주고요. 넣어 주고 그다음에 품지 평가를 하게 돼요. 지금 여기에서 패스 부분은 지금 또 생략이 된 거를 볼 수가 있죠. 왜냐면은이 패스의 결과가 얘가 노드의 결과로 나와요. 그게 무슨 소리냐면 그레이드 도큐먼트 쪽에 보시면은요. 자, 이런 식으로 나와 있는데 얘가 반환하는 값을 볼까요? 반환하는 값이 제레이트나 리라이트잖아요. 이게 노드 명이에요. 그래서 우리가 별도의 패스 지정 없이 그냥 생략하고 들어갔다라고 보시면 돼요. 그래서 그레이드랑 리라이트가 나오게 되는 거고요. 제너레이터와 리라이트어 요거에 따라서 이제 어 나머지 처리를 하게 되는 거죠. 자, 얘를요 우리가 시각화를 해야지 좀 더 잘 이해를 하실 수가 있습니다. 시각화를 해 보면 이제 에이전트한테 질문이 주어져요. 그럼 에이전트는 판단을 하죠. 아, 내가 이거 도구 써야 돼? 말아야 돼? 그러면은 만약에 대한민국의 수도 어디야라는게 들어오면요? 얘 도구 안 써도 되는 거죠. 그럼 어디로 가냐면 바로 and드로 들어가게 됩니다. 그래서 에이전트가 답변 생성하고 and로 나가게 되는 거고요. 만약에 에이전트가 도구를 써야 된다라는 판단이 들면 리트리브를 해서 리라이트를 해서 에이전트한테 주고 그다음에 이제 에이전트가 최종적으로 생성을 해서 이제 엔드로 보내주는 그러한 흐름을 따르고 있다라고 보시면 됩니다. 자, 그래서요 그래프를 한번 실현해 볼게요. 어, 참성전자가 개발한 생성의 AI의 이름은이라는 질문을 던져봤어요. 자, 그러면 자, 여기 보이시나요? 에이전트가요.이 질문을 보고 ень하는 프로세스를 하죠. 덫을 했으니까이 삼성전자의 생성형 AI 이름이라는 쿼리분을 만들어서 PDF 리트리버를 호출을 했으면 좋겠다라는 의견을 줬어요.이 호출하고 검색할 때는 쿼리의 내용도 좋고요. 얘가 알아서 만들어 준 거죠. 그다음에 얘가 어 짐작커인데 여기 닥스 릴러트 부분에서 이제요 내용을 기반으로 PDF 리트리버를 해서 결과를 얻을 수가 있고요. 그다음에 이렇게 얻어진 결과를 리트리브 통해서 이렇게 최종적으로 한번 포매팅된 문서 결를 받아본 다음에요. 받아본 다음에 그다음에 이제 제너레이션으로 들어가게 됩니다. 자, 요거를 한번 다시 한번 정리를 해 볼게요. 에이전트가 만약에 도구를 써야 된다라는 판단을 내리는이 부분 있죠?이 이 부분이 어디냐면 여기 밑에 봤을 때요 부분이 되는 거예요. 도구를 써야겠다라고 얘는 판단 내린 거죠. 자, 그럼 내렸으면은 리트리브를 수행한다고 했으니까 여기 밑에 보면은 리트리브를 수행하죠. 그래서이 도구를 써야겠다라고 판단이 내렸고 그다음에 리트브 해서 XML 태그 형식으로 예쁘게 답변까지 만들어 준 거를 볼 수가 있습니다. 자, 그다음에 여기에서도 어 보시면은 이렇게 쭉 가죠. 그다음에 마지막으로 여기서 필요한 내용들을 다 검색했기 때문에 에이전트 단에서 제네레이트 아 에이전트 따이 아니라 여기서 제네레이트 노드가 별도로 있는데요. 리트리브를 했고 그다음에 리트브의 결과를 제너레이트 노드에 넣어서 최종적으로 문서에 대한 문서의 검색 결과를 바탕으로 답변을 도출해낸 다음에 그다음에 끝내 버리는 요러한 흐름을 따르고 있습니다. 자, 그래서 요거 스트림 그래프를 해서 한번 찍어 보는 것도 좋은 방법이고요. 자, 이런 식으로 에이전트를 써도 토큰 출력이 잘 되죠. 자, 그다음에 대한민국의 수도는 이게 이제 백미죠. 요거는 레그가 전혀 필요 없잖아요. 자, 한번 실행해 보면은 바로 답변이 나온 걸 볼 수가 있어요. 왜? 얘 에이전트가 판단 내리기로 이거는 레그가 필요 없다라고 판단이 내렸으니까. 자, 그다음에 또 하나의 코너 케이스가 있거든요. 이건 뭐냐면 얘가 직접적으로 바로 답변을 못 해요. 그렇다고 해서 문서 검색 결과에도 포함이 되어 있지 않아. 그럴 때 어떻게 되는지 한번 보죠. 자, 이걸 실행하게 되면은요.요 내용은 문서에 없거든요. 그래서 없는데 얘는 그걸 잘 모르니까 없다라는 내용을 모르니까 일단 어 도큐먼트 리트리버를 수행하게 됩니다. 자, 수행해서 관련성 체크를 했는데 노가 떴어요. 그러면 쿼리를 리라이트를 해 주죠. 리라이트 해주고 에이전트에 넣었는데 여전히 모르겠대요. 그래서 얘는요. 리라이트하고 에이전트하고 리라이트하고 에이전트하고 이걸 뺑글뺑글 도는데 우리가 우리가이 관련성 체크 로직이 계속 녹았니까 얘도 이제 재기에 빠지는 것을 볼 수가 있고 최종적으로 그래프 리콜션 에러에서 10 리미트에 도달한 것을 볼 수가 있죠. 그러니까 이게 재기에 빠지는 거는 뭐냐면요. 우리가 아까 그래프 흐름에서 자 보세요. 에이전트의 대한민국의 수도는 어디야? 그건 바로 답변했죠. 그다음에 PDF 리트버 도구를 써서 답변 찾을 수 있는 거는 요기죠. 요렇게 요렇게 지금 여기에서도 조건문이 하나 더 추가가 된 건데요. 요렇게 요렇게 요렇게 해서 최종 답변을 받는 거죠. 리칠브 하고 관련성 체크를 해서 통과를 했으니까 바로 제너레이트 해서 결과를 얻는 것을 볼 수가 있습니다. 자, 그래서 여기까지 했는데 했는데 마지막으로 나온게 지금 요거였었죠. 테디노트의 영체인 튜토리얼. 자, 얘는요. 우리가 이런 상황에 도달한 거죠. 어 얘는이 내용을 모르기 때문에 일단이이 경로로는 갈 수가 없어요. 그다음에 툴을 써야 된다라고 판단 내려서 툴를 썼습니다. 근데 문서 검색 결과에 당연히 트노트 관련된게 없으니까 페일이 났을 거거든요. 페일이 나면 얘 어때요? 리라이트를 하죠. 리라이트를 해서 다시 에이전트로 보낸단 말이에요. 그럼 에이전 다시 판단을 내해서 또 2를 써야 될지 말지를 계속 판단을 내려요. 근데 얘 같은 경우에는 어이 레버스가 노가 떴어요. 그러면은 에이전트로 다시 돌아왔잖아요. 그러면은 에이전트는요. 이게 관련성 체크 노가 됐으니까 다시금 어떻게 툴를 써야 될지 다 지금 프로세스로 들어가게 되는 거예요. 그래서이 터 프로세스를 통해서 내가 어떤 식으로 리트리브 해야 될지 과거 이력이 있으니까이 이력을 토대로 다시금 리트리버를 수행하게 됩니다. 근데 여기서 문제는 지금 웹색 도구가 중간에 없기 때문에 얘가 계속 이렇게 뺑글뺑글 도는 거예요. 왜냐면은 얘가 퀄리 리라이트 했다 한들 어차피 문서 안에는 그 내용이 없거든요. 없기 때문에 쿼리 리라이트 해도 안 나오고 해도 안 나오고 계속 여기서 뺑글뺑글 돌게 되는 그런 스 형장이 일어나게 되는 거죠. 자, 그래서 여기 끝부분에 보시면은요. 결국에는 그래프 리컬션 에러를 뜨고 이걸 현재로서는 해결할 수 있는 방법이 없기 때문에 여기에서는 이게 최선이에요. 그러니까 정리를 하자면이 흐름에이 흐름이 간편하고 좋아요. 대명규 수도 서를 물어보면 바로 답변 나오고 다 좋은데이 흐름을 구현을 했을 때 한 가지 아쉬운 점은 뭐냐면 한 가지가 아쉬운 점뿐만 아니라 굉장히 크리티컬한 거죠. 문서에서도 없고 내가 사전에 알고 있는 정보도 없는 경우에는 그러면은 이거에 대한 해결 방도가 없는 거예요. 그래서 여기에 재기에 빠지게 되는 거죠. 그래서 여러분들이 이걸 만약에 보완한다, 보완하는 관점에서 보면은 저라면은 리라이트 해서 웹 검색을 하든 좀 이렇게 뺑글뺑글 재기가 나타나지 않도록 좀 구성을 해 줄 것 같아요. 그래서 이런 것들은 여러분들의 연습이나 여러분들의 영향이기 때문에 그런 것들을 한번 다양하게 테스트해 보셨으면 좋겠습니다. 자, 이번 튜토리얼의 목적은 뭐였냐면요.이 에이전트를 노드 안에서 한번 써 보자라는 거예요. 그래서 에이전트를 쓰면 여러 가지 라우팅 체 체인이 줄어들 있고 얘한테 툴만 이렇게 지급해 주면 얘가 알아서 툴을 골라서 적절하게 테스크를 잘 해쳐 나가니까 요런 것들에 대해서 한번 알아봤다라고 보시면 돼요. 그래서 이번 시간에는 에이전트를요 랭그래프 안에 넣고이 랭그래프를 구성하는 흐름에 대해서 한번 고민해 봤습니다. 네. 이번 시간에는 아댑티브 레그에 대해서 알아보도록 할게요. 저희 아댑티브 레그는 에이전틱 레그 다음에 나오는 파일이고요.요 아댑티브 레그는 어 요거는 이제 쿼리 분석과 능동적 자기 수정 래그를 결합해서 다양한 데이터 소스에서 정보를 검색하고 생성하는 전략입니다. 사실이 아댑티브 레그라는 거는요. 이제 어 논문 아댑티브 레그에서 사용된 그런 튜토리얼이라고 보시면 되고요. 요것도 마찬가지로 랭그래프의 튜토리얼에 올라왔던 내용을 제가 좀 더 한글화를 하고 저희가 이해하기 쉽도록 좀 재구성한 파일이라고 봐 주시면 될 거 같아요. 그래서 관련된 논문을 참고해 보시는 것도 좋은데요.이 논문의 내용을 아주 짧게 요약을 하자면이 아댑티브 레그라는 전략은 먼저 쿼리 분석하는 전략이 추가로 들어가고요. 그다음에 셀프 리플렉티브 레그를 결합을 하게 됩니다. 그런데 이제 여러분들께서이 셀프 리플렉티브 레그에 대해서 아직까지 배우신 적이 없지만 저희가이 다음에 나오는이 셀프 레그 파트에서이 내용을 좀 더 딥하게 다뤄볼 예정이거든요. 그래서 거기에서 한 번 더 봐 주시면 좋을 것 같고요. 어이 셀프 리플렉티브 레그라는 거는 이제 자가 수정이라는 거를 의미를 합니다. 그러니까이 자가 수정이라는 건 뭐냐면 만약에 우리가 리트리브를 해서 그레이드 도큐먼트를 하고 그다음에 제네레이션을 하게 되는데이 제네레이션 한 결과를 가지고 이제 자가 수정을 하게 되는 거죠. 그러니까 예를 들어서이 관련성이 없는 답변이 나왔다 이러면은 트랜스폼 커리를 하는 이런 자가 수정도 하게 되고요. 혹은 할루스네이션이 발생을 했다 하면은 다시금 제네레이션 하도록 요런 식으로 이제 만들어 주는 것을 의미라 합니다. 그래서 큰 그림에서는 그렇다라는 거고요. 그래서이 아댑티브 레그라는 거는이 셀프 레그 측면인 요기 자가 수정하는 부분과 이제 플러스로 쿼리 분석을 하는 부분.이 이 쿼리 분석이라고 하는 것은 이제 쿼리가 들어왔을 때 이거를 라우팅을 하는 것을 의미를 하는데요.이 라우팅을 할 적에 아이 쿼리를 보고 아이 부분은 웹 검색이 필요하다.이 부분은 내가 벡터 DV에서 문서 검색이 필요하다.이 부분은 이제 라우팅하는 부분이라고 이해해 주시면 되겠습니다. 그래서 정리를 하자면이 아댑티브 래그는 크게 두 축이 있다. 처음으로이 쿼리 쿼리에 대한 분석을 해서 내가 하고자 하는 테스크로 이렇게 분할을 해 주는 거 그게 1번 파트가 되겠고요. 두 번째로는 이제 셀프 레그 부분이라고 말씀드렸죠. 그래서이 제너레이션을 하고이 제너레이션 된 결과에서 어 자체적으로 분석을 해서 할루스네이션이 있으면 다시 제너레이션 하고 혹은 할루스네이션은 없는데 관련성이 없다면 트랜스폼 커리를 해 주는 이런 흐름을 만들어 냈다라고 봐 주시면 될 거 같아요. 자 그러면 저희가 환경 설정을 해 보고 바로 코드로 들어가 보도록 하겠습니다. 자이 코드에서 첫 번째이 환경 가져오는 거는 동일하고요. 그리고 리트버 체인 만드는 것도 요것도 동일합니다. 자, 동일하고 밑으로 한번 내려 볼게요. 자, 먼저 쿼리 라우팅과 문서 평가 부분을 한번 보실게요.이 LMMS 단계라고 하는 거는요 단계를 의미하는 건데요.이 단계에서는 쿼리 라우팅과 문서 평가를 수행한다라고 나와 있고요. 아댑티브 브랙의 중요한 부분으로 효율적인 정보 검색과 생성에 기여한다라고 나와 있죠. 그러니까 여기서 효율적이다라는 의미는 뭐냐면 우리가 유저의 쿼리가 이렇게 들어오잖아요. 들어오면 우리가 무조건적으로 래그를 하고 혹은 무조건적으로 외검 검색을 수행하는게 아니라 얘가 스스로 판단을 내려서 이거를 좀 더 효율적으로 구성을 한다라는 거죠. 그래서 우리는 외 검색과 이제 레그 요렇게 두 가지를 나누어서 진행을 할 건데요. 자,이 부분은 어떻게 구성인지 한번 볼게요. 우리가 이전에는요 에이전틱 레그를 할 때는 이거를 에이전트로 구성을 해서 에이전트 스스로 판단을 내려서 라우팅하는 부분으로 구성을 했는데 여기에서는 에이전트로 구성하는게 아니라 라우팅 체인을 만들어서 구성하는 방법을 한번 보실 거예요. 그래서이 라우트 컬이라는 데이터 클래스 쪽에 보시면은 데이터 소스 부분에 이제 리터럴로 벡터 스토어와 웹서치 둘 중에 하나가 들어갈 수 있다라고 타입 정의를 해 주고요. 그리고 des립션 부분에 보면은 usure question choose to route it to search or 벡터스토어 요렇게 나와 있죠. 그러니까 에이전트 에이전트가 아니라 llm이죠. LM으로 하여금 어이 웹서치로 라우팅을 보낼 것인지 아니면 벡터 스토어로 보낼 것인지를 결정을 지어 주는 그런 클래스라고 보시면 됩니다. 자, 우리가 베이스 모델을 상속받은 라우트 커리이 데이터 클래스를 정리를 해 주잖아요. 그러면이 베이스 모델을 상속받은 라우트 커리를 LM의 위드스트처드 아웃풋 안에다가 이렇게 지정을 하면은 그러면은 얘의 아웃풋은요 데이터 소스가 되는 거고요.이 이 데이터 소스 안에 들어가는 내용은 벡터 스토어와 웹서치가 되게 되는 거죠. 그래서 우리가 앞으로 랭그래프 쪽에서는 에이전트를 쓰는 경우도 많지만 이렇게 툴콜링 펑션을 사용한 펑션 콜링이죠. 펑션 콜링을 사용한 기능인이 with 위드 struc드ed드ed 아웃풋 정형화된 결과물을내는 이러한 구조로 짜여져 있는 코드를 많이 보시게 될 거예요. 그래서 우리가 어 여러분들이 생각하시기에 그냥 에이전트로 구성하면 되는 거 아닌가라고 생각하실 수도 있지만 에이전트로 구성하는 것보다 이렇게 하는 이유는 우리가 보다 좀 더 정용화된 틀을 만들어 주겠다라는 거예요. 그러니까 에이전트로 하면은 얘가 자체적으로 판단서 실행에 옮기는 것까진 좋아요. 좋은데 우리가 에이전트가 많아지게 되면은 이제 컨트롤러빌리티가 떨어진다라고 얘기를 하거든요. 그러니까 만약에 멀티에트로 갔을 때 뭐네 개, 다섯 개가 동시에 막 여러 개가 막 자기 판단에 의해서 움직이다 보니까 내가 원하는 방향성대로 좀 안 나올 수가 있어요. 그래서 어떤 부분에 대해서는 우리가 정형화된 아웃풋 출력을내는 lm의 with struct터ed 아웃풋 안에다가 이렇게 우리가 명시된 데이터 클래스로 정의를 해 줘서 얘가 나올 수 있는 출력값을 이렇게 딱 정형화된 형태로 만들어 주는 거죠. 그리고 이제 프롬프트 쪽에 보시면은 엑스포트 라우팅어 user question션이다라고 나와 있고 어떠한 상황에 따라서 라우팅을 하면 될지를 보다 자세하게 적어 주시는게 좋아요. 왜냐면 lm이 판단을 내릴 적에 여기에 나와 있는이 시스템 프롬프트를 보고 라우팅을 수행하게 되는 거거든요. 그래서이 벡터 스토어가 도큐먼트 요것과 관련된 도큐먼트를 포함하고 있다면 그러니까 도큐먼트가 아니라 도큐먼트와 관련된 질문을 포함하고 있다면 그럴 때에는 벡터 스토어로 라우팅을 해 주고 그리고 그렇지 않다면 웹서치로 수행을 해라라는 시스템 프롬프트를 넣어 주고요. 그다음에 휴먼의 질문이 들어오게 되는 거죠. 그러면 LRM이 요러한 내용을 토대로 아 내가 넥터 스토어로 라우팅을 할지 아니면은 웹서치로 보낼지를 결정을 짓게 되는 겁니다. 자, 요거를 실행을 해서 우리 라우팅 체인을 만들어 주고요. 그다음에이 라우팅 체인에 인보크를 해서 수행을 해 볼게요. 물론 제가 여기다 프린트 구문으로 이렇게 넣어 놓긴 했는데요. 우리가 보다 자세히 확인해 보기 위해서 여기에다가 이렇게 한번 수행을 해 보겠습니다. 자, 이렇게 수행을 하게 되면은 라우트 쿼이라는 객체가 나오게 되는데 이건 우리가 만들어 놓은 데이터 클래스가 되는 거죠. 그래서 데이터 클래스는 여기에서 정의한이 데이터 클래스를 의미하는데요. 여기 안에는 이제 데이터 소스라는 키가 하나 들어가 있는 것을 볼 수가 있습니다. 그래서이 데이터 소스라는 키 안에 우리가 정의한 벡터 스토어와 웹서치가 둘 중에 하나가 선택적으로 지정이 되게 되는 거죠. 자, 이렇게 결과가 나오면요. 우리가 데이터 소스의 키값으로 벡터 스토어를 끄집어 낼 수가 있거든요. 그래서 만약에 여기에 리트라고 한번 넣어 볼게요. 넣어 보고 그다음에 리트에다가 요걸 찍어 보면 이제 객체가 나오는데 여기에 데이터 솔스를 실행을 하면 그 안에 있는 데이터를 끄집어 낼 수가 있는 겁니다. 자, 요런 식으로 만들어 봤고요. 아, 요거를 지우고 다시 한번 실행을 해 보면 프린트 구문으로 우리의 객체가 잘 출력이 되는 것을 확인해 볼 수가 있습니다. 자, 이번에는 저희가 판교에서 가장 맛있는 섬칩 찾아죠? 요거는 AI 브리프와 전혀 관련성 없는 질문이 되겠죠. 이런 질문과 같은 경우에는 이제 데이터 소스의 웹서치로 결과가 나오는 것을 볼 수가 있습니다. 자, 이런 식으로 우리가 잘 나오는 것까지 확인을 했으면 다음으로는 우리가 검색 평가기를 한번 보실 거예요.이 검색 평가하기라는 것은 retri리버그레이더인데요. 한마디로 우리가 검색한 문서에 대해서 ret이딩을 하는 것을 의미를 합니다. 한마디로 우리가 문서들을 이제 쭉 검색해서 가져올 거예요. 가져오면은이 그레이더가 검색된 문서들이 관련성이 있는지 없는지를 평가를 해 준다라는 거죠. 그래서 우리가이 검색 평가기를 언제 쓸 거냐면 다시 위에 구조도로 올라가서 살펴보시면은 여기에서 리트리eve를 하게 되잖아요. 그러면 우리가 문서들을 가지고 올 텐데이 문서들을 가지고 그레이드 도큐먼트를 수행할 때 여기에서 검색 평가기가 동작을 하면서 문서를 이제 평가를 수행하게 됩니다. 그래서이 평가를 수행하게 되고이 관련성이 있는 정보라고 판단이 되면 이제 제너레이션 쪽으로 보내게 되는 거죠. 자, 그래서 여기로 다시 넘어가서 보시면요. 어, 그레이더이고 relevant 오브큐먼트 유저 question이다. 그다음에 필터 에러너스 어리치버스 요렇게 나와 있고요. 바이너리 스코어로 Yes or에 어 스코어를 주게끔 되어 있어요. 자, 그래서 이제 리트b브드 도큐먼트에 어, 우리 검색된 문서들이 들어가게 되고 그다음에 유저 퀘션에 퀘션이 들어오거든요. 그런데이 부분에서 여기 밑에 보시면은 쭉 내려 볼게요. 노드 쪽으로. 어 여기거든요. 문서 관련성 평가 노드. 그래서 체먼트 투션이에요. 근데 여기에 보면은 우리가 알고 있던 그 관련성 평가 로직과는 약간 다르실 거예요. 그러니까 이게 무이 다르냐면 우리가 문서 검색을 하면은 문서를 하나만 검색하는게 아니잖아요. 우리는 지금 뭐 열 개면 열 개 이런 식으로 검색을 할 겁니다. 그러면이 도큐먼트들이 이렇게 열 개가 만약에 있다라고 가정했을 때 이렇게 쭉 쌓여져 있을 거란 말이죠. 그러면이 도큐먼트들을요 반복문을 돌면서이 검색 평가기가 하나씩 하나씩 평가를 하게 되는 거예요.이 부분이 좀 다르죠. 원래 우리가 지금까지는요. 문서가 통으로 있고이 안에 정보가 있어 없어를 딱 한 번만 측정을 하거든요. 근데이 아댑티브 레그에서는 어 재미난 점은이 문서 하나하나에 대한 평가를 수행하게 돼요. 만약에 여러분들이 리버를 했을 때 30개의 문서를 가져왔다 하면은이 30개의 문서 하나하나에 대한 평가를 하죠. 자, 그런데 이거를 왜 개별적으로 평가를 하느냐? 한마디로 얘는요 개별적으로 평가를 해서 관련성 없는 정보 즉 노이즈라고 판단되는 정보를 컨텍스트에서 배제하기 위함이에요. 그래서 우리가 열 개의 문서들을 이렇게 가져왔는데 관련성 있는 정보가 요렇게 세 개만 있다. 그럼 우리가이 하나하나를 다 평가를 하잖아요. 그럼 관련성 없는 정보들은 얘는 빼버리고 얘는 빼버리고 관련성 있는 정보들만 이렇게 가져와서 뽑아내서 얘를 프롬프트로 넣어 주겠다는 거죠. 그래서 결국에는 얘 같은 경우에는요. 역할 자체가 관련성이 어 없으면 다시 뭐 빠꾸르시키던 어떤 단계로 되돌아가라. 이게 아니라요. 관련성 있는 정보들만 추출을 해서 알짜배기로 압축해 주는 그걸 도와주는 역할이라고 보시면 좋을 것 같아요. 그래서 우리가 만약에 이전까지 봤었던 흐름대로라면요. 여기로 봤을 때 그레이드 도큐먼트를 해서 전체 문서를 평가해서 바이너리 스코어 예솔노로 나왔으면 보통은 여기에서 컨디셔널 엣치를 줘 가지고 관련성이 있어 하면 제너레이션 해, 없어 하면 다시 돌아가 이런 식으로 흐름을 짰었단 말이죠. 근데 여기서는 컨디셔너 엣지를 안 준 이유는 관련성 있는 정보들만 압축을 하는 그러한 기능이기 때문에 여기서는 컨디셔널 엣지는 주지는 않았다 이렇게 보시면 되겠습니다. 자, 그러면 다시 돌아가서요.이 검색 평가기는 문서에 대한 평가를 수행하게 되는 거고요. 자,이 검색된 문서를 평가를 어떻게 하는지 한번 볼게요. 먼저 리트리블을 해서 요것도 끊어서 한번 보죠. 독스를 가져옵니다. 그러면 문서 이제 열 개가 가지고 와질 거예요. 독스를 출력을 해 보면 이제 문서가 열 개가 나오죠. 자,이 개서에 대해서 어, 반복문을 돌리는 걸로 저희는 한번 해 볼게요. 자, 요거를요. 요렇게 가져오고 그다음에 포독인 독스를 가져와서 요거를 요렇게 넣어 보고요. 패션에 도큐먼트가 빠졌네요. 여기에 도큐먼트 도큐먼트에다가 페이지에 컨텐츠를 넣어 가지고 한번 생성을 해 보죠. 아, 그리고 요거를 이제 프린트 구문이 빠지면 출력이 안 되니까 요런 식으로 프린트 구문을 넣어 주고 여기에 데이터 솔스가 아니죠. 아, 요거는 라우터니까 오케이 요렇게 한번 구성을 해 봤습니다. 자, 실행을 한번 해 볼게요. 그러면 데이터 소스 아, 죄송합니다. 퀘션 라우터로 적었네요. 리트버 그레이더로 적어야죠. 자, 렇게 하고 퀘션에는 퀘션 넣어 줄게요. 패션. 자, 이렇게 넣어 볼게요. 자, 그러면 바이너리 스코어가 예스 예스 예스 예 나왔어요. 어,이 question이 저 지금 저희가 뭐냐면 삼성전자가 만든 생성의 AI의 이름이라는 질문이 들어온 거잖아요. 그런데 처음네 개 문서에 대해서는 바이너리 스코어가 예스가 나왔어요. 그런데 그다음 세계에 대해서는 노가 나왔죠. 그다음에 예스가 나오고 노가 나왔단 말이에요. 그러면 우리가이 스코어가 만약에 예라고 판단이 되면 우리가 추가해 줄 수가 있어요. 그러니까 가령 우리가 이거를 코드로 좀 수정해 본다라고 하면은 이런 식으로 할 수가 있죠. 만약에 리트라는 변수에다 넣은 다음에 if 리트에 바이너리 스코어가 예스라면은 요거를 어떻게 냐면 필터드 닥스에다가 어드로 독에 페이지 컨텐트를 추가해 줄 수가 있다는 거예요. 혹은 도큐먼트를 추가해 주는 것도 가능하겠죠. 자, 이런 식으로 추가를 한번 해 볼게요. 자, 이렇게 추가를 했습니다. 프린트 구문을 안 찍어서 지금 출력은 없었는데 필터드스를 출력을 해 보면 이제 필터링된 결과를 보실 수가 있는 거예요. 그러니까 우리가 노이즈가 섞여져 있으면 아무래도 할루스테네이션이 나올 가능성이 높다라고 제가 말씀을 드렸는데 이렇게 한번 필터링하는 과정을 거친 다음에 들어가면 보다 양질의 답변으로 이어질 수가 있겠죠. 그래서어요 과정을 우리가 그 그레이더가 해 주는 거라고 봐 주시면 좋을 것 같아요. 제가 요거 코드는 필터링 하는 코드의 예시다. 이렇게 적어 놓고 넘어가도록 할게요. 그래서 요것도 이제 보시면은 이렇게 예스가 잘 나온다라는 것까지 보실 수가 있었어요. 요거를 위로 올려 볼게요. 자, 이렇게 적어 놨습니다. 자, 다음으로는요. 답변 생성을 위한 레그테인을 한번 볼게요. 제가 만들어 놓은 레그 프럼트를 써서 래그를 수행을 할 건데요. 요거는 일반적인 라이브 레그라고 보시면 됩니다. 우리가 이렇게 알고 있는 그 레그가 맞고요. 어, 프롬트를 주고 그다음에 포맷 박스를 해서 우리가 나중에 포매팅 해 가지고 넣어 줄 거예요. 여기에서는 레그 체인을 쓰는데요. 레그체인을 써서 프롬프트 제가 만들어 놓은 기본적인 레그 프럼프트와 그다음에 LLM과 STR 파서를 써서 일반적인 레그를 수행을 할 거예요. 자, 이렇게 수행을 하고요 포맷스는 나중에 문서를 포매팅할 때 쓸 예정입니다. 자, 그래서 레그 체인에 인보크를 해서 컨텍스트에다가 우리가 폼에 닥스를 해서 덕스를 넣어주고요. 여기에다가 이제 필터드 닥스를 넣어 줘도 되지만 우리는 일단은 체 도큐먼트를 한번 넣어 보도록 할게요. 자, 이렇게 해서 제너레이션 하면은 삼성전자가 만든 생성형 AI의 이름은 하우스입니다. 이렇게 잘 나오는 것을 볼 수가 있죠. 자, 다음으로는 우리가 할루스네이션 체커를 한번 볼 겁니다. 자, 요것도 위로 올라가서 한번 볼게요.이 할루스네이션 체커의 역할은요. 얘가 레그체인이 답변을 생성하잖아요. 자,이 흐름이 한번 전반적으로 보면은 라우팅해서 벡터 스토어에서 리트리브를 하고요. 그다음에 그레이드 도큐먼트를 해서 우리가 문서 압축을 합니다. 그래서 10 개 문서에서 다섯 개 문서로 줄어들고 그다음에 제네레이트를 해서 답변 생성을 받았죠. 그래서이 받은 답변에 대해서 할루스네이션 체커를 할 거예요. 그래서 거짓말을 하고 있는지 아닌지를 평가를 한 다음에이 컨디셔널 애를 통해서 거짓말을 했으면 다시 제너레이션으로 보내고 거짓말이 아니면 이제 다음 단계로 보내는 거죠. 그래서 저 역할을 수행하는 할루스네이션 체커를 만들 건데 한마디로 우리는이 평가자를 만든다라고 보시면 돼요. 그래서 그레이드 할루스네이션스의 모델 마찬가지로 베이스 모델을 상속받아서 어 우리가 데이터 클래스를 정의해 준다라고 보시면 돼요. 그래서 여기 안에는 바이너리 스코어로 넣어 줬고요. 엔서가 그라운디드 인펙트라면 예스를 줘라. 그렇지 않으면 노를 줘라. 이렇게 정의를 해 줬고 모델 네임 넣어 주고요. 얘도 마찬가지로 스트럭처드 아웃풋트로 그레이드 할루스네이션을 넣어 주는 것을 볼 수가 있어요. 자, 그렇게 해서 프롬트 비슷하게 넣어 주고요. 그다음에 그레이더를 생성을 해 주게 됩니다. 자, 이렇게 평가기를 만들어 줬고요.이 평가기 안에다가 우리가 검색된 문서인 독스 실제로 우리가 랭그래프의 그래프를 만들 때에는이 독스가 아니라 필터링된 독스가 들어가게 되겠죠. 그래서이 독스가 들어가고 제너레이션 답변 생성된 답변을 넣어 주게 됩니다. 자, 이렇게 해서 할루네이션을 체크를 해 봤더니 바이너리 스코어의 노다. 어, 얘는 거짓말을 하고 있지 않다라고 잘 주는 것을 볼 수가 있어요. 자, 다음으로는 우리가 그레이드 엔서 부분을 한번 보실 건데요.이 그레이드 엔서라는 데이터 클래스도 마찬가지로 베이스 모델을 상속받아서 만들어 주는 것을 볼 수가 있습니다. 여기에 바이너리 스코어에도 보시면요. indicate yes or no. whether the question solves the question이라고 나와 있죠. 자, 그래서이 바이너리 스코어에 보시면은요. 얘가 지금 답변을 생성해 낼 거예요. 요것도 도식을 한번 보죠. 보면은 답변을 만들어 내거든요. 근데이 할로스네이션과 렐러트는 역할이 좀 달라요. 그니까 우리가 흔히 처음에 이걸 처음 접하시는 분들 중에서 할루스네이션과 렐러트가 비슷한 개념이 아닌가라고 생각하시는 분들이 계실 수 있는데 개념이 약간은 달라요. 그니까 우리가 할루스네이션이라고 하는 거는이 정보에 없는 정보를 바탕으로 답변을 만들어내는 거. 한마디로 얘가 거짓말 했는지 안 했는지 여부를 판단하는게 할루스네이션이거든요. 그런데 렐러트는 뭐냐면 얘가 만들어진 답변이 얘가 만들어진 답변이 질문에 대한 관련성이 있는지를 평가하는게 릴러스예요. 그러니까 이런 경우가 있을 수 있거든요. 할루스네이션은 아닌데 질문에는 관련성 없는 엉뚱한 소리를 할 수도 있단 말이에요. 그래서 그걸 체크하는게 바로 렐트입니다. 그래서이 렐트 통과하면 최종 이게 답변이 되겠지만 만약에 렐트가 통과되지 못하면 다시 쿼리를 재조정해 주는 그러한 흐름으로 가게 되는 거죠. 자, 그래서이서 로먼스의 역할은 저분에서 역할이 있다라고 보시면 되겠습니다. 자, 그래서 요거를 만들어 주고요. 엔서 그레이더 엔서 그레이더라고 체인을 만들어 놓고 요거에 인복를 해서 이번에는 question션과 제레이트된 엔서를 넣어 주는 거를 볼 수가 있어요. 지금 위에서 보시면은 여기에서는 할루스네이션 그레이더는 검색된 문서를 기반으로 평가해 주는 거기 때문에 도큐먼트가 입력으로 들어갔단 말이에요. 그런데 얘 같은 경우에는 question션 제너레이션 이런 식으로 들어가게 되는 거죠. 그래서 관련성 평가를 해 봤더니 예스가 잘 나온 것을 볼 수가 있습니다. 자, 이제는 쿼리 제작성 노드를 위한 준비를 한번 해 볼 거예요.이 쿼리 제작성 노드라는 거는요. 우리가 렐러스 체크에서 통과되지 않았을 경우에 그때는 쿼리를 제작성하는 그런 흐름을 줘야 되기 때문에 쿼리 제작성하는 LM을 하나 더 만들어 줄 겁니다. 그래서 리라이트 프롬프트를 요렇게 넣어 주고 어 유저의 질문이 있고요. 요거를 좀 더 개선을 해오 해서 쿼리 제작성을 수행하게 돼요. 요거는 일반적인 SDR 아웃 파서를 댔고요. 그다음에 퀘션을 넣어서 쿼리 제작성도 잘 되는지 보겠습니다. 그래서 삼성전자가 개발한 생성의 AI의 이름은이라는 어 쿼리가 들어왔는데 요거를 이제 명칭은 무엇인가요? 요런 식으로 제작성을 잘 해 주는 것을 볼 수가 있습니다. 자, 다음으로는 우리가 웹서치 툴이 필요해요. 우리가 웹서치 툴은 왜 필요하냐면 요것도 다시 한번 위로 올라갔다 내려올게요. 여기에서 어, 이제 우리가 지금까지 봤었던 흐름은요. 여기에서 전반적으로 나오는요 아랫 부분을 다 보셨다면 이번에는 우리가 윗부분을 한번 보실 거거든요. 만약에이 질문에 대해서 웹색이 필요하다라는 판단이 들면은 우리는 웹서치를 수행을 해야 됩니다. 그래서 웹치를 수행하기 위한 태빌리를 가져올 거고요.이 이 웹서치 수행된 결과를 토대로 이제 제너레이션을 수행하게 되는 거죠. 자, 그래서 어, 요거를요 밑으로 쭉 내려 볼게요. 자, 웹색 로그. 어, 우리는 검색 결과를 세 개를 가져올 겁니다. 세 개를 가져오시고요. 그다음에 웹치 툴에 설치해서 어, 텔레노트 위키스 랭체인 튜토리얼 URL을 알려 주세요. 뭐 이런 식으로 한번 검색을 한번 해 보는 거죠. 자, 그러면은 검색을 이제 세 개 맥스 리트에 세 개로 넣었으니까 세 개의 외문서를 이런 식으로 이제 가져오는 것을 볼 수가 있습니다. 자, 그래서 검색된 결과의 첫 번째 결과 확인해 보실 수가 있고요. 뭐 요런 식으로 이제 링크가 들어가 있는 것도 확인해 볼 수가 있죠. 자, 이렇게 다 됐으면요. 우리가 이제 그래프 정의를 해 볼 차례입니다.이 그래프 안에 들어가는 상태는 생각보다 간단해요. 아, 요것도 오타가 있네요. 도큐먼트. 자, 이렇게 되고요. 어, 먼저 question션 유저가 입력한 질문이 들어오고 그다음에 어, 생성된 답변이 제너레이션에 들어가고요. 그다음에 검색된 문서가 도큐먼트에 들어갈 거예요. 그래서 요런 식으로 어, 넣어 줄 거고 그다음에 다음으로는 그래프의 흐름을 정리해 줄 건데 노드들을 이제 쭉 정의해 주시면 돼요. 사실은 여기까지의 과정들이 좀 어려웠다 뿐이지 이것들을 이제 조립하는 단계가 노드라고 보시면 되겠습니다. 그래서 우리가 몇 개 노드들을 만들어 볼 건데 먼저 리트브 하는 노드는 PDF 문서에서 검색을 해서 문서들을 가져오는 그런 노드예요. 그다음에 제너레이션은 레그체인을 써서 답변 생성을 해 줄 거고요. 이때 입력값으로는 우리가 검색된 문서와 그다음에 질문을 넣어서 답변을 해 줄 겁니다. 그 생성된 답변을 제너레이션에다가 넣어서 이제 세 개의 키워드가 다 완성이 되는 거를 볼 수가 있고요. 지금 여기에서도 사실은 제가 요거 세 개를 반환을 해 줬지만 엄밀히 따지면은 요거는 변하는 값이 아니기 때문에 이렇게만 해 줘도 될 거 같습니다. 네, 문제가 없을 것 같아요. 일단 둘게요. 자, 그다음에 그레이드 큐먼트를 한번 어 보시면은 요게 아까 말씀드린 것처럼 우리가 그레이딩을 해 주는 부분이죠. 그래서 retriever 그레이더가 문서 하나하나에 대해서리 ret 그레이딩 평가를 수행하게 됩니다. 그래서이 그레이드가 예스가 나오면요. 그러면 관련성이 있는 정보다라는 평가가 나오게 되는 거고요.이 필터트 닥스에다가이 문서를 하나씩 하나씩 추가해 주는 것을 볼 수가 있습니다. 자, 다음으로는 트랜스폼 qu쿼리에서는 간단하죠. 저희가 이미 체인을 다 만들어 놨기 때문에 question션 리라이터에 퀘션을 넣어서 리라이터를 해주고이 베 question션을 반환해 주는 것을 볼 수가 있고요. 다음으로는 웹서치 부분입니다. 우리가 웹서치를 해서 어 문서 웹서치 툴을 사용해서 퍼리 검색을 해 줄 거예요. 그래서 웹서치의 결과물들이 웹 리트 독스에 담기게 되는 거고요.이 결과물을 독스에 반환을 해서 이제 다음 노드로 연결해 주는 것을 볼 수가 있습니다. 자, 요런 식으로 이제 노드 구성을 했고요. 그다음에 엣지정이 들어가기 전에 몇 가지 아, 여기 추가 노드들이 있네요. 여기에 요것도 추가 노드라고 추가 노드 정의라고 적어 보겠습니다. 자, 여기에서도 보면은 라우트 퀘션 부분에서는요.이 퀘션을 라우팅을 해서 어, 얘가 웹치로 보낼지 아니면 벡터 스토어로 보낼지 요거를 판단 내려 주는 그러한 노드라고 봐 주시면 될 거 같고요. 그다음에요 문서 관련성 평가 노드에서는 decide to generate를 수행하게 됩니다. 자, 그래서이 필터ter 닥스가 만약에 없다면 그러니까 관련성 있는 문서가 하나도 없다면 얘가 어디로 보내게 되냐면 이제 트랜스폼 쿼리 쪽으로 보내 주게 되는 거고요. 어, 관련성이 있다라고 판단이 되면은 이제 제네레이트 쪽으로 라우팅을 수행하게 됩니다. 자, 다음으로는 할루스네이션 체커 부분이고요.이 이 할루스네이션 그레이더에서는 도큐먼트와 제네레이션을 넣고 할루스네이션을 수행하게 되고요. 만약에 할루스네이션이 있다면 할루스네이션이 있다면 어 요거는 아 죄송합니다. 할루스네이션 체크 여부인데 이게 그라운디니스 체크를 하게 되는 거거든요. 그래서 어 예스라면 그레이드가 예스라면은 그라운드라고 평가를 하게 되는 거고요. 그러면은 그라운드가 됐으니까요 엔서 그라운드에 인보크를 날려서 그다음 과정으로 수행을 하게 됩니다.이 이 엔서 그레이더 같은 경우에는 렐러스 평가를 수행하게 되는 거고요. 만약에 할루스네이션에서 페일이 나오게 되면은 노라고 나오게 되면은 이제 할루스네이션이 있다라고 평가를 하고 그에 맞는 나중에 여기 컨디셔널 엣지에서 할루스네이션이 체크를 해서 있다라고 하면은 어 제네레이션 어 제네레이션 로드로 다시 보내게 되는 거죠. 그래서 다시 한번 답변을 생성하게끔 유도를 해 줄 거예요. 그래서 정리를 하자면요 두 가지의 흐름이 하나의 노드에 들어가 있다라고 보시면 되는데요. 여기에서는 이제 할루스네이션 체크와 더불어서 문서의 관련성 평가까지 동시에 진행이 되고요. 만약에 할루스네이션이 없고 그라운디드가 되어 있다. 그라운디드가 되어 있다라고 하면은 요거에 대해서 엔서 렐러스 평가를 수행하게 되는 거고요. 만약에 할루스네이션이 발생이 됐다 하면 할루스네이션을 반환을 해줌으로써 다시금 제너레이션 하는 걸로 유도를 수행하게 되는 거죠. 자, 그래서 엔서 그레이더까지 수행하게 되고 만약에 엔서가 렐러트 하면은 렐러트 쪽으로 보내게 되고요. 릴러먼트 하지 않다면 not 러먼트 쪽으로 보내게 됩니다. 그래서 이제 세 가지의 결과를 총 반환하게 된다. 요런 흐름으로 만들어지게 되는 거죠. 자, 이렇게 해서 어, 마지막으로 그래프 생성적으로 한번 보실게요. 우리가 웹서치리브 그레이드 도큐먼트 제너레이트 트랜스폼 코리 노드를 추가를 해 줬고요. 애드 컨디셔널 부분에서 라우트 컨디션을 해서 웹서치면은 웹서치 노드로 보내게 되는 거고요. 벡터 스토어라고 결과가 나오면은 리트리브 노드로 보내 주는 것을 볼 수가 있습니다. 자, 다음으로는 엣지 추가를 해서 웹서치에서 제너레이터로 연결을 하고 리트리브에서 그레이드 도큐먼트 쪽으로 보내 주게 되는 거고요. 그레이드 도큐먼츠에 대한 결과가 어 요거에 트랜스폼 쿼리가 나왔으면은 트랜스폼 쿼리 노드로 보내 주게 되고 그다음에 통과를 해서 제네레이트를 해라라는 판단이 쓰게 되면은 제네레이트 노드 쪽으로 보내 주는 것을 볼 수가 있습니다. 자, 그다음에 트랜스폼 코리에서 리트리브로 연결해 주고요. 그리고 제너레이티브 노드에서는 이제 생성된 답변을 토대로 아까 보셨던 할루스네이션 체크를 수행하게 되는 거죠. 그래서이 할루스네이션 체크 수행을 통해서 할루스네이션 여부와 그다음에 릴러스까지 한 방에 다 처리를 한 다음에 최종적으로 이제 결과를네 개 그런 흐름을 어 지금 뛰고 있습니다. 그래서 앱을 컴파일한 다음에 요거에 대한 비주얼라이즈 그래프를 한번 보시면은요. 좀 더 명확하게 보실 수가 있을 거예요. 그래서 웹서치와 그다음에 리트리브 벡터 스토어 쪽으로 보내는 노드와 그다음에 제너레이션 흐름에 따른 정의 요런 식으로 이제 좀 나와 있죠. 이제 그래프들이 막 괴랄하게 이렇게 나와 가지고 좀 이해하시기 어려우실 수가 있는데 상단에 어 적어 놓은 좀 쉬운 도시화 부분을 참고해 주시면 좋을 것 같습니다. 자, 이렇게 나와 있고요. 자, 이제 그래프를 한번 실행을 해서 잘 나온 한번 볼게요. 우리가 삼성전자가 개발한 생성형 AI의 이름은이라고 물어봤어요. 그러면 도큐먼트가 릴러트한 도큐먼트를 이렇게 다섯 개를 어 뽑아 본 거고요. 제너레이트 해서 어 할루스네이션도 통과를 했고 그다음에 렐러스도 통과를 했기 때문에 정상적으로 요런 식으로 제네레이트가 잘 된 것을 볼 수가 있습니다. 자, 요거는 이제 반환값 때문에 렇게 나오긴 하는데요. 원래 같았으면은 요거 반환가 없으면 요렇게까지 잘 생성이 되는 것을 볼 수가 있을 거예요. 자, 그다음에 인풋에 이번에는 웹서칭에 필요한 질문 한번 해 보도록 하겠습니다. 그래서 2024년 노벨 문학상 수상자는 누구인가요? 요거는 벡터디 DB의 저장이 당연히 안 돼 있겠죠. 없는 정보겠죠. 이런 경우에도 잘 나온지 한번 보죠. 스트링 그래프를 해서 2024년 노벨 문학상 수상자는 한국의 작가 한강입니다. 해서 솔스 부분도 잘 나오는 것까지 확인해 볼 수가 있습니다. 만약에 여러분들이 예쁘게 답변 출력을 하고 싶고요 내용이 없었으면 좋겠다. 이건 제가 프린트 구문을 찍어 놨기 때문에 여기에 출력이 되는 거거든요.이 부분을 없애고 싶다 하시는 분들은요. 저희가 확인하기 위한요 프린트 구문들 있죠? 요런 것들을 전부 다 주석을 쳐 주시면 돼요. 저희가 지금은이 중간 과정에서 어떻게 일어나는지 보기 위해서 좀 제가 프린트 구문을 아주 상세하게 넣어 놨다라고 봐 주시면 될 거 같습니다. 자, 그래서 이번 내용이 이번 프로젝트가 어 꽤 길었죠. 아댑티브 레그에 대해서 보셨는데요.이 아댑티브 레그라는 거는 사실 요즘에 현업에서도 많이 고려가 되고 있는 그런 흐름이에요. 왜 그러냐면이 부분이 굉장히 매력적이거든요. 먼저 라우팅을 수행하는 부분도 매력적이고요. 그리고 래그를 했을 때 그레이드 도큐먼트를 해서이 노이즈를 줄이는 걸 레그라는 아 그 래그가 아니죠. llm을 써서 이걸 평가를 통해서 줄여낸다라는 거죠. 그래서 알짜배기 정보만 압축하면 확실히 답변품질이 좋아져요. 그래서 어 요렇게 아댑티브 레그 방식을 써서 우리가 필요한 정보들만 선택적으로 추출해서 제너네이션 하는 부분. 그다음에 어 또 추가적으로 할루스네이션 체커를 통해서 할루스네이션 평가도 들어가고 그다음에 릴러스 체크도 들어가기 때문에 어 요거까지 다 어 통과를 해서 추출해진 답변은 아무래도 좀 확실히 품질이 좀 어느 정도는 보장이 됐다 이렇게 보셔도 좋을 것 같습니다. 자 그런데요.이 파이프라인은 정말 좋긴 좋아요. 좋은데 다만 단점이 있다면 어떤 단점이 있냐면 중간에 LM이 보신 바와 같이 많이 쓰여요. 우리가 그레이드 도큐먼트를 할 때도 쓰이고요. 그다음에 할루스테니션 평가를 할 때도 쓰이고 릴스 체크할 때도 쓰이고요. 트랜스폼 커리할 때도 쓰이고 문서 검색하는 지연 시간도 있습니다. 한마디로 제가 말씀드리기 전 하는 거는이 품질은 좋아질 수가 있겠지만이 중간중간의 과정에서 지연 시간이 많이 늘어나게 돼요. 그래서 우리가 답변을 노출하기까지 꽤나 오랜 시간이 걸릴 수도 있거든요. 그래서이 부분에 대한 고민도 나중에는 같이 필요하실 거예요. 그런데이 늘어난 지연 시간을 요즘에 어떻게 풀어내고 있냐면요. 많이 풀어내고 있어요. 우리가 퍼플렉시티와 같은 UX를 보시면은요. 어, 답변이 나오기까지 꽤나 오랜 시간이 걸립니다. 하지만 사용자로 하여금 이걸 기다릴 수 있게 만드는 요인은 일단 첫 번째이 답변의 신뢰성이죠. 어, 당신이 좀 더 오래 기다리면 내가 좀 더 품질 좋은 답변을 제공해 드리겠습니다. 이런 부분들을 이제 약속을 하고 대신 시간이 오래 걸리더라도 이제 품질 보증을 어떻게 보면 더 해 주는 거죠. 그것도 있고요. 두 번째로는이 아까 UX로 풀어낸다는 부분은 뭐냐면 중간중간 과정에서 중간중간 과정에서 내가 어떤 작업을 현재 수행하고 진행하고 있는지를이 웹사이트상에서 띄워서 보여 줘요. 내가 만약에 검색을 하고 있으면 검색하고 있는 내용들을 보여 주고요. 리트리브나 그레이드 큐먼트를 하고 있으면 그런 과정들을 보여 준다는 거예요. 그래서 사용자로 하여금 멀뚱멀뚱 기다리는게 아니라 아 중간에 얘가 지금 어디까지 왔구나. 를 알려줌으로써 사용자가 인내하고 기다릴 수 있게끔 만들어 주는 거죠. 그래서 우리가 앞으로 품질 좋은 답변을 위해서는 사실 지연 시간이 늘어나는 부분은 어느 정도 우리가 감내는 해야 됩니다. 그렇다고 해서 너무 늘어나는 건 또 안 될 수가 있겠지만 조금은 늘어나도 요즘에는 사용자들이 많이 인내하고 기다려 주시는 편이거든요. 왜냐면 사용자들도 이제 어느 정도는 조금은 학습이 됐어요. 내가 조금 더 오래 기다릴수록 좀 더 정확한 답변을 받을 수 있겠구나라는 기대감도 있고 그런 부분들이 이미 학습이 됐기 때문에 조금 늘어나는 건 저도 괜찮다라고 생각이 들어요. 하지만이 괜찮다 아니다 부분은 이거는 각자가 판단하실 부분이라고 생각이 들고요. 만약에 어 지연 시간이 너무 늘어나서 최종 답변이 나오기까지 너무 오래 걸린다 하면은 아까 제가 말씀드린 부분처럼 중간에 어 스트리밍 출력으로 내가 어떤 부분을 수행하고 있다라는 부분을 유저에게 알려 줌으로써 어 유저가 기다릴 수 있게끔 만드는 그런 부분도 같이 고려하셨으면 좋겠습니다.네 네, 이번 시간에는 저희 아댑티브 레그에 대해서 알아봤습니다.&lt;/raw&gt;&lt;/document&gt;',
 '&lt;document&gt;&lt;title&gt;[허정준 X 테디노트] LLM 에이전트 집중탐구 with 허정준님 - YouTube&lt;/title&gt;&lt;url&gt;https://www.youtube.com/watch?v=zb3v45ik9KI&lt;/url&gt;&lt;content&gt;# [허정준 X 테디노트] LLM 에이전트 집중탐구 with 허정준님 🔥\\n## 테디노트 TeddyNote\\n50100 subscribers\\n211 likes\\n\\n### Description\\n6549 views\\nPosted: 8 Jan 2025\\nLLM 카테고리의 베스트셀러 저자이신 허정준 님을 모시고 라이브를 진행합니다!\\n\\n✅ 라이브에서 다룰 내용\\n- LLM 에이전트의 개념 비교하기(OpenAI, Anthropic, LangChain, Google, Huggingface)\\n- LLM 에이전트의 구성 요소\\n- LLM 에이전트 프레임워크\\n\\n🙇\u200d♂️ 연사님을 소개합니다.\\n💬 허정준\\n- 크몽 AI 엔지니어\\n- \\"LLM을 활용한 실전 AI 애플리케이션 개발\\"( 저자 \\n- 패스트캠퍼스 강사: LangGraph를 활용한 실전 AI 애플리케이션 개발\\n\\n💌 SNS &amp; Email\\n- Email: soss3264@gmail.com\\n- Email: kmong_ai_lab@kmong.com\\n- LinkedIn: \\n\\n✨ 라이브 이벤트 ✨\\n🔥 LangGraph를 활용한 실전 AI 애플리케이션 개발 강의 🔥\\n쿠폰코드: PRDTEA241227_ytl\\n할인율: 35% \\n강의 링크: \\n\\n#허정준 #테디노트라이브 \\n\\n📍 \\"테디노트의 RAG 비법노트\\" 랭체인 강의: \\n📘 랭체인 한국어 튜토리얼(무료 전자책): \\n📝 테디노트(깃헙 블로그) : \\n💻 GitHub 소스코드 저장소: \\n\\n15 comments\\n### Transcript:&lt;/content&gt;&lt;raw&gt;# [허정준 X 테디노트] LLM 에이전트 집중탐구 with 허정준님 🔥\n## 테디노트 TeddyNote\n50100 subscribers\n211 likes\n\n### Description\n6549 views\nPosted: 8 Jan 2025\nLLM 카테고리의 베스트셀러 저자이신 허정준 님을 모시고 라이브를 진행합니다!\n\n✅ 라이브에서 다룰 내용\n- LLM 에이전트의 개념 비교하기(OpenAI, Anthropic, LangChain, Google, Huggingface)\n- LLM 에이전트의 구성 요소\n- LLM 에이전트 프레임워크\n\n🙇\u200d♂️ 연사님을 소개합니다.\n💬 허정준\n- 크몽 AI 엔지니어\n- "LLM을 활용한 실전 AI 애플리케이션 개발"(https://product.kyobobook.co.kr/detail/S000213834592) 저자 \n- 패스트캠퍼스 강사: LangGraph를 활용한 실전 AI 애플리케이션 개발\n\n💌 SNS &amp; Email\n- Email: soss3264@gmail.com\n- Email: kmong_ai_lab@kmong.com\n- LinkedIn: https://www.linkedin.com/in/정준-허-b9b0192a3\n\n✨ 라이브 이벤트 ✨\n🔥 LangGraph를 활용한 실전 AI 애플리케이션 개발 강의 🔥\n쿠폰코드: PRDTEA241227_ytl\n할인율: 35% \n강의 링크: https://fastcampus.co.kr/data_camp_llm\n\n#허정준 #테디노트라이브 \n---\n📍 "테디노트의 RAG 비법노트" 랭체인 강의: https://fastcampus.co.kr/data_online_teddy\n📘 랭체인 한국어 튜토리얼(무료 전자책): https://wikidocs.net/book/14314\n📝 테디노트(깃헙 블로그) : https://teddylee777.github.io\n💻 GitHub 소스코드 저장소: https://github.com/teddylee777\n\n15 comments\n### Transcript:&lt;/raw&gt;&lt;/document&gt;',
 '&lt;document&gt;&lt;title&gt;[Upstage AI x 테디노트] Document Intelligence 파헤치기 - YouTube&lt;/title&gt;&lt;url&gt;https://www.youtube.com/watch?v=BSSzgEtIUp0&lt;/url&gt;&lt;content&gt;... 에 대해 공유드릴 예정입니다. ✓ 라이브에서 다룰 내용 - 문서 기반 업무가 왜 아직도 어려울까? - 업스테이지 Document Intelligece 소개 - 실전&lt;/content&gt;&lt;/document&gt;']</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=036a5ab0">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<br/>
<ul>
<li><code>include_domains</code> 사용 객체 : 특정 도메인만 포함하여 검색</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=8815c514">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [24]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">tavily_tool_with_domains</span> <span class="o">=</span> <span class="n">TavilySearch</span><span class="p">(</span><span class="n">include_domains</span><span class="o">=</span><span class="p">[</span><span class="s2">"github.io"</span><span class="p">,</span> <span class="s2">"naver.com"</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=52a1dca7">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [33]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">result3</span> <span class="o">=</span> <span class="n">tavily_tool_with_domains</span><span class="o">.</span><span class="n">search</span><span class="p">(</span>
    <span class="n">query</span><span class="o">=</span><span class="s2">"파이썬 프로그래밍 팁"</span><span class="p">,</span>  <span class="c1"># 검색 쿼리</span>
    <span class="n">search_depth</span><span class="o">=</span><span class="s2">"advanced"</span><span class="p">,</span>  <span class="c1"># 고급 검색 수준</span>
    <span class="n">max_results</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>  <span class="c1"># 최대 3개 결과</span>
<span class="p">)</span>

<span class="n">result3</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[33]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>[{'url': 'https://hyperconnect.github.io/2023/05/30/Python-Performance-Tips.html',
  'title': '고성능 ML 백엔드를 위한 10가지 Python 성능 최적화 팁 - 하이퍼커넥트',
  'content': '아쉬움을 달래고자 Python 커뮤니티에서는 multi-threading 대신 multi-processing을 사용하여 병렬 처리를 수행하도록 권장합니다. 그렇다면 정말 multi-processing을 쓰는 것이 답일까요? 사실 항상 그렇지만은 않습니다. Python multi-processing에서는 아래와 같은 두가지 문제가 존재하며, 상황에 따라 이 문제가 발생하지 않을 환경에서만 multi-processing을 사용하는 것이 낫습니다.\n\n1. 미리 Process pool을 만들어두지 않고, 매번 Process를 생성(spawning)하게 되면 오버헤드가 매우 높아집니다.\n2. 미리 Process pool을 만들어놔도, 프로세스간에 주고받는 데이터가 크다면 커뮤니케이션 오버헤드가 높아집니다.\n\n### Process 생성(spawn)에 대한 오버헤드\n\n먼저 1번의 경우부터 예시와 함께 보겠습니다. 아래 코드는 fibonacci(25)를 총 4번 수행하는 API입니다. `/multiprocess` 를 호출하면 4개의 multiprocessing pool을 사용하여 병렬로 계산하고, `/singleprocess` 를 호출하면 하나의 스레드로 순차적으로 함수를 네 번 호출합니다. [...] 그리고 profile 하고 싶은 함수에 `@profile` decorator 를 달아줍니다.\n\n```\n@ profile def slow_function(a, b, c):...\n```\n\n그 후\n\n```\n$ -lv\n```\n\n위 명령어로 파이썬 스크립트를 실행해주면 아래와 같이 profiling 결과가 나오는 것을 확인할 수 있습니다. [...] Spawn은 느린 것이 문제고, fork 방식은 안전하지 않은 것이 문제라면 둘 다 사용하지 말아야 한다는 것일까요? 사실 가장 좋은 방법은 HTTP 요청이 올 때마다 매번 spawn이나 fork를 통해 프로세스를 생성하는 대신, 어플리케이션 startup시에 미리 process pool을 만들어 전역변수로 할당해두고, HTTP 요청이 올 때마다 미리 만들어진 process pool을 사용하는 것입니다.\n\n위의 예시 코드에 아래와 같이 `startup_event_handler` 를 만들고, 미리 정의된 process pool를 사용하도록 수정한 예시입니다.\n\n```\nasync def startup_event_handler(): app. state. process_pool = multiprocessing. Pool(4) app. add_event_handler("startup", startup_event_handler) @ app. get("/multiprocess") async def multiprocess_run() -&gt; float: start_time = time. time() app. state. process_pool. map(fibonacci,[25, 25, 25, 25]) elapsed_time = time. time() - start_time print(f"multiprocess elapsed time: {elapsed_time 1000:. 1 f} ms") return elapsed_time\n```',
  'score': 0.5637388,
  'raw_content': '[Tech Blog](/)\n\n\n\n# 고성능 ML 백엔드를 위한 10가지 Python 성능 최적화 팁\n\nYoungsoo Lee, Suhyun Lee, Gunjun Lee\n\n[python](/tag/python.html)   [machine-learning](/tag/machine-learning.html)   [optimization](/tag/optimization.html)\n\nPython은 배우기 쉽고, ML 관련 라이브러리를 포함한 오픈소스 생태계가 상당히 발전해있는 좋은 언어입니다. 편의성이 좋다 보니 여러 회사들이 데이터 분석과 ML 모델 학습뿐만 아니라, 백엔드 서버에서도 Python을 자주 사용합니다. *(대표적으로 Instagram도 백엔드 서버로 Python을 사용합니다 [[0-1]](https://instagram-engineering.com/web-service-efficiency-at-instagram-with-python-4976d078e366))*. 하이퍼커넥트의 많은 ML 백엔드 서버들도 Python으로 작성되고 있는데요, 하지만 Python은 실행 속도가 느리다는 치명적인 단점이 있습니다. Python은 분명 ML 도메인에서 사용하기 좋은 언어이긴 하지만, 응답시간이 중요한 로직에서도 Python 백엔드 서버를 운영하면서 Python의 느린 속도 때문에 많은 고통을 겪어 왔습니다.\n\nPython의 속도가 문제가 되어도, 이미 작성된 로직들을 C++, Go, Rust, Kotlin과 같은 더 빠른 언어로 포팅하기는 쉽지 않습니다. 기본적으로 전체 비즈니스 로직을 새로운 언어로 다시 작성하는 것은 시간이 매우 많이 들며, 또 Numpy나 PyTorch와 같은 라이브러리의 이점을 포기하기도 쉽지 않기 때문이죠. 하이퍼커넥트도 Python에서 다른 언어로 포팅하기 어려운 상황들을 많이 겪어왔고, 그때마다 Python 자체를 최대한 빠르게 사용하기 위한 다양한 트릭들을 발견하며 성능 요구사항을 맞춰왔습니다.\n\n이번 포스트에서는 하이퍼커넥트가 Python으로 작성된 다양한 ML 백엔드 서버들을 운영하며 발견한 성능 최적화 기법 10가지를 공유해 보려 합니다. 특히 다량의 데이터를 사용하는 ML 워크로드에 특화된 최적화 기법들을 다루며, ML 백엔드에서 자주 사용되는 third-party 라이브러리를 효과적으로 사용하는 방법도 같이 공유합니다. Pypy, Numba, C binding 처럼 팀의 반발을 살 수 있으며(?), 유지보수성 난이도가 높아져서 적용이 어려운 방법들은 이번 포스트에선 다루지 않습니다. 단 몇 줄의 코드 수정만으로 서버의 응답시간(latency)을 절반 이상 낮출 수 있는 팁들도 있으니, 재미있게 읽어주세요.\n\n*Note: Python을 사용한다면 일반적으로 CPython implementation [[0-2]](https://en.m.wikipedia.org/wiki/CPython)을 사용할 것이기 때문에,* 글의 내용도 모두 *CPython implementation을 사용하는 것을 가정하고 작성했습니다.*\n\n### Table of Contents\n\n1. [상황에 따라 gc가 병목일 수 있다. 이런 경우 gc 발동 조건을 튜닝할 수 있다.](#1-상황에-따라-gc가-병목일-수-있다-이런-경우-gc-발동-조건을-튜닝할-수-있다)\n2. [Built-in list는 충분히 빠르지 않다. 필요시 array나 numpy를 사용하자.](#2-built-in-list는-충분히-빠르지-않다-필요시-array나-numpy를-사용하자)\n3. [multiprocess는 커뮤니케이션 오버헤드가 높기에, low-latency 시나리오에서 조심히 사용해야한다.](#3-multiprocess는-커뮤니케이션-오버헤드가-높기에-low-latency-시나리오에서-조심히-사용해야한다)\n4. [Pytorch를 multiprocess 환경에서 쓴다면 num\\_threads를 조정하자.](#4-pytorch를-multiprocess-환경에서-쓴다면-num_threads를-조정하자)\n5. [Pydantic은 아주 느리다. 불필요한 곳에서 가급적 사용하지 말자.](#5-pydantic은-아주-느리다-불필요한-곳에서-가급적-사용하지-말자)\n6. [Pandas DataFrame은 생성에 많은 시간이 걸리므로, 유의해서 사용해야 한다.](#6-pandas-dataframe은-생성에-많은-시간이-걸리므로-유의해서-사용해야-한다)\n7. [바닐라 json 패키지는 느리다. orjson이나 ujson을 사용하자.](#7-바닐라-json-패키지는-느리다-orjson이나-ujson을-사용하자)\n8. [Class는 충분히 빠르지 않을 수 있다. 너무 문제가 되면 dict를 사용하자.](#8-class는-충분히-빠르지-않을-수-있다-너무-문제가-되면-dict를-사용하자)\n9. [Python 3.11은 덜 느리다.](#9-python-311은-덜-느리다)\n10. [(보너스) line profiler 사용법](#10-보너스-line-profiler-사용법)\n\n# #1 상황에 따라 gc가 병목일 수 있다. 이런 경우 gc 발동 조건을 튜닝할 수 있다.\n\n일반적인 Python 백엔드 서버에서는 한 요청당 객체를 수 백 개씩 만드는 경우가 드뭅니다. 때문에 garbage collector에 의해 latency가 크게 발생하는 경우도 흔치 않습니다. 하지만 대규모 데이터를 다루는 ML 백엔드의 경우에는 다릅니다. 대표적으로 추천 API 서버에서는 요청이 들어올 때마다 수천~수만 개의 객체를 생성하고 처리해야 합니다. 이런 상황에는 garbage collection(GC)가 문제를 발생시킬 수도 있습니다. 하이퍼커넥트에서 운영 중인 추천 API 서버들도 GC로 인해 실행 속도가 늦어지는 현상이 자주 발견되었고, 코드 몇 줄의 수정을 통해 GC 설정을 조금만 튜닝하자 P99 Latency가 1/3 수준으로 낮아지는 경험을 하기도 했습니다.\n\n그렇다면 GC는 왜, 그리고 어떻게 문제를 일으킬까요? 이를 설명하기 위해 간단하게 Python garbage collection의 동작에 대해 먼저 설명하겠습니다.\n\n### Python GC\n\nPython에서 수명이 다한 객체는 기본적으로 reference counting을 통해 메모리가 회수됩니다. 모든 객체마다 자신이 참조되고 있는 개수(reference count)를 들고 있다가, 이 숫자가 0이 되면 메모리에서 삭제하는 방식이죠 [[1-1](https://devguide.python.org/internals/garbage-collector/), [1-2](https://en.wikipedia.org/wiki/Reference_counting)]. 하지만 reference counting 만으로는 메모리 관리에 한계가 있습니다. 바로 reference cycle이 있는 객체들에 대해서는 영원히 메모리를 회수할 수 없기 때문입니다. (ex. 순환 참조가 있는 linked list 객체) Reference counting 만으로는 reference cycle이 있는 객체들을 제거할 수 없으므로, Python에서는 cyclic garbage collection이라고 하는 작업을 추가로 수행하며, 이를 편히 garbage collection(GC)라고도 부릅니다. *(참고로 JVM 계열 언어에서는 reference counting 방식의 GC가 아닌, tracing garbage collection [[1-3]](https://en.wikipedia.org/wiki/Tracing_garbage_collection) 이라는 방법을 사용합니다.)*\n\nReference counting을 통한 메모리 회수는 보통 매우 빠르게 이루어집니다. 성능 문제는 보통 cyclic garbage collection 단계에서 발생합니다. 생각해봅시다. Garbage 객체를 제거하기 위해서는 먼저 garbage에 해당하는 객체를 찾는 작업이 선행되어야 합니다. 그럼 어떻게 Garbage\xa0객체를 찾을까요? “**모든”** 객체에 대해서 reference를 graph를 그리며, 접근 불가능한 cycle을 찾는 방법 밖에 없습니다. 현재 메모리에 있는 모든 객체에 대해서 전수 조사를 해야하기에 느려질 수 밖에 없는 것이죠.\n\nPython에서는 느린 GC 속도에 대응하기 위해 “Generation” 이라는 최적화 기법을 사용합니다. 이는 JVM에서의 weak generational hypothesis (young gc / old gc) 개념 [[1-4]](https://d2.naver.com/helloworld/1329)과 거의 일치합니다. 대부분의 객체는 짧은 수명을 가지며 생성 이후 빠른 시간안에 메모리에서 해제되어야 할 것들이고, 수명이 오래된 객체는 대부분 전역 변수처럼 존재하여 메모리에서 해제될 필요가 없는 객체라는 가설이죠. 실제로 위 가설을 바탕으로, GC를 수행할 때마다 항상 모든 객체에 대해 scan하는 대신, 특정 generation에 해당하는 객체들에 대해서만 scan을 수행합니다. Young generation 객체는 자주, Old generation 객체는 상대적으로 가끔씩 scan을 수행하는 것이죠.\n\n### Python Generation GC\n\n그렇다면 Python에서 generation은 어떻게 관리되고 있으며, 또 generation마다 GC는 어떤 주기로 실행되고 있을까요?\n\nPython에서 객체는 generation 0, generation 1, generation 2 중 하나에 포함됩니다. 기준은 해당 객체가 cyclic garbage collector로 부터 생존한 횟수입니다. 한 번도 GC 가 불리지 않은 객체는 gen0, 한 번 불렸지만 생존한 객체는 gen1, 두 번 이상 GC가 불렸지만 생존한 객체는 gen2에 속하게 됩니다. Python에서 각 generation마다 GC가 호출되는 빈도 수도 따로 조절됩니다. 이는 Python의 내장 함수인 `gc.get_threshold()` 을 통해 확인할 수 있습니다.\n\n```\n&gt;&gt;&gt; import gc&gt;&gt;&gt; gc. get_threshold()(700, 10, 10)\n```\n\n위 threshold만 보면 다소 헷갈릴 수 있는데요, 사실 `threshold0` 이 의미하는 바와 `threshold1, threshold2` 가 의미하는 바가 살짝 다릅니다. `threshold0` 의 값은 “(number of allocations) - (number of deallocations)이 threshold를 넘으면 gen0 GC가 호출된다”를 의미합니다. 기본 값은 700이니, “객체 생성 수 - 객체 해제 수” 가 700을 넘으면 gen0 GC가 호출된다고 보면 됩니다.\n\n`threshold1` 는 gen1에 대한 기준인데, 이는 “gen0 GC가 몇 번 호출되면 gen1 GC를 호출할 것인지”를 의미합니다. 기본 값으로 gen0 GC가 10번 호출되면 gen1 GC가 한 번 수행됩니다. 비슷하게 `threshold2` 는 “gen1 GC가 몇 번 호출되면 gen2 GC를 호출할 것인지”를 의미합니다. 다만 gen2 GC의 경우에는 여기에 더해 추가로 `long_lived_pending / long_lived_total` 이 25%를 넘을 경우에만 수행된다는 조건도 만족했을 때만 수행됩니다. Gen 2 GC에만 특별한 조건이 붙어있는 이유는 Gen 2 GC를 수행하는데 매우 오랜 시간이 소요되기 때문입니다 [[1-5]](https://devguide.python.org/internals/garbage-collector/#collecting-the-oldest-generation).\n\n### GC 오버헤드\n\n대규모 데이터를 다루는 ML 백엔드 서버에서는 하나의 요청에서 많은 객체가 생성될 수 있고, 이런 시나리오에선 더 자주 Cyclic GC가 발동될 수 있습니다.\n\n간단한 예시를 하나 살펴봅시다. Dummy 객체들을 다수 생성하고, 평균 생성 시간 및 최대 생성 시간을 출력하는 예시입니다. 메모리에 존재하는 객체를 더 많이 늘려주고자 Pytorch 및 Numpy 라이브러리도 사용하지는 않지만 import 해두었습니다.\n\n```\nimport time import numpy as np import torch class DummyClass: def __init__(self): self. foo =[[] for _ in range(4)] def generate_objects() -&gt; None: bar =[DummyClass() for _ in range(1000)] times =[] for _ in range(500): start_time = time. time() generate_objects() times. append(time. time() - start_time) avg_elapsed_time = sum(times)/ len(times)* 1000 max_elapsed_time = max(times)* 1000 print(f"avg time: {avg_elapsed_time:. 2 f}ms, max time: {max_elapsed_time:. 2 f} ms")\n```\n\n그 결과는 아래와 같습니다.\n\n```\navg time: 2.08ms, max time: 22.45ms \n```\n\n평균 케이스와 최악의 케이스가 차이가 많이 나는 것은 확인했습니다. 다만 아직 위 코드가 GC의 영향을 받는지는 확실하지 않습니다. 그렇다면 GC를 끈 상태에서 코드를 다시 실행해봅시다. Python에서는 `gc.disable()` 함수를 호출하는 것 만으로 Cyclic GC를 비활성화 할 수 있습니다.\n\n```\nimport gc... gc. disable()...\n```\n\n```\navg time: 0.73ms, max time: 0.88ms \n```\n\n위 결과를 보면 실행 속도에 큰 차이가 있음을 확인할 수 있습니다. 최악의 케이스(max time)의 경우 GC 여부에 따라 속도가 25배나 차이가 발생합니다. 이 현상이 프로덕션 API 서버에도 발생한다면 간헐적으로 긴 지연이 발생하므로 P99 Latency에 유의미한 영향을 줄 수 있습니다.\n\nGeneration GC별 오버헤드도 알아볼 수 있을까요? `gc.disable()` 대신 `gc.set_threshold(700, 0, 99999999)` 를 사용하면 gen0, gen1 GC는 그대로 수행하고, gen2 GC만 (사실상) 불리지 않도록 설정할 수 있습니다. Gen2 GC만 비활성화한 경우엔 avg time: 0.91ms, max time: 1.15ms의 결과가 나왔으며, GC를 완전히 끈 것보다 오래걸리긴 하지만, GC를 전혀 튜닝하지 않은 케이스와 비교시 매우 빨라짐을 확인할 수 있습니다.\n\n또 다른 실험으로, 위 예시에서 Pytorch 및 Numpy를 import하지 않는다면, GC를 비활성화 하지 않아도 속도가 매우 빨라짐을 확인할 수 있습니다. (Gen2 GC를 비활성화 한 경우와 비슷한 속도). 이를 해석하면 Pytorch 및 Numpy가 상당한 양의 객체를 생성하고, 이들이 해제되지 않은 상태로 메모리에 상주하여 Old generation 객체 가 되어있는데, Gen2 GC가 불릴 때마다 Pytorch 및 Numpy에서 생성한 객체까지 scan을 하느라 매우 많은 시간이 걸렸다고 볼 수 있는 것이죠.\n\n### 하이퍼커넥트의 사례\n\n다수의 객체를 생성하는 ML 백엔드 어플리케이션에선 GC를 튜닝하는 방법이 때론 응답시간을 최적화할 수 있는 매우 효과적인 방법일 수 있습니다. 특히나 ML 백엔드에선 Pytorch나 Numpy와 같은 무거운 라이브러리들을 사용할 가능성이 높기 때문에 더더욱 GC 오버헤드가 클 수 있습니다. GC를 건드리는게 두렵다고요? 위와는 다른 이유기는 하지만 Instagram에서도 Python Django 서버에서 GC를 비활성화 하면서 운영하기도 했습니다 [[1-6]](https://instagram-engineering.com/dismissing-python-garbage-collection-at-instagram-4dca40b29172). 생각만큼 비현실적인 방법은 아닙니다.\n\n물론 GC를 완전히 비활성화 하는 방법은 공격적일 수 있습니다. GC를 완전히 비활성화 하는 대신, 조금 덜 공격적인 방법으로 GC를 튜닝한다면 메모리가 무한히 증가하는 상황을 막으면서도 응답시간을 크게 개선할 수 있습니다. 하이퍼커넥트에서 사용하고 있는 방법으로는 아래와 같습니다.\n\n1. Gen2 GC의 threshold를 높혀서 실행 빈도를 낮게 설정\n2. 어플리케이션 start-up 이후 [`gc.freeze()`](https://docs.python.org/3/library/gc.html#gc.freeze) 를 한 번 호출하여, 라이브러리에서 생성한 Old generation 객체들에 대해서는 Gen2 GC에서 scan하지 않도록 변경\n3. 지속적으로 요청이 들어오는 패턴이 아닌 주기적(ex. 100ms마다)으로 요청이 들어오는 어플리케이션에선, GC 호출 시점과 API 요청 시점이 겹치지 않도록 설정 (수동으로 GC 트리거 시점 조정)\n\n하이퍼커넥트에선 GC 튜닝을 통해 P99 Latency를 최대 1/3 수준까지 줄이기도 했습니다. Python garbage collection에 대한 상세한 설명은 [공식 dev 문서](https://devguide.python.org/internals/garbage-collector/index.html)와 [공식 코드](https://github.com/python/cpython/blob/main/Modules/gcmodule.c)에서 찾아볼 수 있습니다.\n\n# #2 Built-in list는 충분히 빠르지 않다. 필요시 array나 numpy를 사용하자.\n\nPython의 built-in list는 매우 편리하지만, 속도가 결코 빠르지는 않습니다. 이럴 때 python의 built-in array나 numpy의 ndarray를 사용하면 도움이 될 수도 있습니다. “또 numpy야? 진부하다!” 라고 생각하실지 모르겠습니다. 하지만 numpy를 쓴다고 해서 항상 빠른 것은 아니며, 잘못 사용할 경우 오히려 성능을 더 악화시킬 수도 있습니다. 본 섹션에서는 어떤 상황에서 array나 numpy를 쓰는 것이 적절한지 다뤄보고자 합니다.\n\n### Python에서의 list, array 구현 차이\n\n이를 이해하기 위해서 먼저 CPython에서의 list의 구현을 살펴보겠습니다.\n\n```\n/* Python built-in list */ typedef struct{PyObject_VAR_HEAD/* Vector of pointers to list elements. list[0] is ob_item[0], etc. */ PyObject** ob_item; Py_ssize_t allocated;} PyListObject;\n```\n\n위 그림 및 코드처럼 list는 포인터들의 배열, 즉 더블 포인터로 구성되어 있습니다. 이는 리스트 내에서는 인접한 요소들이더라도 실제 메모리 상에서는 요소들이 제각기 다른 주소에 흩어져있을 수 있다는 뜻입니다. 따라서 cache locality가 떨어지고 cache miss가 더 자주 발생해 성능이 하락할 수 있습니다.\n\n반면 Python의 built-in `array` [[2-1]](https://docs.python.org/3/library/array.html) 나 numpy의 `ndarray`는 c의 array처럼 연속된 메모리 공간에 값을 할당합니다. 아래는 built-in `array` 객체의 구현입니다.\n\n```\n/* Python built-in array */ typedef struct arrayobject{PyObject_VAR_HEAD char* ob_item; Py_ssize_t allocated; const struct arraydescr* ob_descr; PyObject* weakreflist;/* List of weak references */ Py_ssize_t ob_exports;/* Number of exported buffers */} arrayobject;\n```\n\nList와 동일하게 `ob_item` 이라는 필드를 가지고 있지만, list의 경우 타입이 `PyObject` 인 반면, array의 경우 타입이 `char*` 인 것을 눈치채셨나요? 이처럼 built-in array는 어떤 객체에 대한 레퍼런스를 들고 있는 것이 아니라, 값 자체를 들고 있기 때문에 locality가 보장됩니다. 대신 int, byte, float 등 primitive한 값만 저장할 수 있다는 제약이 존재합니다.\n\nNumpy의 ndarray가 C로 구현되어 있는 것은 워낙 유명합니다. ndarray 또한 built-in array와 비슷하게 연속된 메모리 공간에 값을 할당하기에, 매우 빠른 속도로 메모리 접근이 가능합니다. 다만 ndarray에서 `dtype=’O’`로 설정하여 객체를 저장하게 된다면, 객체에 대한 reference를 저장하기 때문에 built-in list와 동일한 방식으로 작동합니다 [[2-2]](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.object_).\n\n이러한 차이 때문에 list와 array, ndarray는 상황에 따라 상이한 성능을 보입니다. 여기서는 두 가지 상황에 대해 이들의 성능을 비교해보겠습니다.\n\n### list, array, numpy ndarray의 접근 성능 비교\n\n얼핏 보면 list의 경우 인덱스 상으로는 인접한 요소들이더라도 실제 메모리에서는 제각기 다른 주소에 흩어져있기 때문에 cache locality가 떨어지고 cache miss가 더 자주 발생해 성능이 하락할 것이라고 추론할 수 있습니다. 그런데 진짜로 그럴까요? 아래 벤치마크를 통해 확인해보겠습니다.\n\n```\nimport timeit import array import numpy as np # Parameters for testing N = 10000 # number of rows and columns in the array M = 1000 # number of iterations # Initialize the arrays my_list =[i for i in range(N)] my_array = array. array(\'i\', my_list) my_ndarray = np. array(my_list) def test_list_sum(): sum(my_list) def test_array_sum(): sum(my_array) def test_numpy_sum(): sum(my_ndarray) def test_numpy_npsum(): np. sum(my_ndarray) # Perform the benchmarks list_time = timeit. timeit(test_list_sum, number = M) array_time = timeit. timeit(test_array_sum, number = M) ndarray_sum_time = timeit. timeit(test_numpy_sum, number = M) ndarray_npsum_time = timeit. timeit(test_numpy_npsum, number = M) # Output the results print(f\'list: {list_time* 1000:. 1 f}  ms\') print(f\'array: {array_time* 1000:. 1 f}  ms\') print(f\'ndarray (sum): {ndarray_sum_time* 1000:. 1 f}  ms\') print(f\'ndarray (np.sum): {ndarray_npsum_time* 1000:. 1 f}  ms\')\n```\n\n```\nlist: 72.0 ms array: 126.4 ms ndarray (sum): 373.0 ms ndarray (np.sum): 2.5 ms \n```\n\n결과를 보면 ndarray의 경우 `np.sum()`을 썼을 때는 압도적으로 빠른 성능을 보여주지만 그냥 sum을 했을 때는 list가 array나 ndarray보다 오히려 빠릅니다. 왜 그럴까요?\n\n위의 코드는 모든 요소들을 한 번씩 읽고 더하는 연산을 수행합니다. Built-in list의 경우 `test_list_sum()` 함수를 실행할 때 `memory read` → `arithmetic operation (+)` 이 순차적으로 일어납니다.\n\n그런데 array나 ndarray는 다릅니다. 이들은 python 객체가 아닌 primitive 값을 저장하기 때문에, python 로직(i.e. sum 함수)에서 값에 접근하기 위해서는 먼저 primitive value를 python 객체로 변환해야 합니다. 따라서 `test_array_sum()` 이나 `test_numpy_sum()` 함수를 실행할 때는 다음과 같은 연산이 수행됩니다.\n\n`memory read` → `conversion (int -&gt; Python object)` → `arithmetic operation (+)`\n\n이 변환의 오버헤드로 인해 list보다 더 나쁜 성능을 보이는 것으로 보입니다.\n\n그렇다면 `np.sum()`은 왜 빠른걸까요? 이 함수는 C로 구현되어 있어 요소를 Python 객체로 변환할 필요 없이 primitive 값에 대해 그대로 연산을 수행합니다. 이 경우 모든 값을 C 로직에서 더한 뒤, 최종 결과를 Python 객체로 한 번만 변환하면 되므로 conversion overhead가 거의 없습니다. 또한 C의 for loop이 python의 for loop보다 훨씬 오버헤드가 적고, 일부 연산의 경우 OpenMP와 같은 병렬처리 기술을 활용할 수도 있어 월등히 빠른 것이죠.\n\n즉, numpy를 통해 성능 향상을 극대화하기 위해서는 indexing을 통해 하나씩 접근하는 것이 아니라, numpy에서 제공하는 별도의 operator를 사용하는 것이 중요합니다. 만약 numpy에서 제공하지 않는 자체 함수를 사용해야 하는 경우, `apply_along_axis()` [[2-3]](https://numpy.org/doc/stable/reference/generated/numpy.apply_along_axis.html) 와 같은 함수를 사용하면 그냥 for loop을 돌리는 것보다는 우수한 성능을 보일 때도 있습니다. 하지만 이 또한 pure-python 레벨에서 로직을 수행하는 것이므로 성능 향상을 최대로 가져가려면 최대한 vectorize된 operator를 활용하는 것이 좋겠죠.\n\n### list, array, numpy ndarray의 직렬화 성능 비교\n\n또 다른 경우는 배열을 직렬화(serialization) 하는 상황입니다. 예를 들어 배열에 담긴 값을 DB에 저장하거나 페이로드에 담아 보낼때 binary 데이터로 변환이 필요할 수 있습니다. 이때 array나 ndarray의 경우 이미 연속적인 메모리 공간에 binary 형태로 값이 저장되어 있기 때문에 값을 단순히 읽거나 copy해주면 되지만, list의 경우 메모리 공간 곳곳에 흩어져있는 각각의 값을 읽은 다음 이를 binary로 변환까지 거쳐야 하기 때문에 훨씬 느립니다.\n\nPython에서 널리 사용되는 직렬화/역직렬화 패키지 중 하나인 marshal을 이용해 marshal(직렬화), unmarshal(역직렬화) 성능을 비교해보겠습니다.\n\n```\nimport timeit import array import numpy as np import pickle import marshal import random N = 10000 # number of elements in the array M = 1000 # number of iterations # Initialize the arrays my_list =[random. random() for _ in range(N)] my_list_enc = marshal. dumps(my_list) my_array = array. array(\'f\', my_list) my_array_enc = marshal. dumps(my_array) my_ndarray = np. array(my_list, dtype = np. float32) my_ndarray_enc = marshal. dumps(my_ndarray) def test_list_marshal(): marshal. dumps(my_list) def test_list_unmarshal(): marshal. loads(my_list_enc) def test_array_marshal(): marshal. dumps(my_array) def test_array_unmarshal(): marshal. loads(my_array_enc) def test_ndarray_marshal(): marshal. dumps(my_ndarray) def test_ndarray_unmarshal(): marshal. loads(my_ndarray_enc) # Perform the benchmarks list_marshal_time = timeit. timeit(test_list_marshal, number = M) array_marshal_time = timeit. timeit(test_array_marshal, number = M) ndarray_marshal_time = timeit. timeit(test_ndarray_marshal, number = M) list_unmarshal_time = timeit. timeit(test_list_unmarshal, number = M) array_unmarshal_time = timeit. timeit(test_array_unmarshal, number = M) ndarray_unmarshal_time = timeit. timeit(test_ndarray_unmarshal, number = M)...\n```\n\n```\n[marshal] list: 131.2 ms array: 0.8 ms ndarray: 1.9 ms [unmarshal] list: 155.4 ms array: 0.9 ms ndarray: 0.9 ms \n```\n\nmarshal과 unmarshal 결과를 보면 list와 array, ndarray 사이에 상당한 속도 차이가 있습니다. 특히 list의 경우 다른 두 방식과 직렬화/역직렬화 시간이 무려 80~160배나 차이가 납니다. (다른 직렬화 패키지인 pickle을 사용하더라도 비슷한 결과를 관찰할 수 있습니다) 이는 list의 경우 메모리공간 여기 저기에 흩어져 있는 데이터들을 취합해야 할 뿐만 아니라, 각각의 요소에 대해 data type을 확인한 뒤에 바이너리로 변환해야 해서 추가적인 overhead가 발생하기 때문으로 보입니다.\n\n이처럼 list와 array, ndarray는 얼핏 비슷해 보이지만 자료를 저장하는 방식때문에 성능 면에서는 큰 차이를 보입니다. 만약 직렬화 오버헤드가 큰 상황이라면 array나 ndarray를 사용해서 실행 속도를 최적화하는 것도 고려해볼만 합니다.\n\n### 하이퍼커넥트의 사례\n\n하이퍼커넥트에서 운영하고 있는 추천 서버에서는 임베딩처럼 다수의 float로 이루어진 벡터를 다루는 연산을 많이 수행합니다. 이들 연산의 대부분은 numpy의 vector operator나 fancy indexing을 최대한 활용하고 있습니다. 따라서 복잡한 로직임에도 불구하고 많은 요청량을 감당해내도록 구현하고 있습니다.\n\n이 외에도 위에서 언급한 serialization 상황에서의 성능 개선을 실제로 경험한 사례도 있습니다. 추천 서버의 특성상 데이터베이스에 벡터를 읽고 쓰는 로직이 많은데요, 벡터를 데이터베이스에서 읽을 때 marshal과 같은 빠른 바이너리 인코더를 이용하여 역직렬화를 수행했음에도 불구하고, list 객체의 역직렬화 오버헤드가 상당히 높았습니다. 이를 numpy ndarray 기반의 로직으로 바꾼 결과 역직렬화 시간이 5분의 1로 줄어들었고, 서비스의 end-to-end latency도 크게 개선되었습니다.\n\n다만 위에서도 언급했듯 단순히 numpy나 array를 사용한다고 해서 항상 속도가 빨라지는 것은 아니므로, 어떤 연산을 수행하는지 파악하고, 해당 상황에서 실제로 속도 향상이 있는지 간단한 실험을 통해 미리 테스트해보고 적용하는 것이 좋겠습니다.\n\n# #3 multiprocess는 커뮤니케이션 오버헤드가 높기에, low-latency 시나리오에서 조심히 사용해야한다.\n\n기본적으로 CPU 연산에 많은 시간이 걸린다면 병렬성(parallelism)을 통해서 작업 속도를 빠르게 할 수 있습니다. Multi-threading이나 multi-processing이 대표적인 방법이죠. 하지만 잘 알려져있다시피 Python에서 multi-threading은 Global Interpreter Lock (GIL) [[3-1]](https://wiki.python.org/moin/GlobalInterpreterLock) 때문에 성능을 거의 개선해주지 못합니다.\n\n아쉬움을 달래고자 Python 커뮤니티에서는 multi-threading 대신 multi-processing을 사용하여 병렬 처리를 수행하도록 권장합니다. 그렇다면 정말 multi-processing을 쓰는 것이 답일까요? 사실 항상 그렇지만은 않습니다. Python multi-processing에서는 아래와 같은 두가지 문제가 존재하며, 상황에 따라 이 문제가 발생하지 않을 환경에서만 multi-processing을 사용하는 것이 낫습니다.\n\n1. 미리 Process pool을 만들어두지 않고, **매번 Process를 생성(spawning)하게 되면 오버헤드가 매우 높아집니다.**\n2. 미리 Process pool을 만들어놔도, **프로세스간에 주고받는 데이터가 크다면 커뮤니케이션 오버헤드가 높아집니다.**\n\n### Process 생성(spawn)에 대한 오버헤드\n\n먼저 1번의 경우부터 예시와 함께 보겠습니다. 아래 코드는 fibonacci(25)를 총 4번 수행하는 API입니다. `/multiprocess` 를 호출하면 4개의 multiprocessing pool을 사용하여 병렬로 계산하고, `/singleprocess` 를 호출하면 하나의 스레드로 순차적으로 함수를 네 번 호출합니다.\n\n```\nimport multiprocessing import time from fastapi import FastAPI app = FastAPI() def fibonacci(n: int) -&gt; int: return n if n&lt;= 1 else fibonacci(n - 1) + fibonacci(n - 2) @ app. get("/multiprocess") async def multiprocess_run() -&gt; float: start_time = time. time() with multiprocessing. Pool(4) as pool: pool. map(fibonacci,[25, 25, 25, 25]) elapsed_time = time. time() - start_time print(f"multiprocess elapsed time: {elapsed_time* 1000:. 1 f} ms") return elapsed_time @ app. get("/singleprocess") async def singleprocess_run() -&gt; float: start_time = time. time() for _ in range(4): fibonacci(25) elapsed_time = time. time() - start_time print(f"singleprocess elapsed time: {elapsed_time* 1000:. 1 f} ms") return elapsed_time\n```\n\n각각의 API endpoint를 호출하면 그 결과는 어떨까요? 무려 multiprocess를 사용한 경우가 2배 이상 느립니다. (MacOS에서의 결과)\n\n```\nmultiprocess elapsed time: 304.2ms singleprocess elapsed time: 129.2ms \n```\n\n위 예시에서 multiprocess가 singleprocess보다 느린 이유는 Process를 생성(spawning)하는데서 발생하는 오버헤드입니다. 참고로 python multiprocess를 생성하는 방법으로는 spawn과 fork가 있습니다 [[3-2]](https://docs.python.org/3/library/multiprocessing.html#contexts-and-start-methods). Spawn은 Python 인터프리터를 처음부터 생성하고, 라이브러리도 처음부터 import 하는 방식으로 구현됩니다. 따라서 생성 속도가 아주 느릴 수 밖에 없죠. 이에 반해 fork 방식은 os에서 제공하는 fork sysyem call을 사용합니다. Spawn보다 fork가 더 오버헤드가 적지만, fork는 thread를 사용하는 상황에서 안전하게 메모리를 복사할 수 없어서 문제를 일으킬 수 있습니다 [[3-2](https://docs.python.org/3/library/multiprocessing.html#contexts-and-start-methods), [3-3](https://pythonspeed.com/articles/faster-multiprocessing-pickle/)]. 우리가 직접 thread를 사용하지 않아도 3rd-party 라이브러리에서 thread를 사용하는 경우는 흔하기 때문에, fork 사용시 신중하게 코드를 작성해야 합니다. MacOS와 Windows에서 기본 값은 spawn, Unix에서 기본 값은 fork 방식으로 설정되어 있고, 이는 사용자가 바꿀 수 있습니다.\n\nSpawn은 느린 것이 문제고, fork 방식은 안전하지 않은 것이 문제라면 둘 다 사용하지 말아야 한다는 것일까요? 사실 가장 좋은 방법은 HTTP 요청이 올 때마다 매번 spawn이나 fork를 통해 프로세스를 생성하는 대신, 어플리케이션 startup시에 미리 process pool을 만들어 전역변수로 할당해두고, HTTP 요청이 올 때마다 미리 만들어진 process pool을 사용하는 것입니다.\n\n위의 예시 코드에 아래와 같이 `startup_event_handler` 를 만들고, 미리 정의된 process pool를 사용하도록 수정한 예시입니다.\n\n```\nasync def startup_event_handler(): app. state. process_pool = multiprocessing. Pool(4) app. add_event_handler("startup", startup_event_handler) @ app. get("/multiprocess") async def multiprocess_run() -&gt; float: start_time = time. time() app. state. process_pool. map(fibonacci,[25, 25, 25, 25]) elapsed_time = time. time() - start_time print(f"multiprocess elapsed time: {elapsed_time* 1000:. 1 f} ms") return elapsed_time\n```\n\n위처럼 바꾼 코드에서의 `/multiprocess` endpoint 실행 속도는 아래와 같습니다. 130ms가 걸렸던 single process 방식에 비해 훨씬 빨라진 것을 확인할 수 있습니다.\n\n```\nmultiprocess elapsed time: 49.9ms \n```\n\n### Process간 데이터 전송에 대한 오버헤드\n\n그럼 이제 모든 문제가 해결되었을까요? 그렇다면 이 섹션이 등장하지 않았을 것입니다. 미리 Process pool을 만들어놔도, **프로세스간에 주고받는 데이터가 크다면 커뮤니케이션 오버헤드가 높아질 수 있습니다.** 섹션 초반에서 설명했던 두 번째 문제입니다.\n\nPython에선 process간에 통신시 `pickle`을 통해서 데이터를 직렬화합니다 [[3-4]](https://docs.python.org/3/library/multiprocessing.html#pipes-and-queues). 만약 process간에 주고받는 데이터의 크기가 크다면, pickle을 통해서 데이터를 직렬화하고 다시 받는 쪽에서 역직렬화 하는 오버헤드가, 병렬성으로 부터 개선되는 성능 향상 폭보다 더 커질 수 있습니다.\n\n예시를 하나 살펴 봅시다. 아래는 길이가 512인 벡터 100개를 element-wise sum 하는 예시입니다. `/multiprocess` 를 호출하면 4개의 multiprocessing pool을 사용하여 데이터를 1/4씩 쪼개서 병렬로 계산하고, `/singleprocess` 를 호출하면 하나의 스레드로 모든 데이터에 대해 element-wise sum을 수행합니다. multiprocess에서는 process spawn 오버헤드를 줄이기 위해 미리 process pool을 만드는 방식을 적용하였습니다.\n\n```\nimport multiprocessing import random import time from typing import List from fastapi import FastAPI async def startup_event_handler(): app. state. process_pool = multiprocessing. Pool(4) app = FastAPI() app. add_event_handler("startup", startup_event_handler) def generate_random_vector(size: int) -&gt; List[float]: return[random. random() for _ in range(size)] def element_wise_sum(vectors: List[List[float]]) -&gt; List[float]: ret_vector =[0.0]* len(vectors[0]) for vector in vectors: for i in range(len(vector)): ret_vector[i] += vector[i] return ret_vector @ app. get("/multiprocess") async def multiprocess() -&gt; List[float]: vectors =[generate_random_vector(512) for _ in range(100)] start_time = time. time() result_vector_list = app. state. process_pool. map(element_wise_sum,[vectors[: 25], vectors[25: 50], vectors[50: 75], vectors[75:],]) ret_vector = element_wise_sum(result_vector_list) elapsed_time = time. time() - start_time print(f"multiprocess elapsed time: {elapsed_time* 1000:. 1 f} ms") return ret_vector @ app. get("/singleprocess") async def singleprocess_run() -&gt; List[float]: vectors =[generate_random_vector(512) for _ in range(100)] start_time = time. time() ret_vector = element_wise_sum(vectors) elapsed_time = time. time() - start_time print(f"singleprocess elapsed time: {elapsed_time* 1000:. 1 f} ms") return ret_vector\n```\n\nProcess spawn으로 인한 오버헤드가 제거되었음에도 불구하고, 위 코드를 실행해보면 아래처럼 multiprocess가 더 느린 것을 확인할 수 있습니다. 이는 `vectors` 변수 자체의 크기가 매우 크기 때문에, 이를 다른 프로세스로 보내기 위한 커뮤니케이션 오버헤드가 매우 커서 발생하는 문제입니다.\n\n```\nmultiprocess elapsed time: 12.0ms singleprocess elapsed time: 10.4ms \n```\n\n### 하이퍼커넥트의 사례\n\n어쩌면 위와 같은 예시가 일반적이지 않다고 생각할 수 있습니다. 하지만 대규모 데이터를 다루는 ML 백엔드에서 크기가 큰 벡터를 연산하는 것은 꽤나 빈번히 발생하는 일입니다. 하이퍼커넥트 ML 조직에서도 커뮤니케이션 오버헤드로 인해 multiprocessing을 사용해도 오히려 속도가 느려지는 경험을 했습니다 (latency 5% 이상 저하).\n\n이처럼 Python multiprocessing는 커뮤니케이션 오버헤드가 크기 때문에, 도입하기 전에 어플리케이션 사용 패턴을 충분히 파악한 후 도입해야 합니다. 하이퍼커넥트에서도 병렬성으로 해결 가능한 로직이 보인다고 하더라도, 미리 패턴을 충분히 파악한 후 코드 작업 여부를 결정하고 있습니다.\n\n# #4 Pytorch를 multiprocess 환경에서 쓴다면 num\\_threads를 조정하자.\n\n### Pre-forked worker와 PyTorch / Numpy의 충돌\n\n백엔드 서버가 하드웨어 멀티 코어의 장점을 살리기 위해 여러개의 요청을 동시에 처리하는 일은 빈번히 발생합니다. Python 에서도 gunicorn과 같은 pre-forked worker model을 통해 멀티프로세싱을 지원하는 서버를 손쉽게 만들어낼 수 있습니다. 하이퍼커넥트의 추천 API 서버도 gunicorn [[4-1]](https://gunicorn.org/)을 이용하여 하나의 pod에 pre-forked unvicorn process (*Web Worker* 라고도 부름) 다수를 미리 만들어둔 후, 동시에 여러 요청이 들어왔을 때 다수 process에서 동시에 요청을 처리하며 CPU 자원을 병렬적으로 사용할 수 있도록 활용하고 있습니다.\n\n최신의 CPU는 대부분 여러 개의 코어를 가지고 있기 때문에, 일반적으로 병렬성을 이용하면 CPU의 utility를 높여 더 빠른 응답속도와 처리량을 갖는 서버를 구성할 수 있습니다. 하지만 백엔드 어플리케이션에서 PyTorch나 Numpy를 사용하고 있다면, gunicorn 처럼 병렬로 웹 요청을 처리하는 서버를 사용할 때 유의해야 합니다. 오히려 성능이 더 나빠질 수 있기 때문입니다.\n\nPyTorch나 Numpy는 기본적으로 내부 연산을 멀티스레딩으로 수행합니다. (참고로 여기서의 멀티스레딩은 Python multithreading이 아닌, C-level에서의 멀티스레딩입니다!) 다시 말하면, 이 두 라이브러리에서는 현재 환경에서 가용한 CPU 자원을 최대한으로 사용합니다. vCPU가 4인 VM이나 Container, K8S Pod에서는 PyTorch에서 4개의 스레드를 사용해서 내부 연산을 처리한다는 말이죠. 이 점을 간과한 채 vCPU가 4인 pod에서 gunicorn을 사용해서 4개의 web worker (혹은 pre-forked process)를 띄운다면, 하나의 vCPU가 하나의 worker에서만 독립적으로 사용되지 않고, worker마다 서로 모든 CPU를 사용하려고 싸우며, interleaving 되는 시나리오가 발생할 수 있습니다. 이는 context-switching 오버헤드를 증가시키고, L1/L2 cache-miss를 발생시키며, 결과적으로 성능을 저하시키게 됩니다.\n\n### 예시로 살펴보기\n\n그럼 실제로 Numpy, PyTorch 가 기본적으로 연산을 멀티스레딩으로 수행하는지 알아봅시다. 간단한 방법으로 10,000 by 10,000 행렬곱 연산을 하는 프로그램을 작성하고, htop 과 같은 resource monitoring tool 을 통해 CPU 사용량을 체크해봅시다.\n\n```\nimport numpy as np import torch numpy_a = np. empty(shape =(10000, 10000)) numpy_b = np. empty(shape =(10000, 10000)) numpy_a @ numpy_b torch_a = torch. from_numpy(numpy_a) torch_b = torch. from_numpy(numpy_b) torch_a @ torch_b\n```\n\n위와 같은 코드를 돌려보면 행렬곱을 처리하는 부분에서 따로 멀티 스레드로 동작하도록 지시하지 않았음에도 아래와 같이 CPU 가 모두 사용 되는 것을 알 수 있습니다.\n\n참고로 16개 중 8개의 코어만 쓰는 것은 사실 나머지 8개의 코어는 intel의 Hyper-threading 기술[[4-2]](https://www.intel.com/content/www/us/en/gaming/resources/hyper-threading.html)로, 기존 코어의 두배만큼 뻥튀기되어 만들어진 가짜 코어들이기 때문입니다. 이러한 CPU 을 16개의 logical core, 8개의 physical core 을 가졌다고 합니다. Hyper-threading 은 행렬 곱 연산과 같이 이미 거의 완벽한 수준의 instruction level parallelism이 구현된 경우엔 별 도움이 되지 않기에 적용되지 않아 절반만 사용하는 것처럼 보이게 됩니다.\n\n그렇다면 실제 API 서버에서 어떻게 위 문제를 해결할 수 있을까요? FastAPI와 PyTorch를 사용해서 행렬곱(matmul)을 하는 예시를 작성해보았습니다.\n\n```\nimport os import time import multiprocessing as mp import torch def foo(i: int) -&gt; None: matrix_a = torch. rand(size =(1000, 1000)) matrix_b = torch. rand(size =(1000, 1000)) # warm up for _ in range(10): torch. matmul(matrix_a, matrix_b) start_time = time. perf_counter() for _ in range(100): torch. matmul(matrix_a, matrix_b) print(i, time. perf_counter() - start_time) if __name__ == "__main__": num_processes = len(os. sched_getaffinity(0)) print("num_processes: ", num_processes) with mp. Pool(num_processes) as pool: pool. map(foo, range(num_processes))\n```\n\n위 코드를 실행하여 서버를 띄우고, 요청을 보내면 아래와 같은 결과가 나옵니다.\n\n```\n❯❯❯ taskset 0x55 python main.py num_processes: 4 process #[1]: 8.69 s process #[2]: 8.76 s process #[0]: 8.87 s process #[3]: 8.80 s \n```\n\n그렇다면 각 프로세스가 사용하는 스레드의 개수를 1개로 제한해줬을때는 어떨까요? `OMP_NUM_THREADS` 환경변수를 이용하여 스레드 수를 설정할 수 있습니다. 아래는 각 프로세스마다 사용하는 스레드의 개수를 1개로 제한해줬을 때의 결과이며, 기본 설정과 비교했을 때 6배 가량 빠르게 실행되는 것을 확인할 수 있습니다.\n\n```\n❯❯❯ OMP_NUM_THREADS=1 taskset 0x55 python main.py num_processes: 4 process #[3]: 1.43 s process #[2]: 1.43 s process #[1]: 1.43 s process #[0]: 1.43 s \n```\n\n참고로 위 예시에서는 `OMP_NUM_THREADS` 를 통해 worker당 스레드 수를 제한했지만, PyTorch만 사용하는 경우 `torch.set_num_threads(1)` 함수를 호출하여 스레드 수를 제한할 수도 있습니다.\n\n그렇다면 왜 PyTorch와 Numpy는 최대한의 CPU를 사용하는 것이 기본 설정일까요? 왜냐하면 이들 라이브러리는 데이터 분석과 모델 학습이 주된 사용처이기 때문입니다. 데이터 분석과 모델 학습시에는 백엔드 서버처럼 동시에 여러 작업을 수행할 일이 드물고, 그렇다면 가용한 CPU를 모두 사용하는 것이 더 빠른 속도를 보여주기 때문입니다 [[4-3]](https://pytorch.org/docs/stable/notes/cpu_threading_torchscript_inference.html#tuning-the-number-of-threads).\n\n### 하이퍼커넥트의 사례\n\n하이퍼커넥트에서는 위와 같은 문제를 발견한 후, PyTorch를 사용하는 FastAPI 서버, Nvidia Triton 기반의 모델 서버 등에서 PyTorch 스레드를 1로 제한하는 설정을 추가하였습니다. 그 결과, 서버에 따라 Latency와 Throughput이 각각 최대 3배 이상까지 개선되는 경험을 했습니다. 만약 multi-worker를 사용하는 서버에서 PyTorch를 사용하고 있다면, 단 한 줄짜리 코드 수정으로 성능을 3배까지도 올릴 수 있으니 시도해보시길 추천드립니다.\n\n# #5 Pydantic은 아주 느리다. 불필요한 곳에서 가급적 사용하지 말자.\n\n### Pydantic 이란\n\n최근 많은 곳에서 백엔드 프레임워크로 FastAPI [[5-1]](https://fastapi.tiangolo.com/)를 사용하고 있습니다. FastAPI는 사실상 Flask의 상위 호환 프로젝트라고 봐도 무방할 정도로 좋은 오픈소스라고 생각합니다. 문제는 FastAPI에서 API endpoint를 정의할 때 사용하는 Pydantic입니다. Pydantic [[5-2]](https://docs.pydantic.dev/)은 data validation(type check)과 parsing까지 해주는 라이브러리입니다. 아래처럼 사용할 수 있습니다.\n\n```\nfrom datetime import date from pydantic import BaseModel class User(BaseModel): user_id: int birthday: date User. parse_raw(\'{"user_id": "100", "birthday": "2000-01-01"}\')# User(user_id=100, datetime.date(2000, 1, 1)) \n```\n\nFastAPI는 내부적으로 Pydantic을 아예 포함하고 있고, API request 변수와 response type을 Pydantic 객체로 넣어주면 Swagger UI 까지 자동으로 만들어주고 있습니다. 그만큼 FastAPI를 사용한다면 Pydantic은 필수로 사용할 수 밖에 없죠.\n\nPydantic은 정말 편리합니다. 하지만 편리함에 너무 익숙해져서 data validation이 필요 없는 환경에서도 Pydantic을 남발해서는 안됩니다. 왜냐하면 정말 느리거든요.\n\n### 예시로 보는 Pydantic의 속도\n\n아래는 길이가 50인 float list를 가지고 있는 Pydantic 인스턴스 400개를 생성하는 간단한 예시입니다.\n\n```\nimport timeit from typing import List from pydantic import BaseModel class FeatureSet(BaseModel): user_id: int features: List[float] def create_pydantic_instances() -&gt; None: for i in range(400): obj = FeatureSet(user_id = i, features =[1.0* i + j for j in range(50)],) elapsed_time = timeit. timeit(create_pydantic_instances, number = 1) print(f"pydantic: {elapsed_time* 1000:. 2 f} ms")\n```\n\n```\npydantic: 12.29ms \n```\n\n결과를 보면, 위 코드는 단순히 객체만 수백개 생성했을 뿐인데 12ms라는 생각보다 굉장히 많은 시간이 소요되는 것을 확인할 수 있습니다.\n\n그렇다면 Pydantic이 아닌 바닐라 class로 객체를 생성하면 어떨까요?\n\n```\nimport timeit from typing import List class FeatureSet: def __init__(self, user_id: int, features: List[float]) -&gt; None: self. user_id = user_id self. features = features def create_class_instances() -&gt; None: for i in range(400): obj = FeatureSet(user_id = i, features =[1.0* i + j for j in range(50)],) elapsed_time = timeit. timeit(create_class_instances, number = 1) print(f"class: {elapsed_time* 1000:. 2 f} ms")\n```\n\n```\nclass: 1.54ms \n```\n\n같은 숫자와 property를 가진 위 코드의 실행 결과는 1.5ms로, Pydantic을 사용했을 때보다 8배 가량 빠른 것을 확인할 수 있습니다.\n\n### 하이퍼커넥트의 사례\n\n하이퍼커넥트에서는 불필요한 Pydantic객체를 사용하던 로직을 모두 바닐라 class 혹은 내장 dataclass로 변경 후, 추천 API 서버의 Latency를 2배 이상 개선시킨 경험이 있습니다. 어떤 서버에서는 Pydantic 객체 생성에 걸리는 시간만 200ms 이상 소요되던 케이스도 있었습니다 (p99 기준).\n\nPydantic의 느린 속도를 알고 있는지, 내부 로직을 rust로 작성한 Pydantic V2가 개발 중이기도 합니다 [[5-3]](https://docs.pydantic.dev/blog/pydantic-v2/). 언제 나올지 기대를 하고 있는데요, 아무리 빨라져도 바닐라 Python class 보다 빨라질 수는 없기 때문에 validation이 필요없는 상황에서는 Pydantic을 사용하지 않도록 늘 조심하고 있습니다.\n\n# #6 Pandas DataFrame은 생성에 많은 시간이 걸리므로, 유의해서 사용해야 한다.\n\n데이터를 분석하거나 전처리할 때, 많은 ML 엔지니어들은 Pandas [[6-1]](https://pandas.pydata.org/)를 애용합니다. Pandas는 내부적으로 NumPy를 사용하지만 [[6-2]](https://en.wikipedia.org/wiki/Pandas_(software)), 잘못 사용한다면 기대만큼 빠르게 동작하지 않을 수 있습니다. 특히 Pandas를 사용한다면 가장 많이 사용하게 되는 DataFrame의 경우, 데이터의 재가공 프로세스로 인해 생각보다 느린 성능을 보이기에 주의해서 사용해야 합니다.\n\n### 예시로 보는 pandas 성능\n\n그렇다면 `pandas.DataFrame`은 얼마나 느릴까요? 아래는 속성이 50개인 dict 객체 1000개에 대해 null 값을 0.0으로 imputation 해보는 예시입니다. `pandas.DataFrame`에서 제공하는 `fillna` 메소드를 사용하는 방법과, 순수 Python iteration으로 구현하는 방법을 각각 측정해보았습니다.\n\n```\nimport random import timeit from typing import Dict, Optional import pandas as pd def create_sample_dict() -&gt; Dict[str, Optional[float]]: d ={} for i in range(50): d[f "feature{i} "] = random. random() if random. random()&lt;0.9 else None return d data_list =[create_sample_dict() for _ in range(1000)] def null_imputation_using_df(): df = pd. DataFrame(data_list) return df. fillna(0.0) def null_imputation_in_pure_python(): ret =[] for data in data_list: new_data = data. copy() for key, val in new_data. items(): if val is None: new_data[key] =0.0 ret. append(new_data) return ret elapsed_time = timeit. timeit(null_imputation_using_df, number = 1) print(f"pandas.DataFrame: {elapsed_time* 1000:. 2 f} ms") elapsed_time = timeit. timeit(null_imputation_in_pure_python, number = 1) print(f"pure python: {elapsed_time* 1000:. 2 f} ms")\n```\n\n```\npandas.DataFrame: 6.91ms pure python: 1.78ms \n```\n\n결과를 보면 pandas Dataframe을 쓰는 것 보다, 순수 Python 구현이 3배 이상 빠른 것을 확인할 수 있습니다. Pandas의 내부 구현이 NumPy로 되어있음에도 불구하고, Python for loop이 더 빠른 것은 꽤 의아한 결과입니다. `df.fillna` 명령어가 문제일까요? 사실 대부분의 시간은 `pd.DataFrame(data_list)` 에서 소요됩니다. DataFrame을 만드는 것 자체가 꽤나 많은 시간을 필요로 하기 때문이죠. 그렇다면 왜 DataFrame을 만드는 것이 오래 걸릴까요?\n\n### pandas.DataFrame의 구조와 특징\n\nPandas DataFrame은 컬럼 지향 (column-oriented) 자료구조를 사용합니다 [[6-3](https://dkharazi.github.io/blog/blockmanager), [6-4](https://uwekorn.com/2020/05/24/the-one-pandas-internal.html)]. 내부적으로 컬럼마다 numpy ndarray가 하나씩 있는 구조이며, 다시 말하면 컬럼의 수만큼 ndarray가 만들어지게 됩니다.\n\n예를들면 아래처럼 세개의 컬럼을 가진 DataFrame은 3개의 ndarray를 가지고 있는 형태입니다.\n\n```\ndf = pd. DataFrame([{"id": 111, "rating":5.0, "category": "TRAIN"},{"id": 222, "rating":4.5, "category": "BUS"},{"id": 333, "rating":4.0, "category": "METRO"},{"id": 444, "rating":3.5, "category": "METRO"},])""" id -&gt; ndarray([111, 222, 333, 444], dtype=np.int32) rating -&gt; ndarray([5.0, 4.5, 4.0, 3.5], dtype=np.float32) category -&gt; ndarray(["TRAIN", "BUS", "METRO", "METRO"], dtype=\'O\') """\n```\n\n위와 같은 컬럼 지향 형태로 데이터를 표현한다면, 열 단위로 데이터를 가공하는 연산은 매우 빠르게 수행될 수 있습니다. 예를들면 아래처럼 모든 rating 데이터에 2를 곱하는 연산은 하나의 ndarray만 수정하면 되기 때문에, 로우 지향 자료구조보다 훨씬 빠르게 동작합니다.\n\n```\ndf["rating"] = df["rating"]* 2\n```\n\n한 번 생성된 DataFrame은 잘만 사용하면 빠르게 데이터를 가공하는데 사용할 수 있습니다. 문제는 DataFrame을 처음 생성(construct)하는데의 오버헤드에 있습니다.\n\n처음 등장했던 예시처럼 list of dict 데이터를 pandas.DataFrame으로 바꾸려면 1) 컬럼 지향 형태로 데이터를 재가공 후 numpy ndarray를 생성하는 작업과, 2) 컬럼마다 dtype을 추론하는 작업이 수행되어야 합니다. 이는 필연적으로 입력으로 들어온 데이터의 반복적인 읽기 작업과 전처리 작업을 필요로 하며, 오버헤드가 될 수 있습니다.\n\n### pandas.DataFrame을 잘 사용하기\n\n만약 열단위 데이터 조작이 많이 필요하지 않은 상황이라면, DataFrame을 아예 사용하지 않는 편이 좋습니다. 만약 열단위 데이터 조작이 많이 필요한 상황이라면, DataFrame의 입력 값으로 list of dict가 아닌 numpy ndarray를 넣어주는 것 만으로 성능을 개선할 수 있습니다. Pandas에서 내부적으로 데이터를 전처리 하는 시간괴, dtype을 추론하는 시간을 줄여줄 수 있기 때문입니다.\n\n맨 처음 등장했던 예시에서, `null_imputation_using_df` 함수를 아래처럼 바꾸는 것 만으로 속도를 2배 정도 개선할 수 있습니다.\n\n```\nimport numpy as np(...) def null_imputation_using_df(): arr = np. array([list(d. values()) for d in data_list], dtype = np. float32) df = pd. DataFrame(arr, columns = list(data_list[0]. keys())) return df. fillna(0.0)\n```\n\n```\npandas.DataFrame: 2.35ms \n```\n\n### 하이퍼커넥트의 사례\n\npandas DataFrame은 DataFrame 인스턴스를 생성하는데 필요한 오버헤드보다, 열 단위 조작으로 인한 수행 시간이 더 클때 효율적입니다. 하이퍼커넥트에서는 백엔드 서버 및 모델 서버 대부분에서는 열 단위 조작 시간보다 DataFrame 인스턴스 생성 시간이 더 큰 병목이었으며, 이런 경우에 로직을 Python primitive와 NumPy 만을 사용하도록 바꿨습니다. 그 결과, P99 latency를 절반 이상으로 낮추고, throughput 또한 2배 이상 개선하는 경험을 하기도 했습니다.\n\n# #7 바닐라 json 패키지는 느리다. orjson이나 ujson을 사용하자.\n\nML과 관련된 작업을 하다 보면 json을 쓸 일이 아주 많습니다. 추론에 필요한 feature들도 json의 형태로 표현하면 편리하고, 만약 웹서버를 만들 경우 다양한 속성들을 표현하기 위해서 위해서 json으로 데이터를 주고 받는 경우가 많죠. 일반적으로 python에서 json을 다룰 때는 내장 `json` 패키지를 많이 사용합니다. 이 패키지는 Json문자열을 python dict와 list로 seamless하게 바꿔주기 때문에 아주 편리하죠.\n\n그런데 이 json도 상당한 병목이 될 수 있습니다. Python의 내장 `json` 패키지는 pure python으로 구현되어 있고, 크고 깊은 json 데이터를 다룰 때 예상보다 오랜 시간이 소요될 수 있습니다.\n\n그렇다면 어떻게 해야 할까요? 다행히 내장 패키지보다 더 빠른 orjson[[7-1]](https://github.com/ijl/orjson)이나 ujson[[7-2]](https://github.com/ultrajson/ultrajson)과 같은 서드파티 패키지들이 있습니다. 이런 라이브러리들은 핵심 로직이 Rust나 C로 구현되어 있고, 큰 사이즈의 데이터를 다루는데 적합하도록 최적화되어 있어 내장 패키지보다 처리 속도가 훨씬 빠릅니다.\n\n아래 코드는 서로 다른 json 라이브러리에서 1000개의 property를 가지는 json string을 100번 파싱하는 예시입니다.\n\n```\nimport json import random import timeit import ujson import orjson sample_dict ={} for i in range(1000): sample_dict[f "feature{i} "] = random. random() json_string = json. dumps(sample_dict) def test_json(): return json. loads(json_string) def test_ujson(): return ujson. loads(json_string) def test_orjson(): return orjson. loads(json_string) num_runs = 100 json_time = timeit. timeit(test_json, number = num_runs) ujson_time = timeit. timeit(test_ujson, number = num_runs) orjson_time = timeit. timeit(test_orjson, number = num_runs) print(f\'json: {json_time* 1000:. 1 f}  ms\') print(f\'ujson: {ujson_time* 1000:. 1 f}  ms\') print(f\'orjson: {orjson_time* 1000:. 1 f}  ms\')\n```\n\n결과는 다음과 같습니다.\n\n```\njson: 36.5 ms ujson: 14.4 ms orjson: 8.6 ms \n```\n\n내장 json 패키지와 비교했을 때, ujson의 경우 2배 이상, orjson의 경우 4배 이상 속도가 차이나는 것을 알 수 있습니다. 만약 json 파싱을 heavy하게 해야 하는 상황이라면, 라이브러리를 바꾸는 것만으로도 유의미한 성능 향상을 이룰 수 있을 것입니다.\n\n### 하이퍼커넥트의 사례\n\n하이퍼커넥트의 ML 모델 서빙 서버 중에는, 다량의 feature 데이터를 json 형태로 입력받는 것들이 있었습니다. 서버에서 입력받는 json 데이터는 대부분 다량의 피쳐가 포함된, 큰 사이즈가 많았습니다. 해당 서버들에서 바닐라 json 패키지에서 orjson으로 바꾼 후, p99 latency가 5~10% 정도 개선되는 경험을 했습니다.\n\n# #8 Class는 충분히 빠르지 않을 수 있다. 너무 문제가 되면 dict를 사용하자.\n\n수 십개 이내의 클래스 인스턴스를 만드는 것은 보통 큰 문제가 되지 않습니다. 문제는 수 천개 이상의 클래스를 사용할 때입니다. 너무 많은 클래스 인스턴스를 생성하는 상황에서는, 클래스의 속도조차 문제가 될 수 있습니다.\n\n아래는 property가 30개 있는 class와 dict를 각각 2000개 생성하는 예시입니다.\n\n```\nimport timeit NUM_INSTANCES = 2000 class FeatureSet: def __init__(self, user_id: int, feature1: float, feature2: float,(...) feature30: float,): self. user_id = user_id self. feature1 = feature1 self. feature2 = feature2(...) self. feature30 = feature30 def create_class_instances() -&gt; None: for i in range(NUM_INSTANCES): obj = FeatureSet(user_id = i, feature1 =1.0* i, feature2 =2.0* i,(...) feature30 =30.0* i,) def create_dicts() -&gt; None: for i in range(NUM_INSTANCES): obj ={"user_id": i, "feature1":1.0* i, "feature2":2.0* i,(...) "feature30":30.0* i,} class_time = timeit. timeit(create_class_instance, number = 1) print(f"class: {class_time* 1000:. 1 f} ms") dict_time = timeit. timeit(create_dict, number = 1) print(f"dict: {dict_time* 1000:. 1 f} ms")\n```\n\n위 코드에 대한 실행 결과는 아래와 같습니다 (Python 3.8 환경):\n\n```\nclass: 8.0ms dict: 2.9ms \n```\n\nclass와 dict의 생성 속도가 2.5배 이상 나는 것을 확인할 수 있습니다. 물론 5ms 정도의 차이라면 크지 않다고 생각할 수도 있겠지만, property의 숫자가 늘어날 수록, 생성하는 인스턴스가 많아질수록 격차는 더 커지게 됩니다.\n\n`__slot__` [[8-1]](https://wiki.python.org/moin/UsingSlots) 를 사용하는 것은 도움이 될 수도 있지만, 이는 주로 메모리를 절약 해주는 효과가 크지, 속도를 빠르게 해주지는 않습니다. class 대신 `dataclass`를 사용하는 것도 속도에 큰 차이가 나지 않았습니다.\n\n더불어 클래스에 property가 많으면서 동시에 많은 클래스 인스턴스를 생성하는 상황에서는 `kwargs`와 `setattr` 함수를 사용 또한 조심해야합니다. 보통 property가 많으면 타이핑하기 귀찮기에 kwargs와 setattr 함수를 사용하는 경우가 빈번할 수 있습니다. 하지만 이는 함수를 더 많이 호출하게 되어 속도가 기존보다도 2배 이상 더 느려질 수 있습니다.\n\n물론 class를 포기하고 모든 객체를 dict로 관리하는 것은 기술 부채 측면에서 끔찍한 결정이 될 수 있습니다. 하지만 코드의 아주 일부분 중에서 연산량이 너무 많아 class의 생성 속도 조차 문제가 되는 상황이라면, class를 사용하지 않는 것도 고려해볼 수 있습니다.\n\n*참고로 Python 3.11 부터는 class의 속도가 개선되어 dict와의 격차가 줄어듭니다. 자세한 내용은 다음 섹션에서 다시 다룹니다.*\n\n### 하이퍼커넥트의 사례\n\n하이퍼커넥트 서비스의 경우 수천 개 이상의 오브젝트를 생성해야 하는 극히 일부 로직에서, class의 속도 조차 병목이 되어 제한적으로 dict를 사용하고 있는 부분이 존재합니다. 다만 dict 사용시 mypy와 같은 정적 type checking tool의 효과를 볼 수 없기에, 매우 제한적으로만 이용하고 있습니다.\n\n# #9 Python 3.11은 덜 느리다.\n\n2022년 10월에 릴리즈된 Python 3.11에서는 많은 성능 향상이 있었습니다 [[9-1]](https://medium.com/aiguys/how-python-3-11-is-becoming-faster-b2455c1bc555). 이번 섹션에서는 여러가지 개선점들 중, 앞선 섹션에서 다루었던 클래스의 생성(construction) 속도에 대해 간단히 다뤄보겠습니다. Python 3.11에서는 기존에 클래스를 초기화 할 때 일어났던 비효율적인 연산들을 최적화해 클래스 생성 속도가 훨씬 빨라졌습니다. 아래의 코드를 통해 동일한 속성값(attribute)을 가지는 dict와 class, dataclass를 만드는데 걸리는 시간을 측정해보겠습니다.\n\n```\nimport timeit from dataclasses import dataclass ITERATIONS = 100000 class MyClass: def __init__(self, key1, key2, key3): self. key1 = key1 self. key2 = key2 self. key3 = key3 @ dataclass class MyDataclass: key1: int key2: int key3: int def create_dict(): my_dict ={"key1": 1, "key2": 2, "key3": 3} def create_class(): MyClass(1, 2, 3) def create_dataclass(): MyDataclass(1, 2, 3) dict_time = timeit. timeit(create_dict, number = ITERATIONS) class_time = timeit. timeit(create_class, number = ITERATIONS) dataclass_time = timeit. timeit(create_dataclass, number = ITERATIONS) print(f"dictionary creation time: {dict_time* 1000:. 2 f}  ms") print(f"class creation time: {class_time* 1000:. 2 f}  ms") print(f"dataclass creation time: {dataclass_time* 1000:. 2 f}  ms")\n```\n\n```\n# Python 3.10 dictionary creation time: 9.30 ms class creation time: 23.05 ms dataclass creation time: 22.30 ms # Python 3.11 dictionary creation time: 9.45 ms class creation time: 13.45 ms dataclass creation time: 12.90 ms \n```\n\n3.10에 비해 3.11에서 class와 dataclass 생성 속도가 각각 1.7배 정도 빨라진 것을 알 수 있습니다. 그럼에도 여전히 dict의 생성 속도보다는 1.4배 정도 느린데요, class가 내부적으로 dict를 이용하기 때문에 dict 생성 시간에 class와 관련된 추가적인 오버헤드가 붙어 불가피합니다. 하지만 클래스의 생성 속도때문에 성능 문제를 겪고 있는 상황이라면 Python 3.11로 업그레이드하는 것도 고려해볼만 합니다. 현 시점(2023.05)에서는 아직 Python 3.11을 지원하지않는 라이브러리가 종종 있고, 경우에 따라 라이브러리 버전을 올려야 할 수도 있기 때문에 미리 의존하는 라이브러리들이 Python 3.11을 지원하는지 꼭 체크하는것, 잊지 마세요.\n\nPython 3.11의 클래스 생성 방식 변화가 궁금하시다면 [이 글](https://medium.com/aiguys/how-python-3-11-is-becoming-faster-b2455c1bc555)을 참고하세요. 이 외에도 Python 3.11의 성능 향상에 대해 더 자세히 알고 싶다면 [이 글](https://docs.python.org/3.11/whatsnew/3.11.html#faster-cpython)을 참고하세요.\n\n### 하이퍼커넥트의 사례\n\nPython 3.8로 운영되던 추천 API 서버를 Python 3.11로 올린 이후, 평균 latency가 5~10% 정도 줄어드는 경험을 했습니다.\n\n# #10 (보너스) line profiler 사용법\n\n지금까지 하이퍼커넥트에서 Python으로 ML 백엔드 서버들을 운영하며 발견한 여러 성능 개선 노하우들을 공유드렸습니다. 하지만 상황에 따라 성능에 병목이 생기는 구간은 늘 바뀔 수 있습니다. 고성능 ML 백엔드를 구현하기 위해서 사실 가장 필요한 것은 Python 성능 트릭에 대해서 많이 아는 것이 아니라, 성능 문제가 발생했을 때 해결할 수 있는 능력입니다. 그리고 성능 문제를 해결하기 위해서 가장 먼저 해야할 것은 **어떤 부분이 병목인지를 발견하는 것**입니다.\n\n### line profiler\n\nPython 코드에서 어느 부분이 병목인지 확인하고 싶을 때, 간단하게 진단할 수 있는 툴 중 하나가 [line\\_profiler](https://github.com/pyutils/line_profiler) 입니다. line\\_profiler는 이름 그대로 Python 의 함수를 line by line 으로 실행속도를 측정해주는 프로그램입니다. 더 좋은 프로파일링 툴도 많지만 (ex. cProfile), line\\_profiler는 훨씬 쉽고 직관적으로 직관적으로 어느 부분이 병목인지 알려줍니다.\n\n아래는 line profiler 에 대한 간단 사용 가이드입니다.\n\n```\n$ install \n```\n\n위 명령어를 통해 line profiler 를 설치해줍니다.\n\n그리고 profile 하고 싶은 함수에 `@profile` decorator 를 달아줍니다.\n\n```\n@ profile def slow_function(a, b, c):...\n```\n\n그 후\n\n```\n$ -lv\n```\n\n위 명령어로 파이썬 스크립트를 실행해주면 아래와 같이 profiling 결과가 나오는 것을 확인할 수 있습니다.\n\n```\nWrote profile results to line_p.py.lprof Timer unit: 1e-06 s Total time: 2.86632s from fastapi import FastAPI import numpy as np from line_profiler import LineProfiler app = FastAPI() def heavy_func(n): a = np.random.random((n, n)) b = np.random.random((n, n)) return np.sum(a + b) profiler = LineProfiler() wrapped_heavy_func = profiler(heavy_func) @app.get("/api") async def api(): result = wrapped_heavy_func(100) profiler.print_stats() return result File: line_p.py Function: func at line 3 Line # Hits Time Per Hit % Time Line Contents ============================================================== 3 @profile 4 def func(): 5 10 85541.0 8554.1 3.0 a = np.random.random((1000, 1000)) 6 10 76209.0 7620.9 2.7 b = np.random.random((1000, 1000)) 7 110 473.0 4.3 0.0 for _ in range(10): 8 100 2704098.0 27041.0 94.3 a @ b \n```\n\n### 클라우드 환경에서 프로파일링 하기\n\n클라우드에 직접 모델 서버를 띄워야 하는 상황에선, kernprof 명령어를 사용하기 힘든 경우가 있습니다. 특히 스테이징 환경에서 실제와 비슷한 입력을 받아보며 성능을 측정해보고 싶을 때에도 kernprof은 사용하기 어렵습니다.\n\n이런 경우를 위해 `line_profiler`는 Python 로직 내부에서 프로파일링 실행 및 결과를 출력할 수 있는 API를 제공합니다. 아래는 로직 내부에서 프로파일링을 하는 예시입니다.\n\n```\nfrom fastapi import FastAPI import numpy as np from line_profiler import LineProfiler app = FastAPI() def heavy_func(n): a = np. random. random((n, n)) b = np. random. random((n, n)) return np. sum(a + b) profiler = LineProfiler() wrapped_heavy_func = profiler(heavy_func) @ app. get("/api") async def api(): result = wrapped_heavy_func(100) profiler. print_stats() return result\n```\n\n위 코드를 실행시키고 `/api`로 요청을 보내면 `profiler.print_stats()` 호출에 의해 method 의 프로파일링 결과가 출력되는 것을 확인할 수 있습니다.\n\n```\nFunction: heavy_func at line 7 Line # Hits Time Per Hit % Time Line Contents ============================================================== 7 def heavy_func(n): 8 1 361000.0 361000.0 43.1 a = np.random.random((n, n)) 9 1 139000.0 139000.0 16.6 b = np.random.random((n, n)) 10 1 337000.0 337000.0 40.3 return np.sum(a + b) \n```\n\n하이퍼커넥트에서는 많은 병목 지점을 line profiler 툴을 활용하여 진단해왔습니다. 이 블로그에서 작성된 상당수의 트릭들도 프로파일링을 통해서 발견한 것들이 많습니다. 우리가 작성하는 코드엔 다양한 병목 구간들이 존재할 수 있습니다. 더불어 눈으로 보기에 병목이라고 생각했던 것들도, 프로파일링을 실제로 돌려보니 병목이 아니었던 경우도 많았습니다. 프로파일링이 처음엔 귀찮게 느껴질 수 있어도, 정말 문제가 되는 부분을 찾고 고치기 위한 가장 효율적인 방법은 결국 프로파일링을 먼저해보는 것입니다. 프로그램의 속도가 느리다는 생각이 들 떈, 가장 먼저 병목 지점이 어디인지 또 얼마나 느린지 프로파일링을 통해서 진단해보세요. 병목 지점을 찾게되면 성능 개선은 자연스럽게 따라옵니다.\n\n# 맺으며\n\n이 글에서는 Python의 느린 성능 때문에 고충 받고 있는 분들께 도움이 되고자, 하이퍼커넥트의 Python 성능 개선 팁들을 공유해 보았습니다. 성능 개선 트릭 이외에도, Python에 대해서 충분히 고민하고, 내부 로직에 대해서 이해하려고 노력하며, 또 프로파일링까지 수행하며 성능을 개선하고자 하면, 비즈니스에서 요구하는 수준의 성능은 충분히 만들어낼 수 있다는 메시지도 전달되었기를 바랍니다. 그럼 긴 글 읽어주셔서 감사합니다.\n\n# References\n\n[0-1] &lt;https://instagram-engineering.com/web-service-efficiency-at-instagram-with-python-4976d078e366&gt;\n\n[0-2] [https://en.wikipedia.org/wiki/CPython](https://en.m.wikipedia.org/wiki/CPython)\n\n[1-1] &lt;https://devguide.python.org/internals/garbage-collector/&gt;\n\n[1-2] &lt;https://en.wikipedia.org/wiki/Reference_counting&gt;\n\n[1-3] &lt;https://en.wikipedia.org/wiki/Tracing_garbage_collection&gt;\n\n[1-4] &lt;https://d2.naver.com/helloworld/1329&gt;\n\n[1-5] &lt;https://devguide.python.org/internals/garbage-collector/#collecting-the-oldest-generation&gt;\n\n[1-6] &lt;https://instagram-engineering.com/dismissing-python-garbage-collection-at-instagram-4dca40b29172&gt;\n\n[2-1] &lt;https://docs.python.org/3/library/array.html&gt;\n\n[2-2] &lt;https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.object_&gt;\n\n[2-3] &lt;https://numpy.org/doc/stable/reference/generated/numpy.apply_along_axis.html&gt;\n\n[3-1] &lt;https://wiki.python.org/moin/GlobalInterpreterLock&gt;\n\n[3-2] &lt;https://docs.python.org/3/library/multiprocessing.html#contexts-and-start-methods&gt;\n\n[3-3] &lt;https://pythonspeed.com/articles/faster-multiprocessing-pickle/&gt;\n\n[3-4] &lt;https://docs.python.org/3/library/multiprocessing.html#pipes-and-queues&gt;\n\n[4-1] &lt;https://gunicorn.org/&gt;\n\n[4-2] &lt;https://www.intel.com/content/www/us/en/gaming/resources/hyper-threading.html&gt;\n\n[4-3] &lt;https://pytorch.org/docs/stable/notes/cpu_threading_torchscript_inference.html#tuning-the-number-of-threads&gt;\n\n[5-1] &lt;https://fastapi.tiangolo.com/&gt;\n\n[5-2] &lt;https://docs.pydantic.dev/&gt;\n\n[5-3] &lt;https://docs.pydantic.dev/blog/pydantic-v2/&gt;\n\n[6-1] &lt;https://pandas.pydata.org/&gt;\n\n[6-2] &lt;https://en.wikipedia.org/wiki/Pandas_(software)&gt;\n\n[6-3] &lt;https://dkharazi.github.io/blog/blockmanager&gt;\n\n[6-4] &lt;https://uwekorn.com/2020/05/24/the-one-pandas-internal.html&gt;\n\n[7-1] &lt;https://github.com/ijl/orjson&gt;\n\n[7-2] &lt;https://github.com/ultrajson/ultrajson&gt;\n\n[8-1] &lt;https://wiki.python.org/moin/UsingSlots&gt;\n\n[9-1] &lt;https://medium.com/aiguys/how-python-3-11-is-becoming-faster-b2455c1bc555&gt;\n\n## Read more\n\n* ### [ksqlDB를 이용하여 실시간 ML 피쳐 데이터를 계산하기](/2023/11/21/ksqldb-for-ml-feature-calculation.html)\n\n  Youngsoo Lee\n\n  카프카에서 제공하는 ksqlDB를 사용하여 실시간 피쳐 데이터를 계산하고 사용하는 방법을 공유합니다.\n\n  [ksqlDB](/tag/ksqldb.html) [machine-learning](/tag/machine-learning.html)\n* ### [머신러닝 어플리케이션을 위한 데이터 저장소 기술](/2022/07/11/data-stores-for-ml-apps.html)\n\n  Youngsoo Lee\n\n  머신러닝 어플리케이션의 데이터 사용 패턴을 분석하고, 데이터 사용 패턴에 적합한 데이터 저장소엔 어떠한 것들이 있는지에 대해서 소개합니다.\n\n  [machine-learning](/tag/machine-learning.html) [data-store](/tag/data-store.html)\n* ### [이벤트 기반의 라이브 스트리밍 추천 시스템 운용하기](/2022/01/24/event-driven-recsys.html)\n\n  Youngsoo Lee\n\n  마이크로서비스 아키텍처와 이벤트 주도 아키텍처로 구현된 라이브 스트리밍 추천 시스템을 소개합니다.\n\n  [machine-learning](/tag/machine-learning.html) [recommender-system](/tag/recommender-system.html) [event](/tag/event.html) [microservice](/tag/microservice.html)\n\n[Was it interesting? We are hiring!](https://career.hyperconnect.com/jobs)\n\n '},
 {'url': 'https://shoark7.github.io/programming/python/how-i-studied-python',
  'title': '내가 Python을 공부한 방법',
  'content': "PEP 008: 파이썬의 코딩 컨벤션을 담은 문서로 일단 이 문서만큼은 달달 외워야 한다. 어느 언어에서나 그 언어의 코딩 컨벤션은 익히려고 노력하는 것으로 안다. 파이썬도 마찬가지일 것이고, 나는 알바 경험상 프로그래밍을 처음 해보는 사람들을 많이 봐왔는데 그러면 당연히 컨벤션은 잘들 모른다. 당신도 마찬가지라면 빨리 지금 열어보기를 추천한다.\n Python builtin functions: ‘docs.python.org’에는 도움이 되는 파이썬 문서들이 많은데 나는 파이썬을 처음 공부한다면 이 페이지는 꼭 잘 살펴보라고 말하고 싶다. 파이썬에 있는 주요 내장함수 목록과 그 설명을 담고 있는데 이들은 주요 연구대상이 된다. 내가 파이썬 개발을 할 것이라면 이 주요 함수들은 꼭꼭 연구해야 한다. 물론 나도 다 알고 있지는 않은데 그래도 반드시 한 번씩은 눌러보고 실험을 진행해야 한다.\n\n## 5. 개인 프로젝트 진행하기\n\n여기서부터는 확신은 없다. 음 내 동생을 통해서도 그렇고 파이썬을 어떻게 더 공부하면 좋겠냐는 문의를 종종 받는다. 많이들 알고리즘을 추천하는 모양인데 나는 처음 하는 사람에게 알고리즘을 권유하는 것을 썩 좋아하지 않는다. 나는 대신 작더라도 개인 프로젝트를 꾸준히 해볼 것을 추천한다. [...] 개인적으로 다른 내용들은 다 무시해도 `help`만은 기억하기를 바란다. 마주치는 모든 기능, 클래스, 함수에 도움을 요청하라. 그냥 있으니 쓰지 말고 알고 쓰는 것이 결국에는 시간에서 이긴다. 이건 장담한다. 파이썬 쉘의 강력함은 바로 이런 데 있다.\n\n다음은 `dir`. ‘dir’ 내장함수는 어떤 오브젝트가 가지고 있는 모든 attribute를 문자열의 리스트로 반환한다.\n\n```\nimport math print(dir(math))['__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'acos', 'acosh', 'asin', 'asinh', 'atan', 'atan2', 'atanh', 'ceil', 'copysign', 'cos', 'cosh', 'degrees', 'e', 'erf', 'erfc', 'exp', 'expm1', 'fabs', 'factorial', 'floor', 'fmod', 'frexp', 'fsum', 'gamma', 'gcd', 'hypot', 'inf', 'isclose', 'isfinite', 'isinf', 'isnan', 'ldexp', 'lgamma', 'log', 'log10', 'log1p', 'log2', 'modf', 'nan', 'pi', 'pow', 'radians', 'remainder', 'sin', 'sinh', 'sqrt', 'tan', 'tanh', 'tau', 'trunc']\n``` [...] ```\nprint(issubclass(Sequence, Collection)) True\n```\n\n여기서 계속 공부해가며 나중에는 abc안에 있는 추상 클래스 간의 상속관계를 그림으로 그리는 등 실험 주제는 무궁무진하다. 이런 게 실개발에서 도움되나고? 무슨 상관이야 내가 재밌는데. 솔직히 반반이긴 해.\n\n## 4. 공식 문서\n\n다음은 공식 문서를 많이 살피는 것이다. 어느 언어를 공부해도 마찬가지일 것이다. 공식문서를 살피는 것이 도움이 된다. 파이썬에는 PEP(Python Enhancement Proposal)이라고 해서 ‘파이썬 개발은 좀 이랬으면 좋겠다’를 담은 제안문서와 함께 내장 모듈 등에 대한 사용 예제, 설명문서를 담은 공식 페이지 등이 있다. 그중에서 정말 파이썬을 공부하는 사람들이 꼭 봤으면 하는 문서가 있다면",
  'score': 0.5177909,
  'raw_content': '# 내가 Python을 공부한 방법\n\n2020, Jun 27\n\n## 0. Index\n\n&gt; 1. [들어가며](#1)\n&gt; 2. [20살 이후 공부 연대기](#2)\n&gt; 3. [Python shell 적극 활용하기](#3)\n&gt;    * 3.1. [help, dir, type](#3a)\n&gt;    * 3.2. [다양한 실험하기](#3b)\n&gt; 4. [공식 문서](#4)\n&gt; 5. [개인 프로젝트 진행하기](#5)\n&gt; 6. [그 이후에는..?](#6)\n&gt; 7. [마치며](#7)\n\n## 1. 들어가며\n\n---\n\n오랜만에 글을 쓰누나. 한 달에 한 번은 쓰겠다고 마음 먹었는데, 두 달에 하나 겨우 쓰게 생겼다. 시간 참 빠르다. 입사 후 공부하고 그곳의 Confluence 개인 공간에 글을 쓰고 보니 이 블로그는 거의 돌아보지 못했다. 가끔 이메일에 다른 분들이 댓글 달아주고 메일 보내줘서 기억하고 있었는데. 생각하고 있는 가벼운 주제들은 몇 개 있다. 결국 내가 시간을 내느냐의 문제인데 휴가를 써서라도 정말 써야할 순간에는 쓸 마음이 있다.\n\n오늘 주제는 **내가 비전공자로서 Python(이하 “파이썬”)을 어떻게 공부했는지에 대한 이야기를 조금 해볼까 한다.** 나는 파이썬을 매우 잘하는 것은 아니지만 일단 이것으로 일을 하고 있고, 곧 서술하겠지만 상당한 시간 동안 혼자 공부했기 때문에 비전공자로서 공부하고 싶은 몇몇 분들께 도움이 될 수도 있지 않을까 싶다. 가끔 어떻게 공부했는지나 코드 등에 대한 조언을 구하는 메일이 온다. 그래서 한번 써볼만하다고 생각했는데 결정적 계기는 최근 동생의 파이썬 입문이다.\n\n동생이 학교 교양 과목에서 ‘프로그래밍 입문’ 과목을 수강했는데 언어를 파이썬으로 했나보다. 그래서 과제에 대한 자신의 코드를 들고 왔는데 퇴근 후 피곤했기에 조금 보고 자기 위해 누웠다. 그런데 곧 동생이 따라 들어오더니 `int` 함수의 사용법에 대해 물었다. 근데 너무 짜증이 나고 졸려서 ‘아 좀 너가 찾아봐’라고 대꾸하고 누웠는데 나중에 보니 일말의 미안함이 남더라. ‘int’가 단순히 글자를 숫자로 바꾸는 것뿐 아니라, 여러 진법에 대응 가능하고, 심지어는 사실 함수는 아니라고 말해줬어야 했는데. 하지만 프로그래밍은 결국 자신이 공부해야 한다. 그래서 어떻게 내가 파이썬을 공부했는지, 물가에 데려다 주는 것이 이번 포스트의 목표다.\n\n먼저 포스트를 쓰는 김에 내가 20살 이후로 어떤 공부를 해왔는지에 대해 짧게 살펴본다. 이 일대기 아닌 일대기는 그냥 내가 어떤 삶을 살아왔는지 내가 반추하기 위함이기도 하다. 그후 내가 실제로 파이썬을 독학하며 사용한 방법들을 살펴볼텐데 내 방법이 정답은 아니고 조금은 마이너할 수 있기 때문에 ‘이렇게 공부한 사람도 있구나’하고 참고만 해도 좋겠다. 또 내가 파이썬을 정말 진지하게 공부한 것은 몇 년 전이기 때문에 현재의 상황과는 조금 동떨어져 있을지도.\n\n시작해볼까.\n\n## 2. 20살 이후의 공부 연대기\n\n---\n\n꼭 개발뿐 아니라 내가 20살 이후로 어떤 공부를 했는지 짧게 타임라인으로 살펴보자. 정확한 시기나 기간은 틀릴 확률이 높으나 순서는 대략 맞을 것이다.\n\n쓰고 보니 생각보다 길고, 내가 파이썬을 공부한 방법과는 상관없는 내용이기 때문에 원하면 바로 3장으로 ㄱㄱ\n\n* 2011년, 경영학과 학생이 되다.\n  + 경영학과가 문과 중에서 향후 취업이 유리하다는 엄마의 판단에 경영학과에 입학됨. 지루하기 짝이 없던 경영학원론과 회계학에 진저리를 침.\n* 2012년 - 2014년 6월, 군대.\n  + 정보 업무를 하며 단축키의 위대함에 눈을 뜸. 책을 읽고 독후감을 쓰며 글의 재미에 대해 알게 됨.\n* 2014년, **프로그래밍에 관심을 갖게 됨.**\n  + 재무 수업에서 신기한 엑셀 기능을 쓰시는 교수님께 기능 사용법을 물어보자 ‘직접 찾아보라’는 말에 엑셀 공부 시작. 한때는 매우 좋아해서 모든 문서를 엑셀로 작성하기도 했음.\n* 2015년 여름방학, C 언어를 공부.\n  + 엑셀로는 한계를 느낌. 진짜 프로그래밍을 해봐야겠다는 생각에 C 언어를 도서관에서 한 달 동안 함. 당시 시중에 있는 C 언어 책을 20여 권 모두 살펴보며 책을 고른 것이 기억에 남는다. 무슨 이대 교수님의 책이었는데 꽤 괜찮았던 것으로 기억. 표지까지 대충은 기억이 난다.\n  + 철저히 독학으로 했는데 포인터 부분에서 도저히 이해가 안 가서 때려침.\n* 2015년 겨울방학, Java 공부.\n  + 계기는 기억이 안 나는데 Java를 약 한 달 정도 공부. 책과 함께 네이버 카페에서 어떤 분의 강의를 보면서 공부함. 기억에 남는 건 자동차와 버스, 오토바이를 예로 든 클래스 관련 강의.\n  + 또 기억나는건 처음에 콘솔에 출력할 때 `System.println...` 어쩌고에서 이게 도대체 뭔지 모르겠어서 한 분노. 이는 내가 파이썬을 높게 평가하는 이유이기도 하다.\n* **2016년 초, ‘꿈꾸는 데이터 디자이너’ 교육 수강.**\n  + 내 개발 인생의 전환점. 자바스크립트 D3 라이브러리와 R 언어를 공부해보면서 진짜 프로그래밍이 어떤 것인지 맛을 잠깐 봄. 드라마 대본 자료를 분석하던 경험은 향후 데이터 분석이 굉장히 중요하다는 인식을 하게 됨.\n* **2016년 중순, 파이썬 공부 시작.**\n  + 바로 위 프로그램에서 같은 팀원이었던 누나의 파이썬을 공부해보라는 조언에 파이썬 공부 시작. 당시에는 Codecademy에서 처음 공부했고, 향후 서술할 방법으로 들이파기 시작.\n* **2017년 초, Fastcampus에서 Django 웹 개발 수강**\n  + 혼자 공부하니 한계에 부닥치고 고민하던 때에 우연히 Fastcampus에서 웹 개발 수업을 발견. 아마 내가 2기로 들어갔던 것으로 기억한다. 교육료가 싸지 않기 때문에 엄마에게 돈을 빌리며 죄송했던 마음을 아직도 기억하고 있다.\n  + 당시 네트워크에 대한 지식이 전무해서 힘들었던 기억이… 마지막 프로젝트 기간에 나는 장고 대신 파이썬 공부에 좀더 매진한 것이 기억에 남는다. 사실 이치에 맞지 않는 것으로 현솔 형한테 고맙다고 말하고 싶다.\n* 2017년 중순, 파이썬 공부 삼매경.\n  + 난 파이썬이 정말 좋았고 파이썬 자체를 연구하는 것이 좋았다.\n* 2018년 초, 미적분 과외 받으며 공부.\n  + 난 파이썬이 좋아서 공부했지 사실 취업 생각은 없었다. 정확히 말하면 취업 자체에 대한 관심이 없었다. 하지만 생각해야 할 시기가 왔고, 난 공부했던 웹 개발과 데이터 분석 중에서 고민해야 했다. 처음에는 데이터 분석에 관심이 생겨서 통계를 공부했다. 간단한 1차 회기식을 수식적으로 너무 유도하고 싶었는데 이를 위해서는 미적분에 대한 지식이 필요하다고 해서 과외를 구함.\n  + 과외 선생을 구함. 나보다 한 살 어린 한양대 학생이었는데 나랑 코드가 맞아 미적분을 위대하게 공부하기 시작. 같이 각종 확률분포를 수식으로 풀어보는 데 집중함. 아직도 생각나는 것은 스타벅스에 계량기를 들고 가서 플라스틱 컵의 부피를 미적분으로 구해본 것. 컵의 길이를 직접 재서 예상한 부피와 컵에 담은 물의 부피를 구했을 때 오차 범위 내에서 일치해 굉장한 카타르시스를 느꼈다. 또 이 과외를 계기로 확률에 대한 믿음과 관심이 증대.\n  + 하지만 데이터 분석 공부는 때려침. 이유는 분석 대신 수학적으로 통계에 지나치게 집중해 한계에 부닥침. 막상 보니 데이터 분석 업무하는 사람들 그런 것 없이도 업무 잘하는 것 같다.\n* 2018년 후반, 네트워크 공부 시작\n  + 취업에 대한 길을 잃고 그냥 네트워크 공부 시작함. TCP/IP 등 인터넷 네트워크가 매우 재밌다는 사실을 인지. 난 [이 책](https://kyobobook.co.kr/product/detailViewKor.laf?ejkGb=KOR&amp;mallGb=KOR&amp;barcode=9788989975908&amp;orderClick=LEa&amp;Kc=)으로 친구와 스터디했는데 매우매우 재밌게 공부함. 지금도 큰 도움이 되고 있음.\n  + 단, 책으로 하는 이론 스터디기 때문에 하드웨어 장비를 못 다루고, 저수준 네트워크를 공부해볼 기회가 없어서 안타까움을 많이 느낌.\n* 2019년, 알고리즘 공부\n  + 무슨 바람이 불었는지는 기억이 안 나지만 알고리즘을 공부함. 매우 재밌게 했음. Algospot, Codewars, 백준 등등 다양한 곳에서 공부하고 그 유명한 [종만북](http://www.kyobobook.co.kr/product/detailViewKor.laf?ejkGb=KOR&amp;mallGb=KOR&amp;barcode=9788966260546&amp;orderClick=LEa&amp;Kc=)으로 열심히 했음. 이 책을 공부한 계기는 좀 재밌는데 같이 스터디를 하기 위해 컴퓨터를 공부하는 경영학과 학생 세 명이 모였는데 모여서 책을 같이 보니 생각보다 어려워서 스터디가 첫날에 취소됨. 근데 나는 흥미가 생겨서 혼자 공부함. 그래서 고생도 많이 했지만 큰 도움이 됨. 이 블로그는 이 책에 큰 빚을 지고 있기도 함.\n* 2020년, 취업..\n  + 운이 좋아 나같은 사람도 취업함. 알고 보니 면접, 코딩 테스트에서 그동안의 네트워크, 알고리즘 공부가 헛되지 않음을 인지함.\n\n쓰고 나니 생각보다 기네… **다음 장부터 본격적으로 내가 파이썬을 공부한 방법을 살펴보자.**\n\n## 3. Python shell 적극 활용하기\n\n---\n\n* 먼저 파이썬 쉘은 콘솔(또는 터미널)에 `python` 이라고 입력했을 때 나오는 바로 그 파이썬 입력기라는 것을 짚고 넘어간다. 이 쉘은 언어에 대한 순간적인 접근이 가능하게 해서 궁금한 것을 바로 확인할 수 있게 한다.\n\n나는 파이썬을 정말 좋아서 공부했고, 파이썬 쉘의 존재가 내가 파이썬을 더 잘 알고 언어에 친숙해지는 데 매우 큰 역할을 했다는 것을 강조하고 싶다. 다른 언어를 비하하는 것은 아니지만 내가 이전에 배운 언어들에서는 이런 도구를 찾지 못해서 내가 코딩하면서 발견하게 되는 기능의 명세를 몰라 마음 아팠던 적이 한두번이 아니었기 때문이다. 그래서 이 포스트의 핵심은 3장이기도 하다.\n\n### 3.1. help, dir, type\n\n먼저 함수 셋을 소개한다. 파이썬을 공부해본 사람도 이 함수들은 익숙하지 않을 수 있다. 이 함수들은 파이썬 쉘에서는 매우 유용하지만 현실 개발에서는 보통 유용하지 않기 때문이다. **소개하자면 이 셋은 공부하면서 마주칠, 현실 개발에서 자주 사용할 다양한 기능, 함수, 클래스 등에 대한 메타 정보를 제공하는 helper 기능이다.** 개인적으로 나는 마주치는 기능을 그냥 ‘너는 존재하는구나’라는 부처의 마음으로 사용하는 것을 싫어한다. 쓰는 것도 쓰는 것이지만 일단 이것이 무엇인지, 어떤 인자를 받는지, 다른 활용은 없는지 살펴봐야지. 이 셋은 이 ‘탐색’을 도와주는 고마운 기능들이라 하겠다.\n\n먼저 `help`. help 함수는 인자로 받는 함수, 기능, 클래스 등에 대한 도움 문서를 출력한다. 생각해보면 파이썬에서 기본으로 제공하는 모든 기능 또한 누가 개발한 것이고 이왕 사용자들에게 제공되는 것, 개발자들은 타인이 잘 쓰기를 바라기 때문에 기능에 대한 설명문서를 만들어 놓는다. 그리고 ‘help’ 함수는 그 설명문서를 출력한다. 바로 사용해보자.\n\n파이썬에서 가장 처음 접하게 되는 `print` 함수에 대해 help 해보자.\n\n함수에 대한 설명서가 나온다. 함수가 파이썬에서 기본으로 제공하는 함수이고(built-in), 함수가 어떤 입력을 받는지, 함수의 기본적인 동작이 어떻게 되는지에 대해 설명하고 있다. 처음 보는 `sep`, `end`, `file` 등 찾아보지 않으면 알 수 없는 입력들을 받는다는 것을 알 수 있다. 이런 메타정보를 찾아 봐야 하는 이유가 여기에 있다. *print* 는 워낙 기초적인 함수라 이런 부분을 놓칠 수 있는데 실은 다양한 옵션을 가지고 있고, 알고 있지 않으면 우리는 이 함수의 반쪽짜리 기능만 알고 쓰는 꼴이 된다. 그리고 도저히 이해가 안 가는 부분이 나올 수 있다. 가령 나같은 경우에는 `sys.stdout`이 정말 뭔지 모르겠더라. 이런 부분들은 내가 또 공부할 여지를 남기게 되고 이렇게 깊이를 더하게 된다.\n\n**개인적으로 다른 내용들은 다 무시해도 `help`만은 기억하기를 바란다. 마주치는 모든 기능, 클래스, 함수에 도움을 요청하라. 그냥 있으니 쓰지 말고 알고 쓰는 것이 결국에는 시간에서 이긴다. 이건 장담한다. 파이썬 쉘의 강력함은 바로 이런 데 있다.**\n\n다음은 `dir`. **‘dir’ 내장함수는 어떤 오브젝트가 가지고 있는 모든 attribute를 문자열의 리스트로 반환한다.**\n\n```\nimport math print(dir(math))[\'__doc__\', \'__file__\', \'__loader__\', \'__name__\', \'__package__\', \'__spec__\', \'acos\', \'acosh\', \'asin\', \'asinh\', \'atan\', \'atan2\', \'atanh\', \'ceil\', \'copysign\', \'cos\', \'cosh\', \'degrees\', \'e\', \'erf\', \'erfc\', \'exp\', \'expm1\', \'fabs\', \'factorial\', \'floor\', \'fmod\', \'frexp\', \'fsum\', \'gamma\', \'gcd\', \'hypot\', \'inf\', \'isclose\', \'isfinite\', \'isinf\', \'isnan\', \'ldexp\', \'lgamma\', \'log\', \'log10\', \'log1p\', \'log2\', \'modf\', \'nan\', \'pi\', \'pow\', \'radians\', \'remainder\', \'sin\', \'sinh\', \'sqrt\', \'tan\', \'tanh\', \'tau\', \'trunc\']\n```\n\n위 예시는 파이썬의 유명한 내장모듈인 `math` 모듈이 가지고 있는 모든 attribute를 출력해봤다. 잘 보면 자연상수 `e`와 소수부를 올림하는 `ceil` 함수 등 다양한 속성의 값을 확인할 수 있다. 내가 언급한 attribute는 이것들을 모두 포괄한 개념으로 언급했고 변수, 상수, 메소드, 클래스 등등 math에 얽혀있는 모든 object를 통칭했다. 즉 ‘dir’을 통해서는 특정 오브젝트에서 참조가능한 모든 값들에 접근가능하기 때문에 유용하다. 처음에 ‘math’ 모듈을 사용하면 ‘inf’와 같은 간단한 값만 쓰게 되는데 실제로는 삼각함수 관련 메소드 등 수많은 기능들이 사용대기 중이다.\n\n나같은 경우는 마주치는 모든 객체들에 한 번씩은 `dir`을 입력해보고 기능을 확인한다. 그리고 그중 흥미가 가는 객체는 또다시 탐구해본다. 가령 저 모듈에서 실제로 지금 `degrees`가 뭘까 궁금해지는데 **dir(math.degrees)**, **help(math.degrees)** 와 같이 말이다. 찾아보니 radian을 도로 변환하는 함수라고 한다.\n\n마지막으로 **`type`. 이 함수는 인자의 클래스를 반환한다.**\n\n```\nprint(type(None)) print(type(True)) print(type(print))&lt; class \' NoneType\'&gt; bool\'&gt; builtin_function_or_method\'&gt; bool\'&gt; builtin_function_or_method\'&gt; builtin_function_or_method\'&gt; \n```\n\ntype은 다음과 같이 마주치는 모든 오브젝트에 써볼 수 있다. 그러면서 얻을 수 있는 통찰:\n\n1. 아하, *‘파이썬에서 모든 것은 클래스다’* 라는 말은 헛소리가 아니었구나. 클래스와 인스턴스가 지배하는 파이썬 세계…\n2. 아하, 예상치 못한 클래스들이 파이썬에는 존재하는구나…\n\n2번은 이런 것이다. 파이썬을 처음 배울 때 `int` 메소드를 써볼 일이 많다. 가령 input으로 받은 값을 정수로 바꾼다든지. 이때 int를 단순히 함수라고 생각하는데 하지만 type을 해보면?!\n\n```\nprint(type(int))&lt; class \' type\'&gt; \n```\n\n아.. ‘int는 단순히 함수가 아니구나. type이라는 클래스의 인스턴스구나’라고 깨달을 수 있다. 여기서 ‘그럼 type은 또 뭐야. 지금까지 계속 써왔잖아?’라고 질문을 던질 수 있지만 일단 넘어가고. 중요한 것은 파이썬에서 접하는 수많은 객체들에 type을 해보면 이것들의 성질을 일차적으로 살필 수 있는 괜찮은 수단이 된다.\n\n### 3.2. 다양한 실험하기\n\n**쉘을 통해서 다양한 실험을 하는 것, 이것이 내가 파이썬을 공부한 방법의 8할이라고 감히 말하겠다. 앞선 내장함수들과 기타 내장함수들과 함께 파이썬의 세계를 유영하는 것, 그것이 내 방법이다.** 실제로 내가 연구했던 두 가지 주제를 예시로 간략히 들어보겠다.\n\n먼저 `sum`과 `min`의 미묘한 차이에 대해서. 당시 내가 파이썬을 공부한지 얼마 안 됐을 때였고 반복문과 최소한의 함수만 작성할 수 있던 시기였다. ‘sum’은 다을 알다시피 리스트의 모든 값을 더해 반환하는 함수이고, ‘min’은 리스트의 최소값을 반환하는 함수이다.\n\n```\nparkito =[1, 2, 3, 4, 5] print(sum(parkito)) print(min(parkito)) 15 1\n```\n\n뭐 예상 가능하다. 그런데 ‘min’은 다른 형태의 입력도 받을 수 있다. 단순히 하나의 리스트를 받고 그 원소 중 최소값만 뽑는 것이 아니라 개별값들을 각각 받고 그중 최소값을 찾는 것이다.\n\n```\nprint(min(1, 2, 3, 4, 5)) 1\n```\n\n이렇게 해도 신기하게 에러가 안난다. 반대로 sum은 이런 식으로 입력하면 에러가 난다.\n\n```\nprint(sum(1, 2, 3, 4, 5)) TypeError: sum expected at most 2 arguments, got 5\n```\n\n오호.. 난 이것이 신기했고 이해가 안 갔다. 이 둘은 모두 초보적인 수준의 내장함수이고, 구현도 둘 다 반복문 한 번만 실행시키면 될 정도로 비슷한 내용의 함수이니, 같은 형식의 방식으로 돌아가는 것이 일견 자연스럽게 보였다. 이제 둘은 연구대상이 됐다.\n\n```\nprint(type(sum)) print(type(min))&lt; class \' builtin_function_or_method\'&gt; builtin_function_or_method\'&gt; builtin_function_or_method\'&gt; \n```\n\n흠, 같은 종류의 객체구나 너네?\n\n```\nprint(help(sum)) Help on built - in function sum in module builtins: sum(iterable, start = 0,/) Return the sum of a \'start\' value(default: 0) plus an iterable of numbers...\n```\n\n```\nprint(help(min)) Help on built - in function min in module builtins: min(...) min(iterable,*[, default = obj, key = func]) -&gt; value min(arg1, arg2,* args,*[, key = func]) -&gt; value...\n```\n\n음, 이거 뭐야. 확실히 설명이 조금 다르네? ‘sum’은 ‘start’라는 추가 인자를 받을 수 있는데 ‘min’은 그렇지 않고. 그것은 일단 다음 실험 주제로 남기고, 다만 min은 실험에서 확인했던 것처럼 두 가지의 입력 형태를 가질 수 있다.\n\n흠.. 그냥 그런 것이 아니라 설명문서로까지 작성되어 있을만큼 의도적인 것이네. 게다가 `*`, `[ ]`이런 표시도 의미있을 것 같은데 말이지…\n\n`[]`는 파이썬뿐만 아니라 쉘 등의 타 언어의 설명문서에서도 많이 발견할 수 있는 것으로 그 안의 인자가 optional한, 그러니까 원하면 추가적으로 넣을 수 있는 값이라는 것을 뜻한다. 가령 `key`라는 것은 원하면 넣을 수 있는 값으로 이것 또한 실험주제가 되겠지. `*`는 좀 중요한 것으로 여기서 `packing &amp; unpacking`이 등장한다. 이건 처음에는 어려운 주제니 나중에 다시 연구할 주제고…\n\n위와 같은 프로세스로 별것 아닌 내장함수에서 굉장한 통찰을 이끌어 낼 수 있다. 물론 당장 이런 공부는 시간이 들겠지만 이건 100% 왕도에 이르는 데는 더 가깝다. 또 다른 예를 볼까?\n\n이건 내가 진정으로 열심히 살펴보던 주제로, 내장 모듈 `collections.abc`에 있는 추상 클래스들의 상속관계를 살펴보는 것이다. 예를 들어 list, tuple, str 등은 모두 **순서가 있는 자료들의 모음**으로서, 이들은 abc에 있는 Sequence라는 추상 클래스를 상속한다. 이런 것도 연구를 통해 깨달을 수 있다.\n\n```\nfromcollections.abc import Sequence print(issubclass(list, Sequence)) print(issubclass(tuple, Sequence)) print(issubclass(str, Sequence)) True True True\n```\n\n오호, 여기서 또 연구를 위해 유용한 내장함수가 등장했다. `issubclass`는 인자를 두 개 받아 첫 번째 인자의 두 번째 인자에 대한 서브클래스 여부를 반환한다. list, tuple, str은 그래서 실제로 Sequence라고 부르기도 하며, 셋 모두 Sequence의 메소드를 상속, 구현하고 있다. 가령 Sequence는 ‘index’라는 메소드를 갖고 있는데, 따라서 Sequence를 상속받는 내장클래스들은 모두 ‘index’를 구현하고 있다.\n\n```\nprint(\'index\' in dir(Sequence)) print(\'index\' in dir(list)) print(\'index\' in dir(tuple)) print(\'index\' in dir(str)) True True True True\n```\n\n놀랍기 그지없다. ‘abc’에는 Sequence뿐 아니라 수많은 추상 클래스가 존재하고 이들끼리의 상속관계도 존재한다. 가령 ‘dict’를 보자. ‘dict’는 Sequence와 달리 포함된 데이터끼리의 순서가 존재하지 않기에 Sequence가 아니며 실험을 통해서도 확인할 수 있다. 하지만 자료를 **담고 있는** 것은 Sequence와 마찬가지며 담고 있다는 것을 표현하는 추상 클래스는 ‘Collection’이 있다. dict는 Collection의 서브클래스이며, Sequence도 마찬가지다.\n\n```\nprint(issubclass(Sequence, Collection)) True\n```\n\n여기서 계속 공부해가며 나중에는 abc안에 있는 추상 클래스 간의 상속관계를 그림으로 그리는 등 실험 주제는 무궁무진하다. 이런 게 실개발에서 도움되나고? 무슨 상관이야 내가 재밌는데. 솔직히 반반이긴 해.\n\n## 4. 공식 문서\n\n---\n\n다음은 공식 문서를 많이 살피는 것이다. 어느 언어를 공부해도 마찬가지일 것이다. 공식문서를 살피는 것이 도움이 된다. 파이썬에는 PEP(Python Enhancement Proposal)이라고 해서 ‘파이썬 개발은 좀 이랬으면 좋겠다’를 담은 제안문서와 함께 내장 모듈 등에 대한 사용 예제, 설명문서를 담은 공식 페이지 등이 있다. 그중에서 정말 파이썬을 공부하는 사람들이 꼭 봤으면 하는 문서가 있다면\n\n* [PEP 008](https://www.python.org/dev/peps/pep-0008/): 파이썬의 코딩 컨벤션을 담은 문서로 일단 이 문서만큼은 달달 외워야 한다. 어느 언어에서나 그 언어의 코딩 컨벤션은 익히려고 노력하는 것으로 안다. 파이썬도 마찬가지일 것이고, 나는 알바 경험상 프로그래밍을 처음 해보는 사람들을 많이 봐왔는데 그러면 당연히 컨벤션은 잘들 모른다. 당신도 마찬가지라면 빨리 지금 열어보기를 추천한다.\n* [Python builtin functions](https://docs.python.org/3/library/functions.html): ‘docs.python.org’에는 도움이 되는 파이썬 문서들이 많은데 나는 파이썬을 처음 공부한다면 이 페이지는 꼭 잘 살펴보라고 말하고 싶다. 파이썬에 있는 주요 내장함수 목록과 그 설명을 담고 있는데 이들은 주요 연구대상이 된다. 내가 파이썬 개발을 할 것이라면 이 주요 함수들은 꼭꼭 연구해야 한다. 물론 나도 다 알고 있지는 않은데 그래도 반드시 한 번씩은 눌러보고 실험을 진행해야 한다.\n\n## 5. 개인 프로젝트 진행하기\n\n---\n\n여기서부터는 확신은 없다. 음 내 동생을 통해서도 그렇고 파이썬을 어떻게 더 공부하면 좋겠냐는 문의를 종종 받는다. 많이들 알고리즘을 추천하는 모양인데 나는 처음 하는 사람에게 알고리즘을 권유하는 것을 썩 좋아하지 않는다. **나는 대신 작더라도 개인 프로젝트를 꾸준히 해볼 것을 추천한다.**\n\n가령 내가 만드는 알파고: 컴퓨터와 가위바위보 하기, 나의 일진 실험하기: 로또 게임 만들기 등등. 개인적으로 생각나는 프로젝트로는 쉘로만 돌아가는 금전출납부가 생각이 난다. 내가 사용한 금액을 입력하고 나중에 조회가능하고 또 이를 이쁘게 출력하고… 나름 정말 고심하며 만들었는데 지출내역을 어떻게 저장하냐와 지출금액과 내역은 길이가 임의적인데 어떻게 이에 다 대응해 표를 이쁘게 그리느냐가 정말 관건이었다.\n\n첫 번째는 내가 데이터베이스는 문외한이었기 때문에 json에 지출내역을 저장하면서 json 내장 모듈을 깊이 팠던 것이 기억에 난다. 난 `dump`, `dumps`의 차이와, 이 크고 아름다운 `s`는 도대체 뭐의 약자일까를 많이 고민했었다. 두 번째는 파이썬 포매팅! 가령 새로 입력된 지출내역이 ‘가나다라마바사아자차카타파하를 외치는 자에게 적선’와 같이 길게 들어왔는데 기존 내역의 최대 길이를 넘어섰다고 할 때 그래도 표가 깨지지 않고 이쁘게 나올 수 있을까를 고민했는데, `{}`를 중첩해서 사용하면서 해결했던 것이 기억에 남는다.\n\n중요한 것은 `흥미를 잃지 않는 것`. 난 알고리즘은 처음에 하면 좌절을 많이 느끼고 흥미를 잃기 쉽다고 생각한다. 처음에야 술술 넘어가더라도 조금만 들어가면 최소한의 알고리즘을 알아야 해결할 수 있는 것들이 나올 수 있는데 그때가서 좌절하지 않을까? 그리고 나의 수요에서 비롯된 것이 아닌, 다른 누군가가 원하는 ‘정렬해서 반환해’따위가 처음에 즐거울까?\n\n하지만 취향을 얼마든지 탄다.\n\n## 6. 그 이후에는..?\n\n---\n\n너와 나는 프로그래밍을 왜 할까? 그중에서도 왜 파이썬을 공부하는가? 만약 더 해보고 싶다면 그중에서 자신이 관심있는 분야를 더 해보면 좋겠다. 직장인이라서 자동화에 관심있을 수도 있고, 취업을 위해 웹개발이나 데이터분석 등에 관심있을 수도 있지. 그러면 그쪽으로 공부해보자. 그리고 취업을 위해서라면 알고리즘을 더 해볼 수도 있겠지. 네이버 등의 온라인 코딩 테스트에서 지원하는 언어들이 조금씩 다른데 어느 회사든 파이썬은 다 지원했던 것 같다. 그러니 파이썬으로 알고리즘을 공부하는 것도 나쁘지 않다. 알고리즘을 공부할 수 있는 사이트는 정말정말 많은데 내가 해봤던 목록은 [다음](https://gist.github.com/shoark7/38bcff39588b528d37313a669fdfd75d)과 같다.\n\n음 그리고 웹개발을 한다면 HTTP만큼은 최소한은 공부할 것을 추천한다. 시간이 허락한다면 TCP 정도까지. TCP까지는 웹 개발에 매우 큰 도움이 되는지는 아직 잘 모르겠는데 회사면접에서 물어보기도 했던 기억이 난다. Slow starter~!\n\n## 7. 마치며\n\n---\n\n너무 오랜만에 글 쓴다. 지난 글들을 보면 ‘맨날 쓰려고 했는데 못 썼다 ㅠㅠ’와 같은 내용들만 있어서 이제는 반드시 언제 쓰겠다고 확신은 못하겠다. 머릿속에 써보고 싶은 주제들은 있는데 흠 시간을 낼 수 있을지. 사실 회사 Confluence에도 글을 쓰고 있고, 회사 개술 블로그에도 글을 쓰고 싶은 마음이 있어 이 블로그가 방치되는 것은 아닌지 모르겠다.\n\n하지만 버리지 않았다. 이 블로그는 나중에 책으로 나올 수 있는 진정한 나의 글들이 담기고 있고, 블로그 포맷도 바꿔서 언젠가 다른 플랫폼(AWS 등)으로 이전하는 것도 고려하고 있다. 현 블로그가 이제는 외양이 만족스럽지 않기 때문이다. Endowment effect의 영향일까.\n\n포스트 얘기를 조금만 하자면 이 방법은 왕도인냥 말했지만 꼭 그렇지는 않다고도 느낀다. 자기에게 맞는 방법이 최선이 아닐까. 하지만 연구하는 식의 공부가 맞는 사람들에게는 내 방법도 괜찮을 것이다. 너, 나와 같이 실험하지 않을래?\n\n이상 포스트를 마칩니다.\n\n[Twitter](https://twitter.com/intent/tweet?text=내가 Python을 공부한 방법&amp;url=https://shoark7.github.io/programming/python/how-i-studied-python "Share on Twitter") [Facebook](https://facebook.com/sharer.php?u=https://shoark7.github.io/programming/python/how-i-studied-python "Share on Facebook") [Google+](https://plus.google.com/share?url=https://shoark7.github.io/programming/python/how-i-studied-python "Share on Google+")\n\n[# newbie](/tags#newbie) [# python](/tags#python)\n\n '},
 {'url': 'https://m.blog.naver.com/hupers/222845934642',
  'title': '파이썬 독학을 위한 개발툴 6종 - 네이버 블로그',
  'content': "아나콘다 스파이더\n\nPython의 리포지토리(repository)를 가장 많이 보유하고 있는 Anaconda에 속해있는 스파이더(spyder)는 다른 개발언어를 접해보지 않고 바로 파이썬 독학을 시작한다면 데이터 사이언스와 머신 러닝에 최적화된 스파이더가 가장 적합합니다. 공부하기 편한 개발환경이며, Windows는 물론 macOS와 linux에서도 사용 가능합니다. 자신이 개발한 프로그램을 배포도 가능하고 OSS 라이브러리와 모듈을 설치 및 환경설정도 command line 없이도 가능합니다.\n\n파이참\n\n젯브레인사에서 만든 파이참은 텍스트 에디터처럼 되어 있어 웹 기반 front-end 개발에 편리합니다. 다만, 무료 버전의 기능이 딱 파이썬 공부할 정도로만 사용할 수 있어 커뮤니티 버전이 아닌 프로페셔널 버전을 구매하기에 대체 개발툴이 많아 꺼려지지만, IntelliJ IDE를 사랑하거나 해외에서 많이 쓰이는 툴이기에 있어 보이고 싶다면 PyCharm이 좋습니다. 물론, JetBrains에서 다양한 언어 개발을 위한 IDE를 정말 잘 만듭니다.\n\n&gt; 2. 웹 기반 프로그램\n&gt;\n&gt; VS Code, Colaboratory, jupyter notebook\n\n개발하고자 하는 PC에 별도의 프로그램을 설치하지 않고, 바로 웹 브라우저로 사이트에 접속해서 코딩 할 수 있습니다. 따라서 인터넷이 반드시 되어야 하는데요. 그럼에도 불구하고 자신의 PC 사양이 낮아도 성능에 대한 고민 없이 프로그래밍 개발을 할 수 있어 간단한 파이썬 독학 방법입니다.\n\n웹 비주얼 스튜디오 코드 [...] PC에 파이썬 개발을 위한 프로그램을 설치하게 되면 디스크 용량은 차지하게 되지만 CPU의 최대 성능을 사용하며 빠른 연산이 필요한 프로그램을 개발할 수 있으며, 인터넷이 되지 않는 경우에도 사용할 수 있어 언제 어디서나 파이썬 독학을 할 수 있죠.\n\n비주얼 스튜디오 코드\n\n그중에서 마이크로소프트사의 비주얼 스튜디오 코드는 가볍지만 강력하게 활용할 수 있는 윈도우 OS 최적의 개발툴입니다. 아래에 설명드릴 비주얼스튜디오 2022에서 프로그래밍 관련된 기능을 집중하였고, 오랜 전통의 MS사 개발툴이기에 더 이상 설명은 필요 없을 정도입니다. C++에서 시작된 OpenCV 개발에 효율적이므로 사진, 영상 분야로 개발하고 싶으시다면 MS의 Visual Studio를 선택하시면 됩니다.\n\n비주얼 스튜디오 2022\n\n위에서 언급한 VS Code의 확장판(원래는 VS 코드가 축소판임)인 비주얼스튜디오 2022는 매년 혹은 격년마다 버전업을 하고 있고, VB, C# 등 닷넷(.Net) 버전의 프로그램 개발툴에서 시작하여 파이썬까지 코딩할 수 있도록 발전되어 왔습니다. 강력한 테스트 기능과 소스 관리, 협업이 가능하여 개발툴로만 따지만 현존 최고가 아닐까 싶습니다.\n\nMS가 오픈소스에 대한 정책을 도입하면서부터 맥OS, 리눅스에서도 개발할 수 있게 만들어 맥북 사용자들도 MS 프로그램을 개발할 수 있게 되었습니다.(물론 닷넷 기반 앱은 불가)\n\n아나콘다 스파이더 [...] 웹 비주얼 스튜디오 코드\n\n가장 먼저 소개하기는 했지만 MS라서 그런 것이고, 실제 최적 사용방법은 개인 PC가 없어 PC방 또는 여러 장소의 컴퓨터를 상황에 따라 사용한다면 MS 계정으로 로그인하여 개발 환경 그대로 언제 어디서나 같은 환경으로 할 수 있어 좋습니다.\n\n코랩\n\n구글에서 만든 Colaboratory는 '코랩'이라고 줄여서 부르는데, 구글 드라이브에 저장하는 것처럼 파일을 save 하고, 블로그처럼 외부에서 내용을 확인할 수 있게 공개도 가능하여, 강의 자료로 자주 활용합니다. 강사가 미리 작성해 놓고, 학생은 해당 URI로 접속하여 내용 확인하고 실습하는 형태로 쓰죠.\n\n유료로 결재하면 더 빠른 CPU와 하드웨어 자원을 활용할 수 있으므로 구글 Cloud 서버에서 Pilot 형태로 프로그램을 운영할 수도 있습니다.\n\n주피터 노트북\n\n구글의 코랩과 유사한 방식으로 사용을 하며, 많은 대학생과 파이썬 독학하고자 하는 학생들에게 사랑받는 주피터 노트북입니다. 타이틀도 참 잘 지었듯이 노트 필기하듯이 코딩하고, 온라인상으로 코드를 저장하고 공개할 수 있습니다.\n\n이미 많은 노트 자료가 있기에 혼자서 따라 해 볼 수 있기에 처음 시작하시는 분들께 추천합니다.",
  'score': 0.374837,
  'raw_content': '[본문 바로가기](#ct)\n\n# [블로그](/Recommendation.naver)\n\n## [카테고리 이동](#) [사랑나무아빠의 행복한 세상](/PostList.naver?blogId=hupers)\n\n[검색](/PostSearchList.naver?blogId=hupers)\n\n파이썬 독학을 위한 개발툴 6종\n\n[**사랑나무아빠**](/PostList.naver?blogId=hupers)\n\n2022. 8. 11. 19:14\n\n[이웃추가](#)\n\n* **본문 폰트 크기 조정** 가\n* [공유하기](#)\n* [URL복사](#)\n* [신고하기](#)\n\n요즘 IT 개발자(프로그래머) 품귀 현상(?)으로 기업의 프로젝트 진행에 어려움을 겪고 있습니다. 저 역시 마찬가지로 프로젝트 매니징(PM)을 하면서 동시에 코딩도 해야 하는 상황에 직면했죠. 그래서, 이번에 데이터 분석 관련된 플젝을 하면서 파이썬(python)을 접하게 되었는데요. 개인 프로젝트로 웹 스크래핑을 해보면서 혼자서 배우고 있습니다. 10시간 정도 파이썬 독학을 하였는데, C#, JAVA 대비 쉽게 언어를 습득할 수 있었고, 개발환경이 다양하고 편리해서 C, C++, VB 시절의 개발자인 저는 너무 재미있습니다. ^^\n\n&gt; 파이썬 개발툴 6종\n&gt;\n&gt; VS Code, Visual Studio, PyCharm, Jupyter notebook, colab, spyder\n\n그럼, 본격적으로 공부를 시작하기 전에 개발툴(IDE)의 종류를 살펴보고, 상황에 따라 어떤 IDE가 좋은지 알려드리겠습니다.\n\n---\n\n먼저, 종류를 2가지로 나눌 수 있습니다.\n\n1. 설치형 통합 개발 환경(IDE)\n2. 웹 기반 스크립트 개발환경\n\n---\n\n&gt; 1. 설치형 프로그램\n&gt;\n&gt; Visual Studio Code, VS 2022, PyCharm, Anaconda Sypder\n\nPC에 파이썬 개발을 위한 프로그램을 설치하게 되면 디스크 용량은 차지하게 되지만 CPU의 최대 성능을 사용하며 빠른 연산이 필요한 프로그램을 개발할 수 있으며, 인터넷이 되지 않는 경우에도 사용할 수 있어 언제 어디서나 파이썬 독학을 할 수 있죠.\n\n비주얼 스튜디오 코드\n\n그중에서 마이크로소프트사의 비주얼 스튜디오 코드는 가볍지만 강력하게 활용할 수 있는 윈도우 OS 최적의 개발툴입니다. 아래에 설명드릴 비주얼스튜디오 2022에서 프로그래밍 관련된 기능을 집중하였고, 오랜 전통의 MS사 개발툴이기에 더 이상 설명은 필요 없을 정도입니다. C++에서 시작된 OpenCV 개발에 효율적이므로 사진, 영상 분야로 개발하고 싶으시다면 MS의 Visual Studio를 선택하시면 됩니다.\n\n비주얼 스튜디오 2022\n\n위에서 언급한 VS Code의 확장판(원래는 VS 코드가 축소판임)인 비주얼스튜디오 2022는 매년 혹은 격년마다 버전업을 하고 있고, VB, C# 등 닷넷(.Net) 버전의 프로그램 개발툴에서 시작하여 파이썬까지 코딩할 수 있도록 발전되어 왔습니다. 강력한 테스트 기능과 소스 관리, 협업이 가능하여 개발툴로만 따지만 현존 최고가 아닐까 싶습니다.\n\nMS가 오픈소스에 대한 정책을 도입하면서부터 맥OS, 리눅스에서도 개발할 수 있게 만들어 맥북 사용자들도 MS 프로그램을 개발할 수 있게 되었습니다.(물론 닷넷 기반 앱은 불가)\n\n아나콘다 스파이더\n\nPython의 리포지토리(repository)를 가장 많이 보유하고 있는 Anaconda에 속해있는 스파이더(spyder)는 다른 개발언어를 접해보지 않고 바로 파이썬 독학을 시작한다면 데이터 사이언스와 머신 러닝에 최적화된 스파이더가 가장 적합합니다. 공부하기 편한 개발환경이며, Windows는 물론 macOS와 linux에서도 사용 가능합니다. 자신이 개발한 프로그램을 배포도 가능하고 OSS 라이브러리와 모듈을 설치 및 환경설정도 command line 없이도 가능합니다.\n\n파이참\n\n젯브레인사에서 만든 파이참은 텍스트 에디터처럼 되어 있어 웹 기반 front-end 개발에 편리합니다. 다만, 무료 버전의 기능이 딱 파이썬 공부할 정도로만 사용할 수 있어 커뮤니티 버전이 아닌 프로페셔널 버전을 구매하기에 대체 개발툴이 많아 꺼려지지만, IntelliJ IDE를 사랑하거나 해외에서 많이 쓰이는 툴이기에 있어 보이고 싶다면 PyCharm이 좋습니다. 물론, JetBrains에서 다양한 언어 개발을 위한 IDE를 정말 잘 만듭니다.\n\n---\n\n&gt; 2. 웹 기반 프로그램\n&gt;\n&gt; VS Code, Colaboratory, jupyter notebook\n\n개발하고자 하는 PC에 별도의 프로그램을 설치하지 않고, 바로 웹 브라우저로 사이트에 접속해서 코딩 할 수 있습니다. 따라서 인터넷이 반드시 되어야 하는데요. 그럼에도 불구하고 자신의 PC 사양이 낮아도 성능에 대한 고민 없이 프로그래밍 개발을 할 수 있어 간단한 파이썬 독학 방법입니다.\n\n웹 비주얼 스튜디오 코드\n\n가장 먼저 소개하기는 했지만 MS라서 그런 것이고, 실제 최적 사용방법은 개인 PC가 없어 PC방 또는 여러 장소의 컴퓨터를 상황에 따라 사용한다면 MS 계정으로 로그인하여 개발 환경 그대로 언제 어디서나 같은 환경으로 할 수 있어 좋습니다.\n\n코랩\n\n구글에서 만든 Colaboratory는 \'코랩\'이라고 줄여서 부르는데, 구글 드라이브에 저장하는 것처럼 파일을 save 하고, 블로그처럼 외부에서 내용을 확인할 수 있게 공개도 가능하여, 강의 자료로 자주 활용합니다. 강사가 미리 작성해 놓고, 학생은 해당 URI로 접속하여 내용 확인하고 실습하는 형태로 쓰죠.\n\n유료로 결재하면 더 빠른 CPU와 하드웨어 자원을 활용할 수 있으므로 구글 Cloud 서버에서 Pilot 형태로 프로그램을 운영할 수도 있습니다.\n\n주피터 노트북\n\n구글의 코랩과 유사한 방식으로 사용을 하며, 많은 대학생과 파이썬 독학하고자 하는 학생들에게 사랑받는 주피터 노트북입니다. 타이틀도 참 잘 지었듯이 노트 필기하듯이 코딩하고, 온라인상으로 코드를 저장하고 공개할 수 있습니다.\n\n이미 많은 노트 자료가 있기에 혼자서 따라 해 볼 수 있기에 처음 시작하시는 분들께 추천합니다.\n\n---\n\n이렇게 파이썬 개발 할 수 있는 방법에 대해 알아보았는데요. 아마도 이 글은 코딩에 관심이 있고, IT 프로그래머가 되고 싶은 분들이 보셨을 거라 예상이 되네요. 그렇기에 **혼자서 공부하는 방법**과 **무슨 개발 언어를 습득**해야 할지, 그리고 **어떻게 진로를 잡아야** 할지 궁금하실 텐데요. 다양한 IT 회사를 경험하며 얻은 경험을 기반으로 네이버 익스퍼트에서 진로 상담을 진행하고 있으니 둘러보시면 좋을 것 같네요.\n\n상담하신 분들의 후기 평점 5점 만점으로 결정에 후회는 없으실 거예요.\n\n(이벤트 가격으로 할인을 하고 있는데, 다음 달에는 인상되니 참고하세요. ^^;)\n\n[**(8월 이벤트)IT 개발자/프로그래머 진로 상담 : 네이버 eXpert**\n\n엑스퍼트: 4차 산업혁명의 시대를 맞이하며 개발자들의 인기가 날로 높아지고 있습니다. 많은 IT 기업에서 인력난을 호소하고 있지만, IT 학원과 대학에서는 실무에 적합한 인재를 키...\n\nm.expert.naver.com](https://m.expert.naver.com/mobile/expert/product/detail?storeId=100015672&amp;productId=100034205)\n\n{"title":"파이썬 독학을 위한 개발툴 6종","source":"https://blog.naver.com/hupers/222845934642","blogName":"사랑나무아..","domainIdOrBlogId":"hupers","nicknameOrBlogId":"사랑나무아빠","logNo":222845934642,"smartEditorVersion":4,"meDisplay":true,"lineDisplay":true,"outsideDisplay":true,"cafeDisplay":true,"blogDisplay":true}\n\n[닫기](#)\n\n[이 블로그 홈](/hupers)\n\n**사랑나무아빠(hupers)** 님을 이웃추가하고 새글을 받아보세요\n\n[취소](#) [이웃추가](#)'}]</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=99abc118">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<br/>
<ul>
<li><code>exclude_domains</code> 사용 객체 : 특정 도메인을 제외하고 검색</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=24900e6f">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [29]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">tavily_tool_exclude</span> <span class="o">=</span> <span class="n">TavilySearch</span><span class="p">(</span><span class="n">exclude_domains</span><span class="o">=</span><span class="p">[</span><span class="s2">"ads.com"</span><span class="p">,</span> <span class="s2">"spam.com"</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=3680ea41">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [32]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">result4</span> <span class="o">=</span> <span class="n">tavily_tool_exclude</span><span class="o">.</span><span class="n">search</span><span class="p">(</span>
    <span class="n">query</span><span class="o">=</span><span class="s2">"건강한 식단"</span><span class="p">,</span>  <span class="c1"># 검색 쿼리</span>
    <span class="n">search_depth</span><span class="o">=</span><span class="s2">"basic"</span><span class="p">,</span>  <span class="c1"># 기본 검색 수준</span>
    <span class="n">max_results</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span>  <span class="c1"># 최대 7개 결과</span>
<span class="p">)</span>

<span class="n">result4</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[32]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>[{'url': 'https://www.youtube.com/watch?v=_GOHIO0O_uU',
  'title': '올해는 진짜 건강하게 먹어야지   위 건강 지키는 건강한 식단을 알려드림',
  'content': '[About](https://www.youtube.com/about/)[Press](https://www.youtube.com/about/press/)[Copyright](https://www.youtube.com/about/copyright/)[Contact us](/t/contact_us/)[Creators](https://www.youtube.com/creators/)[Advertise](https://www.youtube.com/ads/)[Developers](https://developers.google.com/youtube)[Terms](/t/terms)[Privacy](/t/privacy)[Policy &amp; Safety](https://www.youtube.com/about/policies/)[How YouTube works](https://www.youtube.com/howyoutubeworks?utm_campaign=ytgen&amp;utm_source=ythp&amp;utm_medium=LeftNav&amp;utm_content=txt&amp;u=https%3A%2F%2Fwww.youtube.com%2Fhowyoutubeworks%3Futm_source%3Dythp%26utm_medium%3DLeftNav%26utm_campaign%3Dytgen)[Test new features](/new)[NFL Sunday Ticket](https://tv.youtube.com/learn/nflsundayticket).',
  'score': 0.7520126,
  'raw_content': '[About](https://www.youtube.com/about/)[Press](https://www.youtube.com/about/press/)[Copyright](https://www.youtube.com/about/copyright/)[Contact us](/t/contact_us/)[Creators](https://www.youtube.com/creators/)[Advertise](https://www.youtube.com/ads/)[Developers](https://developers.google.com/youtube)[Terms](/t/terms)[Privacy](/t/privacy)[Policy &amp; Safety](https://www.youtube.com/about/policies/)[How YouTube works](https://www.youtube.com/howyoutubeworks?utm_campaign=ytgen&amp;utm_source=ythp&amp;utm_medium=LeftNav&amp;utm_content=txt&amp;u=https%3A%2F%2Fwww.youtube.com%2Fhowyoutubeworks%3Futm_source%3Dythp%26utm_medium%3DLeftNav%26utm_campaign%3Dytgen)[Test new features](/new)[NFL Sunday Ticket](https://tv.youtube.com/learn/nflsundayticket)\n\n© 2026 Google LLC'},
 {'url': 'https://m.10000recipe.com/recipe/list.html?q=%EA%B1%B4%EA%B0%95%EC%8B%9D%EB%8B%A8',
  'title': '건강식단 - 요리를 즐겁게~ 만개의레시피',
  'content': '#### &lt;건강식단&gt;부드러운 순두부달걀탕! #### 소고기무들깨탕~어린이국/건강식단. #### 건강식단~시원하게먹는 머위대들깨국! #### 건강식단 가시오가피순 된장무침! #### 표고버섯콩비지들깨탕~영양식단,건강식단. #### 건강식단/기력회복에 좋은 전복내장죽! #### &lt;건강식단&gt; 꼬시래기볶음! 다이어트 건강 식단 닭가슴살 완자 스테이크. #### &lt;건강식단&gt; 호박잎쌈밥. #### &lt;건강식단&gt; 소고기미역국. #### (건강식단)당근무나물볶음! #### (건강식단/다이어트)토마토 당근주스! #### 가리비들깨미역국~건강식단! #### (다이어트/건강식단) 목이버섯볶음! #### (건강식단)뽀얀국물 제첩국! #### 쑥버무리/ 휴일점심메뉴/건강식단. #### 수비드 닭가슴살 루꼴라 샐러드 산뜻하고 담백한 건강식단! #### 머위대들깨볶음~제철밥상/건강식단. #### 어린이반찬/건강식단 소고기들깨미역국! * 굿스푼 도시락 나물 비빔밥 12팩 맛있는 밥 반찬 건강한 영양 관리 음식 간편 식단. * 굿스푼 도시락 나물 비빔밥 12팩 맛있는 밥 반찬 건강한 영양 관리 음식 간편 식단. * 포르미 포르미 반칙도시락 8종12팩 건강 운동 식단 닭가슴살 간편 냉동 한끼 아침 식사. * 포르미 포르미 반칙도시락 시즌2 8종8팩 건강 운동 식단 간편 냉동 한끼 아침 식사. * 굿스푼 저당 도시락 9종 9팩 간헐적 단식 식단 1일 2식 칼로리 관리 음식 잡곡 곤약밥 건강 반찬 도시락. 일반 회원은 스크랩이 3개까지 가능하며,. 일반 회원은 3개의 폴더만 생성 가능하며,. 엄선된 레시피로 **만개의레시피 영양사가 제공하는 식단**을 이용하실 수 있습니다.',
  'score': 0.37754068,
  'raw_content': '* [정확순](javascript:void(0);)\n* [최신순](javascript:void(0);)\n* [추천순](javascript:void(0);)\n\n#### [&lt;건강식단&gt;부드러운 순두부달걀탕!](/recipe/6925166)\n\nby 왕눈이2\n\n4.9(35) 조회수 7.8만\n\n#### [아이들 건강식단- 청경채두부볶음 레시피](/recipe/6830411)\n\nby 하나미\n\n4.4(8) 조회수 2만\n\n#### [&lt;신혼요리&gt; 얼큰한버섯국끓이기! /초스피드, 건강식단](/recipe/6867870)\n\nby LIFEplus주돌\n\n5(4) 조회수 2만\n\n#### [[참치브로콜리주먹밥] 진짜 쉬운 다이어트도시락,건강식단/ 적은재료로 간단하게](/recipe/6927414)\n\nby 유튜버아뜨\n\n5(5) 조회수 3만\n\n#### [소고기무들깨탕~어린이국/건강식단](/recipe/6949191)\n\nby 왕눈이의맛있는이야기\n\n5(3) 조회수 9,079\n\n#### [건강식단~시원하게먹는 머위대들깨국!](/recipe/6934408)\n\nby 왕눈이의맛있는이야기\n\n4.3(3) 조회수 8,045\n\n#### [건강식단 가시오가피순 된장무침!](/recipe/6910989)\n\nby 왕눈이2\n\n5(1) 조회수 4,956\n\n#### [표고버섯콩비지들깨탕~영양식단,건강식단](/recipe/6975684)\n\nby 왕눈이의맛있는이야기\n\n4(1) 조회수 4,526\n\n#### [아삭 건강한 깍두기 담그는법~](/recipe/6868573)\n\nby 팬이맘\n\n5(361) 조회수 175.2만\n\n#### [건강 가지를 스테이크로 즐겨요.](/recipe/6847506)\n\nby 환갑을꿈꾸는아줌마\n\n4.8(150) 조회수 23.5만\n\n#### [건강식단/기력회복에 좋은 전복내장죽!](/recipe/6925263)\n\nby 왕눈이2\n\n5(1) 조회수 4,830\n\n#### [&lt;건강식단&gt; 꼬시래기볶음!](/recipe/6917879)\n\nby 왕눈이2\n\n조회수 9,676\n\n#### [&lt;신혼요리&gt; 시금치된장국 끓이기! /시금치요리, 맛있는 국끓이기/ 건강식단](/recipe/6867868)\n\nby LIFEplus주돌\n\n5(1) 조회수 6,829\n\n#### [닭가슴살의 변신! 다이어트 건강 식단 닭가슴살 완자 스테이크](/recipe/6963424)\n\nby 쿡앤핏\n\n5(1) 조회수 3,076\n\n#### [&lt;건강식단&gt; 호박잎쌈밥](/recipe/6918093)\n\nby 왕눈이2\n\n조회수 5,691\n\n#### [&lt;건강식단&gt; 소고기미역국](/recipe/6923520)\n\nby 왕눈이2\n\n조회수 3,245\n\n#### [에그인헬 만들기, 중독성 있는 홈브런치요리, 지중해 식단, 건강 식단](/recipe/6970106)\n\nby 평안해의작은부엌\n\n5(1) 조회수 8,329\n\n#### [(건강식단)당근무나물볶음!](/recipe/7039835)\n\nby 왕눈이의맛있는이야기\n\n조회수 737\n\n#### [(건강식단/다이어트)토마토 당근주스!](/recipe/7067888)\n\nby 왕눈이의맛있는이야기\n\n조회수 316\n\n#### [가리비들깨미역국~건강식단!](/recipe/6995647)\n\nby 왕눈이의맛있는이야기\n\n조회수 1,080\n\n#### [초간단/건강식단으로 좋은 양파볶음!](/recipe/6923878)\n\nby 왕눈이2\n\n조회수 2,456\n\n#### [(다이어트/건강식단) 목이버섯볶음!](/recipe/6927401)\n\nby 왕눈이2\n\n조회수 4,337\n\n#### [(건강식단)뽀얀국물 제첩국!](/recipe/6979147)\n\nby 왕눈이의맛있는이야기\n\n조회수 4,062\n\n#### [새해 건강식단 오버나잇 오트밀](/recipe/7018448)\n\nby 뿡씨스터즈\n\n조회수 768\n\n#### [쑥버무리/ 휴일점심메뉴/건강식단](/recipe/6957007)\n\nby 재시리\n\n조회수 854\n\n#### [&lt;건강식단&gt; 지금이 딱이야~ 봄동나물무침!](/recipe/6927110)\n\nby 왕눈이2\n\n조회수 3,795\n\n#### [수비드 닭가슴살 루꼴라 샐러드 산뜻하고 담백한 건강식단!](/recipe/6935829)\n\nby 대상\n\n조회수 1,221\n\n#### [야채찜요리 닭가슴살 야채찜으로 배부르게 건강식단해요.](/recipe/7047187)\n\nby 나래노리Narae\n\n조회수 1,066\n\n#### [머위대들깨볶음~제철밥상/건강식단](/recipe/6960830)\n\nby 왕눈이의맛있는이야기\n\n조회수 2,175\n\n#### [어린이반찬/건강식단 소고기들깨미역국!](/recipe/6932086)\n\nby 왕눈이의맛있는이야기\n\n조회수 2,226\n\n**파워쇼핑광고** [가입신청](https://m.searchad.naver.com/product/shopProduct)\n\n* 굿스푼 도시락 나물 비빔밥 12팩 맛있는 밥 반찬 건강한 영양 관리 음식 간편 식단\n\n  **51,600원**\n\n  미스터네이처\n\n  리뷰1,875\n* 굿스푼 도시락 나물 비빔밥 12팩 맛있는 밥 반찬 건강한 영양 관리 음식 간편 식단\n\n  **51,600원**\n\n  미스터네이처 다이어트\n\n  구매 159 | 리뷰1,200\n* 포르미 포르미 반칙도시락 8종12팩 건강 운동 식단 닭가슴살 간편 냉동 한끼 아침 식사\n\n  **54,000원**\n\n  롯데홈쇼핑\n* 포르미 포르미 반칙도시락 시즌2 8종8팩 건강 운동 식단 간편 냉동 한끼 아침 식사\n\n  **37,600원**\n\n  롯데홈쇼핑\n\n  리뷰4\n* 간단도시락 도시락메뉴 건강식단 직장인냉동도시락 식단도시락\n\n  **43,000원**\n\n  성사마켓\n* 굿스푼 저당 도시락 9종 9팩 간헐적 단식 식단 1일 2식 칼로리 관리 음식 잡곡 곤약밥 건강 반찬 도시락\n\n  **41,900원**\n\n  미스터네이처 다이어트\n\n  구매 274 | 리뷰1,029\n\n#### 프리미엄 서비스\n\n프리미엄 이용권을 구매하시면,   \n**명예의전당**을 자유롭게   \n이용하실 수 있습니다.\n\n#### 프리미엄 서비스\n\n프리미엄 이용권을 구매하시면,   \n**일반 배너 광고를 제거**하실 수 있습니다.   \n(※단, 브랜드쉐프의 상품 광고 제외)\n\n#### 프리미엄 서비스\n\n일반 회원은 스크랩이 3개까지 가능하며,   \n프리미엄 이용권 구매 시   \n**스크랩 폴더는 50개까지 생성** 가능합니다.\n\n#### 프리미엄 서비스\n\n일반 회원은 3개의 폴더만 생성 가능하며,   \n프리미엄 이용권 구매 시 **50개까지 자유롭게   \n생성이 가능**합니다.\n\n#### 프리미엄 서비스\n\n프리미엄 이용권을 구매하시면,   \n엄선된 레시피로 **만개의레시피 영양사가 제공하는 식단**을 이용하실 수 있습니다.\n\n#### 프리미엄 서비스\n\n프리미엄 이용권을 구매하시면,   \n**다년간에 걸쳐 축적된 데이타 기반의   \n추천 알고리즘** 서비스를   \n검색어 입력시에도 받으실 수 있습니다.'},
 {'url': 'https://www.herbalife.com/ko-kr/wellness-resources/articles/heart-healthy-foods',
  'title': '장보기 목록에 추가해야 할, 심장에 좋은 음식&amp;간식 10가지 - Herbalife',
  'content': '심장 건강 식단은 저지방 단백질, 충분한 과일과 채소, 적절한 양의 섬유질, 적당한 양의 설탕, 소금, 포화 지방 등 건강에 좋은 다양한 식품을 섭취하는 식단입니다. 정말',
  'score': 0.25238404,
  'raw_content': None},
 {'url': 'https://www.reddit.com/r/simpleliving/comments/l4gwzj/what_is_the_cheapest_healthiest_diet/?tl=ko',
  'title': '가장 싸고 건강한 식단은 뭐임? : r/simpleliving - Reddit',
  'content': '지중해식 식단. 채소, 과일, 곡물, 콩류, 견과류, 생선, 그리고 적당량의 가금류(고기 먹는 경우)를 강조해. 요거트랑 치즈 같은 발효 유제품을 조금,',
  'score': 0.15405756,
  'raw_content': None},
 {'url': 'https://liverfoundation.org/ko/%EA%B1%B4%EA%B0%95%EA%B3%BC-%EC%9B%B0%EB%B9%99/%EA%B1%B4%EA%B0%95%ED%95%9C-%EC%83%9D%ED%99%9C/%EC%A1%B0%EB%A6%AC%EB%B2%95/',
  'title': '건강한 간 다이어트 레시피: 간에 좋은 음식 - American Liver Foundation',
  'content': '30일간의 간 건강 식단 계획이 담긴 PDF 파일을 여기에서 다운로드할 수 있습니다. 이 웹사이트에 제공된 식사 계획은 일반적인 건강한 식사',
  'score': 0.07864238,
  'raw_content': '![](https://liverfoundation.org/wp-content/uploads/2025/12/ALF50-Full-Lockup.svg)\n\n## 언어 선택\n\n# 30일 간 건강 식단 계획\n\n[**30일간의 간 건강 식단 계획이 담긴 PDF 파일을 여기에서 다운로드할 수 있습니다.**](https://liverfoundation.org/wp-content/uploads/2024/09/30-Day-Meal-Calendar.pdf)\n\n이 웹사이트에 제공된 식사 계획은 일반적인 건강한 식사를 위한 것이며 특정 질병이나 질환을 진단, 치료 또는 치료하도록 설계된 것이 아닙니다. 일반 인구의 전반적인 웰빙을 지원하기 위해 만들어졌습니다. 검토하세요\xa0[식품 안전에 대한 모범 사례 및 중요 정보](https://liverfoundation.org/ko/%EA%B1%B4%EA%B0%95%EA%B3%BC-%EC%9B%B0%EB%B9%99/%EA%B1%B4%EA%B0%95%ED%95%9C-%EC%83%9D%ED%99%9C/%EC%8B%9D%ED%92%88-%EC%95%88%EC%A0%84%EC%97%90-%EB%8C%80%ED%95%9C-%EB%AA%A8%EB%B2%94-%EC%82%AC%EB%A1%80-%EB%B0%8F-%EC%A4%91%EC%9A%94-%EC%A0%95%EB%B3%B4/ "https://liverfoundation.org/health-and-wellness/healthy-lifestyle/best-practices-for-food-safety-and-important-information/")\xa0이러한 요리법과 관련이 있습니다.\n\n![](https://liverfoundation.org/wp-content/uploads/2024/09/MERCK-logo.jpg)\n![](https://liverfoundation.org/wp-content/uploads/2024/09/MFP-App-Logo.jpg)\n![](https://liverfoundation.org/wp-content/uploads/2024/09/Mid-America-Transplant.jpg)\n\n# 기부를\n\n# 이메일 업데이트 받기\n\n![](https://liverfoundation.org/wp-content/uploads/2025/12/ALF50-Short.svg)\n![](https://liverfoundation.org/wp-content/uploads/2023/07/Threads_app_logo-White.svg)\n![](https://liverfoundation.org/wp-content/uploads/2022/06/Charity_Watch-Top_Rated.png)\n![](https://liverfoundation.org/wp-content/uploads/2023/11/Four-Star-Rating-Badge-Full-Color.png)\n![](https://liverfoundation.org/wp-content/uploads/2023/05/AST_Logo_Final_Transparent.png)\n![](https://liverfoundation.org/wp-content/uploads/2022/06/National_Health_Council-Standards-of-Excellence.png)\n![](https://cdn.candid.org/images/nonprofit-profiles/seals/2024/candid-seal-platinum-2024.png)\n![](https://liverfoundation.org/wp-content/uploads/2025/12/Everyday-Health-2025-Trusted-Health-Resource-Badge.png)'},
 {'url': 'https://www.greating.co.kr/careMain',
  'title': '식단관리 - 내 몸을 위한 추천 식단 - 그리팅몰',
  'content': '# 식단관리 - 내 몸을 위한 추천 식단. 건강한 일상을 지키는 가장 쉬운 관리. ## **건강식단**. **건강식단과 함께 구매 시 연속혈당측정기 10% 할인**. ※ 식단 설계 마지막 단계에서 추가하세요. ## 이번 주 메뉴 매일 바뀌는 메뉴를 만나보세요! 필요한 영양 균형을 잡아주는 전문가의 레시피. ## **질환맞춤식단**. **질환맞춤식단과 함께 구매 시 연속혈당측정기 10% 할인**. ※ 식단 설계 마지막 단계에서 추가하세요. ## **그리팅 영양죽**. 따뜻한 죽을 더해 건강한 일상을 회복하세요. ## **챌린지 식단**. 빠르고 확실한 단기 목표가 있다면. ## **식단관리 고객 리뷰**. ## **이벤트**. 그리팅은 다양한 대학병원, 연구기관과 함께. 그리팅 앱을 설치하고 더 간편하게 건강을 챙겨보세요! 그리팅 앱을 설치하고 더 간편하게 건강을 챙겨보세요! 오늘 하루 보지 않기 닫기. 상품 리뷰로 본 **‘추천 키워드’**. *※ 일부 효능/효과 관련 리뷰는 구매자의 주관적인 소견이며 개인별로 상이할 수 있습니다.*. 전체 (0)   내 문의 (0). **상품문의 작성  레이어 팝업 닫기**. 상품에 대한 내용을 판매자에게 문의할 수 있습니다. **추천 키워드 안내  레이어 팝업 닫기**. 실제 구매자들이 해당 제품의 장점으로 꼽은 키워드입니다. TOP3 키워드를 통해 제품의 특징을 더 정확히 전달드려요.',
  'score': 0.045692034,
  'raw_content': "* [로그인](javascript:fnLogin();)\n* [회원가입](/member/join/memberjoin)\n* [쿠폰등록](/myPage/randomCouponRegist)\n* [스크랩](/myPage/myScrap)\n* [고객센터](/serviceCenter/serviceCenterMain) \n  + [공지사항](/serviceCenter/notice)\n  + [자주하는 질문](/serviceCenter/faq)\n  + [1:1 문의](/serviceCenter/myPersonalInquery)\n  + [고객의 소리](/serviceCenter/qna)\n\n[브랜드 직송](javascript:fnMoveHome('market', 1);)\n\n[건강마켓](javascript:fnMoveHome('market', 1);) [식단관리](javascript:fnMoveHome('meals', 1);)\n\n[카테고리](#)\n\n* [건강식단](/planMeals/healthyMeals)\n  + [저속식단](/planMeals/careWellness)\n  + [칼로리식단](/planMeals/careLight)\n  + [저당식단](/planMeals/careLow)\n  + [단백질식단](/planMeals/careHighP)\n  + [마이그리팅](/planMeals/careMyGreating)\n* [질환맞춤식단](/planMeals/planMeals)\n  + [당뇨식단](/planMeals/careDiabetes)\n  + [고혈압식단](/planMeals/careHTension)\n  + [암환자식단](/planMeals/careCancer)\n  + [신장질환식단  \n    (투석환자용)](/planMeals/careKidney)\n  + [신장질환식단  \n    (비투석환자용)](/planMeals/careDisKidney)\n* [챌린지식단](/planMeals/challenge)\n  + [당뇨식단(냉동)](/market/marketDetail?itemId=166994&amp;toggle=meals)\n  + [뷰티핏](/market/marketDetail?itemId=102760&amp;toggle=meals)\n  + [프로틴업](/market/marketDetail?itemId=102759&amp;toggle=meals)\n  + [저당플랜](/market/marketDetail?itemId=150326&amp;toggle=meals)\n  + [저속도시락](/market/marketDetail?itemId=158116&amp;toggle=meals)\n* [라운지](/story/storyMain)\n  + [브랜드 소개](/story/brandStoryMain)\n  + [그리팅 매거진](/story/greatingLife/greatingLifeList)\n  + [그리팅 TV](/story/month/monthStoryList)\n* [서비스](#none)\n  + [이용방법](/story/guideMain)\n  + [배송안내](/spComn/checkAddress)\n  + [모바일 이용권](/main/boardDetail?freeboardId=340)\n  + [제휴 문의/안내](/groupOrder/groupOrderMain)\n  + [공지사항](/serviceCenter/notice)\n  + [고객센터](/serviceCenter/serviceCenterMain)\n\n- [영양진단](https://care.greating.co.kr/?sid=2&amp;inPath=G&amp;careMain=Y)\n- [건강식단](/planMeals/healthyMeals)\n- [질환맞춤식단](/planMeals/planMeals)\n- [챌린지식단](/planMeals/challenge)\n- [이벤트](/event/eventList?targetMenuType=1)\n- [고객후기](/story/reviewMain)\n- [임상/연구](/planMeals/researchList)\n\n\n\n# 식단관리 - 내 몸을 위한 추천 식단\n\n건강한 일상을 지키는 가장 쉬운 관리\n\n## [**건강식단**](/planMeals/healthyMeals)\n\n**건강식단과 함께 구매 시 연속혈당측정기 10% 할인**\n\n※ 식단 설계 마지막 단계에서 추가하세요\n\n## 이번 주 메뉴 매일 바뀌는 메뉴를 만나보세요!\n\n* [건강식단](#)\n* [질환맞춤식단](#)\n\n* [저속식단](#)\n* [칼로리식단](#)\n* [저당식단](#)\n* [단백질식단](#)\n* [마이그리팅](#)\n* [당뇨식단](#)\n* [고혈압식단](#)\n* [암환자식단](#)\n* [신장질환식단(투석환자용)](#)\n* [신장질환식단(비투석환자용)](#)\n\n필요한 영양 균형을 잡아주는 전문가의 레시피\n\n## [**질환맞춤식단**](/planMeals/planMeals)\n\n**질환맞춤식단과 함께 구매 시 연속혈당측정기 10% 할인**\n\n※ 식단 설계 마지막 단계에서 추가하세요\n\n한 세트에 두 팩씩! 지금 체험해보세요\n\n## **그리팅 영양죽**\n\n따뜻한 죽을 더해 건강한 일상을 회복하세요\n\n## [**챌린지 식단**](/planMeals/challenge)\n\n빠르고 확실한 단기 목표가 있다면\n\n#단기관리 #한끼뚝딱\n\n## **식단관리 고객 리뷰**\n\n## [**이벤트**](/event/eventList?targetMenuType=1)\n\n## [**임상/연구**](/planMeals/researchList)\n\n그리팅은 다양한 대학병원, 연구기관과 함께   \n임상 연구를 진행하고 있습니다.   \n\\*이미지 클릭하여 논문 보러 가기\n\n공지사항\n\n[+](/serviceCenter/notice)\n\n앱 설치 안내\n\n앱에서만 제공하는 서비스입니다.   \n그리팅 앱을 설치하고 더 간편하게 건강을 챙겨보세요!\n\n앱 설치 안내\n\n모바일에서만 제공하는 서비스입니다.   \n그리팅 앱을 설치하고 더 간편하게 건강을 챙겨보세요!\n\n[오늘 하루 보지 않기](#) [닫기](#)\n\n [세이프티   \n스코어?](#;)  [상단으로 바로가기](#)\n\n[레이어 팝업 닫기](#)\n\n[옵션선택](#)\n\n총 상품금액  0원\n\n상세보기\n\n[닫기](#)\n\n* [**상품정보**](#)\n* [**상품리뷰** 0](#)\n* [**상품문의** 0](#)\n* [**배송/교환**](#)\n\n상품 리뷰로 본 **‘추천 키워드’**\n\n*※ 일부 효능/효과 관련 리뷰는 구매자의 주관적인 소견이며 개인별로 상이할 수 있습니다.*\n\n등록된 상품리뷰가 없습니다.\n\n전체 (0)   내 문의 (0)\n\n* **배송안내**\n\n**상품문의 작성  [레이어 팝업 닫기](#)** \n\n상품에 대한 내용을 판매자에게 문의할 수 있습니다.\n\n**추천 키워드 안내  [레이어 팝업 닫기](#)** \n\n실제 구매자들이 해당 제품의 장점으로 꼽은 키워드입니다. TOP3 키워드를 통해 제품의 특징을 더 정확히 전달드려요.\n\n[레이어 팝업 닫기](#)\n\n상세보기\n\n[닫기](#)\n\n상세보기\n\n[닫기](#)\n\n "},
 {'url': 'https://m.health.chosun.com/svc/news_view.html?contid=2025092602727',
  'title': "치킨·떡볶이 안 끊고도, '건강 식단' 챙기는 법… 8대 2 법칙, 뭘까?",
  'content': '실제로 건강식 80%, 먹고 싶은 음식 20%로 식단을 구성한 사람들과 건강식 100%로 식단을 구성한 사람들을 3개월 후 비교한 결과, 전자에서는 식단 포기율이 16.67%였지만, 후자에서는 58.8%였다는 연구 결과가 있다. 나머지 80%를 어떻게 건강식으로 채울지 잘 모르겠다면, 지중해식 시간을 따라 해보는 게 좋다. 지중해식 식단은 비타민을 비롯한 항산화 물질이 풍부해 노쇠 예방에 이롭다. 바쁜 일상을 살다 보면 지중해식 식단을 철저히 지키기가 어려울 수 있다. 하버드대 의과대학 연구팀이 노쇠가 시작되지 않은 33~86세 성인 2384명을 대상으로 평소 식단이 지중해식 식단에 얼마나 가까운지 조사해 점수화한 후, 노쇠 발생 가능성을 예측했다. 그 결과 지중해식 식단에 가까운 정도가 1점 높아질 때마다 노쇠 가능성이 3%씩 낮아지는 게 확인됐다. 이에 연구팀은 60세 미만일 때부터 지중해식 식단을 실천하려고 노력하는 것이 노쇠를 막는 데 도움이 된다는 결론을 내렸다. 지중해식 식단에서 섭취하는 항산화 물질이 스트레스에 의한 체내 조직 손상을 방지하는 덕분이다. 지중해식 식단은 몸속 염증을 조절하는데도 도움을 준다. 염증을 제거하는 데 도움이 되는 식품은 토마토, 올리브유, 녹색잎 채소, 견과류, 등푸른생선, 신선한 과일 등이었다. 지중해식 식단만 잘 따라도 이들 식품을 골고루 먹을 수 있다.',
  'score': 0.04115289,
  'raw_content': '## 글자크기\n\n다이어트\n\n# 치킨·떡볶이 안 끊고도, ‘건강 식단’ 챙기는 법… 8대 2 법칙, 뭘까?\n\n이해림 기자\n\n입력 2025/09/28 08:11\n\n건강을 관리하려고 마음먹었다면 식단부터 바꿔야 한다. 몸에 좋지 않은 음식을 바로 끊기 어렵다면, 절충안이 있다.   \n  \n영국 공인 영양사 프란체스카 랜캐스터는 “일일 권장 섭취 열량의 80%는 건강식 위주로 먹고, 20%는 좋아하는 음식들로 채워도 양질의 식단을 유지할 수 있다”고 말했다. 실제로 건강식 80%, 먹고 싶은 음식 20%로 식단을 구성한 사람들과 건강식 100%로 식단을 구성한 사람들을 3개월 후 비교한 결과, 전자에서는 식단 포기율이 16.67%였지만, 후자에서는 58.8%였다는 연구 결과가 있다.  \n  \n나머지 80%를 어떻게 건강식으로 채울지 잘 모르겠다면, 지중해식 시간을 따라 해보는 게 좋다. 지중해식 식단은 비타민을 비롯한 항산화 물질이 풍부해 노쇠 예방에 이롭다. 포화지방이 적고 식이섬유는 풍부한 과일, 채소, 곡물, 견과류 등을 주식으로 한다. 생선과 해산물은 주 2회 이상, 가금류와 달걀은 주 3회 이하, 채소는 매일 먹으면 된다. 지방은 버터나 마가린 대신 카놀라유와 올리브유로 섭취한다.   \n  \n  \n바쁜 일상을 살다 보면 지중해식 식단을 철저히 지키기가 어려울 수 있다. 이럴 땐 최대한 비슷하게 챙겨 먹으려고 노력하는 것만으로도 건강에 보탬이 된다. 하버드대 의과대학 연구팀이 노쇠가 시작되지 않은 33~86세 성인 2384명을 대상으로 평소 식단이 지중해식 식단에 얼마나 가까운지 조사해 점수화한 후, 노쇠 발생 가능성을 예측했다. 그 결과 지중해식 식단에 가까운 정도가 1점 높아질 때마다 노쇠 가능성이 3%씩 낮아지는 게 확인됐다. 이에 연구팀은 60세 미만일 때부터 지중해식 식단을 실천하려고 노력하는 것이 노쇠를 막는 데 도움이 된다는 결론을 내렸다. 지중해식 식단에서 섭취하는 항산화 물질이 스트레스에 의한 체내 조직 손상을 방지하는 덕분이다.  \n  \n지중해식 식단은 몸속 염증을 조절하는데도 도움을 준다. 염증이 만성화되면 돌연변이 세포의 발생이 잦아져, 암세포가 생길 확률도 높아진다. 실제로 항염 식단이 조기 사망 위험을 18% 줄이고, 심혈관질환에 의한 사망 위험을 20% 줄였다는 스웨덴 카롤린스카대 연구 결과가 있다. 염증을 제거하는 데 도움이 되는 식품은 토마토, 올리브유, 녹색잎 채소, 견과류, 등푸른생선, 신선한 과일 등이었다. 지중해식 식단만 잘 따라도 이들 식품을 골고루 먹을 수 있다.\n\n## 관련기사\n\n* [*·*\n\n  “주말도 빼놓지 않아” 다이어트 유지어터 박세미… 열중한 ‘두 가지’ 운동은?](/svc/news_view.html?contid=2025092602949)\n* [*·*\n\n  “너무 말랐네” 45kg 감량 최준희, 개미 허리 인증… 건강엔 괜찮을까?](/svc/news_view.html?contid=2025092602834)\n* [*·*\n\n  “체중 왜 안 빠지지”… 걱정 마세요, ‘이 방법’ 쓰면 날씬해져요](/svc/news_view.html?contid=2025092602743)\n\n '}]</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=41b462c4">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<br/>
<h3 id="Image-%EC%83%9D%EC%84%B1-%EB%8F%84%EA%B5%AC-(DALL-E)">Image 생성 도구 (DALL-E)<a class="anchor-link" href="#Image-%EC%83%9D%EC%84%B1-%EB%8F%84%EA%B5%AC-(DALL-E)">¶</a></h3><ul>
<li><code>DallEAPIWrapper</code> : OpenAI의 DALL-E 이미지 생성기를 위한 래퍼(wrapper)</li>
<li>DALL-E API를 쉽게 통합하여 텍스트 기반 이미지 생성 기능을 구현 가능</li>
</ul>
<br/>
<h4 id="%EC%A3%BC%EC%9A%94-%EC%86%8D%EC%84%B1">주요 속성<a class="anchor-link" href="#%EC%A3%BC%EC%9A%94-%EC%86%8D%EC%84%B1">¶</a></h4><ul>
<li><code>model</code>: 사용할 DALL-E 모델 이름 (기본값: "dall-e-2", "dall-e-3")</li>
<li><code>n</code>: 생성할 이미지 수 (기본값: 1)</li>
<li><code>size</code>: 생성할 이미지 크기<ul>
<li><code>"dall-e-2"</code>: "1024x1024", "512x512", "256x256"</li>
<li><code>"dall-e-3"</code>: "1024x1024", "1792x1024", "1024x1792"</li>
</ul>
</li>
<li><code>style</code>: 생성될 이미지의 스타일 (기본값: <code>"natural"</code>, <code>"vivid"</code>)</li>
<li><code>quality</code>: 생성될 이미지의 품질 (기본값: <code>"standard"</code>, <code>"hd"</code>)</li>
<li><code>max_retries</code>: 생성 시 최대 재시도 횟수</li>
</ul>
<br/>
<h4 id="%EC%A3%BC%EC%9A%94-%EA%B8%B0%EB%8A%A5">주요 기능<a class="anchor-link" href="#%EC%A3%BC%EC%9A%94-%EA%B8%B0%EB%8A%A5">¶</a></h4><ul>
<li>DALL-E API를 사용하여 텍스트 설명에 기반한 이미지 생성</li>
</ul>
<br/>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=4c4707f3">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [15]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">langchain_core.output_parsers</span><span class="w"> </span><span class="kn">import</span> <span class="n">StrOutputParser</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_core.prompts</span><span class="w"> </span><span class="kn">import</span> <span class="n">PromptTemplate</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_openai</span><span class="w"> </span><span class="kn">import</span> <span class="n">ChatOpenAI</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=bb01a02b">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [16]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">llm</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">"gpt-4o-mini"</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">max_tokens</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=8cd2867a">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<ul>
<li>DALL-E 이미지 생성을 위한 프롬프트 템플릿 정의</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=9c8517c7">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [17]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">prompt</span> <span class="o">=</span> <span class="n">PromptTemplate</span><span class="o">.</span><span class="n">from_template</span><span class="p">(</span>
    <span class="s2">"Generate a detailed IMAGE GENERATION prompt for DALL-E based on the following description. "</span>
    <span class="s2">"Return only the prompt, no intro, no explanation, no chatty, no markdown, no code block, no nothing. Just the prompt"</span>
    <span class="s2">"Output should be less than 1000 characters. Write in English only."</span>
    <span class="s2">"Image Description: </span><span class="se">\n</span><span class="si">{image_desc}</span><span class="s2">"</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=d558434d">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [18]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">chain</span> <span class="o">=</span> <span class="n">prompt</span> <span class="o">|</span> <span class="n">llm</span> <span class="o">|</span> <span class="n">StrOutputParser</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=0a3c3b74">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [19]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">image_prompt</span> <span class="o">=</span> <span class="n">chain</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span>
    <span class="p">{</span><span class="s2">"image_desc"</span><span class="p">:</span> <span class="s2">"스마트폰을 바라보는 사람들을 풍자한 neo-classicism painting"</span><span class="p">}</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=5b1a18eb">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [20]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">image_prompt</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>A neo-classical painting depicting a group of people gathered in a grand, elegantly designed room, each absorbed in their smartphones, contrasting classical beauty with modern technology. The figures, dressed in luxurious 18th-century attire, reflect a range of emotions from joy to frustration as they interact with their devices. The background features ornate columns, intricate frescoes on the ceiling, and marble sculptures that symbolize historical intellect and artistry. Soft, diffused lighting illuminates their faces, highlighting the juxtaposition of timeless elegance with contemporary distractions. The scene captures a satirical commentary on modern society's obsession with technology, blending traditional art techniques with a humorous modern twist. Ensure the colors are rich and vibrant, emphasizing both the historical elements and the stark presence of the smartphones.
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=3ab36656">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<br/>
<ul>
<li>이미지 프롬프트를 <code>DallEAPIWrapper</code>에 입력하여 이미지를 생성</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=69e3e4e0">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [21]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">langchain_community.utilities.dalle_image_generator</span><span class="w"> </span><span class="kn">import</span> <span class="n">DallEAPIWrapper</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">IPython.display</span><span class="w"> </span><span class="kn">import</span> <span class="n">Image</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=8fb5fda4">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [22]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">dalle</span> <span class="o">=</span> <span class="n">DallEAPIWrapper</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">"dall-e-3"</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="s2">"1024x1024"</span><span class="p">,</span> <span class="n">quality</span><span class="o">=</span><span class="s2">"standard"</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=4cf7aecb">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [23]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">query</span> <span class="o">=</span> <span class="s2">"스마트폰을 바라보는 사람들을 풍자한 neo-classicism painting"</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=c0826002">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [24]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">image_url</span> <span class="o">=</span> <span class="n">dalle</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">chain</span><span class="o">.</span><span class="n">invoke</span><span class="p">({</span><span class="s2">"image_desc"</span><span class="p">:</span> <span class="n">query</span><span class="p">}))</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=7baa4094">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [25]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">Image</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">image_url</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[25]:</div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/html" tabindex="0">
<img alt="No description has been provided for this image" src="https://oaidalleapiprodscus.blob.core.windows.net/private/org-9m3vHlDcWHG7CCHmQYpFuo6G/user-lhD0FkyBMxZO4eRQM4zu9I89/img-TrUeHcWe0nxA7Ung3GfB5o8o.png?st=2026-02-20T05%3A45%3A23Z&amp;se=2026-02-20T07%3A45%3A23Z&amp;sp=r&amp;sv=2026-02-06&amp;sr=b&amp;rscd=inline&amp;rsct=image/png&amp;skoid=8eb2c87c-0531-4dab-acb3-b5e2adddce6c&amp;sktid=a48cca56-e6da-484e-a814-9c849652bcb3&amp;skt=2026-02-20T06%3A13%3A34Z&amp;ske=2026-02-21T06%3A13%3A34Z&amp;sks=b&amp;skv=2026-02-06&amp;sig=DA7E4nrj33FTtz3tA2QyPy8weWLU%2B74pIooQE598tpo%3D" width="500"/>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=baea60f0">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<br/>
<h3 id="%EC%82%AC%EC%9A%A9%EC%9E%90-%EC%A0%95%EC%9D%98-%EB%8F%84%EA%B5%AC-(Custom-Tool)">사용자 정의 도구 (Custom Tool)<a class="anchor-link" href="#%EC%82%AC%EC%9A%A9%EC%9E%90-%EC%A0%95%EC%9D%98-%EB%8F%84%EA%B5%AC-(Custom-Tool)">¶</a></h3><ul>
<li>LangChain 에서 제공하는 빌트인 도구 외에도 사용자가 직접 도구를 정의하여 사용 가능</li>
<li><code>langchain.tools</code> 모듈에서 제공하는 <code>tool</code> 데코레이터를 사용하여 함수를 도구로 변환</li>
</ul>
<br/>
<h4 id="@tool-%EB%8D%B0%EC%BD%94%EB%A0%88%EC%9D%B4%ED%84%B0"><code>@tool</code> 데코레이터<a class="anchor-link" href="#@tool-%EB%8D%B0%EC%BD%94%EB%A0%88%EC%9D%B4%ED%84%B0">¶</a></h4><ul>
<li>함수를 도구로 변환하는 기능을 제공</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=02ee7b2d">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [26]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">langchain.tools</span><span class="w"> </span><span class="kn">import</span> <span class="n">tool</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=11e3004a">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [31]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="nd">@tool</span>
<span class="k">def</span><span class="w"> </span><span class="nf">add_numbers</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Add two numbers"""</span>
    <span class="k">return</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span>

<span class="n">add_numbers</span><span class="o">.</span><span class="n">invoke</span><span class="p">({</span><span class="s2">"a"</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="s2">"b"</span><span class="p">:</span> <span class="mi">4</span><span class="p">})</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[31]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>7</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=fdb2a8bf">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [30]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="nd">@tool</span>
<span class="k">def</span><span class="w"> </span><span class="nf">multiply_numbers</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Multiply two numbers"""</span>
    <span class="k">return</span> <span class="n">a</span> <span class="o">*</span> <span class="n">b</span>

<span class="n">multiply_numbers</span><span class="o">.</span><span class="n">invoke</span><span class="p">({</span><span class="s2">"a"</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="s2">"b"</span><span class="p">:</span> <span class="mi">4</span><span class="p">})</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[30]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>12</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=540e8133">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<br/>
<hr/>
</div>
</div>
</div>
</div>
</main>
</body>
</html>

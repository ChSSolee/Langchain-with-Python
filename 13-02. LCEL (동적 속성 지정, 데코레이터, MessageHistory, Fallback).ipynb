{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "065794fe",
   "metadata": {},
   "source": [
    "## ë™ì  ì†ì„± ì§€ì •(`configurable_fields`, `configurable_alternatives`)\n",
    "\n",
    "<br>\n",
    "\n",
    "### ëŸ°íƒ€ì„ì— ì²´ì¸ ë‚´ë¶€ êµ¬ì„±\n",
    "1. `configurable_fields` ë©”ì„œë“œì…ë‹ˆë‹¤. ì´ ë©”ì„œë“œë¥¼ í†µí•´ ì‹¤í–‰ ê°€ëŠ¥í•œ ê°ì²´ì˜ íŠ¹ì • í•„ë“œë¥¼ êµ¬ì„±\n",
    "2. `configurable_alternatives` ë©”ì„œë“œì…ë‹ˆë‹¤. ì´ ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ë©´ ëŸ°íƒ€ì„ ì¤‘ì— ì„¤ì •í•  ìˆ˜ ìˆëŠ” íŠ¹ì • ì‹¤í–‰ ê°€ëŠ¥í•œ ê°ì²´ì— ëŒ€í•œ ëŒ€ì•ˆì„ ë‚˜ì—´\n",
    "\n",
    "<br>\n",
    "\n",
    "### `configurable_fields`\n",
    "- ì‹œìŠ¤í…œì˜ ì„¤ì • ê°’ì„ ì •ì˜í•˜ëŠ” í•„ë“œ\n",
    "\n",
    "<br>\n",
    "\n",
    "### ë™ì  ì†ì„± ì§€ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e26dce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a0f2ee",
   "metadata": {},
   "source": [
    "- `configurable_fields` ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ `model_name` ì†ì„±ì„ ë™ì  êµ¬ì„± ê°€ëŠ¥í•œ í•„ë“œë¡œ ì§€ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47280051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸ì…ë‹ˆë‹¤.',\n",
       " 'additional_kwargs': {'refusal': None},\n",
       " 'response_metadata': {'token_usage': {'completion_tokens': 8,\n",
       "   'prompt_tokens': 15,\n",
       "   'total_tokens': 23,\n",
       "   'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "    'audio_tokens': 0,\n",
       "    'reasoning_tokens': 0,\n",
       "    'rejected_prediction_tokens': 0},\n",
       "   'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       "  'model_provider': 'openai',\n",
       "  'model_name': 'gpt-4o-2024-08-06',\n",
       "  'system_fingerprint': 'fp_fa7f5b168b',\n",
       "  'id': 'chatcmpl-D4eJUCpVv2RV3fNixqlLOZsEi0QID',\n",
       "  'service_tier': 'default',\n",
       "  'finish_reason': 'stop',\n",
       "  'logprobs': None},\n",
       " 'type': 'ai',\n",
       " 'name': None,\n",
       " 'id': 'lc_run--019c1c42-872c-74a3-aeb6-8114ece9d2e6-0',\n",
       " 'tool_calls': [],\n",
       " 'invalid_tool_calls': [],\n",
       " 'usage_metadata': {'input_tokens': 15,\n",
       "  'output_tokens': 8,\n",
       "  'total_tokens': 23,\n",
       "  'input_token_details': {'audio': 0, 'cache_read': 0},\n",
       "  'output_token_details': {'audio': 0, 'reasoning': 0}}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_classic.prompts import PromptTemplate\n",
    "from langchain_core.runnables import ConfigurableField\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
    "\n",
    "model.invoke(\"ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì•¼?\").__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec80cf5",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- `model.invoke()` í˜¸ì¶œì‹œ `config={\"configurable\": {\"í‚¤\": \"ê°’\"}}` í˜•ì‹ìœ¼ë¡œ ë™ì  ì§€ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c68c299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸ì…ë‹ˆë‹¤.',\n",
       " 'additional_kwargs': {'refusal': None},\n",
       " 'response_metadata': {'token_usage': {'completion_tokens': 8,\n",
       "   'prompt_tokens': 15,\n",
       "   'total_tokens': 23,\n",
       "   'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "    'audio_tokens': 0,\n",
       "    'reasoning_tokens': 0,\n",
       "    'rejected_prediction_tokens': 0},\n",
       "   'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       "  'model_provider': 'openai',\n",
       "  'model_name': 'gpt-4o-2024-08-06',\n",
       "  'system_fingerprint': 'fp_fa7f5b168b',\n",
       "  'id': 'chatcmpl-D4eJWCtx7sW43j9LwwDOu4sDAaZW4',\n",
       "  'service_tier': 'default',\n",
       "  'finish_reason': 'stop',\n",
       "  'logprobs': None},\n",
       " 'type': 'ai',\n",
       " 'name': None,\n",
       " 'id': 'lc_run--019c1c42-8dba-7c33-b03a-13b55aa9935f-0',\n",
       " 'tool_calls': [],\n",
       " 'invalid_tool_calls': [],\n",
       " 'usage_metadata': {'input_tokens': 15,\n",
       "  'output_tokens': 8,\n",
       "  'total_tokens': 23,\n",
       "  'input_token_details': {'audio': 0, 'cache_read': 0},\n",
       "  'output_token_details': {'audio': 0, 'reasoning': 0}}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\n",
    "    \"ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì•¼?\",\n",
    "    config={\"configurable\": {\"gpt_version\": \"gpt-3.5-turbo\"}},\n",
    ").__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78309b87",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- `model` ê°ì²´ì˜ `with_config()` ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ `configurable` ë§¤ê°œë³€ìˆ˜ë¥¼ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e00e806d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸ì…ë‹ˆë‹¤.',\n",
       " 'additional_kwargs': {'refusal': None},\n",
       " 'response_metadata': {'token_usage': {'completion_tokens': 8,\n",
       "   'prompt_tokens': 15,\n",
       "   'total_tokens': 23,\n",
       "   'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "    'audio_tokens': 0,\n",
       "    'reasoning_tokens': 0,\n",
       "    'rejected_prediction_tokens': 0},\n",
       "   'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       "  'model_provider': 'openai',\n",
       "  'model_name': 'gpt-4o-2024-08-06',\n",
       "  'system_fingerprint': 'fp_fa7f5b168b',\n",
       "  'id': 'chatcmpl-D4eJWVpnU06rf8TsCcY60QtcpJJIU',\n",
       "  'service_tier': 'default',\n",
       "  'finish_reason': 'stop',\n",
       "  'logprobs': None},\n",
       " 'type': 'ai',\n",
       " 'name': None,\n",
       " 'id': 'lc_run--019c1c42-930e-7473-b952-651b04abc258-0',\n",
       " 'tool_calls': [],\n",
       " 'invalid_tool_calls': [],\n",
       " 'usage_metadata': {'input_tokens': 15,\n",
       "  'output_tokens': 8,\n",
       "  'total_tokens': 23,\n",
       "  'input_token_details': {'audio': 0, 'cache_read': 0},\n",
       "  'output_token_details': {'audio': 0, 'reasoning': 0}}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.with_config(configurable={\"gpt_version\": \"gpt-4o-mini\"}).invoke(\n",
    "    \"ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì•¼?\"\n",
    ").__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c09577c",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- í•¨ìˆ˜ë¥¼ ì²´ì¸ì˜ ì¼ë¶€ë¡œ ì‚¬ìš©í•  ë•Œì—ë„ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ í™œìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "819b4f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(\"{x} ë³´ë‹¤ í° ìœ„ì˜ ë‚œìˆ˜ë¥¼ ìƒì„±\")\n",
    "chain = (\n",
    "    prompt | model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f7f9ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': '0ë³´ë‹¤ í° ë‚œìˆ˜ë¥¼ ìƒì„±í•˜ë ¤ë©´ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì— ë”°ë¼ ë‹¤ì–‘í•œ ë°©ë²•ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, Pythonì—ì„œëŠ” `random` ëª¨ë“ˆì„ ì‚¬ìš©í•˜ì—¬ ë‚œìˆ˜ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‹¤ìŒì€ 0ë³´ë‹¤ í° ë‚œìˆ˜ë¥¼ ìƒì„±í•˜ëŠ” ê°„ë‹¨í•œ ì˜ˆì œì…ë‹ˆë‹¤.\\n\\n```python\\nimport random\\n\\n# 0ë³´ë‹¤ í° ë‚œìˆ˜ë¥¼ ìƒì„±\\nrandom_number = random.uniform(0.0001, 1.0)\\nprint(random_number)\\n```\\n\\nì´ ì½”ë“œëŠ” 0.0001ê³¼ 1.0 ì‚¬ì´ì˜ ì‹¤ìˆ˜ ë‚œìˆ˜ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. `random.uniform(a, b)` í•¨ìˆ˜ëŠ” aì™€ b ì‚¬ì´ì˜ ì‹¤ìˆ˜ ë‚œìˆ˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. 0ë³´ë‹¤ í° ì •ìˆ˜ë¥¼ ì›í•œë‹¤ë©´ `random.randint(a, b)` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n\\n```python\\nimport random\\n\\n# 0ë³´ë‹¤ í° ì •ìˆ˜ ë‚œìˆ˜ë¥¼ ìƒì„±\\nrandom_integer = random.randint(1, 100)\\nprint(random_integer)\\n```\\n\\nì´ ì½”ë“œëŠ” 1ê³¼ 100 ì‚¬ì´ì˜ ì •ìˆ˜ ë‚œìˆ˜ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ì›í•˜ëŠ” ë²”ìœ„ì— ë§ê²Œ ìˆ«ìë¥¼ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.',\n",
       " 'additional_kwargs': {'refusal': None},\n",
       " 'response_metadata': {'token_usage': {'completion_tokens': 228,\n",
       "   'prompt_tokens': 15,\n",
       "   'total_tokens': 243,\n",
       "   'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "    'audio_tokens': 0,\n",
       "    'reasoning_tokens': 0,\n",
       "    'rejected_prediction_tokens': 0},\n",
       "   'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       "  'model_provider': 'openai',\n",
       "  'model_name': 'gpt-4o-2024-08-06',\n",
       "  'system_fingerprint': 'fp_fa7f5b168b',\n",
       "  'id': 'chatcmpl-D4eJYBRGWZ71cT0ZMKKM7CAn01qL5',\n",
       "  'service_tier': 'default',\n",
       "  'finish_reason': 'stop',\n",
       "  'logprobs': None},\n",
       " 'type': 'ai',\n",
       " 'name': None,\n",
       " 'id': 'lc_run--019c1c42-9695-71c2-a35a-5e980ee1865e-0',\n",
       " 'tool_calls': [],\n",
       " 'invalid_tool_calls': [],\n",
       " 'usage_metadata': {'input_tokens': 15,\n",
       "  'output_tokens': 228,\n",
       "  'total_tokens': 243,\n",
       "  'input_token_details': {'audio': 0, 'cache_read': 0},\n",
       "  'output_token_details': {'audio': 0, 'reasoning': 0}}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.with_config(configurable={\"gpt_version\": \"gpt-4o\"}).invoke({\"x\": 0}).__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad03fc81",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### `HubRunnable`: LangChain Hubì˜ ì„¤ì • ë³€ê²½\n",
    "- `HubRunnable` ì„ ì‚¬ìš©í•˜ë©´ Hub ì— ë“±ë¡ëœ í”„ë¡¬í”„íŠ¸ì˜ ì „í™˜ì„ ìš©ì´\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d598373c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic.runnables.hub import HubRunnable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2afa66e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = HubRunnable(\"teddynote/rag-prompt-korean\").configurable_fields(\n",
    "    # ì†Œìœ ì ì €ì¥ì†Œ ì»¤ë°‹ì„ ì„¤ì •í•˜ëŠ” ConfigurableField\n",
    "    \n",
    "    owner_repo_commit=ConfigurableField(\n",
    "    \n",
    "        # í•„ë“œì˜ ID\n",
    "        id=\"hub_commit\",\n",
    "    \n",
    "        # í•„ë“œì˜ ì´ë¦„\n",
    "        name=\"Hub Commit\",\n",
    "    \n",
    "        # í•„ë“œì— ëŒ€í•œ ì„¤ëª…\n",
    "        description=\"Korean RAG prompt by teddynote\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b9c788a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableConfigurableFields(default=HubRunnable(bound=ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': 'teddynote', 'lc_hub_repo': 'rag-prompt-korean', 'lc_hub_commit_hash': '4214de29c72c82d13121c710b0ee7021d31ad088f0eb1d6ddebcaaeab46b1f8b'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template=\"ë‹¹ì‹ ì€ ì§ˆë¬¸-ë‹µë³€(Question-Answering)ì„ ìˆ˜í–‰í•˜ëŠ” ì¹œì ˆí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ì£¼ì–´ì§„ ë¬¸ë§¥(context) ì—ì„œ ì£¼ì–´ì§„ ì§ˆë¬¸(question) ì— ë‹µí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.\\nê²€ìƒ‰ëœ ë‹¤ìŒ ë¬¸ë§¥(context) ì„ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸(question) ì— ë‹µí•˜ì„¸ìš”. ë§Œì•½, ì£¼ì–´ì§„ ë¬¸ë§¥(context) ì—ì„œ ë‹µì„ ì°¾ì„ ìˆ˜ ì—†ë‹¤ë©´, ë‹µì„ ëª¨ë¥¸ë‹¤ë©´ `ì£¼ì–´ì§„ ì •ë³´ì—ì„œ ì§ˆë¬¸ì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤` ë¼ê³  ë‹µí•˜ì„¸ìš”.\\ní•œê¸€ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”. ë‹¨, ê¸°ìˆ ì ì¸ ìš©ì–´ë‚˜ ì´ë¦„ì€ ë²ˆì—­í•˜ì§€ ì•Šê³  ê·¸ëŒ€ë¡œ ì‚¬ìš©í•´ ì£¼ì„¸ìš”. Don't narrate the answer, just answer the question. Let's think step-by-step.\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='#Question: \\n{question} \\n\\n#Context: \\n{context} \\n\\n#Answer:'), additional_kwargs={})]), kwargs={}, config={}, config_factories=[], owner_repo_commit='teddynote/rag-prompt-korean'), fields={'owner_repo_commit': ConfigurableField(id='hub_commit', name='Hub Commit', description='Korean RAG prompt by teddynote', annotation=None, is_shared=False)})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94453feb",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- `with_config` ì§€ì • ì—†ì´ `prompt.invoke()` ë©”ì„œë“œë¥¼ í˜¸ì¶œí•˜ë©´ ì²˜ìŒ ì„¤ì •í•œ `\"rlm/rag-prompt\"` hub ì— ë“±ë¡ëœ í”„ë¡¬í”„íŠ¸ë¥¼ `pull` í•˜ì—¬ ê°€ì ¸ì˜´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "142b41f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"ë‹¹ì‹ ì€ ì§ˆë¬¸-ë‹µë³€(Question-Answering)ì„ ìˆ˜í–‰í•˜ëŠ” ì¹œì ˆí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ì£¼ì–´ì§„ ë¬¸ë§¥(context) ì—ì„œ ì£¼ì–´ì§„ ì§ˆë¬¸(question) ì— ë‹µí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.\\nê²€ìƒ‰ëœ ë‹¤ìŒ ë¬¸ë§¥(context) ì„ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸(question) ì— ë‹µí•˜ì„¸ìš”. ë§Œì•½, ì£¼ì–´ì§„ ë¬¸ë§¥(context) ì—ì„œ ë‹µì„ ì°¾ì„ ìˆ˜ ì—†ë‹¤ë©´, ë‹µì„ ëª¨ë¥¸ë‹¤ë©´ `ì£¼ì–´ì§„ ì •ë³´ì—ì„œ ì§ˆë¬¸ì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤` ë¼ê³  ë‹µí•˜ì„¸ìš”.\\ní•œê¸€ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”. ë‹¨, ê¸°ìˆ ì ì¸ ìš©ì–´ë‚˜ ì´ë¦„ì€ ë²ˆì—­í•˜ì§€ ì•Šê³  ê·¸ëŒ€ë¡œ ì‚¬ìš©í•´ ì£¼ì„¸ìš”. Don't narrate the answer, just answer the question. Let's think step-by-step.\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='#Question: \\nHello \\n\\n#Context: \\nWorld \\n\\n#Answer:', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.invoke({\"question\": \"Hello\", \"context\": \"World\"}).messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40d64b84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[HumanMessage(content='ì£¼ì–´ì§„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ë¬¸ì¥ì„ ìš”ì•½í•˜ì„¸ìš”. ë‹µë³€ì€ ë°˜ë“œì‹œ í•œê¸€ë¡œ ì‘ì„±í•˜ì„¸ìš”\\n\\nCONTEXT: Hello\\n\\nSUMMARY:', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.with_config(\n",
    "    configurable={\"hub_commit\": \"teddynote/simple-summary-korean\"}\n",
    ").invoke({\"context\": \"Hello\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df174df9",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Configurable Alternatives: Runnable ê°ì²´ ìì²´ì˜ ëŒ€ì•ˆ ì„¤ì •\n",
    "- ëŸ°íƒ€ì„ì— ì„¤ì •í•  ìˆ˜ ìˆëŠ” `Runnable`ì— ëŒ€í•œ ëŒ€ì•ˆ êµ¬ì„±\n",
    "\n",
    "<br>\n",
    "\n",
    "#### LLMê°ì²´ì˜ ëŒ€ì•ˆ ì„¤ì •\n",
    "- ì˜ˆ) `ChatAnthropic`ì˜ ëŒ€ì•ˆ ì„¤ì •\n",
    "\n",
    "\n",
    "```python\n",
    "# import os\n",
    "\n",
    "# os.environ[\"ANTHROPIC_API_KEY\"] = \"ANTHROPIC API KEYë¥¼ ì…ë ¥í•©ë‹ˆë‹¤.\"\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.runnables import ConfigurableField\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatAnthropic(\n",
    "    temperature=0, model=\"claude-3-5-sonnet-20240620\"\n",
    ").configurable_alternatives(\n",
    "    # ì´ í•„ë“œì— idë¥¼ ë¶€ì—¬í•©ë‹ˆë‹¤.\n",
    "    # ìµœì¢… ì‹¤í–‰ ê°€ëŠ¥í•œ ê°ì²´ë¥¼ êµ¬ì„±í•  ë•Œ, ì´ idë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ í•„ë“œë¥¼ êµ¬ì„±\n",
    "\n",
    "    ConfigurableField(id=\"llm\"),\n",
    "    # ê¸°ë³¸ í‚¤ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "    # ì´ í‚¤ë¥¼ ì§€ì •í•˜ë©´ ìœ„ì—ì„œ ì´ˆê¸°í™”ëœ ê¸°ë³¸ LLM(ChatAnthropic)ì´ ì‚¬ìš©\n",
    "\n",
    "    default_key=\"anthropic\",\n",
    "    # 'openai'ë¼ëŠ” ì´ë¦„ì˜ ìƒˆ ì˜µì…˜ì„ ì¶”ê°€í•˜ë©°, ì´ëŠ” `ChatOpenAI()`ì™€ ë™ì¼\n",
    "\n",
    "    openai=ChatOpenAI(model=\"gpt-4o-mini\"),\n",
    "    # 'gpt4'ë¼ëŠ” ì´ë¦„ì˜ ìƒˆ ì˜µì…˜ì„ ì¶”ê°€í•˜ë©°, ì´ëŠ” `ChatOpenAI(model=\"gpt-4\")`ì™€ ë™ì¼\n",
    "\n",
    "    gpt4o=ChatOpenAI(model=\"gpt-4o\"),\n",
    "    # ì—¬ê¸°ì— ë” ë§ì€ êµ¬ì„± ì˜µì…˜ì„ ì¶”ê°€\n",
    ")\n",
    "prompt = PromptTemplate.from_template(\"{topic} ì— ëŒ€í•´ ê°„ë‹¨íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.\")\n",
    "chain = prompt | llm\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "- Anthropicì„ ê¸°ë³¸ìœ¼ë¡œ í˜¸ì¶œ\n",
    "\n",
    "```python\n",
    "chain.invoke({\"topic\": \"ë‰´ì§„ìŠ¤\"}).__dict__\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "- `chain.with_config(configurable={\"llm\": \"ëª¨ë¸\"})`ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©í•  llmìœ¼ë¡œ ë‹¤ë¥¸ ëª¨ë¸ì„ ì§€ì •\n",
    "\n",
    "```python\n",
    "chain.with_config(configurable={\"llm\": \"openai\"}).invoke({\"topic\": \"ë‰´ì§„ìŠ¤\"}).__dict__\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "- ì²´ì¸ì˜ ì„¤ì •ì„ ë³€ê²½í•˜ì—¬ ì‚¬ìš©í•  ì–¸ì–´ ëª¨ë¸ì„ `gpt4o` ë¡œ ì§€ì •\n",
    "\n",
    "```python\n",
    "chain.with_config(configurable={\"llm\": \"gpt4o\"}).invoke({\"topic\": \"ë‰´ì§„ìŠ¤\"}).__dict__\n",
    "```\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4f304c",
   "metadata": {},
   "source": [
    "### í”„ë¡¬í”„íŠ¸ì˜ ëŒ€ì•ˆ ì„¤ì • ë°©ë²•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89395ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eeb34833",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(\n",
    "    \"{country} ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì•¼?\"  # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
    "    \n",
    ").configurable_alternatives(\n",
    "    # ì´ í•„ë“œì— idë¥¼ ë¶€ì—¬\n",
    "    ConfigurableField(id=\"prompt\"),\n",
    "    \n",
    "    # ê¸°ë³¸ í‚¤ë¥¼ ì„¤ì •\n",
    "    default_key=\"capital\",\n",
    "    \n",
    "    # 'area'ì´ë¼ëŠ” ìƒˆë¡œìš´ ì˜µì…˜ì„ ì¶”ê°€\n",
    "    area=PromptTemplate.from_template(\"{country} ì˜ ë©´ì ì€ ì–¼ë§ˆì•¼?\"),\n",
    "    \n",
    "    # 'population'ì´ë¼ëŠ” ìƒˆë¡œìš´ ì˜µì…˜ì„ ì¶”ê°€\n",
    "    population=PromptTemplate.from_template(\"{country} ì˜ ì¸êµ¬ëŠ” ì–¼ë§ˆì•¼?\"),\n",
    "    \n",
    "    # 'eng'ì´ë¼ëŠ” ìƒˆë¡œìš´ ì˜µì…˜ì„ ì¶”ê°€\n",
    "    eng=PromptTemplate.from_template(\"{input} ì„ ì˜ì–´ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”.\"),\n",
    "    # ì—¬ê¸°ì— ë” ë§ì€ êµ¬ì„± ì˜µì…˜ì„ ì¶”ê°€\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab3b18c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca46cab",
   "metadata": {},
   "source": [
    "- ì•„ë¬´ëŸ° ì„¤ì •ì´ ì—†ë‹¤ë©´ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "305d3f2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸ì´ë‹¤.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 23, 'total_tokens': 39, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-D4eJkg3qlzDtv3iuqcqxxLDEW8kK3', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c1c42-c698-7112-aade-531a504549a2-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 23, 'output_tokens': 16, 'total_tokens': 39, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"country\": \"ëŒ€í•œë¯¼êµ­\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a9511d",
   "metadata": {},
   "source": [
    "- `with_config` ë¡œ ë‹¤ë¥¸ í”„ë¡¬í”„íŠ¸ë¥¼ í˜¸ì¶œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "322a48fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='ëŒ€í•œë¯¼êµ­ì˜ ì´ ë©´ì ì€ ì•½ 100,363kmÂ² ì…ë‹ˆë‹¤.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 25, 'total_tokens': 50, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-D4eJlQmLFfGzPk4wuIneqe9QmEMw0', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c1c42-c85e-7ba3-84e1-c6f98a3270fd-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 25, 'output_tokens': 25, 'total_tokens': 50, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.with_config(configurable={\"prompt\": \"area\"}).invoke({\"country\": \"ëŒ€í•œë¯¼êµ­\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfbc175",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### í”„ë¡¬í”„íŠ¸ & LLM ëª¨ë‘ ë³€ê²½\n",
    "\n",
    "<br>\n",
    "\n",
    "```python\n",
    "# LLM ëŒ€ì•ˆ ì„¤ì •\n",
    "llm = ChatAnthropic(\n",
    "    temperature=0, model=\"claude-3-5-sonnet-20240620\"\n",
    ").configurable_alternatives(\n",
    "    ConfigurableField(id=\"llm\"),\n",
    "    default_key=\"anthropic\",\n",
    "    openai=ChatOpenAI(model=\"gpt-4o-mini\"),\n",
    "    gpt4=ChatOpenAI(model=\"gpt-4o\"),\n",
    ")\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ ëŒ€ì•ˆ ì„¤ì •\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"{company} ì— ëŒ€í•´ì„œ 20ì ì´ë‚´ë¡œ ì„¤ëª…í•´ ì¤˜.\"\n",
    ").configurable_alternatives(\n",
    "    ConfigurableField(id=\"prompt\"),\n",
    "    default_key=\"description\",\n",
    "    founder=PromptTemplate.from_template(\"{company} ì˜ ì°½ë¦½ìëŠ” ëˆ„êµ¬ì¸ê°€ìš”?\"),\n",
    "    competitor=PromptTemplate.from_template(\"{company} ì˜ ê²½ìŸì‚¬ëŠ” ëˆ„êµ¬ì¸ê°€ìš”?\"),\n",
    ")\n",
    "\n",
    "# ë­ì²´ì¸ ì—°ê²°\n",
    "chain = prompt | llm\n",
    "\n",
    "chain.with_config(configurable={\"prompt\": \"founder\", \"llm\": \"openai\"}).invoke(\n",
    "    {\"company\": \"ì• í”Œ\"}\n",
    ").__dict__\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "### ì„¤ì • ì €ì¥\n",
    "- íŠ¹ì • ì‘ì—…ì„ ìœ„í•´ ì‚¬ìš©ì ì •ì˜ëœ ì²´ì¸ì„ êµ¬ì„±í•œ í›„, ì´ë¥¼ ì¬ì‚¬ìš© ê°€ëŠ¥í•œ ê°ì²´ë¡œ ì €ì¥í•¨ìœ¼ë¡œì¨ í–¥í›„ ìœ ì‚¬í•œ ì‘ì—…ì—ì„œ ì†ì‰½ê²Œ í™œìš©\n",
    "\n",
    "<br>\n",
    "\n",
    "```python\n",
    "gpt4_competitor_chain = chain.with_config(\n",
    "    configurable={\"llm\": \"gpt4\", \"prompt\": \"competitor\"}\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f737cbc8",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<br>\n",
    "\n",
    "## `@chain`ë°ì½”ë ˆì´í„°ë¡œ `Runnable` êµ¬ì„±\n",
    "- `@chain` ë°ì½”ë ˆì´í„°ë¥¼ ì¶”ê°€í•˜ì—¬ ì„ì˜ì˜ í•¨ìˆ˜ë¥¼ ì²´ì¸ìœ¼ë¡œ ë³€í™˜\n",
    "  - `RunnableLambda`ë¡œ ë˜í•‘í•˜ëŠ” ê²ƒê³¼ ê¸°ëŠ¥ì ìœ¼ë¡œ ë™ì¼\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9dda6ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import chain\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ea1c94",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- `prompt1` ì€ ì£¼ì–´ì§„ ì£¼ì œì— ëŒ€í•œ ì§§ì€ ì„¤ëª…ì„, `prompt2` ëŠ” ì˜ì–´ë¡œ ë²ˆì—­í•´ ë‹¬ë¼ëŠ” ìš”ì²­ í”„ë¡¬í”„íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "043b83f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = ChatPromptTemplate.from_template(\"{topic} ì— ëŒ€í•´ ì§§ê²Œ í•œê¸€ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.\")\n",
    "prompt2 = ChatPromptTemplate.from_template(\n",
    "    \"{sentence} ë¥¼ emojië¥¼ í™œìš©í•œ ì¸ìŠ¤íƒ€ê·¸ë¨ ê²Œì‹œê¸€ë¡œ ë§Œë“¤ì–´ì£¼ì„¸ìš”.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f406756",
   "metadata": {},
   "source": [
    "- `custom_chain` í•¨ìˆ˜ëŠ” ì…ë ¥ í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ì ì •ì˜ ì²´ì¸ì„ ì‹¤í–‰\n",
    "  - `@chain` ë°ì½”ë ˆì´í„°ë¡œ ì‚¬ìš©ì ì •ì˜ í•¨ìˆ˜ë¥¼ ë°ì½”ë ˆì´íŒ… í•˜ë©°, ë°ì½”ë ˆì´íŒ…ì„ í†µí•´ í•¨ìˆ˜ë¥¼ `Runnable` í•œ ê°ì²´ë¡œ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60b459c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@chain\n",
    "def custom_chain(text):\n",
    "    chain1 = prompt1 | ChatOpenAI(model=\"gpt-4o-mini\") | StrOutputParser()\n",
    "    output1 = chain1.invoke({\"topic\": text})\n",
    "\n",
    "    chain2 = prompt2 | ChatOpenAI(model=\"gpt-4o-mini\") | StrOutputParser()\n",
    "\n",
    "    return chain2.invoke({\"sentence\": output1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac5b780",
   "metadata": {},
   "source": [
    "- `custom_chain`ì€ ì´ì œ ì‹¤í–‰ ê°€ëŠ¥í•œ ê°ì²´(`runnable`)ì´ë¯€ë¡œ, `invoke()` ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ada44543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸŒŒ ì–‘ìì—­í•™ì˜ ë†€ë¼ìš´ ì„¸ê³„! ğŸ§¬âœ¨\n",
      "\n",
      "ì–‘ìì—­í•™ì€ ì›ìì™€ ì…ì ìˆ˜ì¤€ì—ì„œ ìì—°ì˜ ë²•ì¹™ì„ ì„¤ëª…í•˜ëŠ” ë¬¼ë¦¬í•™ì˜ í•œ ë¶„ì•¼ì…ë‹ˆë‹¤. ğŸ”¬ğŸ’¡ ê³ ì „ì  ë¬¼ë¦¬í•™ìœ¼ë¡œëŠ” ë¯¸ì‹œ ì„¸ê³„ì˜ ì‹ ë¹„ë¡œìš´ í˜„ìƒë“¤ì„ ì„¤ëª…í•˜ê¸° ì–´ë ¤ìš´ë°ìš”, ê·¸ê³³ì—ì„œëŠ” ì…ìê°€ ë™ì‹œì— ì—¬ëŸ¬ ìƒíƒœì— ìˆì„ ìˆ˜ ìˆëŠ” 'ì¤‘ì²©'ê³¼ ê´€ì¸¡ì— ë”°ë¼ ìƒíƒœê°€ ê²°ì •ë˜ëŠ” 'ì¸¡ì • ë¬¸ì œ' ê°™ì€ í¥ë¯¸ë¡œìš´ ê°œë…ë“¤ì´ ì¡´ì¬í•´ìš”! ğŸ¤¯ğŸ” \n",
      "\n",
      "ì–‘ìì—­í•™ì€ ì›ì êµ¬ì¡°, í™”í•™ ê²°í•©, ë°˜ë„ì²´, ì´ˆì „ë„ì²´ ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ ì¤‘ìš”í•œ ì—­í• ì„ í•˜ê³  ìˆìŠµë‹ˆë‹¤. ğŸ”—âš›ï¸\n",
      "\n",
      "ì´ ì‹ ë¹„ë¡œìš´ ì„¸ê³„ì— ëŒ€í•´ ë” ì•Œê³  ì‹¶ë‹¤ë©´ â†“ğŸ‘‡ğŸ’¬\n",
      "\n",
      "#ì–‘ìì—­í•™ #ê³¼í•™ #ë¬¼ë¦¬í•™ #ë¯¸ì‹œì„¸ê³„ #ì›ì #í™”í•™ #ë°˜ë„ì²´ #ì´ˆì „ë„ì²´ #ìš°ì£¼ì˜ë¹„ë°€ #physics #science #quantummechanics ğŸŒŒğŸ§ªâœ¨\n"
     ]
    }
   ],
   "source": [
    "print(custom_chain.invoke(\"ì–‘ìì—­í•™\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7645cf21",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<br>\n",
    "\n",
    "## `RunnableWithMessageHistory`\n",
    "\n",
    "<br>\n",
    "\n",
    "### ë©”ì‹œì§€ ê¸°ë¡(ë©”ëª¨ë¦¬) ì¶”ê°€\n",
    "- **ëŒ€í™”í˜• ì• í”Œë¦¬ì¼€ì´ì…˜ ë˜ëŠ” ë³µì¡í•œ ë°ì´í„° ì²˜ë¦¬ ì‘ì—…ì„ êµ¬í˜„í•  ë•Œ ì´ì „ ë©”ì‹œì§€ì˜ ë§¥ë½ì„ ìœ ì§€í•´ì•¼ í•  í•„ìš”ê°€ ìˆì„ ë•Œ ì¤‘ìš”**\n",
    "\n",
    "<br>\n",
    "\n",
    "#### ì‹¤ì œ í™œìš© ì˜ˆì‹œ\n",
    "- ëŒ€í™”í˜• ì±—ë´‡ ê°œë°œ: ì‚¬ìš©ìì™€ì˜ ëŒ€í™” ë‚´ì—­ì„ ê¸°ë°˜ìœ¼ë¡œ ì±—ë´‡ì˜ ì‘ë‹µì„ ì¡°ì •\n",
    "- ë³µì¡í•œ ë°ì´í„° ì²˜ë¦¬: ë°ì´í„° ì²˜ë¦¬ ê³¼ì •ì—ì„œ ì´ì „ ë‹¨ê³„ì˜ ê²°ê³¼ë¥¼ ì°¸ì¡°í•˜ì—¬ ë‹¤ìŒ ë‹¨ê³„ì˜ ë¡œì§ì„ ê²°ì •\n",
    "- ìƒíƒœ ê´€ë¦¬ê°€ í•„ìš”í•œ ì• í”Œë¦¬ì¼€ì´ì…˜: ì‚¬ìš©ìì˜ ì´ì „ ì„ íƒì„ ê¸°ì–µí•˜ê³  ê·¸ì— ë”°ë¼ ë‹¤ìŒ í™”ë©´ì´ë‚˜ ì •ë³´ë¥¼ ì œê³µ\n",
    "\n",
    "<br>\n",
    "\n",
    "- `RunnableWithMessageHistory`ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ìƒíƒœë¥¼ ìœ ì§€í•˜ê³ , ì‚¬ìš©ì ê²½í—˜ì„ í–¥ìƒì‹œí‚¤ë©°, ë” ì •êµí•œ ì‘ë‹µ ë©”ì»¤ë‹ˆì¦˜ì„ êµ¬í˜„í•  ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” ê°•ë ¥í•œ ë„êµ¬\n",
    "\n",
    "<br>\n",
    "\n",
    "### íŠœí† ë¦¬ì–¼\n",
    "\n",
    "<br>\n",
    "\n",
    "- **ë©”ì‹œì§€ ê¸°ë¡ì„ íš¨ê³¼ì ìœ¼ë¡œ ê´€ë¦¬í•˜ë ¤ë©´ ë‹¤ìŒ ë‘ ê°€ì§€ ì£¼ìš” ìš”ì†Œê°€ í•„ìš”**\n",
    "  - **`Runnable`**: ì£¼ë¡œ `Retriever`, `Chain` ê³¼ ê°™ì´ `BaseChatMessageHistory` ì™€ ìƒí˜¸ì‘ìš©í•˜ëŠ” `runnable` ê°ì²´\n",
    "  - **`BaseChatMessageHistory`ì˜ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë°˜í™˜í•˜ëŠ” í˜¸ì¶œ ê°€ëŠ¥í•œ ê°ì²´(callable)**: ë©”ì‹œì§€ ê¸°ë¡ì„ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ê°ì²´. ì´ ê°ì²´ëŠ” ë©”ì‹œì§€ ê¸°ë¡ì„ ì €ì¥, ê²€ìƒ‰, ì—…ë°ì´íŠ¸í•˜ëŠ” ë° ì‚¬ìš©. ë©”ì‹œì§€ ê¸°ë¡ì€ ëŒ€í™”ì˜ ë§¥ë½ì„ ìœ ì§€í•˜ê³ , ì‚¬ìš©ìì˜ ì´ì „ ì…ë ¥ì— ê¸°ë°˜í•œ ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ë° í•„ìš”\n",
    "  \n",
    "<br>\n",
    "\n",
    "#### ë©”ì‹œì§€ ê¸°ë¡\n",
    "- ë©”ì‹œì§€ ê¸°ë¡ì„ êµ¬í˜„í•˜ëŠ” ë°ì—ëŠ” ì—¬ëŸ¬ ë°©ë²•ì´ ì¡´ì¬ (https://docs.langchain.com/oss/python/integrations/providers/overview)\n",
    "- ë©”ì‹œì§€ ê¸°ë¡ì„ ê´€ë¦¬í•˜ëŠ” ë°©ë²•ì„ ì„ íƒí•  ë•ŒëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ìš”êµ¬ì‚¬í•­, ì˜ˆìƒë˜ëŠ” íŠ¸ë˜í”½ ì–‘, ë©”ì‹œì§€ ë°ì´í„°ì˜ ì¤‘ìš”ì„± ë° ë³´ì¡´ ê¸°ê°„ ë“±ì„ ê³ ë ¤\n",
    "- ì¸ë©”ëª¨ë¦¬ ë°©ì‹ì€ êµ¬í˜„ì´ ê°„ë‹¨í•˜ê³  ë¹ ë¥´ì§€ë§Œ, ë°ì´í„°ì˜ ì˜êµ¬ì„±ì´ ìš”êµ¬ë˜ëŠ” ê²½ìš° `Redis`ì™€ ê°™ì€ ì˜êµ¬ì ì¸ ì €ì¥ì†Œë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ë” ì í•©\n",
    "\n",
    "<br>\n",
    "\n",
    "1. **ì¸ë©”ëª¨ë¦¬ `ChatMessageHistory` ì‚¬ìš©**\n",
    "- ì´ ë°©ë²•ì€ ë©”ëª¨ë¦¬ ë‚´ì—ì„œ ë©”ì‹œì§€ ê¸°ë¡ì„ ê´€ë¦¬í•˜ë©°, ì£¼ë¡œ ê°œë°œ ë‹¨ê³„ë‚˜ ê°„ë‹¨í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ì‚¬ìš©\n",
    "- ì¸ë©”ëª¨ë¦¬ ë°©ì‹ì€ ë¹ ë¥¸ ì ‘ê·¼ ì†ë„ë¥¼ ì œê³µí•˜ì§€ë§Œ, ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì¬ì‹œì‘í•  ë•Œ ë©”ì‹œì§€ ê¸°ë¡ì´ ì‚¬ë¼ì§€ëŠ” ë‹¨ì \n",
    "\n",
    "<br>\n",
    "\n",
    "2. `RedisChatMessageHistory`ë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜êµ¬ì ì¸ ì €ì¥ì†Œ í™œìš©\n",
    "- `Redis`ë¥¼ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì€ ë©”ì‹œì§€ ê¸°ë¡ì„ ì˜êµ¬ì ìœ¼ë¡œ ì €ì¥\n",
    "  - `Redis`ëŠ” ë†’ì€ ì„±ëŠ¥ì„ ì œê³µí•˜ëŠ” ì˜¤í”ˆ ì†ŒìŠ¤ ì¸ë©”ëª¨ë¦¬ ë°ì´í„° êµ¬ì¡° ì €ì¥ì†Œë¡œ, ë¶„ì‚° í™˜ê²½ì—ì„œë„ ì•ˆì •ì ìœ¼ë¡œ ë©”ì‹œì§€ ê¸°ë¡ì„ ê´€ë¦¬\n",
    "  - **ì´ ë°©ë²•ì€ ë³µì¡í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ ë˜ëŠ” ì¥ê¸°ê°„ ìš´ì˜ë˜ëŠ” ì„œë¹„ìŠ¤ì— ì í•©**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "afc4e302",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73aae292",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI()\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"ë‹¹ì‹ ì€ {ability} ì— ëŠ¥ìˆ™í•œ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. 20ì ì´ë‚´ë¡œ ì‘ë‹µí•˜ì„¸ìš”\",\n",
    "        ),\n",
    "        \n",
    "        # ëŒ€í™” ê¸°ë¡ì„ ë³€ìˆ˜ë¡œ ì‚¬ìš©, history ê°€ MessageHistory ì˜ key ê°€ ë¨\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{input}\"),  # ì‚¬ìš©ì ì…ë ¥ì„ ë³€ìˆ˜ë¡œ ì‚¬ìš©\n",
    "    ]\n",
    ")\n",
    "runnable = prompt | model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61023a4e",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### íœ˜ë°œì„± ëŒ€í™”ê¸°ë¡: ì¸ë©”ëª¨ë¦¬(In-Memory)\n",
    "\n",
    "* `RunnableWithMessageHistory` ì„¤ì • ë§¤ê°œë³€ìˆ˜\n",
    "  * `runnable`\n",
    "  * `BaseChatMessageHistory` ì´ê±°ë‚˜ ìƒì†ë°›ì€ ê°ì²´. ex) `ChatMessageHistory`\n",
    "  * `input_messages_key`: `chain` ì„ `invoke()` í• ë•Œ ì‚¬ìš©ì ì¿¼ë¦¬ ì…ë ¥ìœ¼ë¡œ ì§€ì •í•˜ëŠ” key\n",
    "  * `history_messages_key`: ëŒ€í™” ê¸°ë¡ìœ¼ë¡œ ì§€ì •í•˜ëŠ” key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "387ad9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad7b2752",
   "metadata": {},
   "outputs": [],
   "source": [
    "store = {}  # ì„¸ì…˜ ê¸°ë¡ì„ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075c7fbe",
   "metadata": {},
   "source": [
    "- ì„¸ì…˜ IDë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì„¸ì…˜ ê¸°ë¡ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "20ff9323",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_session_history(session_ids: str) -> BaseChatMessageHistory:\n",
    "    print(session_ids)\n",
    "    \n",
    "    if session_ids not in store:  # ì„¸ì…˜ IDê°€ storeì— ì—†ëŠ” ê²½ìš°\n",
    "        # ìƒˆë¡œìš´ ChatMessageHistory ê°ì²´ë¥¼ ìƒì„±í•˜ì—¬ storeì— ì €ì¥\n",
    "        store[session_ids] = ChatMessageHistory()\n",
    "    return store[session_ids]  # í•´ë‹¹ ì„¸ì…˜ IDì— ëŒ€í•œ ì„¸ì…˜ ê¸°ë¡ ë°˜í™˜"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60a740c",
   "metadata": {},
   "source": [
    "- `input_messages_key`ëŠ” ìµœì‹  ì…ë ¥ ë©”ì‹œì§€ë¡œ ì²˜ë¦¬ë  í‚¤ë¥¼ ì§€ì •í•˜ê³ , `history_messages_key`ëŠ” ì´ì „ ë©”ì‹œì§€ë¥¼ ì¶”ê°€í•  í‚¤ë¥¼ ì§€ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d91fe327",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = (\n",
    "    RunnableWithMessageHistory(  # RunnableWithMessageHistory ê°ì²´ ìƒì„±\n",
    "        runnable,  # ì‹¤í–‰í•  Runnable ê°ì²´\n",
    "        get_session_history,  # ì„¸ì…˜ ê¸°ë¡ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜\n",
    "        input_messages_key=\"input\",  # ì…ë ¥ ë©”ì‹œì§€ì˜ í‚¤\n",
    "        history_messages_key=\"history\",  # ê¸°ë¡ ë©”ì‹œì§€ì˜ í‚¤\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "63671d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abc123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Trigonometric function representing the ratio of the adjacent side to the hypotenuse of a right triangle.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 47, 'total_tokens': 68, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-D4eJu2mb6kz0gHn7x0qVpb2Pj97em', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c1c42-ee4f-7601-a035-d0ef49d529c2-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 47, 'output_tokens': 21, 'total_tokens': 68, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    {\"ability\": \"math\", \"input\": \"What does cosine mean?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ba213d",
   "metadata": {},
   "source": [
    "- ê°™ì€ `session_id` ë¥¼ ì…ë ¥í•˜ë©´ ì´ì „ ëŒ€í™” ìŠ¤ë ˆë“œì˜ ë‚´ìš©ì„ ê°€ì ¸ì˜¤ê¸° ë•Œë¬¸ì— ì´ì–´ì„œ ëŒ€í™”ê°€ ê°€ëŠ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d28ea762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abc123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='ì§ê°ì‚¼ê°í˜•ì˜ ì¸ì ‘ë³€ê³¼ ë¹—ë³€ì˜ ë¹„ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì‚¼ê°í•¨ìˆ˜ì…ë‹ˆë‹¤.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 39, 'prompt_tokens': 93, 'total_tokens': 132, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-D4eJu2NNbb2HOdEeqb8RtYF1xSglV', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c1c42-f088-7e51-a930-f70708b14438-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 93, 'output_tokens': 39, 'total_tokens': 132, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    {\"ability\": \"math\", \"input\": \"ì´ì „ì˜ ë‚´ìš©ì„ í•œê¸€ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.\"},\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6112ab",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "* í•˜ì§€ë§Œ ë‹¤ë¥¸ `session_id` ë¥¼ ì§€ì •í•˜ë©´ ëŒ€í™”ê¸°ë¡ì´ ì—†ê¸° ë•Œë¬¸ì— ë‹µë³€ì„ ì œëŒ€ë¡œ ìˆ˜í–‰í•˜ì§€ ëª» í•¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9f17a776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def234\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='ìˆ˜í•™ì— ëŠ¥ìˆ™í•œ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 58, 'total_tokens': 77, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-D4eJw3mK8042EFNFSYBBr8Rkn2oFC', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c1c42-f3ae-7f62-958a-5bd5bc2970ad-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 58, 'output_tokens': 19, 'total_tokens': 77, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    {\"ability\": \"math\", \"input\": \"ì´ì „ì˜ ë‚´ìš©ì„ í•œê¸€ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”\"},\n",
    "    config={\"configurable\": {\"session_id\": \"def234\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ae41e6",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- ë©”ì‹œì§€ ê¸°ë¡ì„ ì¶”ì í•˜ëŠ” ë° ì‚¬ìš©ë˜ëŠ” êµ¬ì„± ë§¤ê°œë³€ìˆ˜ëŠ” `ConfigurableFieldSpec` ê°ì²´ì˜ ë¦¬ìŠ¤íŠ¸ë¥¼ `history_factory_config` ë§¤ê°œë³€ìˆ˜ë¡œ ì „ë‹¬í•˜ì—¬ ì‚¬ìš©ì ì •ì˜\n",
    "  \n",
    "  $\\rightarrow$ **`history_factory_config` ë¥¼ ìƒˆë¡œ ì„¤ì •í•˜ê²Œ ë˜ë©´ ê¸°ì¡´ `session_id` ì„¤ì •ì„ ë®ì–´ì”€**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ad0a4492",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import ConfigurableFieldSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1bb8a2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_session_history(user_id: str, conversation_id: str) -> BaseChatMessageHistory:\n",
    "    # ì£¼ì–´ì§„ user_idì™€ conversation_idì— í•´ë‹¹í•˜ëŠ” ì„¸ì…˜ ê¸°ë¡ì„ ë°˜í™˜\n",
    "    \n",
    "    if (user_id, conversation_id) not in store:\n",
    "        # í•´ë‹¹ í‚¤ê°€ storeì— ì—†ìœ¼ë©´ ìƒˆë¡œìš´ ChatMessageHistoryë¥¼ ìƒì„±í•˜ì—¬ ì €ì¥\n",
    "        store[(user_id, conversation_id)] = ChatMessageHistory()\n",
    "        \n",
    "    return store[(user_id, conversation_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "762688e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(\n",
    "    runnable,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\",\n",
    "    history_factory_config=[\n",
    "        ConfigurableFieldSpec(\n",
    "            id=\"user_id\",\n",
    "            annotation=str,\n",
    "            name=\"User ID\",\n",
    "            description=\"ì‚¬ìš©ìì˜ ê³ ìœ  ì‹ë³„ìì…ë‹ˆë‹¤.\",\n",
    "            default=\"\",\n",
    "            is_shared=True,\n",
    "        ),\n",
    "        ConfigurableFieldSpec(\n",
    "            id=\"conversation_id\",\n",
    "            annotation=str,\n",
    "            name=\"Conversation ID\",\n",
    "            description=\"ëŒ€í™”ì˜ ê³ ìœ  ì‹ë³„ìì…ë‹ˆë‹¤.\",\n",
    "            default=\"\",\n",
    "            is_shared=True,\n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "da4d0301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='ì•ˆë…•í•˜ì„¸ìš”. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 43, 'total_tokens': 64, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-D4eJxtAE4LNzSxwhw7RgeITnacLJ4', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c1c42-f984-7be0-85cb-59842ae3e227-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 43, 'output_tokens': 21, 'total_tokens': 64, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    {\"ability\": \"math\", \"input\": \"Hello\"},\n",
    "    config={\"configurable\": {\"user_id\": \"123\", \"conversation_id\": \"1\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d803e0",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### ë‹¤ì–‘í•œ Keyë¥¼ ì‚¬ìš©í•œ `Runnable`ì„ ì‚¬ìš©í•œ ì˜ˆì‹œ\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `Message`ê°ì²´ë¥¼ ì…ë ¥, `dict`í˜•íƒœì˜ ì¶œë ¥\n",
    "- **`input_messages_key=\"input\"` ì„ ìƒëµí•˜ë©´, ì…ë ¥ìœ¼ë¡œ `Message` ê°ì²´ë¥¼ ë„£ë„ë¡ ì„¤ì •ë¨**\n",
    "  - ì…ë ¥ í‚¤ë¥¼ ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´, LangChainì€ **\"ì „ë‹¬ëœ ë°ì´í„° ìì²´ê°€ ê³§ ëŒ€í™” ë‚´ìš©\"** ì´ë¼ê³  ê°„ì£¼\n",
    "  - ë™ì‘: ì‚¬ìš©ìê°€ ë˜ì§„ `[HumanMessage(...)]` ë¦¬ìŠ¤íŠ¸ë¥¼ ê·¸ëŒ€ë¡œ ë°›ì•„ë“¤ì´ê³ , ì—¬ê¸°ì— history ë¦¬ìŠ¤íŠ¸ë¥¼ í•©ì³ì„œ ëª¨ë¸ì—ê²Œ ì „ì†¡\n",
    "- **`input_messages_key=\"input\"`ì´ ìˆì„ ë•Œ**\n",
    "  - ì…ë ¥ í‚¤ë¥¼ ì§€ì •í•˜ë©´, LangChainì€ **\"ì—¬ëŸ¬ ë°ì´í„°ê°€ ë‹´ê¸´ ë°•ìŠ¤(Dict) ì•ˆì—ì„œ íŠ¹ì • ì´ë¦„í‘œ(Key)ê°€ ë¶™ì€ ê²ƒë§Œ ëŒ€í™” ë‚´ìš©ìœ¼ë¡œ ì“°ê² ë‹¤\"** ëŠ” ëœ»\n",
    "  - ë™ì‘: `invoke` ì‹œì ì— `{\"input\": \"ì§ˆë¬¸\"}` ë˜ëŠ” `{\"input\": [HumanMessage(...)]}`ì™€ ê°™ì´ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ì „ë‹¬\n",
    "\n",
    "  \n",
    "- ë©”ì‹œì§€ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ê³  ë”•ì…”ë„ˆë¦¬ë¥¼ ì¶œë ¥ìœ¼ë¡œ ë°˜í™˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "290a44c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.runnables import RunnableParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "43168621",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RunnableParallel({\"output_message\": ChatOpenAI()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "46d53502",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    \n",
    "    # ì„¸ì…˜ IDì— í•´ë‹¹í•˜ëŠ” ëŒ€í™” ê¸°ë¡ì´ ì €ì¥ì†Œì— ì—†ìœ¼ë©´ ìƒˆë¡œìš´ ChatMessageHistoryë¥¼ ìƒì„±\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    \n",
    "    # ì„¸ì…˜ IDì— í•´ë‹¹í•˜ëŠ” ëŒ€í™” ê¸°ë¡ì„ ë°˜í™˜\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3f1cac",
   "metadata": {},
   "source": [
    "- ì²´ì¸ì— ëŒ€í™” ê¸°ë¡ ê¸°ëŠ¥ì„ ì¶”ê°€í•œ `RunnableWithMessageHistory` ê°ì²´ë¥¼ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "617b900f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    # ì…ë ¥ ë©”ì‹œì§€ì˜ í‚¤ë¥¼ \"input\"ìœ¼ë¡œ ì„¤ì •(ìƒëµì‹œ Message ê°ì²´ë¡œ ì…ë ¥)\n",
    "    # input_messages_key=\"input\",\n",
    "    # ì¶œë ¥ ë©”ì‹œì§€ì˜ í‚¤ë¥¼ \"output_message\"ë¡œ ì„¤ì • (ìƒëµì‹œ Message ê°ì²´ë¡œ ì¶œë ¥)\n",
    "    output_messages_key=\"output_message\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "75e2d0bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_message': AIMessage(content='The cosine of an angle in a right triangle is the ratio of the length of the adjacent side to the length of the hypotenuse.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 112, 'total_tokens': 140, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-D4eJy3ysClwLokPJhoKKwnPoG28pP', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c1c42-fc0b-7a61-8b7a-14778d34ddca-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 112, 'output_tokens': 28, 'total_tokens': 140, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"what is the definition of cosine?\")],\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e06457de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_message': AIMessage(content='ì§ê° ì‚¼ê°í˜•ì—ì„œ ê°ì˜ ì½”ì‚¬ì¸ì€ ì¸ì ‘ ë³€ì˜ ê¸¸ì´ë¥¼ ë¹—ë³€ì˜ ê¸¸ì´ë¡œ ë‚˜ëˆˆ ë¹„ìœ¨ì…ë‹ˆë‹¤.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 48, 'prompt_tokens': 165, 'total_tokens': 213, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-D4eJzn6skBfu97DXg0Kcv85JjKx2N', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c1c43-023c-7d22-8a8e-ad4c5c85c496-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 165, 'output_tokens': 48, 'total_tokens': 213, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"ì´ì „ì˜ ë‚´ìš©ì„ í•œê¸€ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”!\")],\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e10be53",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### `Messages` ê°ì²´ë¥¼ ì…ë ¥, `Messages` ê°ì²´ì˜ ì¶œë ¥\n",
    "- **`output_messages_key=\"output_message\"` ì„ ìƒëµí•˜ë©´, ì¶œë ¥ìœ¼ë¡œ `Message` ê°ì²´ë¥¼ ë°˜í™˜**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f6afb462",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(\n",
    "    ChatOpenAI(),\n",
    "    get_session_history,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0d38625a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='ì½”ì‚¬ì¸ì€ ìˆ˜í•™ì ìœ¼ë¡œ ë‘ ì§ì„ ì´ ì´ë£¨ëŠ” ê°ì„ ë‚˜íƒ€ë‚´ëŠ” ì‚¼ê°í•¨ìˆ˜ ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤. ê°ë„ê°€ ì£¼ì–´ì¡Œì„ ë•Œ ì½”ì‚¬ì¸ í•¨ìˆ˜ë¥¼ í†µí•´ ê·¸ ê°ë„ì— ëŒ€í•œ ì¸ì ‘ë³€ê³¼ ë¹—ë³€ì˜ ë¹„ìœ¨ì„ ê³„ì‚°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¦‰, ë‘ ì§ì„ ì´ ì´ë£¨ëŠ” ê°ë„ì— ëŒ€í•œ ì½”ì‚¬ì¸ ê°’ì€ ì¸ì ‘ë³€ì˜ ê¸¸ì´ë¥¼ ë¹—ë³€ì˜ ê¸¸ì´ë¡œ ë‚˜ëˆˆ ê²ƒì…ë‹ˆë‹¤. ì´ëŠ” ì‚¼ê°í˜• ë‚´ì—ì„œ ê°ë„ì™€ ë³€ì˜ ê¸¸ì´ì˜ ê´€ê³„ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì¤‘ìš”í•œ ìš”ì†Œ ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 185, 'prompt_tokens': 24, 'total_tokens': 209, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-D4eK0gTBi1soo6wtZmVt2TCbWyA1t', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c1c43-0520-7d71-8bcd-36c1e0f851b2-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 24, 'output_tokens': 185, 'total_tokens': 209, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"ì½”ì‚¬ì¸ì˜ ì˜ë¯¸ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\")],\n",
    "    config={\"configurable\": {\"session_id\": \"def123\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd61222",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### ëª¨ë“  ë©”ì‹œì§€ ì…ë ¥ê³¼ ì¶œë ¥ì„ ìœ„í•œ ë‹¨ì¼ í‚¤ë¥¼ ê°€ì§„ `Dict`\n",
    "- **ëª¨ë“  ì…ë ¥ ë©”ì‹œì§€ì™€ ì¶œë ¥ ë©”ì‹œì§€ì— ëŒ€í•´ ë‹¨ì¼ í‚¤ë¥¼ ì‚¬ìš©í•˜ëŠ” ë°©ì‹**\n",
    "- `itemgetter(\"input_messages\")`ë¥¼ ì‚¬ìš©í•˜ì—¬ ì…ë ¥ ë©”ì‹œì§€ë¥¼ ì¶”ì¶œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8d82f1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a9422fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(\n",
    "    # \"input_messages\" í‚¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ì…ë ¥ ë©”ì‹œì§€ë¥¼ ê°€ì ¸ì™€ ChatOpenAI()ì— ì „ë‹¬\n",
    "    itemgetter(\"input_messages\") | ChatOpenAI(),\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input_messages\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2858b882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='ì½”ì‚¬ì¸ì€ ì‚¼ê°í•¨ìˆ˜ ì¤‘ í•˜ë‚˜ë¡œ, ì§ê°ì‚¼ê°í˜•ì—ì„œì˜ í•œ ê°ì˜ ì½”ì‚¬ì¸ ê°’ì€ í•´ë‹¹ ê°ì˜ ì¸ì ‘ ë³€ì˜ ê¸¸ì´ë¥¼ ë¹—ë³€ì˜ ê¸¸ì´ë¡œ ë‚˜ëˆˆ ê°’ì´ë‹¤. ë‹¤ì‹œ ë§í•´, ê° Î¸ì˜ ì½”ì‚¬ì¸ ê°’ì€ cos(Î¸) = a/cë¡œ ì •ì˜ë˜ë©°, ì—¬ê¸°ì„œ aëŠ” ê° Î¸ì˜ ì¸ì ‘ ë³€ì˜ ê¸¸ì´ì´ê³  cëŠ” ë¹—ë³€ì˜ ê¸¸ì´ì´ë‹¤. ì´ëŠ” ì§ê° ì‚¼ê°í˜• ë‚´ì—ì„œ ê°ì˜ í¬ê¸°ì™€ ë³€ì˜ ê¸¸ì´ë¥¼ ì—°ê²°ì‹œí‚¤ëŠ” ì¤‘ìš”í•œ ìˆ˜í•™ì  ê°œë…ì´ë‹¤.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 182, 'prompt_tokens': 24, 'total_tokens': 206, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-D4eK2THfZU1Dl3Um3GuyDDqxg0Avt', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c1c43-0c9c-71f1-94da-4e72aa389a88-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 24, 'output_tokens': 182, 'total_tokens': 206, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    {\"input_messages\": \"ì½”ì‚¬ì¸ì˜ ì˜ë¯¸ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"xyz123\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e35423d",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<br>\n",
    "\n",
    "## ì‚¬ìš©ì ì •ì˜ ì œë„ˆë ˆì´í„° (`generator`)\n",
    "\n",
    "- ì œë„ˆë ˆì´í„° í•¨ìˆ˜ (`yield` í‚¤ì›Œë“œë¥¼ ì‚¬ìš©í•˜ê³  ì´í„°ë ˆì´í„°ì²˜ëŸ¼ ë™ì‘í•˜ëŠ” í•¨ìˆ˜)ë¥¼ LCEL íŒŒì´í”„ë¼ì¸ì—ì„œ ì‚¬ìš©\n",
    "  - ì œë„ˆë ˆì´í„°ì˜ ì‹œê·¸ë‹ˆì²˜ëŠ”  `Iterator[Input] -> Iterator[Output]`ì´ì–´ì•¼ í•˜ë©°, ë¹„ë™ê¸° ì œë„ˆë ˆì´í„°ì˜ ê²½ìš°ì—ëŠ” `AsyncIterator[Input] -> AsyncIterator[Output]`\n",
    "- ì œë„ˆë ˆì´í„°ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ìš©ë„ë¡œ ìœ ìš©\n",
    "  - ì‚¬ìš©ì ì •ì˜ ì¶œë ¥ íŒŒì„œ êµ¬í˜„\n",
    "  - ì´ì „ ë‹¨ê³„ì˜ ì¶œë ¥ì„ ìˆ˜ì •í•˜ë©´ì„œ ìŠ¤íŠ¸ë¦¬ë° ê¸°ëŠ¥ ìœ ì§€\n",
    "\n",
    "<br>\n",
    "\n",
    "#### ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ëª©ë¡ì— ëŒ€í•œ ì‚¬ìš©ì ì •ì˜ ì¶œë ¥ íŒŒì„œì˜ˆì‹œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9a9982e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterator, List\n",
    "\n",
    "from langchain_classic.prompts.chat import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f2d8b632",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "    # ì£¼ì–´ì§„ íšŒì‚¬ì™€ ìœ ì‚¬í•œ 5ê°œì˜ íšŒì‚¬ë¥¼ ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ëª©ë¡ìœ¼ë¡œ ì‘ì„±\n",
    "    \"Write a comma-separated list of 5 companies similar to: {company}\"\n",
    ")\n",
    "\n",
    "model = ChatOpenAI(temperature=0.0, model=\"gpt-4-turbo-preview\")\n",
    "str_chain = prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "274cf595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft, Amazon, Apple, Facebook (Meta), Alibaba"
     ]
    }
   ],
   "source": [
    "for chunk in str_chain.stream({\"company\": \"Google\"}):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "613bbdab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Microsoft, Amazon, Apple, Facebook (Meta), Alibaba'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_chain.invoke({\"company\": \"Google\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf7ad31",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- **`split_into_list` í•¨ìˆ˜ëŠ” LLM í† í°ì˜ ì´í„°ë ˆì´í„°ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸ì˜ ì´í„°ë ˆì´í„°ë¥¼ ë°˜í™˜**\n",
    "- ë§ˆì§€ë§‰ ì²­í¬ë¥¼ `yield`í•˜ì—¬ ë°˜í™˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "44e850d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_list(input: Iterator[str]) -> Iterator[List[str]]:\n",
    "    \n",
    "    # ì‰¼í‘œê°€ ë‚˜ì˜¬ ë•Œê¹Œì§€ ë¶€ë¶„ ì…ë ¥ì„ ë³´ê´€\n",
    "    buffer = \"\"\n",
    "    for chunk in input:\n",
    "        # í˜„ì¬ ì²­í¬ë¥¼ ë²„í¼ì— ì¶”ê°€\n",
    "        buffer += chunk\n",
    "        # ë²„í¼ì— ì‰¼í‘œê°€ ìˆëŠ” ë™ì•ˆ ë°˜ë³µ\n",
    "        while \",\" in buffer:\n",
    "            # ë²„í¼ë¥¼ ì‰¼í‘œë¡œ ë¶„í• \n",
    "            comma_index = buffer.index(\",\")\n",
    "            # ì‰¼í‘œ ì´ì „ì˜ ëª¨ë“  ë‚´ìš©ì„ ë°˜í™˜\n",
    "            yield [buffer[:comma_index].strip()]\n",
    "            # ë‚˜ë¨¸ì§€ëŠ” ë‹¤ìŒ ë°˜ë³µì„ ìœ„í•´ ì €ì¥\n",
    "            buffer = buffer[comma_index + 1 :]\n",
    "    # ë§ˆì§€ë§‰ ì²­í¬ë¥¼ ë°˜í™˜\n",
    "    yield [buffer.strip()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb610815",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- `str_chain` ë³€ìˆ˜ì˜ ë¬¸ìì—´ì„ íŒŒì´í”„(`|`) ì—°ì‚°ìë¥¼ ì‚¬ìš©í•˜ì—¬ `split_into_list` í•¨ìˆ˜ì— ì „ë‹¬\n",
    "- `split_into_list` í•¨ìˆ˜ëŠ” ë¬¸ìì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë¶„í• í•˜ëŠ” ì—­í• \n",
    "- ë¶„í• ëœ ë¦¬ìŠ¤íŠ¸ëŠ” `list_chain` ë³€ìˆ˜ì— í• ë‹¹\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8e14c7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_chain = str_chain | split_into_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de625651",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- `list_chain` ê°ì²´ì˜ `stream` ë©”ì„œë“œë¥¼ í˜¸ì¶œí•˜ì—¬ ì…ë ¥ ë°ì´í„°ì— ëŒ€í•œ ì¶œë ¥ì„ ìƒì„±\n",
    "- `stream` ë©”ì„œë“œëŠ” ì¶œë ¥ì„ ì²­í¬(chunk) ë‹¨ìœ„ë¡œ ë°˜í™˜, ê° ì²­í¬ëŠ” ë°˜ë³µë¬¸ì„ í†µí•´ ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "28269294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Microsoft']\n",
      "['Amazon']\n",
      "['Apple']\n",
      "['Facebook (Meta)']\n",
      "['Alibaba']\n"
     ]
    }
   ],
   "source": [
    "for chunk in list_chain.stream({\"company\": \"Google\"}):\n",
    "    print(chunk, flush=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "14ad0a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Microsoft', 'Amazon', 'Apple', 'Facebook (Meta)', 'Alibaba']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_chain.invoke({\"company\": \"Google\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f84c91",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### ë¹„ë™ê¸° (Asynchronous)\n",
    "- `asplit_into_list` í•¨ìˆ˜ëŠ” ë¹„ë™ê¸° ì œë„ˆë ˆì´í„°(`AsyncIterator[str]`)ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸ì˜ ë¹„ë™ê¸° ì œë„ˆë ˆì´í„°(`AsyncIterator[List[str]]`)ë¥¼ ë°˜í™˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "41f24b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import AsyncIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "018180b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def asplit_into_list(input: AsyncIterator[str]) -> AsyncIterator[List[str]]:\n",
    "    \n",
    "    buffer = \"\"\n",
    "    async for chunk in input:\n",
    "        buffer += chunk\n",
    "        while \",\" in buffer:\n",
    "            comma_index = buffer.index(\",\")\n",
    "            yield [\n",
    "                buffer[:comma_index].strip()\n",
    "            ]  # ì‰¼í‘œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë¶„í• í•˜ì—¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜\n",
    "            buffer = buffer[comma_index + 1:]\n",
    "    yield [buffer.strip()]  # ë‚¨ì€ ë²„í¼ ë‚´ìš©ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4bd0c0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "alist_chain = str_chain | asplit_into_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c6a55039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Microsoft']\n",
      "['Amazon']\n",
      "['Apple']\n",
      "['Facebook (Meta)']\n",
      "['Alibaba']\n"
     ]
    }
   ],
   "source": [
    "async for chunk in alist_chain.astream({\"company\": \"Google\"}):\n",
    "    print(chunk, flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1db0edb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Microsoft', 'Amazon', 'Apple', 'Facebook (Meta)', 'Alibaba']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await alist_chain.ainvoke({\"company\": \"Google\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0e6ef5",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Runtime Arguments ë°”ì¸ë”©\n",
    "- **`Runnable` ì‹œí€€ìŠ¤ ë‚´ì—ì„œ `Runnable`ì„ í˜¸ì¶œí•  ë•Œ, ì´ì „ `Runnable`ì˜ ì¶œë ¥ì´ë‚˜ ì‚¬ìš©ì ì…ë ¥ì— í¬í•¨ë˜ì§€ ì•Šì€ ìƒìˆ˜ ì¸ìë¥¼ ì „ë‹¬í•´ì•¼ í•  ê²½ìš°,**\n",
    "  \n",
    "  `Runnable.bind()`ë¥¼ ì‚¬ìš©í•˜ë©´ ì¸ìë¥¼ ì‰½ê²Œ ì „ë‹¬í•  ìˆ˜ ìˆìŒ\n",
    "\n",
    "- `RunnablePassthrough`ë¥¼ ì‚¬ìš©í•˜ì—¬ `{equation_statement}` ë³€ìˆ˜ë¥¼ í”„ë¡¬í”„íŠ¸ì— ì „ë‹¬í•˜ê³ , `StrOutputParser`ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì˜ ì¶œë ¥ì„ ë¬¸ìì—´ë¡œ íŒŒì‹±í•˜ëŠ” `runnable` ê°ì²´ë¥¼ ìƒì„±\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "#### ë°©ì •ì‹ ì˜ˆì œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "39c8411c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ba92c52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Write out the following equation using algebraic symbols then solve it. \"\n",
    "            \"Use the format\\n\\nEQUATION:...\\nSOLUTION:...\\n\\n\",\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"{equation_statement}\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d67b8430",
   "metadata": {},
   "outputs": [],
   "source": [
    "runnable = (\n",
    "    {\"equation_statement\": RunnablePassthrough()} | prompt | model | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e4303bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EQUATION: x^3 + 7 = 12\n",
      "SOLUTION: x^3 = 12 - 7\n",
      "x^3 = 5\n",
      "x = âˆ›5\n"
     ]
    }
   ],
   "source": [
    "print(runnable.invoke(\"x raised to the third plus seven equals 12\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1233343c",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- íŠ¹ì • `stop`ë‹¨ì–´ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ í˜¸ì¶œí•˜ëŠ” ê²½ìš°, `model.bind()`ë¥¼ ì‚¬ìš©í•˜ì—¬ ì–¸ì–´ëª¨ë¸ì„ í˜¸ì¶œí•˜ê³ , ìƒì„±ëœ í…ìŠ¤íŠ¸ì—ì„œ `\"SOLUTION\"` í† í°ê¹Œì§€ë§Œ ì¶œë ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8e59aad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EQUATION: x^3 + 7 = 12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "runnable = (\n",
    "    {\"equation_statement\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model.bind(\n",
    "        stop=\"SOLUTION\"\n",
    "    )\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(runnable.invoke(\"x raised to the third plus seven equals 12\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52433ade",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### `OpenAI Functions` ê¸°ëŠ¥\n",
    "- `binding`ì˜ ìœ ìš©í•œ í™œìš© ë°©ë²• ì¤‘ í•˜ë‚˜ëŠ” í˜¸í™˜ë˜ëŠ” OpenAI ëª¨ë¸ì— OpenAI Functionsë¥¼ ì—°ê²°í•˜ëŠ” ê²ƒ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8071e04",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- OpenAI Functionsë¥¼ ìŠ¤í‚¤ë§ˆì— ë§ê²Œ ì •ì˜í•œ ì½”ë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "de30e653",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_function = {\n",
    "    \"name\": \"solver\",  # í•¨ìˆ˜ì˜ ì´ë¦„\n",
    "    \n",
    "    # í•¨ìˆ˜ì˜ ì„¤ëª…: ë°©ì •ì‹ì„ ìˆ˜ë¦½í•˜ê³  í•´ê²°\n",
    "    \"description\": \"Formulates and solves an equation\",\n",
    "    \n",
    "    \"parameters\": {  # í•¨ìˆ˜ì˜ ë§¤ê°œë³€ìˆ˜\n",
    "        \"type\": \"object\",  # ë§¤ê°œë³€ìˆ˜ì˜ íƒ€ì…: ê°ì²´\n",
    "        \"properties\": {  # ë§¤ê°œë³€ìˆ˜ì˜ ì†ì„±\n",
    "            \"equation\": {  # ë°©ì •ì‹ ì†ì„±\n",
    "                \"type\": \"string\",  # ë°©ì •ì‹ì˜ íƒ€ì…: ë¬¸ìì—´\n",
    "                \"description\": \"The algebraic expression of the equation\",  # ë°©ì •ì‹ì˜ ëŒ€ìˆ˜ì‹ í‘œí˜„\n",
    "            },\n",
    "            \"solution\": {  # í•´ë‹µ ì†ì„±\n",
    "                \"type\": \"string\",  # í•´ë‹µì˜ íƒ€ì…: ë¬¸ìì—´\n",
    "                \"description\": \"The solution to the equation\",  # ë°©ì •ì‹ì˜ í•´ë‹µ\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"equation\", \"solution\"],  # í•„ìˆ˜ ë§¤ê°œë³€ìˆ˜: ë°©ì •ì‹ê³¼ í•´ë‹µ\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1d125c",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- `bind()` ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ `solver`ë¼ëŠ” ì´ë¦„ì˜ í•¨ìˆ˜ í˜¸ì¶œì„ ëª¨ë¸ì— ë°”ì¸ë”©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0e7663e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\\n\"equation\": \"x^3 + 7 = 12\",\\n\"solution\": \"x = âˆ›5\"\\n}', 'name': 'solver'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 95, 'total_tokens': 122, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'id': 'chatcmpl-D4eKEQVWFt1fskyTXwHyH80pVXeU7', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c1c43-3bc6-7bb0-8613-54cd9e52128c-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 95, 'output_tokens': 27, 'total_tokens': 122, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Write out the following equation using algebraic symbols then solve it.\",\n",
    "        ),\n",
    "        (\"human\", \"{equation_statement}\"),\n",
    "    ]\n",
    ")\n",
    "model = ChatOpenAI(model=\"gpt-4\", temperature=0).bind(\n",
    "    function_call={\"name\": \"solver\"},  # openai_function schema ë¥¼ ë°”ì¸ë”©\n",
    "    functions=[openai_function],\n",
    ")\n",
    "\n",
    "runnable = {\"equation_statement\": RunnablePassthrough()} | prompt | model\n",
    "\n",
    "runnable.invoke(\"x raised to the third plus seven equals 12\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4c85cc",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### `OpenAI Tools` ì—°ê²°\n",
    "- OpenAIì—ì„œ ì œê³µí•˜ëŠ” tools(ë„êµ¬) ê°ì²´ëŠ” OpenAIì˜ ë‹¤ì–‘í•œ ê¸°ëŠ¥ì„ ê°„í¸í•˜ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì¤Œ\n",
    "  - ì˜ˆ) `tool.run` ë©”ì„œë“œë¥¼ í˜¸ì¶œí•˜ì—¬ ìì—°ì–´ë¡œ ëœ ì§ˆë¬¸ì„ ì…ë ¥í•˜ë©´, í•´ë‹¹ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "94d9367d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_current_weather\",  # í˜„ì¬ ë‚ ì”¨ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜ì˜ ì´ë¦„\n",
    "            \"description\": \"ì£¼ì–´ì§„ ìœ„ì¹˜ì˜ í˜„ì¬ ë‚ ì”¨ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤\",  # í•¨ìˆ˜ì— ëŒ€í•œ ì„¤ëª…\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"ë„ì‹œì™€ ì£¼, ì˜ˆ: San Francisco, CA\",  # ìœ„ì¹˜ ë§¤ê°œë³€ìˆ˜ì— ëŒ€í•œ ì„¤ëª…\n",
    "                    },\n",
    "                    # ì˜¨ë„ ë‹¨ìœ„ ë§¤ê°œë³€ìˆ˜ (ì„­ì”¨ ë˜ëŠ” í™”ì”¨)\n",
    "                    \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "                },\n",
    "                \"required\": [\"location\"],  # í•„ìˆ˜ ë§¤ê°œë³€ìˆ˜ ì§€ì •\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca63487c",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- `bind()` ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ `tools`ë¥¼ ëª¨ë¸ì— ë°”ì¸ë”©\n",
    "- `invoke()` ë©”ì„œë“œë¥¼ í˜¸ì¶œí•˜ì—¬ \"ìƒŒí”„ë€ì‹œìŠ¤ì½”, ë‰´ìš•, ë¡œìŠ¤ì•¤ì ¤ë ˆìŠ¤ì˜ í˜„ì¬ ë‚ ì”¨ì— ëŒ€í•´ ì•Œë ¤ì¤˜?\"ë¼ëŠ” ì§ˆë¬¸ì„ ëª¨ë¸ì— ì „ë‹¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5c41ce31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 84, 'prompt_tokens': 127, 'total_tokens': 211, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-D4eKFnn9nkT2lB9O46o7yeKhfgwqz', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019c1c43-4142-7193-8b6a-aca3481309ac-0', tool_calls=[{'name': 'get_current_weather', 'args': {'location': 'San Francisco, CA', 'unit': 'celsius'}, 'id': 'call_Et4S2mswHRNkL1pwjap2Zx0b', 'type': 'tool_call'}, {'name': 'get_current_weather', 'args': {'location': 'New York, NY', 'unit': 'celsius'}, 'id': 'call_VGyyNzcxksRdmkkgSXgQmASS', 'type': 'tool_call'}, {'name': 'get_current_weather', 'args': {'location': 'Los Angeles, CA', 'unit': 'celsius'}, 'id': 'call_is7xCB7XmiIwkyArSRobnvXq', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 127, 'output_tokens': 84, 'total_tokens': 211, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\").bind(tools=tools)\n",
    "model.invoke(\"ìƒŒí”„ë€ì‹œìŠ¤ì½”, ë‰´ìš•, ë¡œìŠ¤ì•¤ì ¤ë ˆìŠ¤ì˜ í˜„ì¬ ë‚ ì”¨ì— ëŒ€í•´ ì•Œë ¤ì¤˜?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff07578a",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<br>\n",
    "\n",
    "## í´ë°±(`fallback`) ëª¨ë¸ ì§€ì •\n",
    "- **LLM ì• í”Œë¦¬ì¼€ì´ì…˜ì—ëŠ” LLM API ë¬¸ì œ, ëª¨ë¸ ì¶œë ¥ í’ˆì§ˆ ì €í•˜, ë‹¤ë¥¸ í†µí•© ê´€ë ¨ ì´ìŠˆ ë“± ë‹¤ì–‘í•œ ì˜¤ë¥˜/ì‹¤íŒ¨ê°€ ì¡´ì¬í•˜ë©°, ì´ëŸ¬í•œ ë¬¸ì œë¥¼ ì²˜ë¦¬í•˜ê³  ê²©ë¦¬í•˜ëŠ”ë° `fallback` ê¸°ëŠ¥ì„ í™œìš©**\n",
    "-  `fallback` ì„ LLM ìˆ˜ì¤€ë¿ë§Œ ì•„ë‹ˆë¼ ì „ì²´ ì‹¤í–‰ ê°€ëŠ¥í•œ ìˆ˜ì¤€ì— ì ìš© ê°€ëŠ¥\n",
    "\n",
    "<br>\n",
    "\n",
    "### LLM API Error ì— ëŒ€ì²˜ ë°©ë²•\n",
    "- LLM API ì˜¤ë¥˜ ì²˜ë¦¬ëŠ” `fallback` ì„ ì‚¬ìš©í•˜ëŠ” ê°€ì¥ ì¼ë°˜ì ì¸ ì‚¬ë¡€ ì¤‘ í•˜ë‚˜\n",
    "- LLM API ì— ëŒ€í•œ ìš”ì²­ì€ ë‹¤ì–‘í•œ ì´ìœ ë¡œ ì‹¤íŒ¨í•  ìˆ˜ ìˆìŒ (ì˜ˆ: APIê°€ ë‹¤ìš´, ì†ë„ ì œí•œì— ë„ë‹¬, ê·¸ ì™¸ ì—¬ëŸ¬ ê°€ì§€ ë¬¸ì œê°€ ë°œìƒ)\n",
    "  \n",
    "  $\\rightarrow$  `fallback` ì„ ì‚¬ìš©í•˜ë©´ ì´ëŸ¬í•œ ìœ í˜•ì˜ ë¬¸ì œë¡œë¶€í„° ë³´í˜¸í•˜ëŠ” ë° ë„ì›€\n",
    "\n",
    "- **ì¤‘ìš”**: ê¸°ë³¸ì ìœ¼ë¡œ ë§ì€ LLM ë˜í¼(wrapper)ëŠ” ì˜¤ë¥˜ë¥¼ í¬ì°©í•˜ê³  ì¬ì‹œë„\n",
    "  - `fallback` ì„ ì‚¬ìš©í•  ë•ŒëŠ” ì´ëŸ¬í•œ ê¸°ë³¸ ë™ì‘ì„ í•´ì œ $\\rightarrow$ ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ ì²« ë²ˆì§¸ ë˜í¼ê°€ ê³„ì† ì¬ì‹œë„\n",
    "\n",
    "<br>\n",
    "\n",
    "### `RateLimitError`\n",
    "- **`RateLimitError` ëŠ” OpenAI APIì˜ API í˜¸ì¶œ ë¹„ìš© ì œí•œì„ ì´ˆê³¼í–ˆì„ ë•Œ ë°œìƒí•˜ëŠ” ì˜¤ë¥˜**\n",
    "- ì´ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ë©´ ì¼ì • ì‹œê°„ ë™ì•ˆ API ìš”ì²­ì´ ì œí•œë˜ë¯€ë¡œ, ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œëŠ” ì´ì— ëŒ€í•œ ì ì ˆí•œ ì²˜ë¦¬ê°€ í•„ìš”\n",
    "\n",
    "<br>\n",
    "\n",
    "#### \n",
    "\n",
    "\n",
    "```python\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from unittest.mock import patch\n",
    "\n",
    "import httpx\n",
    "from openai import RateLimitError\n",
    "\n",
    "request = httpx.Request(\"GET\", \"/\")  # GET ìš”ì²­ì„ ìƒì„±\n",
    "response = httpx.Response(\n",
    "    200, request=request\n",
    ")  # 200 ìƒíƒœ ì½”ë“œì™€ í•¨ê»˜ ì‘ë‹µì„ ìƒì„±\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "- `\"rate limit\"` ë©”ì‹œì§€ì™€ ì‘ë‹µ ë° ë¹ˆ ë³¸ë¬¸ì„ í¬í•¨í•˜ëŠ” `RateLimitError`ë¥¼ ìƒì„±\n",
    "\n",
    "```python\n",
    "error = RateLimitError(\"rate limit\", response=response, body=\"\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727ee9b2",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- `openai_llm`ë³€ìˆ˜ì— `ChatOpenAI`ê°ì²´ë¥¼ ìƒì„±í•˜ê³ , `max_retries` ë§¤ê°œë³€ìˆ˜ë¥¼ 0ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ API í˜¸ì¶œë¹„ìš© ì œí•œ ë“±ìœ¼ë¡œ ì¸í•œ ì¬ì‹œë„ë¥¼ ë°©ì§€\n",
    "- `with_fallbacks`ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ `anthropic_llm`ì„ `fallback` LLMìœ¼ë¡œ ì„¤ì •í•˜ê³  ì´ë¥¼ `llm`ë³€ìˆ˜ì— í• ë‹¹\n",
    "\n",
    "```python\n",
    "openai_llm = ChatOpenAI(max_retries=0)\n",
    "\n",
    "# Anthropicì˜ ChatAnthropic ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ anthropic_llm ê°ì²´ë¥¼ ìƒì„±\n",
    "anthropic_llm = ChatAnthropic(model=\"claude-3-opus-20240229\")\n",
    "\n",
    "# openai_llmì„ ê¸°ë³¸ìœ¼ë¡œ ì‚¬ìš©í•˜ê³ , ì‹¤íŒ¨ ì‹œ anthropic_llmì„ ëŒ€ì²´ë¡œ ì‚¬ìš©í•˜ë„ë¡ ì„¤ì •\n",
    "llm = openai_llm.with_fallbacks([anthropic_llm])\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "- OpenAI APIì˜ ë¹„ìš© ì œí•œ(`rate limit`)ì„ ì‹œë®¬ë ˆì´ì…˜í•˜ê³ , API í˜¸ì¶œë¹„ìš© ì œí•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì„ ë•Œì˜ ë™ì‘ì„ í…ŒìŠ¤íŠ¸\n",
    "  \n",
    "  **`with_fallbacks()` ë¡œ ëŒ€ì²´ ëª¨ë¸ì´ ì„¤ì •ë˜ì–´ ìˆê³ , ëŒ€ì²´ ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ ìˆ˜í–‰í–ˆë‹¤ë©´, `RateLimitError` ê°€ ë°œìƒí•˜ì§€ ì•ŠìŒ**\n",
    "  \n",
    "```python\n",
    "with patch(\"openai.resources.chat.completions.Completions.create\", side_effect=error):\n",
    "    try:\n",
    "        print(llm.invoke(\"ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì•¼?\"))\n",
    "    except RateLimitError:\n",
    "        print(\"ì—ëŸ¬ ë°œìƒ\")\n",
    "```\n",
    "\n",
    "```text\n",
    "content='ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸íŠ¹ë³„ì‹œì…ë‹ˆë‹¤. \\n\\nì„œìš¸ì€ í•œë°˜ë„ ì¤‘ì•™ì— ìœ„ì¹˜í•˜ë©°, í•œê°•ì„ ë¼ê³  ìˆëŠ” ëŒ€í•œë¯¼êµ­ ìµœëŒ€ì˜ ë„ì‹œì…ë‹ˆë‹¤. ì„œìš¸ì˜ ì¸êµ¬ëŠ” ì•½ 1000ë§Œ ëª…ìœ¼ë¡œ ì „ì²´ í•œêµ­ ì¸êµ¬ì˜ ì•½ 20%ê°€ ì„œìš¸ì— ê±°ì£¼í•˜ê³  ìˆìŠµë‹ˆë‹¤. \\n\\nì„œìš¸ì€ ì¡°ì„ ì‹œëŒ€ë¶€í„° í•œêµ­ì˜ ìˆ˜ë„ ì—­í• ì„ í•´ì™”ìœ¼ë©°, í˜„ì¬ëŠ” ì •ì¹˜, ê²½ì œ, ì‚¬íšŒ, ë¬¸í™” ë“± ëŒ€í•œë¯¼êµ­ì˜ ì¤‘ì‹¬ì§€ ì—­í• ì„ í•˜ê³  ìˆìŠµë‹ˆë‹¤. ëŒ€í•œë¯¼êµ­ ì •ë¶€ ì£¼ìš” ê¸°ê´€ë“¤ì´ ì„œìš¸ì— ìœ„ì¹˜í•´ ìˆìœ¼ë©°, ë‹¤ì–‘í•œ ê¸°ì—…ì˜ ë³¸ì‚¬ë„ ì„œìš¸ì— ë§ì´ ìë¦¬ì¡ê³  ìˆìŠµë‹ˆë‹¤.\\n\\në˜í•œ ê³ ê¶, ë°•ë¬¼ê´€, í˜„ëŒ€ì  ê±´ì¶•ë¬¼ ë“± ìƒˆë¡œìš´ ê²ƒê³¼ ì „í†µì ì¸ ê²ƒì´ ì¡°í™”ë¥¼ ì´ë£¨ëŠ” ë§¤ë ¥ì ì¸ ë„ì‹œë¡œì„œ, ë§ì€ ê´€ê´‘ê°ì´ ë°©ë¬¸í•˜ëŠ” ê¸€ë¡œë²Œ ë„ì‹œì´ê¸°ë„ í•©ë‹ˆë‹¤.' response_metadata={'id': 'msg_012yS3DPqGNPoAoyVQR2xrWE', 'content': [ContentBlock(text='ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸íŠ¹ë³„ì‹œì…ë‹ˆë‹¤. \\n\\nì„œìš¸ì€ í•œë°˜ë„ ì¤‘ì•™ì— ìœ„ì¹˜í•˜ë©°, í•œê°•ì„ ë¼ê³  ìˆëŠ” ëŒ€í•œë¯¼êµ­ ìµœëŒ€ì˜ ë„ì‹œì…ë‹ˆë‹¤. ì„œìš¸ì˜ ì¸êµ¬ëŠ” ì•½ 1000ë§Œ ëª…ìœ¼ë¡œ ì „ì²´ í•œêµ­ ì¸êµ¬ì˜ ì•½ 20%ê°€ ì„œìš¸ì— ê±°ì£¼í•˜ê³  ìˆìŠµë‹ˆë‹¤. \\n\\nì„œìš¸ì€ ì¡°ì„ ì‹œëŒ€ë¶€í„° í•œêµ­ì˜ ìˆ˜ë„ ì—­í• ì„ í•´ì™”ìœ¼ë©°, í˜„ì¬ëŠ” ì •ì¹˜, ê²½ì œ, ì‚¬íšŒ, ë¬¸í™” ë“± ëŒ€í•œë¯¼êµ­ì˜ ì¤‘ì‹¬ì§€ ì—­í• ì„ í•˜ê³  ìˆìŠµë‹ˆë‹¤. ëŒ€í•œë¯¼êµ­ ì •ë¶€ ì£¼ìš” ê¸°ê´€ë“¤ì´ ì„œìš¸ì— ìœ„ì¹˜í•´ ìˆìœ¼ë©°, ë‹¤ì–‘í•œ ê¸°ì—…ì˜ ë³¸ì‚¬ë„ ì„œìš¸ì— ë§ì´ ìë¦¬ì¡ê³  ìˆìŠµë‹ˆë‹¤.\\n\\në˜í•œ ê³ ê¶, ë°•ë¬¼ê´€, í˜„ëŒ€ì  ê±´ì¶•ë¬¼ ë“± ìƒˆë¡œìš´ ê²ƒê³¼ ì „í†µì ì¸ ê²ƒì´ ì¡°í™”ë¥¼ ì´ë£¨ëŠ” ë§¤ë ¥ì ì¸ ë„ì‹œë¡œì„œ, ë§ì€ ê´€ê´‘ê°ì´ ë°©ë¬¸í•˜ëŠ” ê¸€ë¡œë²Œ ë„ì‹œì´ê¸°ë„ í•©ë‹ˆë‹¤.', type='text')], 'model': 'claude-3-opus-20240229', 'role': 'assistant', 'stop_reason': 'end_turn', 'stop_sequence': None, 'type': 'message', 'usage': Usage(input_tokens=22, output_tokens=339)}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b9ba8d",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- `llm.with_fallbacks()` ì„¤ì •í•œ ëª¨ë¸ë„ ì¼ë°˜ `runnable` ëª¨ë¸ê³¼ ë™ì¼í•˜ê²Œ ë™ì‘í•©ë‹ˆë‹¤.\n",
    "\n",
    "```python\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"ì§ˆë¬¸ì— ì§§ê³  ê°„ê²°í•˜ê²Œ ë‹µë³€í•´ ì£¼ì„¸ìš”.\",  # ì‹œìŠ¤í…œ ì—­í•  ì„¤ëª…\n",
    "        ),\n",
    "        (\"human\", \"{country} ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì…ë‹ˆê¹Œ?\"),  # ì‚¬ìš©ì ì§ˆë¬¸ í…œí”Œë¦¿\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm  # í”„ë¡¬í”„íŠ¸ì™€ ì–¸ì–´ ëª¨ë¸ì„ ì—°ê²°í•˜ì—¬ ì²´ì¸ ìƒì„±\n",
    "\n",
    "# chain = prompt | ChatOpenAI() # ì´ ì½”ë“œì´ ì£¼ì„ì„ í’€ê³  ì‹¤í–‰í•˜ë©´ \"ì˜¤ë¥˜ ë°œìƒ\" ë¬¸êµ¬ê°€ ì¶œë ¥ë©ë‹ˆë‹¤.\n",
    "with patch(\"openai.resources.chat.completions.Completions.create\", side_effect=error):\n",
    "    try:\n",
    "        print(chain.invoke({\"country\": \"ëŒ€í•œë¯¼êµ­\"}))  # ì²´ì¸ì„ í˜¸ì¶œí•˜ì—¬ ê²°ê³¼ ì¶œë ¥\n",
    "    except RateLimitError:  # API ë¹„ìš© ì œí•œ ì˜¤ë¥˜ ì²˜ë¦¬\n",
    "        print(\"ì˜¤ë¥˜ ë°œìƒ\")\n",
    "```\n",
    "\n",
    "```text\n",
    "content='ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸íŠ¹ë³„ì‹œì…ë‹ˆë‹¤.' response_metadata={'id': 'msg_013FiBouyK7dRti21HMLRvwR', 'content': [ContentBlock(text='ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸íŠ¹ë³„ì‹œì…ë‹ˆë‹¤.', type='text')], 'model': 'claude-3-opus-20240229', 'role': 'assistant', 'stop_reason': 'end_turn', 'stop_sequence': None, 'type': 'message', 'usage': Usage(input_tokens=46, output_tokens=23)}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad0a5f7",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### ì²˜ë¦¬í•´ì•¼í•  ì˜¤ë¥˜ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ëª…ì‹œ\n",
    "- íŠ¹ì • ì˜¤ë¥˜ë¥¼ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ `fallback` ì´ í˜¸ì¶œë˜ëŠ” ì‹œì ì„ ë” ëª…í™•í•˜ê²Œ ì§€ì •\n",
    "  - ì˜ˆ) íŠ¹ì • ì˜ˆì™¸ í´ë˜ìŠ¤ë‚˜ ì˜¤ë¥˜ ì½”ë“œë¥¼ ì§€ì •í•¨ìœ¼ë¡œì¨ í•´ë‹¹ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì„ ë•Œë§Œ `fallback` ë¡œì§ì´ ì‹¤í–‰ë˜ë„ë¡ ì„¤ì •\n",
    "    \n",
    "    $\\rightarrow$ ì´ë ‡ê²Œ í•˜ë©´ ë¶ˆí•„ìš”í•œ `fallback` í˜¸ì¶œì„ ì¤„ì´ê³ , ì˜¤ë¥˜ ì²˜ë¦¬ì˜ íš¨ìœ¨ì„±ì„ ë†’ì¼ ìˆ˜ ìˆìŒ\n",
    "\n",
    "<br>\n",
    "\n",
    "- ì˜ˆ) `exceptions_to_handle` íŒŒë¼ë¯¸í„°ì—ì„œ `KeyboardInterrupt` ì˜ˆì™¸ê°€ ë°œìƒì‹œì—ë§Œ `fallback` ì´ êµ¬ë™ë˜ë„ë¡ ì„¤ì •\n",
    "  \n",
    "  $\\rightarrow$ ë”°ë¼ì„œ, `KeyboardInterrupt` ë¥¼ ì œì™¸í•œ ëª¨ë“  ì˜ˆì™¸ì—ì„œëŠ” `fallback` ì´ ë°œìƒí•˜ì§€ ì•ŠìŒ\n",
    "\n",
    "\n",
    "```python\n",
    "llm = openai_llm.with_fallbacks(\n",
    "    # ëŒ€ì²´ LLMìœ¼ë¡œ anthropic_llmì„ ì‚¬ìš©í•˜ê³ , ì˜ˆì™¸ ì²˜ë¦¬í•  ëŒ€ìƒìœ¼ë¡œ KeyboardInterruptë¥¼ ì§€ì •\n",
    "    [anthropic_llm],\n",
    "    exceptions_to_handle=(KeyboardInterrupt,),  # ì˜ˆì™¸ ì²˜ë¦¬ ëŒ€ìƒì„ ì§€ì •\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "with patch(\"openai.resources.chat.completions.Completions.create\", side_effect=error):\n",
    "    try:\n",
    "        print(chain.invoke({\"country\": \"ëŒ€í•œë¯¼êµ­\"}))\n",
    "    except RateLimitError:\n",
    "        print(\"ì˜¤ë¥˜ ë°œìƒ\")\n",
    "```\n",
    "\n",
    "```text\n",
    "content='ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸íŠ¹ë³„ì‹œì…ë‹ˆë‹¤.' response_metadata={'id': 'msg_01UbBNaKkSPecHATCKVwyMHQ', 'content': [ContentBlock(text='ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸íŠ¹ë³„ì‹œì…ë‹ˆë‹¤.', type='text')], 'model': 'claude-3-opus-20240229', 'role': 'assistant', 'stop_reason': 'end_turn', 'stop_sequence': None, 'type': 'message', 'usage': Usage(input_tokens=46, output_tokens=23)}\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `fallback`ì— ì—¬ëŸ¬ ëª¨ë¸ì„ ìˆœì°¨ì ìœ¼ë¡œ ì§€ì •\n",
    "```python\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ ìƒì„±\n",
    "prompt_template = (\n",
    "    \"ì§ˆë¬¸ì— ì§§ê³  ê°„ê²°í•˜ê²Œ ë‹µë³€í•´ ì£¼ì„¸ìš”.\\n\\nQuestion:\\n{question}\\n\\nAnswer:\"\n",
    ")\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "- ì˜¤ë¥˜ë¥¼ ë°œìƒì‹œí‚¤ëŠ” `chain`ê³¼, ì •ìƒì ì¸ `chain` 2ê°€ì§€ë¥¼ ìƒì„±\n",
    "\n",
    "```python\n",
    "chat_model = ChatOpenAI(model_name=\"gpt-fake\")\n",
    "bad_chain = prompt | chat_model\n",
    "```\n",
    "\n",
    "- `fallback` ì²´ì¸\n",
    "\n",
    "```python\n",
    "fallback_chain1 = prompt | ChatOpenAI(model=\"gpt-3.6-turbo\") # ì˜¤ë¥˜\n",
    "fallback_chain2 = prompt | ChatOpenAI(model=\"gpt-3.5-turbo\") # ì •ìƒ\n",
    "fallback_chain3 = prompt | ChatOpenAI(model=\"gpt-4-turbo-preview\") # ì •ìƒ\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "- ë‘ ê°œì˜ ì²´ì¸ì„ ê²°í•©í•˜ì—¬ ìµœì¢… ì²´ì¸ì„ ìƒì„±\n",
    "\n",
    "```python\n",
    "chain = bad_chain.with_fallbacks(\n",
    "    [fallback_chain1, fallback_chain2, fallback_chain3])\n",
    "\n",
    "chain.invoke({\"question\": \"ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì•¼?\"})\n",
    "```\n",
    "\n",
    "```text\n",
    "AIMessage(content='ì„œìš¸ì…ë‹ˆë‹¤.', response_metadata={'token_usage': {'completion_tokens': 5, 'prompt_tokens': 46, 'total_tokens': 51}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_b28b39ffa8', 'finish_reason': 'stop', 'logprobs': None})\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

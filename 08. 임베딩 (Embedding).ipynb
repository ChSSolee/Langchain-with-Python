{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e69e973a",
   "metadata": {},
   "source": [
    "# 임베딩(Embedding)\n",
    "- **임베딩은 Retrieval-Augmented Generation(RAG) 시스템의 세 번째 단계로, 문서분할 단계에서 생성된 문서 단위들을 기계가 이해할 수 있는 수치적 형태로 변환하는 과정**\n",
    "- **문서의 의미를 벡터(숫자의 배열) 형태로 표현함으로써, 사용자가 입력한 질문(Query) 에 대하여 DB 에 저장한 문서 조각/단락(Chunk) 을 검색하여 가져올 때 유사도 계산시 활용**\n",
    "\n",
    "<br>\n",
    "\n",
    "### 임베딩의 필요성\n",
    "- **의미 이해**: 자연어는 매우 복잡하고 다양한 의미를 내포. **임베딩을 통해 이러한 텍스트를 정량화된 형태로 변환함으로써, 컴퓨터가 문서의 내용과 의미를 더 잘 이해하고 처리**\n",
    "- **정보 검색 향상**: 수치화된 벡터 형태로의 변환은 문서 간의 유사성을 계산하는 데 있어 필수적. 이는 관련 문서를 검색하거나, 질문에 가장 적합한 문서를 찾는 작업을 용이\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src='https://wikidocs.net/images/page/233777/capture-20240612-004924.png' width=600>\n",
    "\n",
    "<br>\n",
    "\n",
    "### 임베딩된 단락 활용 예시\n",
    "\n",
    "<img src='https://wikidocs.net/images/page/233777/capture-20240612-005049.png' width=600>\n",
    "\n",
    "- 1번 단락: [0.1, 0.5, 0.9, ... , 0.1, 0.2]\n",
    "- 2번 단락: [0.7, 0.1, 0.3, ... , 0.5, 0.6]\n",
    "- 3번 단락: [0.9, 0.4, 0.5, ... , 0.4, 0.3]\n",
    "\n",
    "<br>\n",
    "\n",
    "> **질문: \"시장조사기관 IDC 가 예측한 AI 소프트웨어 시장의 연평균 성장률은 어떻게 되나요?\"**\n",
    "\n",
    "<br>\n",
    "\n",
    "- **유사도 계산**\n",
    "  - **1번: 80% -> 선택!**\n",
    "  - 2번: 30%\n",
    "  - 3번: 25%\n",
    "\n",
    "<br>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<br>\n",
    "\n",
    "## `OpenAIEmbeddings`\n",
    "- 문서 임베딩은 문서의 내용을 수치적인 벡터로 변환하는 과정. 이 과정을 통해 문서의 의미를 수치화하고, 다양한 자연어 처리 작업에 활용\n",
    "- 대표적인 사전 학습된 언어 모델로는 BERT와 GPT가 있으며, 이러한 모델들은 문맥적 정보를 포착하여 문서의 의미를 인코딩\n",
    "- 문서 임베딩은 토큰화된 문서를 모델에 입력하여 임베딩 벡터를 생성하고, 이를 평균하여 전체 문서의 벡터를 생성. 이 벡터는 문서 분류, 감성 분석, 문서 간 유사도 계산 등에 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4eabd76a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1891b960",
   "metadata": {},
   "source": [
    "- 지원되는 모델 목록\n",
    "  - https://platform.openai.com/docs/guides/embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78aca92",
   "metadata": {},
   "source": [
    "<table><thead><tr><th>Model</th><th>~ Pages per dollar</th><th>Performance on <a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/embeddings-benchmark/mteb\" class=\"kZ98Q\" data-underline=\"\">MTEB</a> eval</th><th>Max input</th></tr></thead><tbody><tr><td>text-embedding-3-small</td><td>62,500</td><td>62.3%</td><td>8192</td></tr><tr><td>text-embedding-3-large</td><td>9,615</td><td>64.6%</td><td>8192</td></tr><tr><td>text-embedding-ada-002</td><td>12,500</td><td>61.0%</td><td>8192</td></tr></tbody></table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75bfbd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3006e308",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "text = \"임베딩 테스트를 하기 위한 샘플 문장입니다.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f4359f",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 쿼리 임베딩\n",
    "- 텍스트를 벡터 공간에 매핑하여 의미적으로 유사한 텍스트를 찾거나 텍스트 간의 유사도를 계산하는 데 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78318e3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.007761634886264801,\n",
       " 0.03675474599003792,\n",
       " 0.019477618858218193,\n",
       " -0.019760848954319954,\n",
       " 0.017146404832601547]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_result = embeddings.embed_query(text)\n",
    "\n",
    "query_result[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa79729",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Document 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff76ed78",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_result = embeddings.embed_documents(\n",
    "    [text]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8731a452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.007778503466397524,\n",
       " 0.03677903115749359,\n",
       " 0.019533412531018257,\n",
       " -0.019729509949684143,\n",
       " 0.017180250957608223]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_result[0][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25e3d2e",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 차원 지정\n",
    "- `text-embedding-3` 모델 클래스를 사용하면 반환되는 임베딩의 크기를 지정 가능\n",
    "  - 기본적으로 `text-embedding-3-small`는 1536 차원의 임베딩을 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d16cc744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc_result[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec10fe5",
   "metadata": {},
   "source": [
    "- 임베딩의 크기를 1024로 축소\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4bf3e29c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_1024 = OpenAIEmbeddings(model=\"text-embedding-3-small\", dimensions=1024)\n",
    "\n",
    "len(embeddings_1024.embed_documents([text])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e992c1",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 유사도 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e05e4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2521fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = \"안녕하세요? 반갑습니다.\"\n",
    "sentence2 = \"안녕하세요? 반갑습니다!\"\n",
    "sentence3 = \"안녕하세요? 만나서 반가워요.\"\n",
    "sentence4 = \"Hi, nice to meet you.\"\n",
    "sentence5 = \"I like to eat apples.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d0f12a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [sentence1, sentence2, sentence3, sentence4, sentence5]\n",
    "embedded_sentences = embeddings_1024.embed_documents(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39c3afac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(a, b):\n",
    "    return cosine_similarity([a], [b])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "107b54c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[유사도 0.9644] 안녕하세요? 반갑습니다. \t <=====> \t 안녕하세요? 반갑습니다!\n",
      "[유사도 0.8376] 안녕하세요? 반갑습니다. \t <=====> \t 안녕하세요? 만나서 반가워요.\n",
      "[유사도 0.5042] 안녕하세요? 반갑습니다. \t <=====> \t Hi, nice to meet you.\n",
      "[유사도 0.1362] 안녕하세요? 반갑습니다. \t <=====> \t I like to eat apples.\n",
      "[유사도 0.8144] 안녕하세요? 반갑습니다! \t <=====> \t 안녕하세요? 만나서 반가워요.\n",
      "[유사도 0.4792] 안녕하세요? 반갑습니다! \t <=====> \t Hi, nice to meet you.\n",
      "[유사도 0.1318] 안녕하세요? 반갑습니다! \t <=====> \t I like to eat apples.\n",
      "[유사도 0.5128] 안녕하세요? 만나서 반가워요. \t <=====> \t Hi, nice to meet you.\n",
      "[유사도 0.1409] 안녕하세요? 만나서 반가워요. \t <=====> \t I like to eat apples.\n",
      "[유사도 0.2249] Hi, nice to meet you. \t <=====> \t I like to eat apples.\n"
     ]
    }
   ],
   "source": [
    "for i, sentence in enumerate(embedded_sentences):\n",
    "    for j, other_sentence in enumerate(embedded_sentences):\n",
    "        if i < j:\n",
    "            print(\n",
    "                f\"[유사도 {similarity(sentence, other_sentence):.4f}] {sentences[i]} \\t <=====> \\t {sentences[j]}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ff6561",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<br>\n",
    "\n",
    "### 캐시 임베딩(`CacheBackedEmbeddings`)\n",
    "- Embeddings는 재계산을 피하기 위해 저장되거나 일시적으로 캐시될 수 있음\n",
    "- 캐시 지원 embedder는 embeddings를 키-값 저장소에 캐싱하는 embedder 주변에 래퍼. 텍스트는 해시되고 이 해시는 캐시에서 키로 사용\n",
    "\n",
    "<br>\n",
    "\n",
    "- `CacheBackedEmbeddings`를 초기화하는 주요 지원 방법은 `from_bytes_store`\n",
    "  - `underlying_embeddings`: 임베딩을 위해 사용되는 embedder\n",
    "  - `document_embedding_cache`: 문서 임베딩을 캐싱하기 위한 ByteStore 중 하나\n",
    "  - `namespace`: (선택 사항, 기본값은 \"\") 문서 캐시를 위해 사용되는 네임스페이스. 이 네임스페이스는 다른 캐시와의 충돌을 피하기 위해 사용\n",
    "    - 예) 사용된 임베딩 모델의 이름으로 설정\n",
    "- **동일한 텍스트가 다른 임베딩 모델을 사용하여 임베딩될 때 충돌을 피하기 위해 namespace 매개변수를 설정하는 것이 중요**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e922f4b5",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### `LocalFileStore` 에서 임베딩 사용 (영구 보관)\n",
    "- 로컬 파일 시스템을 사용하여 임베딩을 저장하고 FAISS 벡터 스토어를 사용하여 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4ef6a52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.embeddings import CacheBackedEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0cdd083d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sha256_encoder(data) -> str:\n",
    "    if isinstance(data, str):\n",
    "        data = data.encode(\"utf-8\")\n",
    "    return hashlib.sha256(data).hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8322d86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = OpenAIEmbeddings()\n",
    "store = LocalFileStore(\"./cache/\")\n",
    "\n",
    "cached_embedder = CacheBackedEmbeddings.from_bytes_store(\n",
    "    underlying_embeddings=embedding,\n",
    "    document_embedding_cache=store,\n",
    "    # namespace=embedding.model,\n",
    "    key_encoder=sha256_encoder,   # ★ SHA-256 적용\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "751fe8b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['llm_cache.db', 'sqlite.db']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(store.yield_keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3240f9",
   "metadata": {},
   "source": [
    "- 문서를 로드하고, 청크로 분할한 다음, 각 청크를 임베딩하고 벡터 저장소에 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a502a919",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b5cac708",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_documents = TextLoader(\"./data/appendix-keywords.txt\").load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "\n",
    "documents = text_splitter.split_documents(raw_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4624a1",
   "metadata": {},
   "source": [
    "- 문서로부터 FAISS 데이터베이스 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3df7a684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 62.5 ms\n",
      "Wall time: 1.79 s\n"
     ]
    }
   ],
   "source": [
    "%time db = FAISS.from_documents(documents, cached_embedder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5f2135",
   "metadata": {},
   "source": [
    "- 캐싱된 임베딩을 사용하여 FAISS 데이터베이스 생성 $\\rightarrow$ **임베딩을 다시 계산할 필요가 없기 때문에 훨씬 더 빠르게 처리**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "de60f60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.6 ms\n",
      "Wall time: 12 ms\n"
     ]
    }
   ],
   "source": [
    "%time db2 = FAISS.from_documents(documents, cached_embedder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32148a4e",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang_env",
   "language": "python",
   "name": "lang_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
